[
  {
    "objectID": "lab-quiz/lab-quiz-01.html",
    "href": "lab-quiz/lab-quiz-01.html",
    "title": "Lab Quiz 01 Info",
    "section": "",
    "text": "Our first lab quiz is scheduled for Friday of Week 3. The first half of class will cover new content, and the second half of class you will complete the in-person portion of the lab quiz."
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#r-basics",
    "href": "lab-quiz/lab-quiz-01.html#r-basics",
    "title": "Lab Quiz 01 Info",
    "section": "R Basics",
    "text": "R Basics\n\nGiven a vector, list, or data frame, extract an element of interest.\n\nKnow how to use each extractor (x$__, x[__], x[[__]]) and what they return\nConstruct logical vectors to use as an index to subset a vector or data frame\nConstruct integer vectors to use as an index to subset a vector or data frame\n\n\nGiven a vector, list, or data frame, obtain a quick summary such as the length, dimension, or type of each element\n\nFunctions to know: length(), nrow(), ncol(), dim(), summary(), glimpse(), class(), typeof(), head(), tail()."
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#data-visualization",
    "href": "lab-quiz/lab-quiz-01.html#data-visualization",
    "title": "Lab Quiz 01 Info",
    "section": "Data Visualization",
    "text": "Data Visualization\n\nIdentify the appropriate layer to add to a static graphic in order to display specific information\n\nYou should know the geom (and associated aesthetics) for the following charts: bar/column chart, histograms, boxplots, density plots, violin plots, scatterplots, time series line plots, map, chloropleth map\n\n\nGiven a graphical summary and data set, recreate the graphic\n\nbase layers\naxis labels, titles, captions\n\nscale_x functions for aesthetics\n\nfacet_wrap() and facet_grid()\n\n\n\nGiven a question of interest and data set, construct an appropriate graphic to address/answer the question\n\nYou should know when the graphs mentioned above are appropriate\n\n\nGiven a graphic, describe the strengths and weaknesses of it from a design perspective\n\nCore principles:\nAccessibility considerations: color, alt text, …."
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#data-wrangling",
    "href": "lab-quiz/lab-quiz-01.html#data-wrangling",
    "title": "Lab Quiz 01 Info",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nKnow how the following verbs act on a data set: filter, distinct, slice, slice_min, slice_max, mutate, select, arrange\n\nSyntax for using\nDescribe what the output would look like\n\n\nGiven a data set and goal, identify and utilize the appropriate verb to create the data set of interest"
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#resubmission",
    "href": "lab-quiz/lab-quiz-01.html#resubmission",
    "title": "Lab Quiz 01 Info",
    "section": "Resubmission",
    "text": "Resubmission\nYou may resubmit the lab quiz by 11am on Sunday (48 hours). All questions and grading will remain the same, except I will look at your output file instead of your .rmd when grading."
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#rules",
    "href": "lab-quiz/lab-quiz-01.html#rules",
    "title": "Lab Quiz 01 Info",
    "section": "Rules",
    "text": "Rules\n\nYour solutions must be written up in the R Markdown (Rmd) file called lab-quiz-01.Rmd. This file must include your code and write up for each task. Your “submission” will be whatever is in your exam repository at the deadline. Commit and push the Rmd and outputs of that file.\nThis exam is closed notes, closed internet, closed other people.\n\nYou have until 10:45am to complete this exam and turn it in via gradescope and your personal Github repo - late work will not be accepted. Technical difficulties are not an excuse for late work - do not wait until the last minute to knit / commit / push.\n\nIf you do have technical issues, you will be able to solve them for the resubmission, but if you do not turn in the in-class portion you will not receive any points\n\nExample: I run into a knitting issue and don’t leave myself time to commit to github and submit to gradescope, so I’m not able to turn anything in for the in-class portion. I work hard over the weekend to make sure everything is correct for the resubmission. I earn 0/10 on the in-class and 10/10 on the resubmission, so my score for the lab quiz is 10/20.\nExample: I run into a knitting issue 2 minutes before the deadline, but make sure to commit my .rmd and submit to gradescope before trying to solve the issue. I fix the knitting issue over over the weekend, and also find an error in one of my problems I submitted. I earn 8/10 on the in-class (1 unsuccessful problem + no output file) and 10/10 on the resubmission, so my score for the lab quiz is 18/20.\n\n\n\n\nEven if the answer seems obvious from the R output, make sure to state it in your narrative as well. For example, if the question is asking what is 2 + 2, and you have the code in your document, you should additionally have a sentence that states “2 + 2 is 4.”\nYou may only use tidyverse and nycflights13 (and its dependencies) for this assignment. Your solutions may not use any other R packages."
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#data",
    "href": "lab-quiz/lab-quiz-01.html#data",
    "title": "Lab Quiz 01 Info",
    "section": "Data",
    "text": "Data\nThe nycflights23 package contains information about all flights that departed from NYC (e.g. EWR, JFK and LGA) in 2023. The main data is in the flights data frame, but there are additional data sets which may help understand what causes delays, specifically:\n\n\nweather: hourly meteorological data for each airport\n\nplanes: construction information about each plane\n\nairports: airport names and locations\n\nairlines: translation between two letter carrier codes and names\n\nFor this lab quiz, we’re going to work with a random sample of this data (called `flights_sampl)\n\nlibrary(tidyverse)\nlibrary(nycflights23)\nq &lt;- 0"
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#questions",
    "href": "lab-quiz/lab-quiz-01.html#questions",
    "title": "Lab Quiz 01 Info",
    "section": "Questions",
    "text": "Questions\nQuestion 1\nWrite out two different ways to access the dep_delay variable in the flights dataset. Save each to an object called dep_delay1 and dep_delay2.\nQuestion 2\nThe code below creates a new dataset called delayed_flights, which consists of all flights that had a departure delay of more than 5 minutes. Show me a second way to create this dataset. (One option is to create a logical vector, and then index the flights data using that vector)\n\ndelayed_flights = flights %&gt;%\n  filter(dep_delay &gt; 5)\n\nQuestion 3\nIs there a relationship between departure delay (among flights that departed at least 5 minutes late) and which NYC airport the flight departed from? Create an appropriate visualization to answer this question. (use the delayed_flights dataset)\nQuestion 4\nRecreate the plot included below using the flights data. Once you have created the visualization, in no more than one paragraph, describe what you think the point of this visualization might be.\n\n\nWarning: Removed 12534 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nQuestion 5\nIs this a chloropleth map? Explain how you can tell.\n\nQuestion 6\nIn the map above, what is the geom(s) used? What about the aesthetics?"
  },
  {
    "objectID": "carleton-only-syllabus.html",
    "href": "carleton-only-syllabus.html",
    "title": "Stat 220: Introduction to Data Science",
    "section": "",
    "text": "Meetings\nMWF 3a\n9:50-11 MW | 9:40-10:40 F\nCMC 102\n\n\nProfessor\nAmanda Luby\nCMC 223\n\n\n\naluby@carleton.edu\n\n\n\nOffice Hours\nMon 11-12 | Tues 2-3 | Wed 4-5 | Fri 11-12 (appt)\nBy appt through my Google Calendar\nCMC 307\n\n\nWebsite\ngithub.com/stat220-w25\n\n\n\nTexts\nR for Data Science (2nd Ed)\nhttps://r4ds.hadley.nz/\nWickham, Çetinkaya-Rundel, Grolemund\n\n\n\n\nModern Data Science with R (3rd Ed)\nhttps://mdsr-book.github.io/mdsr3e/\nBaumer, Kaplan, Horton\n\n\n\n\nFundamentals of Data Visualization\nhttps://clauswilke.com/dataviz/\nWilke\n\n\n\nSoftware\nMaize RStudio Server maize.mathcs.carleton.edu\n\n\n\n\nR (optional) free from r-project.org\n\n\n\n\nRStudio (optional) free from rstudio.com/downloads"
  },
  {
    "objectID": "carleton-only-syllabus.html#meetings",
    "href": "carleton-only-syllabus.html#meetings",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Meetings",
    "text": "Meetings\nThere will be three course meetings per week (Mondays, Wednesdays, and Fridays). Daily attendance and active participation is expected. Course meetings will combine demonstrations/lecture and in-class group exercises. On most days, I’ll ask you to complete a reading or watch a short video before class."
  },
  {
    "objectID": "carleton-only-syllabus.html#assignments",
    "href": "carleton-only-syllabus.html#assignments",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Assignments",
    "text": "Assignments\nHomework will be assigned once-ish per week, distributed via GitHub. You will submit homework assignments via gradescope. You will use quarto for all assignments and submit all necessary work for each assignment on GitHub."
  },
  {
    "objectID": "carleton-only-syllabus.html#portfolio-projects",
    "href": "carleton-only-syllabus.html#portfolio-projects",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Portfolio Projects",
    "text": "Portfolio Projects\nPortfolio project require you to integrate several smaller computational tasks and require clear communication of the proposed solution or findings to a broader audience. You will typically work in pairs or triples."
  },
  {
    "objectID": "carleton-only-syllabus.html#lab-quizzes",
    "href": "carleton-only-syllabus.html#lab-quizzes",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Lab Quizzes",
    "text": "Lab Quizzes\nPart of being proficient in data science is being able to do basic data analysis “on the fly”, without access to class resources. There will be 3 short (~30 minute) in-class lab quizzes to assess your ability to do basic tasks in R. I recognize that “in the real world”, you will almost always have access to your resources, so you will also have 48 hours to re-submit."
  },
  {
    "objectID": "carleton-only-syllabus.html#final-project",
    "href": "carleton-only-syllabus.html#final-project",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Final Project",
    "text": "Final Project\nThe final project is a capstone experience synthesizing everything you’ve learned over the course of the term. This is an opportunity for you to exercise your creativity and create something meaningful. The final project is wildly open-ended and more details will follow."
  },
  {
    "objectID": "carleton-only-syllabus.html#communication",
    "href": "carleton-only-syllabus.html#communication",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Communication",
    "text": "Communication\nAssignments and slides will be shared publicly on our course website. Grades will be posted on Moodle. Please use our github discussion page for any homework or course content questions; email me privately with any personal matters (grade discussions, illness, emergency, etc.). Any time-sensitive announcements will be sent via email. It is your responsibility to make sure that your notification settings allow time-sensitive announcements to reach you."
  },
  {
    "objectID": "carleton-only-syllabus.html#how-each-assignment-is-graded",
    "href": "carleton-only-syllabus.html#how-each-assignment-is-graded",
    "title": "Stat 220: Introduction to Data Science",
    "section": "How each assignment is graded",
    "text": "How each assignment is graded\nEach assignment will include a short rubric with the specifications of how I will evaluate your work. In general, these are the “marks” that you can receive on each course component:\n\n\n\n\n\n\n\n\n\nHow it’s evaluated\nHow it’s recorded\n\n\n\n\nHomework Problems\nCompleteness, Correctness, and Effort\nSuccessful or Not Successful\n\n\nLab Quiz Problems\nCompleteness and Correctness\nSuccessful or Not Successful\n\n\nPortfolio Projects\nCompleteness, effort, correctness, and communication quality\nExcellent, Successful, or Retry\n\n\nFinal Project\nCompleteness, effort, correctness, and communication quality\nExcellent, Succesful, or Not Successful"
  },
  {
    "objectID": "carleton-only-syllabus.html#earning-a-course-grade",
    "href": "carleton-only-syllabus.html#earning-a-course-grade",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Earning a course grade",
    "text": "Earning a course grade\nYour course grade is assigned using the table below. Each row indicates the minimum percentage of “Successful” results needed to satisfy the requirement of that grade. To earn a grade, complete all requirements listed in the row for that grade.\n\n\n\n\n\n\n\n\n\n\n\nHomework Problems\nLab Quiz Problems\nPortfolio Projects (4 total)\nFinal Project\n\n\n\n\nA\n85%\n90%\n2 Excellent\nExcellent\n\n\nB\n75%\n80%\n4 Successful\nSuccessful\n\n\nC\n65%\n70%\n3 Successful\nSuccessful\n\n\nD\n55%\n50%\n2 Successful\nSuccessful\n\n\n\nExample: Ben finishes the course with 82% of homework problems successfully completed, 85% of lab quiz problems successfully completed, 2/4 portfolio projects marked “excellent”, and a “Successful” final project. Ben satisfies everything in the “B” row and earns a “B” in the course."
  },
  {
    "objectID": "carleton-only-syllabus.html#plusminus-grades",
    "href": "carleton-only-syllabus.html#plusminus-grades",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Plus/minus grades",
    "text": "Plus/minus grades\n“Plus” and “minus” grades will be given if you complete all the requirements for a base letter grade and make sufficient progress toward the next grade. Below is an overview:\n\nIf “B” base grade:\n\nand A in two bins: “B+”\nand A in three bins: “A-”\n\nIf “C” base grade:\n\nand at least B in two bins: “C+”\nand at least B in three bins: “B-”\n\nIf “D” base grade:\n\nand at least C in two bins: “D+”\nand at least C in three bins: “C-”\n\nIf “F” base grade:\n\nand at least D in two bins: “D-”\n\n\nExample: Mira finishes the course with 88% of homework problems successfully completed, 85% of lab quiz problems successfully completed, 3/4 portfolio projects marked “excellent”, and a “Successful” final project. Mira satisfies everything in the “B” row, and meets the “A” threshold for two bins (homework and portfolio projects). Mira earns a B+. If Mira instead receives “excellent” marks on the final project, Mira earns an A-."
  },
  {
    "objectID": "carleton-only-syllabus.html#how-lab-quiz-resubmissions-work",
    "href": "carleton-only-syllabus.html#how-lab-quiz-resubmissions-work",
    "title": "Stat 220: Introduction to Data Science",
    "section": "How lab quiz resubmissions work",
    "text": "How lab quiz resubmissions work\nWhen you resubmit a lab quiz, you change the denominator for your quiz bin. Let’s say you earn a successful mark on 7/10 problems on the in-class version and 9/10 on the resubmission. Your ultimate score is (7+9)/(10+10). You are not required to do resubmissions."
  },
  {
    "objectID": "carleton-only-syllabus.html#important-points-about-this-grading-system",
    "href": "carleton-only-syllabus.html#important-points-about-this-grading-system",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Important points about this grading system",
    "text": "Important points about this grading system\n\nDifferent categories of coursework do not “average together”: you can’t make up for less-than-great work on portfolio projects by doing very well on quizzes, for instance. Each course grade requires consistent quality across all bins to earn the grade\nYou do not have to do everything. If you want an “A” in the class, for example, you don’t have to complete every quiz question correctly, only 90% of them."
  },
  {
    "objectID": "carleton-only-syllabus.html#tokens",
    "href": "carleton-only-syllabus.html#tokens",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Tokens",
    "text": "Tokens\n\nTurning in a token provides either (a) a 72-hour extension on a homework assignment, or (b) a revision on a portfolio project\nTokens may be used for extensions on the final project milestone check-ins, but not for the final due-date. Milestone check-ins cannot be revised\nYou may use a token for an extension on the lab quiz resubmission, but not on the in-class portion. You do not need to use a token to resubmit each lab quiz.\nYou can revise the same portfolio project multiple times, if needed, but you must spend a token each time.\nA portfolio project must be completed with a good-faith effort to be eligible for revision. If I deem a submission to be “not assessable” due to a lack of effort, then it cannot be revised.\nAll revisions must be submitted by 11:59pm on the last day of class."
  },
  {
    "objectID": "carleton-only-syllabus.html#textbook",
    "href": "carleton-only-syllabus.html#textbook",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Textbook",
    "text": "Textbook\nThere is no “perfect” data science textbook. We will use excerpts from the following texts:\n\nR for Data Science 2e\nModern Data Science with R 3e\nFundamentals of Data Visualization\n\nThese books are all freely available online. If you prefer a hard copy, they are also available for purchase through the publisher."
  },
  {
    "objectID": "carleton-only-syllabus.html#software",
    "href": "carleton-only-syllabus.html#software",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Software",
    "text": "Software\nThe use of the R programming language, with the RStudio interface is an essential component of this course. You have two options for using RStudio:\n\nThe server version of RStudio on the web at https://maize.mathcs.carleton.edu. The advantage of using the server version is that all of your work will be stored in the cloud, where it is automatically saved and backed up. This means that you can access your work from any computer on campus using a web browser. The downside is that you have to share limited computational resources with each other!\nA local version of RStudio installed on your machine.The downside to this approach is that your work is only stored locally, but I get around this problem by keeping all of my work on GitHub. You will learn how to use GitHub throughout the course.\n\nNote that you do not have to choose one or the other, you may use both. However, it is important that you understand the distinction so that you can keep track of your work. Both R and RStudio are free and open-source."
  },
  {
    "objectID": "computing/computing-cheatsheets.html",
    "href": "computing/computing-cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://posit.co/resources/cheatsheets. We haven’t covered every function and functionality listed on them, but you might still find them useful as references.",
    "crumbs": [
      "Computing",
      "Cheatsheets"
    ]
  },
  {
    "objectID": "computing/rstudio-stat220.html",
    "href": "computing/rstudio-stat220.html",
    "title": "Using RStudio in Stat 220",
    "section": "",
    "text": "There will be a lot of RStudio content thrown your way this term, most in the form of .Rmd (R Markdown) files. To stay organized, I strongly suggest you create a stat220 folder that contains the following subfolders:\nTo get started with this organization, follow the steps below.",
    "crumbs": [
      "Computing",
      "Rstudio in Stat 220"
    ]
  },
  {
    "objectID": "computing/rstudio-stat220.html#file-organization-using-maize",
    "href": "computing/rstudio-stat220.html#file-organization-using-maize",
    "title": "Using RStudio in Stat 220",
    "section": "File organization: Using maize",
    "text": "File organization: Using maize\nThe server (online) version of RStudio is run from a Unix server. You can navigate this file system using Unix commands, but I assume that most or all of you will just use RStudio to access your files on this server.\n1. In RStudio, click the Files tab in the lower right-hand window. Note: this is not the same as the File menu option.\n\n\n\n\n\n\n\n\n2. Verify that you are in your HOME folder (should simply say Home right under the New Folder button). To navigate to your Home folder (if somehow you are not in it), click the … button (far right side of the Files tab) and enter a ~ (tilde) symbol\n\n\n\n\n\n\n\n\n3. Click the New Folder button and name the folder stat220.\n\n\n\n\n\n\n\n\n4. Click on this newly created (empty) stat220 folder. Within the folder create another New Folder and name it assignments.\n\n\n\n\n\n\n\n\n5. Within the stat220 folder, create an RStudio project called content with the following steps:\n\n\na. Click the Project button in the upper right corner of your RStudio window and select New Project….\n\n\n\n\n\n\n\n\n\n\n\nb. Select New Directory and then New Project\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nc. Enter content as the Directory name and use the Browse button to find your stat220 folder. Then click Create Project.\n\n\n\n\n\n\n\n\n\n\n\nd. You should now have a new folder called content in your stat220 folder and this folder will contain an RStudio project .Rproj. Feel free to add subfolders to this content folder (e.g. slides, examples, etc).\n\n\n\n\n\n\n\n\n\nWarning: Do not create an RStudio project in the main stat220 folder because it is not good practice to have RStudio projects in subfolders of another project (e.g. a project within a project is not recommended).",
    "crumbs": [
      "Computing",
      "Rstudio in Stat 220"
    ]
  },
  {
    "objectID": "computing/rstudio-stat220.html#file-organization-using-your-own-rstudio",
    "href": "computing/rstudio-stat220.html#file-organization-using-your-own-rstudio",
    "title": "Using RStudio in Stat 220",
    "section": "File organization: Using your own RStudio",
    "text": "File organization: Using your own RStudio\nCreate a folder called stat220 somewhere on your computer. Within this folder create an assignments subfolder. Then complete step 5 from above to create a content RStudio project folder.",
    "crumbs": [
      "Computing",
      "Rstudio in Stat 220"
    ]
  },
  {
    "objectID": "computing/rstudio-stat220.html#rstudio-projects",
    "href": "computing/rstudio-stat220.html#rstudio-projects",
    "title": "Using RStudio in Stat 220",
    "section": "RStudio projects",
    "text": "RStudio projects\nOnce you’ve created a project, your R session should be running within that project folder. You can check which project you are in by checking the project name in the upper right part of your RStudio window. Here we see the content project is open:\n\n\n\n\n\n\n\n\nRunning R from an RStudio project sets your working directory to the project folder:\n\n\n\n\n\n\n\n\nThis allows for easy file path access to all files related to this project.\nTo start a project, click on the .Rproj file or use the Open Project… option shown in step 5 above.",
    "crumbs": [
      "Computing",
      "Rstudio in Stat 220"
    ]
  },
  {
    "objectID": "computing/rstudio-stat220.html#best-practices-or-what-not-to-do",
    "href": "computing/rstudio-stat220.html#best-practices-or-what-not-to-do",
    "title": "Using RStudio in Stat 220",
    "section": "Best practices (or what not to do)",
    "text": "Best practices (or what not to do)\n\nNever save files to a lab computer hard drive (e.g. desktop, downloads, etc). They will be erased when you log off.\nDo not use gmail as a file storage system! Avoid emailing yourself files that you created (and saved) on a lab computer. Eventually you will lose work this way.\nAvoid using online versions of google drive and dropbox. Similar to gmail, downloading, editing a doc, then uploading it back to drive/dropbox is another great way to lose work.\nAvoid this and this.",
    "crumbs": [
      "Computing",
      "Rstudio in Stat 220"
    ]
  },
  {
    "objectID": "computing/rstudio-stat220.html#acknowledgments",
    "href": "computing/rstudio-stat220.html#acknowledgments",
    "title": "Using RStudio in Stat 220",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis guide is based on the guide from Katie St. Clair and is licensed under the CC BY-NC 3.0 Creative Commons License.",
    "crumbs": [
      "Computing",
      "Rstudio in Stat 220"
    ]
  },
  {
    "objectID": "activities/07-dplyr1.html",
    "href": "activities/07-dplyr1.html",
    "title": "\ndplyr 1: Verbs",
    "section": "",
    "text": "Click the “code” button above to copy and paste the source code, or pull a fresh version of the “activities” repo from GitHub."
  },
  {
    "objectID": "activities/07-dplyr1.html#part-1",
    "href": "activities/07-dplyr1.html#part-1",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 1",
    "text": "Part 1\n\nFind all flights that had an arrival delay of two or more hours.\nFind all flights to MSP\nFind all flights that arrived more than two hours late, but left less than one hour late\n(if time) Find all flights that were delayed by at least an hour, but made up over 30 minutes in flight"
  },
  {
    "objectID": "activities/07-dplyr1.html#part-2",
    "href": "activities/07-dplyr1.html#part-2",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 2",
    "text": "Part 2\nUse arrange to answer the following questions:\n\nWhich flights traveled the farthest?\nWhich traveled the shortest?\nWhich flights lasted the longest?\nWhich lasted the shortest?"
  },
  {
    "objectID": "activities/07-dplyr1.html#part-3",
    "href": "activities/07-dplyr1.html#part-3",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 3",
    "text": "Part 3\nCreate a new column in flights giving the average speed of the flight while it was in the air. What are the units of this variable? Make the variable in terms of miles per hour."
  },
  {
    "objectID": "activities/07-dplyr1.html#part-5",
    "href": "activities/07-dplyr1.html#part-5",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 5",
    "text": "Part 5\nSuppose that you don’t think the FAA gives enough information in their definition of a delayed flight, so you come up with the following delay categories:\n\n\ndep_delay &lt;= 0 -&gt; none\n\ndep_delay between 1 and 15 minutes -&gt; minimal\n\ndep_delay between 16 and 30 minutes -&gt; delayed\n\ndep_delay between 31 and 60 minutes -&gt; major\n\ndep_delay over 60 minutes -&gt; extreme\n\nUse mutate() and case_when() to create a delay_category variable in the flights data frame.\nand we can check with select():"
  },
  {
    "objectID": "activities/07-dplyr1.html#part-6",
    "href": "activities/07-dplyr1.html#part-6",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 6",
    "text": "Part 6\nChain the last two parts together, so that the resulting dataset contains both avg_speed and delay_category. Pipe this new dataset into ggplot() to answer the question “is there a relationship between average speed and how late a flight is delayed?”\nIf you have time, create a new graph which only contains flights to MSP.\n\n\n\n\n\n\nAdapted from Adam Loy’s materials"
  },
  {
    "objectID": "activities/03-ggplot-intro.html",
    "href": "activities/03-ggplot-intro.html",
    "title": "Intro to ggplot2\n",
    "section": "",
    "text": "Note: the setup chunk includes the line eval = FALSE. Make sure to delete this when you are ready to knit your file.\nThe data we’re using today contains information about all seasons of Survivor and comes from the survivoR R package. In the show, a group of people (called castaways) are placed in an isolated location, where they must provide food, fire, and shelter for themselves. The castaways compete in challenges testing the contestants’ physical abilities like running and swimming or their mental abilities like puzzles and endurance challenges for rewards and immunity from elimination. The castaways are progressively eliminated from the game as they are voted out by their fellow contestants until only two or three remain. At that point, the players who were eliminated (the “jury”) vote for the winner. The winner is given the title of “Sole Survivor” and is awarded the grand prize of $1,000,000\nseason_summary = readr::read_csv(\"https://math.carleton.edu/aluby/stat220/survivor_season_summary.csv\")\n#&gt; Rows: 47 Columns: 30\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr  (13): version, version_season, season_name, location, country, tribe_se...\n#&gt; dbl  (13): season, n_cast, n_tribes, n_finalists, n_jury, viewers_reunion, v...\n#&gt; date  (4): premiered, ended, filming_started, filming_ended\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "activities/03-ggplot-intro.html#round-1-view-the-data-pipes",
    "href": "activities/03-ggplot-intro.html#round-1-view-the-data-pipes",
    "title": "Intro to ggplot2\n",
    "section": "Round 1: View the data + pipes",
    "text": "Round 1: View the data + pipes\n1. To get started, load the tidyverse and and take a glimpse at the dataset. How many rows and columns are there? What does each row represent?\nLoading the tidyverse loads 8 packages, one of which is ggplot2. You can certainly load each package individually, but it has become common to simply load the tidyverse.\n2. The code below filters season_summary to include only survivor seasons that aired in the US. What does |&gt; do? (Try to answer this with your group, then run ?\"|&gt;\" in the console to load the help page if you need to)\n\nseason_summary |&gt;\n  filter(season == \"US\")"
  },
  {
    "objectID": "activities/03-ggplot-intro.html#round-2-scatterplots",
    "href": "activities/03-ggplot-intro.html#round-2-scatterplots",
    "title": "Intro to ggplot2\n",
    "section": "Round 2: Scatterplots",
    "text": "Round 2: Scatterplots\nFirst, let’s create a scatterplot of imdb_mean vs. viewers_mean.\nA note on wording: when we say imdb_mean vs. viewers_mean, this should be interpreted as “variable on the y-axis” vs. “variable on the x-axis”.\n3. Fill in the data and aesthetic mapping in the below code chunk. What is returned? What’s missing?\n\n# Fill in the blanks\nggplot(data = ___, mapping = aes(x = ___, y = ___))\n\n4. Add the appropriate geometric object to create the scatterplot. This is called adding a layer to a plot. Remember to always put the + at the end of a line, never at the start.\n\n# Copy your code from the previous chunk and add a geom\n\nWhat do you notice? Write a sentence or two describing your findings\n5. You must remember to put the aesthetic mappings in the aes() function! What happens if you forget?\n\n# Add a layer and see what happens\nggplot(data = ___, x = ___, y = ___)\n\n6. The aesthetic mappings can be specified in the geom layer if you prefer, instead of the main ggplot() call. Give it a try:\n\n# Rebuild the scatterplot with your aesthetic mapping in the geom layer\nggplot(data = ___)"
  },
  {
    "objectID": "activities/03-ggplot-intro.html#round-3-additional-aesthetics",
    "href": "activities/03-ggplot-intro.html#round-3-additional-aesthetics",
    "title": "Intro to ggplot2\n",
    "section": "Round 3: Additional Aesthetics",
    "text": "Round 3: Additional Aesthetics\nx and y are not the only aesthetic mappings possible. In this section you’ll explore the color, size, shape, and alpha (i.e. transparency) aesthetics.\n7. Create a scatterplot of imdb_mean vs. viewers_mean. Add the color aesthetic to map country2 to the point color.\n\nggplot(data = ___) +\n  geom_point(aes(x = ___, y = ___, color = ___))\n\n8. Create a scatterplot of imdb_mean vs. viewers_mean. Use shape to represent country2. Is this plot easier or harder to interpret than the previous plot?\n9. Create a scatterplot of imdb_mean vs. viewers_mean. Use both shape and color to represent the four_regions. Is this plot easier or harder to interpret than the previous two plots?\n10. Create a scatterplot of imdb_mean vs. viewers_mean. Use color to represent the season. What did you learn from the plot?\n11. Create a scatterplot of imdb_mean vs. viewers_mean. Use size to represent the season.\n12. Look back at your scatterplots from the last few questions. Explain the differences when you map aesthetics to discrete and continuous variables.\n13. Create a scatterplot of imdb_mean vs. viewers_mean. Use alpha to represent the season."
  },
  {
    "objectID": "activities/03-ggplot-intro.html#round-4-visualizing-distributions",
    "href": "activities/03-ggplot-intro.html#round-4-visualizing-distributions",
    "title": "Intro to ggplot2\n",
    "section": "Round 4: Visualizing Distributions",
    "text": "Round 4: Visualizing Distributions\n14. Build a histogram of viewers_mean using geom_histogram(). Don’t hesitate to look at the ggplot2 cheat sheet for help!\n\n# Fill in the blanks\nggplot(___) +\n  geom_histogram(aes(x = ___))\n\nWhat have you learned about the distribution of average viewership?\n15. By default, ggplot2 uses 30 bins. To change the number of bins, to say 15, add the argument bins = 15 to geom_histogram(). Note: this is not an aesthetic mapping.\n\n# Fill in the blanks\nggplot(___) +\n  geom_histogram(aes(x = ___), bins = ___)\n\n16. Instead of a histogram, let’s create a kernel density plot. To do this, substitute geom_density() into your code for question 14.\n17. Now, let’s make side-by-side boxplots of viewers_mean for each country2.\n\n# Fill in the blanks\nggplot(___) +\n  geom_boxplot(aes(x = ___, y = ___))\n\n18. A violin plot is a kernel density on its side, made symmetric. Change your code from question 17 to use geom_violin(). Which plot do you prefer, boxplots or violin plots? Why?\n\n# Put your violin plot code here"
  },
  {
    "objectID": "activities/03-ggplot-intro.html#round-5-bar-and-column-charts-labeling",
    "href": "activities/03-ggplot-intro.html#round-5-bar-and-column-charts-labeling",
    "title": "Intro to ggplot2\n",
    "section": "Round 5: Bar and column charts + Labeling",
    "text": "Round 5: Bar and column charts + Labeling\nHow many seasons were filmed in each country? Let’s find out!\n19. Make a bar chart of the number of seasons filmed in each country2 using geom_bar()\n\n# Fill in the blanks\nggplot(___) +\n  geom_bar(aes(x = ___))\n\n20. country2 has a category called “other”. Make a bar chart of country (which includes all individual countries) instead.\n\n# Fill in the blanks\nggplot(___) +\n  geom_bar(aes(x = ___))\n\n21. When you have lots of categories, it’s sometimes hard to read the labels on the x-axis. One trick is to flip the axes. Change geom_bar() to use the y aesthetic from your code in question 20 instead.\n22. In ggplot2 you can add/change the title, subtitle, caption, and x- and y-axis labels by adding a labs() layer. Below is an example illustrating it’s use. Choose one graph from today and add all labels.\n\nggplot(data = mpg) +\n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  labs(\n    title = \"Put your informative title here\",\n    subtitle = \"and your subtitle here\",\n    x = \"New x label\",\n    y = \"New y label\",\n    caption = \"Put a caption here\"\n  )"
  },
  {
    "objectID": "activities/08-dplyr2.html",
    "href": "activities/08-dplyr2.html",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "",
    "text": "Note: continue using your 07-dplyr.rmd file for this activity. You can copy and paste code chunks using the “code” button above. We will continue to use the nycflights23 dataset."
  },
  {
    "objectID": "activities/08-dplyr2.html#chunk-1",
    "href": "activities/08-dplyr2.html#chunk-1",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "Chunk 1",
    "text": "Chunk 1\n\nlog2(sqrt(16))"
  },
  {
    "objectID": "activities/08-dplyr2.html#chunk-2",
    "href": "activities/08-dplyr2.html#chunk-2",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "Chunk 2:",
    "text": "Chunk 2:\n\nlibrary(nycflights23) # need to load, not in pipeline\nmsp &lt;- filter(flights, dest == \"MSP\", carrier == \"DL\")\nmsp_narrow &lt;- select(msp, year, month, day, starts_with(\"sched\"), \n                     contains(\"delay\"), origin)\nmsp_narrow &lt;- relocate(msp_narrow, origin, everything())"
  },
  {
    "objectID": "activities/08-dplyr2.html#your-turn-from-last-time",
    "href": "activities/08-dplyr2.html#your-turn-from-last-time",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "“Your turn” from last time",
    "text": "“Your turn” from last time\nChain the last two parts together, so that the resulting dataset contains both avg_speed and delay_category. Pipe this new dataset into ggplot() to answer the question “is there a relationship between average speed and how late a flight is delayed?”\nIf you have time, create a new graph which only contains flights to MSP."
  },
  {
    "objectID": "activities/08-dplyr2.html#summarize",
    "href": "activities/08-dplyr2.html#summarize",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "summarize()",
    "text": "summarize()\nUse summarize() to compute statistics about the data:\n\nThe lowest and highest distance traveled\nThe lowest and highest air_time\nThe median dep_delay"
  },
  {
    "objectID": "activities/08-dplyr2.html#summarize-ii",
    "href": "activities/08-dplyr2.html#summarize-ii",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "\nsummarize() II",
    "text": "summarize() II\nExtract the rows for Delta flights. (Hint: look at the airlines dataset, which is also distributed in the {nycflights23} R package, to find the carrier shortcut code)\nThen use summarize() and a summary function to find:\n\nThe number of flights in this subset\nThe median dep_delay. How does it compare to the overall median?"
  },
  {
    "objectID": "activities/08-dplyr2.html#group_by",
    "href": "activities/08-dplyr2.html#group_by",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "group_by()",
    "text": "group_by()\nUse group_by(), summarize(), and slice_max() to display the five dest airports with the most flights from NYC airports in 2023. Your display should include the median flight delay for these airports."
  },
  {
    "objectID": "activities/07-dplyr1-sols.html",
    "href": "activities/07-dplyr1-sols.html",
    "title": "\ndplyr 1: Verbs",
    "section": "",
    "text": "Identify the verb (function) that does the following:\n\nPicks rows by their values\nReorders the rows\nPicks variables by their names\nCreates new variables with functions of existing variables"
  },
  {
    "objectID": "activities/07-dplyr1-sols.html#part-1",
    "href": "activities/07-dplyr1-sols.html#part-1",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 1",
    "text": "Part 1\n\nFind all flights that had an arrival delay of two or more hours.\nFind all flights to MSP\nFind all flights that arrived more than two hours late, but left less than one hour late\n(if time) Find all flights that were delayed by at least an hour, but made up over 30 minutes in flight\n\n\nfilter(flights, dep_delay &gt;= 120)\n\n# A tibble: 15,367 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1        1           2038       203      328              3\n 2  2023     1     1       33           2140       173      238           2352\n 3  2023     1     1       36           2048       228      223           2252\n 4  2023     1     1      831            600       151     1044            838\n 5  2023     1     1      925            700       145     1214           1005\n 6  2023     1     1     1000            700       180     1322           1019\n 7  2023     1     1     1017            817       120     1454           1311\n 8  2023     1     1     1056            700       236     1345           1027\n 9  2023     1     1     1109            735       214     1417           1048\n10  2023     1     1     1110            829       161     1412           1211\n# ℹ 15,357 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\nfilter(flights, dest == \"MSP\")\n\n# A tibble: 5,938 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1      603            605        -2      800            818\n 2  2023     1     1      655            700        -5      841            907\n 3  2023     1     1      657            700        -3      902            927\n 4  2023     1     1      749            750        -1      938           1006\n 5  2023     1     1      951           1000        -9     1159           1237\n 6  2023     1     1     1207           1217       -10     1430           1445\n 7  2023     1     1     1312           1059       133     1518           1319\n 8  2023     1     1     1314           1153        81     1518           1357\n 9  2023     1     1     1506           1500         6     1712           1717\n10  2023     1     1     1513           1512         1     1724           1721\n# ℹ 5,928 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\nfilter(flights, (dep_delay &gt;=120) & (arr_delay &lt; 60))\n\n# A tibble: 5 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2023     4    10     2158           1955       123       12           2316\n2  2023     4    30     2130           1930       120     2358           2259\n3  2023     5     1     1212            955       137     1617           1528\n4  2023     6     1     1201           1000       121     1425           1326\n5  2023     7    26     2135           1929       126       21           2335\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "activities/07-dplyr1-sols.html#part-2",
    "href": "activities/07-dplyr1-sols.html#part-2",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 2",
    "text": "Part 2\nUse arrange to answer the following questions:\n\nWhich flights traveled the farthest?\nWhich traveled the shortest?\nWhich flights lasted the longest?\nWhich lasted the shortest?\n\n\narrange(flights, desc(distance))\n\n# A tibble: 435,352 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1      949            900        49       NA           1525\n 2  2023     1     1     1023           1000        23     1637           1610\n 3  2023     1     2      919            900        19     1543           1525\n 4  2023     1     2      951           1000        -9     1620           1610\n 5  2023     1     3      922            900        22     1535           1525\n 6  2023     1     3     1007           1000         7     1630           1610\n 7  2023     1     4      912            900        12     1511           1525\n 8  2023     1     4     1001           1000         1     1630           1610\n 9  2023     1     5      854            900        -6     1454           1525\n10  2023     1     5      949           1000       -11     1600           1610\n# ℹ 435,342 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\narrange(flights, distance)\n\n# A tibble: 435,352 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1      816            820        -4      910            921\n 2  2023     1     2      820            820         0      907            921\n 3  2023     1     2     2324           2159        85       41           2300\n 4  2023     1     3       14           2158       136      104           2259\n 5  2023     1     3      815            820        -5      913            921\n 6  2023     1     4      756            759        -3      903            900\n 7  2023     1     4     1353           1347         6     1449           1448\n 8  2023     1     5      804            759         5      908            900\n 9  2023     1     5     1346           1347        -1     1444           1447\n10  2023     1     6      817            759        18      926            900\n# ℹ 435,342 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\narrange(flights, desc(air_time))\n\n# A tibble: 435,352 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     3     9     1009           1000         9     1720           1605\n 2  2023     1    10      913            900        13     1615           1525\n 3  2023     3    10      852            900        -8     1616           1537\n 4  2023     3     8      853            900        -7     1608           1525\n 5  2023     1    31      858            900        -2     1627           1525\n 6  2023     4     2     1104           1000        64     1702           1510\n 7  2023     1    28     1121            900       141     1820           1525\n 8  2023     3    23      851            900        -9     1451           1437\n 9  2023     2     4     1005           1000         5     1649           1605\n10  2023     3     7     1345            900       285     2100           1525\n# ℹ 435,342 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\narrange(flights, air_time)\n\n# A tibble: 435,352 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1    12     2151           2155        -4     2247           2256\n 2  2023     1     3     1155           1200        -5     1235           1311\n 3  2023     1    12     1452           1455        -3     1540           1607\n 4  2023     1    15      757            759        -2      839            900\n 5  2023     1    19     1450           1455        -5     1536           1607\n 6  2023     2     5     1422           1430        -8     1511           1538\n 7  2023     3     1     1438           1440        -2     1524           1548\n 8  2023     3    17      825            835       -10      911            945\n 9  2023     4     6     1201           1109        52     1255           1218\n10  2023     6     8     2211           2149        22     2256           2242\n# ℹ 435,342 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "activities/07-dplyr1-sols.html#part-3",
    "href": "activities/07-dplyr1-sols.html#part-3",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 3",
    "text": "Part 3\nCreate a new column in flights giving the average speed of the flight while it was in the air. What are the units of this variable? Make the variable in terms of miles per hour.\n\nmutate(flights, avg_speed = distance/air_time)\n\n# A tibble: 435,352 × 20\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1        1           2038       203      328              3\n 2  2023     1     1       18           2300        78      228            135\n 3  2023     1     1       31           2344        47      500            426\n 4  2023     1     1       33           2140       173      238           2352\n 5  2023     1     1       36           2048       228      223           2252\n 6  2023     1     1      503            500         3      808            815\n 7  2023     1     1      520            510        10      948            949\n 8  2023     1     1      524            530        -6      645            710\n 9  2023     1     1      537            520        17      926            818\n10  2023     1     1      547            545         2      845            852\n# ℹ 435,342 more rows\n# ℹ 12 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, avg_speed &lt;dbl&gt;"
  },
  {
    "objectID": "activities/07-dplyr1-sols.html#part-5",
    "href": "activities/07-dplyr1-sols.html#part-5",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 5",
    "text": "Part 5\nSuppose that you don’t think the FAA gives enough information in their definition of a delayed flight, so you come up with the following delay categories:\n\n\ndep_delay &lt;= 0 -&gt; none\n\ndep_delay between 1 and 15 minutes -&gt; minimal\n\ndep_delay between 16 and 30 minutes -&gt; delayed\n\ndep_delay between 31 and 60 minutes -&gt; major\n\ndep_delay over 60 minutes -&gt; extreme\n\nUse mutate() and case_when() to create a delay_category variable in the flights data frame.\n\nmutate(flights, delay_category = case_when(\n  dep_delay &lt;= 0 ~ \"none\",\n  dep_delay &lt;= 15 ~ \"minimal\",\n  dep_delay &lt;= 30 ~ \"delayed\",\n  dep_delay &lt;= 60 ~ \"major\",\n  dep_delay &gt; 60 ~ \"extreme\"\n))\n\n# A tibble: 435,352 × 20\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1        1           2038       203      328              3\n 2  2023     1     1       18           2300        78      228            135\n 3  2023     1     1       31           2344        47      500            426\n 4  2023     1     1       33           2140       173      238           2352\n 5  2023     1     1       36           2048       228      223           2252\n 6  2023     1     1      503            500         3      808            815\n 7  2023     1     1      520            510        10      948            949\n 8  2023     1     1      524            530        -6      645            710\n 9  2023     1     1      537            520        17      926            818\n10  2023     1     1      547            545         2      845            852\n# ℹ 435,342 more rows\n# ℹ 12 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, delay_category &lt;chr&gt;\n\n\nand we can check with select():\n\nmutate(flights, delay_category = case_when(\n  dep_delay &lt;= 0 ~ \"none\",\n  dep_delay &lt;= 15 ~ \"minimal\",\n  dep_delay &lt;= 30 ~ \"delayed\",\n  dep_delay &lt;= 60 ~ \"major\",\n  dep_delay &gt; 60 ~ \"extreme\"\n)) %&gt;%\n  select(dep_delay, delay_category)\n\n# A tibble: 435,352 × 2\n   dep_delay delay_category\n       &lt;dbl&gt; &lt;chr&gt;         \n 1       203 extreme       \n 2        78 extreme       \n 3        47 major         \n 4       173 extreme       \n 5       228 extreme       \n 6         3 minimal       \n 7        10 minimal       \n 8        -6 none          \n 9        17 delayed       \n10         2 minimal       \n# ℹ 435,342 more rows"
  },
  {
    "objectID": "activities/07-dplyr1-sols.html#part-6",
    "href": "activities/07-dplyr1-sols.html#part-6",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 6",
    "text": "Part 6\nChain the last two parts together, so that the resulting dataset contains both avg_speed and delay_category. Pipe this new dataset into ggplot() to answer the question “is there a relationship between average speed and how late a flight is delayed?”\nIf you have time, create a new graph which only contains flights to MSP.\n\nflights %&gt;%\n  mutate(\n    delay_category = case_when(\n      dep_delay &lt;= 0 ~ \"none\",\n      dep_delay &lt;= 15 ~ \"minimal\",\n      dep_delay &lt;= 30 ~ \"delayed\",\n      dep_delay &lt;= 60 ~ \"major\",\n      dep_delay &gt; 60 ~ \"extreme\"\n    ),\n    avg_speed = distance/air_time\n  ) %&gt;%\n  ggplot(aes(y = delay_category, x = avg_speed, fill = delay_category)) + \n  geom_boxplot() + \n  theme(legend.position = \"none\")\n\nWarning: Removed 12534 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nflights %&gt;%\n  filter(dest == \"MSP\") %&gt;%\n  mutate(\n    delay_category = case_when(\n      dep_delay &lt;= 0 ~ \"none\",\n      dep_delay &lt;= 15 ~ \"minimal\",\n      dep_delay &lt;= 30 ~ \"delayed\",\n      dep_delay &lt;= 60 ~ \"major\",\n      dep_delay &gt; 60 ~ \"extreme\"\n    ),\n    avg_speed = distance/air_time\n  ) %&gt;%\n  ggplot(aes(y = delay_category, x = avg_speed, fill = delay_category)) + \n  geom_boxplot() + \n  theme(legend.position = \"none\")\n\nWarning: Removed 133 rows containing non-finite outside the scale range\n(`stat_boxplot()`)."
  },
  {
    "objectID": "activities/12-factors.html",
    "href": "activities/12-factors.html",
    "title": "12-factors",
    "section": "",
    "text": "gss_cat gets loaded with the forcats package in the tidyverse use gss_cat to answer the following questions (I’d use a graph, but do whatever you’d like!)\n\ngss_cat\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Not str r… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Strong de… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Ind,near … Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n10  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n# ℹ 21,473 more rows\n\n\n\nWhich religions watch the least TV?\nDo married people watch more or less TV than single people?"
  },
  {
    "objectID": "activities/12-factors.html#hotel-bookings-by-month",
    "href": "activities/12-factors.html#hotel-bookings-by-month",
    "title": "12-factors",
    "section": "Hotel bookings by month",
    "text": "Hotel bookings by month\n\n# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md\nhotels &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\", show_col_types = FALSE)\n\n\nRun the code and examine the plot. How are the months ordered? What would be a better order?\n\n\nhotels %&gt;%\n  group_by(hotel, arrival_date_month) %&gt;%   # group by hotel type and arrival month\n  summarize(mean_adr = mean(adr)) %&gt;%       # calculate mean adr for each group\n  ggplot(aes(\n    x = arrival_date_month,                 # x-axis = arrival_date_month\n    y = mean_adr,                           # y-axis = mean_adr calculated above\n    group = hotel,                          # group lines by hotel type\n    color = hotel)                          # and color by hotel type\n    ) +\n  geom_line() +                             # use lines to represent data\n  theme_minimal() +                         # use a minimal theme\n  labs(\n    x = \"Arrival month\",                    # customize labels\n    y = \"Mean ADR (average daily rate)\",\n    title = \"Comparison of resort and city hotel prices across months\",\n    subtitle = \"Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year\",\n    color = \"Hotel type\"\n    )\n\n\n\n\n\n\n\n\nReorder the months on the x-axis (levels of arrival_date_month) in a way that makes more sense. Use a function from the forcats package."
  },
  {
    "objectID": "activities/12-factors.html#more-hotel-bookings-by-room-type",
    "href": "activities/12-factors.html#more-hotel-bookings-by-room-type",
    "title": "12-factors",
    "section": "More hotel bookings by room type",
    "text": "More hotel bookings by room type\n\nCreate a bar chart of the reserved_room_type.\nCreate another bar chart where you have bars for the top three room types and an “other” category lumping the other room types together."
  },
  {
    "objectID": "activities/12-factors.html#more-hotel-bookings-by-room-type-1",
    "href": "activities/12-factors.html#more-hotel-bookings-by-room-type-1",
    "title": "12-factors",
    "section": "More hotel bookings by room type",
    "text": "More hotel bookings by room type\n\nRun the code and examine the plot. How are the months ordered? What would be a better order?\n\n\nhotels %&gt;%\n  group_by(meal, arrival_date_month) %&gt;%   # group by meal type and arrival month\n  summarize(mean_adr = mean(adr)) %&gt;%       # calculate mean adr for each group\n  ggplot(aes(\n    x = arrival_date_month,                 # x-axis = arrival_date_month\n    y = mean_adr,                           # y-axis = mean_adr calculated above\n    group = meal,                          # group lines by meal type\n    color = meal)                          # and color by meal type\n    ) +\n  geom_line() +                             # use lines to represent data\n  theme_minimal() +                         # use a minimal theme\n  labs(\n    x = \"Arrival month\",                    # customize labels\n    y = \"Mean ADR (average daily rate)\",\n    color = \"Meal type\"\n    ) +\n  ggthemes::scale_color_colorblind()\n\n\n\n\n\n\n\n\nReorder the levels of meal type in a way that makes more sense. Use a function from the forcats package to do this."
  },
  {
    "objectID": "activities/09-tidyr.html",
    "href": "activities/09-tidyr.html",
    "title": "\ntidyr: Reshaping Data",
    "section": "",
    "text": "Click the “code” button above to copy and paste the source code, or pull a fresh version of the “activities” repo from GitHub."
  },
  {
    "objectID": "activities/09-tidyr.html#task-1",
    "href": "activities/09-tidyr.html#task-1",
    "title": "\ntidyr: Reshaping Data",
    "section": "Task 1",
    "text": "Task 1\n\nTidy this data set by\n\nSelecting the series and e*_7day columns\nPivoting the data to add a column for episode and a column for rating (we’ll clean up the episode column later)\n\n\n\n# include your code here"
  },
  {
    "objectID": "activities/09-tidyr.html#task-2",
    "href": "activities/09-tidyr.html#task-2",
    "title": "\ntidyr: Reshaping Data",
    "section": "Task 2",
    "text": "Task 2\n\n\nClean the episode and period column\nMake a line plot with episode on the x-axis, rating on the y-axis, colored by series. (You will also need to map the group aesthetic to series)"
  },
  {
    "objectID": "activities/09-tidyr.html#relig_income",
    "href": "activities/09-tidyr.html#relig_income",
    "title": "\ntidyr: Reshaping Data",
    "section": "relig_income",
    "text": "relig_income\nThe relig_income dataset in the {tidyr} package stores counts based on a survey which (among other things) asked people about their religion and annual income:\n\nrelig_income\n\n# A tibble: 18 × 11\n   religion `&lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k`\n   &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 Agnostic      27        34        60        81        76       137        122\n 2 Atheist       12        27        37        52        35        70         73\n 3 Buddhist      27        21        30        34        33        58         62\n 4 Catholic     418       617       732       670       638      1116        949\n 5 Don’t k…      15        14        15        11        10        35         21\n 6 Evangel…     575       869      1064       982       881      1486        949\n 7 Hindu          1         9         7         9        11        34         47\n 8 Histori…     228       244       236       238       197       223        131\n 9 Jehovah…      20        27        24        24        21        30         15\n10 Jewish        19        19        25        25        30        95         69\n11 Mainlin…     289       495       619       655       651      1107        939\n12 Mormon        29        40        48        51        56       112         85\n13 Muslim         6         7         9        10         9        23         16\n14 Orthodox      13        17        23        32        32        47         38\n15 Other C…       9         7        11        13        13        14         18\n16 Other F…      20        33        40        46        49        63         46\n17 Other W…       5         2         3         4         2         7          3\n18 Unaffil…     217       299       374       365       341       528        407\n# ℹ 3 more variables: `$100-150k` &lt;dbl&gt;, `&gt;150k` &lt;dbl&gt;,\n#   `Don't know/refused` &lt;dbl&gt;\n\n\nUse pivot_longer() to tidy this dataset."
  },
  {
    "objectID": "activities/09-tidyr.html#anscombe",
    "href": "activities/09-tidyr.html#anscombe",
    "title": "\ntidyr: Reshaping Data",
    "section": "anscombe",
    "text": "anscombe\nAnscombe’s quartet is a built-in dataset in R.\n\nanscombe\n\n   x1 x2 x3 x4    y1   y2    y3    y4\n1  10 10 10  8  8.04 9.14  7.46  6.58\n2   8  8  8  8  6.95 8.14  6.77  5.76\n3  13 13 13  8  7.58 8.74 12.74  7.71\n4   9  9  9  8  8.81 8.77  7.11  8.84\n5  11 11 11  8  8.33 9.26  7.81  8.47\n6  14 14 14  8  9.96 8.10  8.84  7.04\n7   6  6  6  8  7.24 6.13  6.08  5.25\n8   4  4  4 19  4.26 3.10  5.39 12.50\n9  12 12 12  8 10.84 9.13  8.15  5.56\n10  7  7  7  8  4.82 7.26  6.42  7.91\n11  5  5  5  8  5.68 4.74  5.73  6.89\n\n\nThis dataset contains four pairs of variables (x1 and y1, x2 and y2, etc) that underlie Anscombe’s quartet, a collection of four datasets that have the same summary statistics (mean, sd, correlation etc), but have quite different data. We want to produce a dataset with columns set, x and y:\n# A tibble: 44 × 3\n   set       x     y\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 1        10  8.04\n 2 2        10  9.14\n 3 3        10  7.46\nThere are (at least) two ways to do this. The first is a little more intuitive, but not as efficient:\n\nFirst, we’ll create a new “index” column, so we don’t lose track of which x values map to which y values.\n\n\nanscombe &lt;- anscombe %&gt;%\n  mutate(\n    index = 1:nrow(anscombe)\n  )\n\n\nNext, use pivot_longer() on all of the columns but index. Use the default for names_to and values_to. The first few rows of your result should look like this:\n\n# A tibble: 88 × 3\n   index name  value\n   &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;\n 1     1 x1    10   \n 2     1 x2    10   \n 3     1 x3    10  \n\nNext, separate name into variable and set. This is a little tricky, since there’s no separator character (the values of name are x1 and x2 instead of x_1 or x_2). Instead, set sep = 1, which tells R to split the column after the first character. The first few rows of your result should look like this:\n\n# A tibble: 88 × 4\n   index variable set   value\n   &lt;int&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n 1     1 x        1     10   \n 2     1 x        2     10   \n 3     1 x        3     10   \n\nFinally, use pivot_wider() with names_from variable and values_from value. Call your tidy dataset anscombe_tidy.\n\nIf all went well, you should be able to run the following two chunks to generate the summary statistics and scatterplots for Anscombe’s quartet.\n\nanscombe_tidy %&gt;%\n  group_by(set) %&gt;%\n  summarize(\n    mean_x = mean(x),\n    mean_y = mean(y),\n    sd_x = sd(x),\n    sd_y = sd(y),\n    cor = cor(x,y)\n  )\n\n\nanscombe_tidy %&gt;%\n  ggplot(aes(x = x, y = y)) + \n  geom_point() + \n  facet_wrap(~set)\n\nThe second way to do this is directly within pivot_longer():\n\nanscombe %&gt;%\n  pivot_longer(\n    -index,\n    names_to = c(\".value\", \"set\"),\n    names_pattern = \"(.)(.)\"\n  )\n\n# A tibble: 44 × 4\n   index set       x     y\n   &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1 1        10  8.04\n 2     1 2        10  9.14\n 3     1 3        10  7.46\n 4     1 4         8  6.58\n 5     2 1         8  6.95\n 6     2 2         8  8.14\n 7     2 3         8  6.77\n 8     2 4         8  5.76\n 9     3 1        13  7.58\n10     3 2        13  8.74\n# ℹ 34 more rows\n\n\npull up the help page for pivot_longer and try to explain the new arguments."
  },
  {
    "objectID": "portfolio/portfolio-1.html",
    "href": "portfolio/portfolio-1.html",
    "title": "Portfolio Project 1",
    "section": "",
    "text": "Overview\nIn your first mini-project, you’ll apply what you’ve learned about ggplot2 and design principles to replicate and redesign a published graph. This project consists of three parts:\n\nReplicating an existing graph using ggplot2. Depending on the graph you choose, this may require some creativity in recreating data.\nUsing design principles from class, re-design the original graph to be better. This should include, at minimum, changes to two of the “layers” of the grammar of graphics (data, aesthetics, geometries, facets, statistics, coordinates, and theme).\nA written summary (no more than 1 printed page) including (1) an evaluation of the original graph and (2) reasoning for your design choices in improving the graph. This should include references to readings and discussions from class.\n\n\n\nOptions and Examples\nThe list below includes some good places to get started finding a graph. You do not have to choose a graph from one of these sources. It can be hard to find associated data with some published graphs, so don’t spend too much time trying to find data for a specific graph before moving on.\n\nOur World In Data\nFiveThirtyEight + Associated R Package (See available data here).\nHelpMeViz\nDataIsPlural\nTidyTuesday – If you choose this option, please be especially kind in your critique. This is a weekly R community activity, and many submissions are by beginners.\nr/dataisbeautiful\nr/dataisugly\n\n\n\nSubmission\nYour submission should include two visualizations (replication and improvement), a written overview of your work, and all associated code. You should work in a rmarkdown or quarto file. Your knitted/rendered file can be either pdf or html. I will distribute GitHub skeleton repos that you should fill in as you work. You should commit your final code and output file to your repo and link your repo to gradescope to submit.\n\n\nRubric\nA successful project will:\n\nInclude all necessary components pushed to GitHub and linked to gradescope\nContain code, plots, and written summary in a single .rmd document\nThe .rmd with all necessary code for recreation\nThe .rmd does not include unnecessary code\nProvide a thoughtful summary and critique\nThe replication matches the original graph on all layers of the grammar of graphics (data, aesthetics, geometries, facets, statistics, coordinates, and theme)\nThe improved graph has made changes to at least two of the layers\n\nAesthetics faithfully represent the representation of the underlying data\n\nMeet minimum submission quality standards\n\nVery few grammatical mistakes, spelling mistakes, or typos\nAppropriate labels and font sizes\nA readable theme\nThe rendered document does not contain any unnecessary content (package loading messages, warnings, etc.)\n\n\nAn excellent project will meet all of the requirements for a successful project, plus\n\nBe published (publicly!) to the web. (It is a portfolio project, after all). I recommend using RPubs as it’s very easy to publish a standalone website through RStudio, but if you have a public-facing website, that’s great too! Please include a URL in your YAML header so I can find it when grading.\n\nThere are lots of reasons you might not want the world to know that you are enrolled in this class, and this is one of your rights under FERPA. If you’re not comfortable including your name, you don’t have to! Your public document can be authored by “Student” (which has a history of being used in statistics).\nIf you are not comfortable attaching your name to something public-facing and this solution doesn’t work for you, please contact me on slack at least 72 hours before the due date so we can make an alternative plan.\n\nThe improved graph has made changes to at least four of the layers of the grammar of graphics (data, aesthetics, geometries, facets, statistics, coordinates, and theme)\n\nAll changes to aesthetics, geometries, etc. should be faithful representations of the underlying data (e.g. changes for the sake of making a change don’t count!)\n\n\nFor this portfolio project, you may work individually or in pairs. If you choose to work in a pair, let me know as soon as you decide so I can make a group repo for you. Both partners should have a record of committing and pushing to the repo.\n\n\nFAQ\nIf you have any questions, please post them to the #portfolio-projects channel on slack.",
    "crumbs": [
      "Portfolio Projects",
      "Portfolio Project 1"
    ]
  },
  {
    "objectID": "notes/01-r-basics.html",
    "href": "notes/01-r-basics.html",
    "title": "R Basics",
    "section": "",
    "text": "In your previous statistics course at Carleton, you likely loaded at least one add-on R package. In this course, we’ll use a lot of tools found in the tidyverse of R packages. To load many of these packages at once, you can use the library(&lt;package_name&gt;) command. So to load the tidyverse we run:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\nNote\n\n\n\nAbove we see a lot of extra info printed when we load the tidyverse. These messages are just telling you what packages are now available to you and warning you that a few functions (e.g., filter) has been replaced by the tidyverse version. We’ll see how to suppress these messages later."
  },
  {
    "objectID": "notes/01-r-basics.html#loading-r-packages",
    "href": "notes/01-r-basics.html#loading-r-packages",
    "title": "R Basics",
    "section": "",
    "text": "In your previous statistics course at Carleton, you likely loaded at least one add-on R package. In this course, we’ll use a lot of tools found in the tidyverse of R packages. To load many of these packages at once, you can use the library(&lt;package_name&gt;) command. So to load the tidyverse we run:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\nNote\n\n\n\nAbove we see a lot of extra info printed when we load the tidyverse. These messages are just telling you what packages are now available to you and warning you that a few functions (e.g., filter) has been replaced by the tidyverse version. We’ll see how to suppress these messages later."
  },
  {
    "objectID": "notes/01-r-basics.html#creating-and-naming-objects",
    "href": "notes/01-r-basics.html#creating-and-naming-objects",
    "title": "R Basics",
    "section": "Creating and naming objects",
    "text": "Creating and naming objects\nAll R statements where you create objects have the form:\n\nobject_name &lt;- value\n\nAt first, we’ll be creating a lot of data objects. For example, we an load a data set containing the ratings for each episode of The Office using the code\n\noffice_ratings &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-17/office_ratings.csv\")\n\nIn this class you will be creating a lot of objects, so you’ll need to come up with names for those objects. Trying to think of informative/meaningful names for objects is hard, but necessary work! Below are the fundamental rules for naming objects in R:\n\nnames can’t start with a number\nnames are case-sensitive\nsome common letters are used internally by R and should be avoided as variable names (c, q, t, C, D, F, T, I)\nThere are reserved words that R won’t let you use for variable names (for, in, while, if, else, repeat, break, next)\nR will let you use the name of a predefined function—but don’t do it!\n\nYou can always check to see if you the name you want to use is already taken via exists():\nFor example lm exists\n\nexists(\"lm\")\n\n[1] TRUE\n\n\nbut carleton_college doesn’t.\n\nexists(\"carleton_college\")\n\n[1] FALSE\n\n\nThere are also a lot of naming styles out there, and if you have coded in another language, you may have already developed a preference. Below is an illustration by Allison Horst\n\n\n\n\n\n\n\n\nI generally following the tidyverse style guide, so you’ll see that I use only lowercase letters, numbers, and _ (snake case)."
  },
  {
    "objectID": "notes/01-r-basics.html#overviews-of-data-frames",
    "href": "notes/01-r-basics.html#overviews-of-data-frames",
    "title": "R Basics",
    "section": "Overviews of data frames",
    "text": "Overviews of data frames\nAbove, you loaded in a data set called office_ratings. Data sets are stored as a special data structure called a data frame. Data frames are the most-commonly used data structure for data analysis in R. For now, think of them like spreadsheets.\nOnce you have your data frame, you can get a quick overview of it using a few commands (below I use data_set as a generic placeholder for the data frame’s name):\n\n\n\n\n\n\nCommand\nDescription\n\n\n\nhead(data_set)\nprint the first 6 rows\n\n\ntail(data_set)\nprint the last 6 rows\n\n\nglimpse(data_set)\na quick overview where columns run down the screen and the data values run across. This allows you to see every column in the data frame.\n\n\nstr(data_set)\na quick overview like glimpse(), but without some of the formatting\n\n\nsummary(data_set)\nquick summary statistics for each column\n\n\ndim(data_set)\nthe number of rows and columns\n\n\nnrow(data_set)\nthe number of rows\n\n\nncol(data_set)\nthe number of columns"
  },
  {
    "objectID": "notes/01-r-basics.html#tibbles",
    "href": "notes/01-r-basics.html#tibbles",
    "title": "R Basics",
    "section": "Tibbles",
    "text": "Tibbles\nA tibble, or a tbl_df is another version of a data frame which is used by default in a lot of the tidyverse packages that we’ll use.\n\nTibbles are data.frames that are lazy and surly: they do less (i.e. they don’t change variable names or types, and don’t do partial matching) and complain more (e.g. when a variable does not exist). This forces you to confront problems earlier, typically leading to cleaner, more expressive code. Tibbles also have an enhanced print() method which makes them easier to use with large datasets containing complex objects.\n\n\n\n\n\n\n\n Check point\n\n\n\nRun the above commands on the office_ratings data set. Compare and contrast the information returned by each command.\n\n\n\n\n\n\n\n\nGetting a spreadsheet\n\n\n\nIn RStudio, you can run the command View(data_set) to pull up a spreadsheet representation of a data frame. You can also click on the name of the data frame in the Environment pane. This can be a great way help you think about the data, and even has some interactive functions (e.g., filtering and searching); however, never include View(data_set) in an .Rmd file!!\n\n\n\n\n\n\n\n\nReview from intro stats\n\n\n\nIn intro stats we used the terms cases (or observations) and variables to describe the rows and columns of a data frame, respectively."
  },
  {
    "objectID": "notes/01-r-basics.html#extracting-pieces-of-data-frames",
    "href": "notes/01-r-basics.html#extracting-pieces-of-data-frames",
    "title": "R Basics",
    "section": "Extracting pieces of data frames",
    "text": "Extracting pieces of data frames\nSince data frames are the fundamental data structure for most analyses in R, it’s important to know how to work with them. You already know how to get an overview of a data frame, but that isn’t always very informative. Often, you want to extract pieces of a data frame, such as a specific column or row.\nExtracting rows\nData frames can be indexed by their row/column numbers. To extract elements of a data frame, the basic syntax is data_set[row.index, column.index]. So, to extract the 10th row of office_ratings we run\n\noffice_ratings[10, ]\n\n# A tibble: 1 × 6\n  season episode title    imdb_rating total_votes air_date  \n   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n1      2       4 The Fire         8.4        2713 2005-10-11\n\n\nNotice that to extract an entire row, we leave the column index position blank.\nWe can also extract multiple rows by creating a vector of row indices. For example, we can extract the first 5 rows via\n\noffice_ratings[1:5, ]\n\n# A tibble: 5 × 6\n  season episode title         imdb_rating total_votes air_date  \n   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n1      1       1 Pilot                 7.6        3706 2005-03-24\n2      1       2 Diversity Day         8.3        3566 2005-03-29\n3      1       3 Health Care           7.9        2983 2005-04-05\n4      1       4 The Alliance          8.1        2886 2005-04-12\n5      1       5 Basketball            8.4        3179 2005-04-19\n\n\nHere, 1:5 create a sequence of integers from 1 to 5.\nWe could also specify arbitrary row index values by combing the values into a vector. For example, we could extract the 1st, 13th, 64th, and 128th rows via\n\noffice_ratings[c(1, 13, 64, 128), ]\n\n# A tibble: 4 × 6\n  season episode title            imdb_rating total_votes air_date  \n   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n1      1       1 Pilot                    7.6        3706 2005-03-24\n2      2       7 The Client               8.6        2631 2005-11-08\n3      4      13 Job Fair                 7.9        1977 2008-05-08\n4      7      11 Classy Christmas         8.9        2138 2010-12-09\n\n\nExtracting columns\nSimilar to extracting rows, we can use a numeric index to extract the columns of a data frame. For example, to extract the 3rd column, we can run\n\noffice_ratings[,3]\n\n# A tibble: 188 × 1\n   title            \n   &lt;chr&gt;            \n 1 Pilot            \n 2 Diversity Day    \n 3 Health Care      \n 4 The Alliance     \n 5 Basketball       \n 6 Hot Girl         \n 7 The Dundies      \n 8 Sexual Harassment\n 9 Office Olympics  \n10 The Fire         \n# ℹ 178 more rows\n\n\nAlternatively, we can pass in the column name in quotes instead of the column number\n\noffice_ratings[,\"title\"]\n\n# A tibble: 188 × 1\n   title            \n   &lt;chr&gt;            \n 1 Pilot            \n 2 Diversity Day    \n 3 Health Care      \n 4 The Alliance     \n 5 Basketball       \n 6 Hot Girl         \n 7 The Dundies      \n 8 Sexual Harassment\n 9 Office Olympics  \n10 The Fire         \n# ℹ 178 more rows\n\n\nNotice that the extracted column is still formatted as a data frame (or tibble). If you want to extract the contents of the column and just have a vector of titles, you have a few options.\n\nYou could use double brackets with the column number:\n\n\noffice_ratings[[3]]\n\n\nYou could use double brackets with the column name in quotes:\n\n\noffice_ratings[[\"title\"]]\n\n\nYou could use the $ extractor with the column name (not in quotes):\n\n\noffice_ratings$title\n\n\n\n\n\n\n\n Check point\n\n\n\n\nExtract the 35th row of office_ratings.\nExtract rows 35, 36, 37, and 38 of office_ratings.\nExtract the imdb_rating column from office ratings using the column index number.\nExtract the imdb_rating column from office ratings using the column name."
  },
  {
    "objectID": "notes/01-r-basics.html#lists",
    "href": "notes/01-r-basics.html#lists",
    "title": "R Basics",
    "section": "Lists",
    "text": "Lists\nIt turns out that data frames are special cases of lists, a more general data structure. In a data frame, each column is an element of the data list and each column must be of the same length. In general, lists can be comprised of elements of vastly different lengths and data types.\nAs an example, let’s construct a list of the faculty in the MAST department and what is being taught this winter.\n\nstat_faculty &lt;- c(\"Kelling\", \"Loy\", \"Luby\", \"Poppick\", \"St. Clair\", \"Wadsworth\")\nstat_courses &lt;- c(120, 220, 230, 250, 285, 330)\nmath_faculty &lt;- c(\"Brooke\", \"Davis\", \"Egge\", \"Gomez-Gonzales\", \"Haunsperger\", \"Johnson\", \n                  \"Meyer\", \"Montee\", \"Shrestha\",\"Terry\", \"Thompson\", \"Turnage-Butterbaugh\")\nmath_courses &lt;- c(101, 106, 111, 120, 210, 211, 232, 236, 240, 241, 251, 321, 333, 395)\n\nmast &lt;- list(stat_faculty = stat_faculty, stat_courses = stat_courses, \n             math_faculty = math_faculty, math_courses = math_courses)\n\nOverview of a list\nYou can get an overview of a list a few ways:\n\n\nglimpse(list_name) and str(list_name) list the elements of the list and the first few entries of each element.\n\n\nglimpse(mast)\n\nList of 4\n $ stat_faculty: chr [1:6] \"Kelling\" \"Loy\" \"Luby\" \"Poppick\" ...\n $ stat_courses: num [1:6] 120 220 230 250 285 330\n $ math_faculty: chr [1:12] \"Brooke\" \"Davis\" \"Egge\" \"Gomez-Gonzales\" ...\n $ math_courses: num [1:14] 101 106 111 120 210 211 232 236 240 241 ...\n\n\n\n\nlength(list_name) will tell you how many elements are in the list\n\n\nlength(mast)\n\n[1] 4\n\n\nExtracting elements of a list\nSince data frames are lists, you’ve already seen how to extract elements of a list. For example, to extract the stat_faculty you could run\n\nmast[[1]]\n\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n\nor\n\nmast[[\"stat_faculty\"]]\n\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you had only used a single bracket above, the returned object would still be a list, which is typically not what we would want.\n\nmast[1]\n\n$stat_faculty\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n\n\n\n\n\n\n\n\n\n Check point\n\n\n\nExtract the statistics courses offered this term."
  },
  {
    "objectID": "notes/01-r-basics.html#vectors",
    "href": "notes/01-r-basics.html#vectors",
    "title": "R Basics",
    "section": "Vectors",
    "text": "Vectors\nThe columns of the office_ratings data frame and the elements of the mast list were comprised of (atomic) vectors. Unlike lists, all elements within a vector share the same type. For example, all names in the stat_faculty vector were character strings and all ratings in the imdb_rating column were numeric. We’ll deal with a variety of types of vectors in this course, including:\n\nnumeric\ncharacter (text)\nlogical (TRUE/FALSE)\n\nExtracting elements of a vector\nJust like with lists (and therefore data frames), we use brackets to extract elements from a vector. As an example, let’s work with the title column from office_ratings.\n\ntitle &lt;- office_ratings$title # vector of titles\n\nTo extract the 111th title, we run\n\ntitle[111]\n\n[1] \"New Leads\"\n\n\nor two extract the 100th through 111th titles, we run\n\ntitle[100:111]\n\n [1] \"Double Date\"          \"Murder\"               \"Shareholder Meeting\" \n [4] \"Scott's Tots\"         \"Secret Santa\"         \"The Banker\"          \n [7] \"Sabre\"                \"Manager and Salesman\" \"The Delivery: Part 1\"\n[10] \"The Delivery: Part 2\" \"St. Patrick's Day\"    \"New Leads\"           \n\n\nNegative indices\nSometimes, we want to “kick out” elements of our vector. To do this, we can use a negative index value. For example,\n\ntitle[-1]\n\nreturns all but the first title—that is, it kicks out the first title. To kick out multiple elements, we need to negate a vector of indices. For example, below we kick out the first 10 titles\n\ntitle[-c(1:10)]\n\nAnd now we kick out the 5th, 50th, and 150th titles\n\ntitle[-c(5, 50, 150)]\n\nThis idea can be adapted to lists and data frames. For example, to kick out the first row of office_ratings, we run\n\noffice_ratings[-1,]\n\n# A tibble: 187 × 6\n   season episode title             imdb_rating total_votes air_date  \n    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n 1      1       2 Diversity Day             8.3        3566 2005-03-29\n 2      1       3 Health Care               7.9        2983 2005-04-05\n 3      1       4 The Alliance              8.1        2886 2005-04-12\n 4      1       5 Basketball                8.4        3179 2005-04-19\n 5      1       6 Hot Girl                  7.8        2852 2005-04-26\n 6      2       1 The Dundies               8.7        3213 2005-09-20\n 7      2       2 Sexual Harassment         8.2        2736 2005-09-27\n 8      2       3 Office Olympics           8.4        2742 2005-10-04\n 9      2       4 The Fire                  8.4        2713 2005-10-11\n10      2       5 Halloween                 8.2        2561 2005-10-18\n# ℹ 177 more rows\n\n\nor to kick out the math courses from the mast list we run\n\nmast[-4]\n\n$stat_faculty\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n$stat_courses\n[1] 120 220 230 250 285 330\n\n$math_faculty\n [1] \"Brooke\"              \"Davis\"               \"Egge\"               \n [4] \"Gomez-Gonzales\"      \"Haunsperger\"         \"Johnson\"            \n [7] \"Meyer\"               \"Montee\"              \"Shrestha\"           \n[10] \"Terry\"               \"Thompson\"            \"Turnage-Butterbaugh\"\n\n\nLogical indices\nIt’s great to be able to extract (or omit) elements using indices, but sometimes we don’t know what index value we should use. For example, if you wanted to extract all of the 300-level statistics courses from the stat_courses vector, you would need to manually determine that positions 2:5 meet that requirement. That’s a lot of work! A better alternative is to allow R to find the elements meeting that requirement using logical operators. Below is a table summarizing common logical operators in R.\n\n\nComparison\nMeaning\n\n\n\n&lt;\nless than\n\n\n&gt;\ngreater than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;=\ngreater than or equal to\n\n\n==\nis equal to\n\n\n!=\nnot equal to\n\n\n\nIn order to extract the 300-level statistics courses, we’ll take two steps:\n\nWe’ll determine whether each course is numbered at least 300,\nthen we’ll use that sequence of TRUEs/FALSEs to extract the course.\n\nSo, first we use the logical operator &gt;= to compare stat_courses and 300. This returns TRUE if the element meets the specification and FALSE otherwise.\n\nstat_courses &gt;= 300\n\n[1] FALSE FALSE FALSE FALSE FALSE  TRUE\n\n\nNow, we can use this vector as our index. Only the TRUE elements will be extracted:\n\nstat_courses[stat_courses &gt;= 300]\n\n[1] 330\n\n\nThe same idea can be used with data frames and lists, just remember how to format the brackets and indices!\n\n\n\n\n\n\n Check point\n\n\n\n\nExtract all statistics courses below 250 from stat_courses.\nExtract all math courses except for 240 (probability) from math_courses.\nExtract all rows from season 3 of The Office."
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "The best place to come for help is Amanda’s office hours! I can help with anything related to the course. You can also check my calendar for one-on-one appointment slots.\n\n\n\nStudents needing help with their Statistics coursework and R/Rstudio questions can get help from Stats Lab Assistants in the Stats Lab in CMC 304. Stats Lab Assistants are primiarily for Stat 120 (Intro Stats), but they may also be able to assist with general R/Rstudio questions.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#where-can-i-get-help",
    "href": "course-faq.html#where-can-i-get-help",
    "title": "FAQ",
    "section": "",
    "text": "The best place to come for help is Amanda’s office hours! I can help with anything related to the course. You can also check my calendar for one-on-one appointment slots.\n\n\n\nStudents needing help with their Statistics coursework and R/Rstudio questions can get help from Stats Lab Assistants in the Stats Lab in CMC 304. Stats Lab Assistants are primiarily for Stat 120 (Intro Stats), but they may also be able to assist with general R/Rstudio questions.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "slides/06/slides06.html#today",
    "href": "slides/06/slides06.html#today",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Today",
    "text": "Today\n\n{patchwork}\nColorblind-friendly color palettes\nWriting alt-text"
  },
  {
    "objectID": "slides/06/slides06.html#small-multiples",
    "href": "slides/06/slides06.html#small-multiples",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Small Multiples",
    "text": "Small Multiples\nEach plot shares aesthetics but shows different subsets of data"
  },
  {
    "objectID": "slides/06/slides06.html#compound-plots",
    "href": "slides/06/slides06.html#compound-plots",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Compound Plots",
    "text": "Compound Plots\nThe plots might share data, but don’t share aesthetics"
  },
  {
    "objectID": "slides/06/slides06.html#compound-plot-example",
    "href": "slides/06/slides06.html#compound-plot-example",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Compound Plot Example",
    "text": "Compound Plot Example\n\nlibrary(palmerpenguins)\nggplot(penguins) + \n  geom_histogram(bins = 20, col = \"white\", aes(x = body_mass_g))\n\n\n\n\n\n\n\nggplot(penguins) + \n  geom_histogram(bins = 20, col = \"white\", aes(x = flipper_length_mm))\n\n\n\n\n\n\n\nggplot(penguins) + \n  geom_point(aes(x = body_mass_g, y = flipper_length_mm))"
  },
  {
    "objectID": "slides/06/slides06.html#patchwork",
    "href": "slides/06/slides06.html#patchwork",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Patchwork",
    "text": "Patchwork\n\nlibrary(patchwork)\np1 = ggplot(penguins) + \n  geom_histogram(bins = 20, col = \"white\", aes(x = body_mass_g))\n\np2 = ggplot(penguins) + \n  geom_histogram(bins = 20, col = \"white\", aes(x = flipper_length_mm))\n\np3 = ggplot(penguins) + \n  geom_point(aes(x = body_mass_g, y = flipper_length_mm))\n\n(p1 + p2)/p3"
  },
  {
    "objectID": "slides/06/slides06.html#patchwork-layout-2",
    "href": "slides/06/slides06.html#patchwork-layout-2",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Patchwork (layout 2)",
    "text": "Patchwork (layout 2)\n\np3 + (p1/p2)\n\n\n\n\n\n\n\n\n\n\nFor more complex layouts, see the “Controlling Layouts” vignette"
  },
  {
    "objectID": "slides/06/slides06.html#patchwork-with-a-shared-legend",
    "href": "slides/06/slides06.html#patchwork-with-a-shared-legend",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Patchwork (with a shared legend)",
    "text": "Patchwork (with a shared legend)\n\np1 = ggplot(penguins) + \n  geom_histogram(bins = 20, col = \"white\", aes(x = body_mass_g, fill = species))\n\np2 = ggplot(penguins) + \n  geom_histogram(bins = 20,  col = \"white\", aes(x = flipper_length_mm, fill = species))\n\np3 = ggplot(penguins) + \n  geom_point(pch = 21, alpha = .9, col = \"white\", aes(x = body_mass_g, y = flipper_length_mm, fill = species)) +\n  theme(legend.position = \"none\")\n\np3 + (p1/p2) + \n  plot_layout(guides = 'collect')"
  },
  {
    "objectID": "slides/06/slides06.html#patchwork-with-annotation",
    "href": "slides/06/slides06.html#patchwork-with-annotation",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Patchwork (with annotation)",
    "text": "Patchwork (with annotation)\n\np3 + (p1/p2) + \n  plot_layout(guides = 'collect') + \n  plot_annotation(\n    title = \"Penguin Plot\",\n    tag_levels = \"A\"\n  )"
  },
  {
    "objectID": "slides/06/slides06.html#patchwork-with-a-common-theme",
    "href": "slides/06/slides06.html#patchwork-with-a-common-theme",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Patchwork (with a common theme)",
    "text": "Patchwork (with a common theme)\n\np3 + (p1/p2) + \n  plot_layout(guides = 'collect') & \n  theme_minimal() &\n  scale_fill_viridis_d()"
  },
  {
    "objectID": "slides/06/slides06.html#but-what-does-this-have-to-do-with-accessibility",
    "href": "slides/06/slides06.html#but-what-does-this-have-to-do-with-accessibility",
    "title": "(Closer to) Accessible Data Viz",
    "section": "But what does this have to do with accessibility?",
    "text": "But what does this have to do with accessibility?\n\nOutput (knitted files, slides, websites, etc.) should be designed to make it as easy as possible for the user to understand your content\nThere’s a cognitive load involved with scrolling or turning a physical page and trying to remember a visual from the previous page\nWhen plots belong together, we should put them together"
  },
  {
    "objectID": "slides/06/slides06.html#color-scales",
    "href": "slides/06/slides06.html#color-scales",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Color scales",
    "text": "Color scales\nUse colorblind friendly color scales (e.g., Okabe Ito, viridis)"
  },
  {
    "objectID": "slides/06/slides06.html#section-1",
    "href": "slides/06/slides06.html#section-1",
    "title": "(Closer to) Accessible Data Viz",
    "section": "",
    "text": "colorBlindness::displayAllColors(scales::hue_pal()(10))"
  },
  {
    "objectID": "slides/06/slides06.html#section-2",
    "href": "slides/06/slides06.html#section-2",
    "title": "(Closer to) Accessible Data Viz",
    "section": "",
    "text": "colorBlindness::displayAllColors(rainbow(10))"
  },
  {
    "objectID": "slides/06/slides06.html#section-3",
    "href": "slides/06/slides06.html#section-3",
    "title": "(Closer to) Accessible Data Viz",
    "section": "",
    "text": "colorBlindness::displayAllColors(colorblindr::palette_OkabeIto)"
  },
  {
    "objectID": "slides/06/slides06.html#section-4",
    "href": "slides/06/slides06.html#section-4",
    "title": "(Closer to) Accessible Data Viz",
    "section": "",
    "text": "colorBlindness::displayAllColors(viridisLite::viridis(10))"
  },
  {
    "objectID": "slides/06/slides06.html#double-encoding",
    "href": "slides/06/slides06.html#double-encoding",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Double encoding",
    "text": "Double encoding\nUse shape and color where possible\n\n\n\nDefault ggplot2 scale\n\n\n\n\n\n\n\n\n\n\nDefault ggplot2 scale with deuteranopia\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mine Çetinkaya-Rundel, Sta313. Generated with {colorblindr}."
  },
  {
    "objectID": "slides/06/slides06.html#use-direct-labeling",
    "href": "slides/06/slides06.html#use-direct-labeling",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Use direct labeling",
    "text": "Use direct labeling\n\nPrefer direct labeling where color is used to display information over a legend\nQuicker to read\nEnsures graph can be understood without reliance on color"
  },
  {
    "objectID": "slides/06/slides06.html#without-direct-labeling",
    "href": "slides/06/slides06.html#without-direct-labeling",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Without direct labeling",
    "text": "Without direct labeling\n\n\nDefault ggplot2 scale\n\n\n\n\n\n\n\n\n\n\nDefault ggplot2 scale with deuteranopia\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mine Çetinkaya-Rundel, Sta313. Generated with {colorblindr}."
  },
  {
    "objectID": "slides/06/slides06.html#with-direct-labeling",
    "href": "slides/06/slides06.html#with-direct-labeling",
    "title": "(Closer to) Accessible Data Viz",
    "section": "With direct labeling",
    "text": "With direct labeling\n\n\nDefault ggplot2 scale\n\n\n\n\n\n\n\n\n\n\nDefault ggplot2 scale with deuteranopia\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mine Çetinkaya-Rundel, Sta313. Generated with {colorblindr}."
  },
  {
    "objectID": "slides/06/slides06.html#use-whitespace-or-pattern-to-separate-elements",
    "href": "slides/06/slides06.html#use-whitespace-or-pattern-to-separate-elements",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Use whitespace or pattern to separate elements",
    "text": "Use whitespace or pattern to separate elements\n\nSeparate elements with whitespace or pattern\nAllows for distinguishing between data without entirely relying on contrast between colors"
  },
  {
    "objectID": "slides/06/slides06.html#without-whitespace",
    "href": "slides/06/slides06.html#without-whitespace",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Without whitespace",
    "text": "Without whitespace\n\n\nDefault ggplot2 scale\n\n\n\n\n\n\n\n\n\n\nDefault ggplot2 scale with tritanopia\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mine Çetinkaya-Rundel, Sta313. Generated with {colorblindr}."
  },
  {
    "objectID": "slides/06/slides06.html#with-whitespace",
    "href": "slides/06/slides06.html#with-whitespace",
    "title": "(Closer to) Accessible Data Viz",
    "section": "With whitespace",
    "text": "With whitespace\n\n\nDefault ggplot2 scale\n\n\n\n\n\n\n\n\n\n\nDefault ggplot2 scale with tritanopia\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mine Çetinkaya-Rundel, Sta313. Generated with {colorblindr}."
  },
  {
    "objectID": "slides/06/slides06.html#alternative-text",
    "href": "slides/06/slides06.html#alternative-text",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Alternative text",
    "text": "Alternative text\n\nIt is read by screen readers in place of images allowing the content and function of the image to be accessible to those with visual or certain cognitive disabilities.\nIt is displayed in place of the image in browsers if the image file is not loaded or when the user has chosen not to view images.\nIt provides a semantic meaning and description to images which can be read by search engines or be used to later determine the content of the image from page context alone.\n\n\n\nSource: WebAIM"
  },
  {
    "objectID": "slides/06/slides06.html#alt-and-surrounding-text",
    "href": "slides/06/slides06.html#alt-and-surrounding-text",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Alt and surrounding text",
    "text": "Alt and surrounding text\nCHART TYPE of TYPE OF DATA where REASON FOR INCLUDING CHART\n(plus link to data source somewhere in the text)\n\nCHART TYPE: It’s helpful for people with partial sight to know what chart type it is and gives context for understanding the rest of the visual.\nTYPE OF DATA: What data is included in the chart? The x and y axis labels may help you figure this out.\nREASON FOR INCLUDING CHART: Think about why you’re including this visual. What does it show that’s meaningful. There should be a point to every visual and you should tell people what to look for.\nLink to data source: Don’t include this in your alt text, but it should be included somewhere in the surrounding text.\n\n\n\nSource: Writing Alt Text for Data Visualization"
  },
  {
    "objectID": "slides/06/slides06.html#alt-text-practice",
    "href": "slides/06/slides06.html#alt-text-practice",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Alt Text Practice",
    "text": "Alt Text Practice\nCHART TYPE of TYPE OF DATA where REASON FOR INCLUDING CHART\n\n\n\n\n\n\n\n\n\n\n\n\n\nA scatterplot\nof median hourly wage of RN’s by year in California, Minnesota, and New York. The x-axis starts at the year 1996 and ends at the year 2020.\nThe three states follow the same linear increasing trend until about 2007, when New York and Minnesota begin to flatten.\n\n\n\n\n\n−+\n01:30"
  },
  {
    "objectID": "slides/06/slides06.html#section-5",
    "href": "slides/06/slides06.html#section-5",
    "title": "(Closer to) Accessible Data Viz",
    "section": "",
    "text": "Accessible Visualization via Natural Language Descriptions: A Four-Level Model of Semantic Content\nAlan Lundgard, MIT CSAIL\nArvind Satyanarayan, MIT CSAIL\nIEEE Transactions on Visualization & Computer Graphics (Proceedings of IEEE VIS), 2021\n\nTo demonstrate how our model can be applied to evaluate the effectiveness of visualization descriptions, we conduct a mixed-methods evaluation with 30 blind and 90 sighted readers, and find that these reader groups differ significantly on which semantic content they rank as most useful. Together, our model and findings suggest that access to meaningful information is strongly reader-specific, and that research in automatic visualization captioning should orient toward descriptions that more richly communicate overall trends and statistics, sensitive to reader preferences."
  },
  {
    "objectID": "slides/06/slides06.html#lets-try-it",
    "href": "slides/06/slides06.html#lets-try-it",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Let’s try it!",
    "text": "Let’s try it!\nCHART TYPE of TYPE OF DATA where REASON FOR INCLUDING CHART\n\n\nTake one graph and two blank cards\nWrite an alt text description of your graph on one of your blank cards.\n\nPlease label with your plot number!\n\nIn two’s or three’s, trade alt text descriptions only\nOn your second blank card, try to draw the graph based on the alt text provided.\nNow, look at the original graph. How’d you do?\nTape the original graphs, alt text, and hand drawn graphs up on the board and have a look around\n\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/06/slides06.html#recap",
    "href": "slides/06/slides06.html#recap",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Recap",
    "text": "Recap\n\nWhat was hard about writing alt text?\nLooking at the graphs, do you notice things that make it harder/easier to write alt text?\nWhat was hard about recreating from the alt text?"
  },
  {
    "objectID": "slides/06/slides06.html#adding-alt-text-to-plots",
    "href": "slides/06/slides06.html#adding-alt-text-to-plots",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Adding alt text to plots",
    "text": "Adding alt text to plots\nShort:\n\n```{r}\n#| fig-alt: Alt text goes here.\n\n# code for plot goes here\n```\n\n\nLonger:\n\n```{r}\n#| fig-alt: |\n#|   Longer alt text goes here. Make sure to add line breaks ~roughly\n#|   80 characters.\n\n# code for plot goes here\n```"
  },
  {
    "objectID": "slides/06/slides06.html#using-okabe-ito-palette",
    "href": "slides/06/slides06.html#using-okabe-ito-palette",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Using Okabe Ito palette",
    "text": "Using Okabe Ito palette\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = hourly_wage_median, color = state)) +\n  geom_point(size = 2) +\n  ggthemes::scale_color_colorblind() +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(\n    x = \"Year\", y = \"Median hourly wage\", color = \"State\",\n    title = \"Median hourly wage of Registered Nurses\"\n  ) +\n  theme(\n    legend.position = c(0.15, 0.75),\n    legend.background = element_rect(fill = \"white\", color = \"white\")\n  )"
  },
  {
    "objectID": "slides/06/slides06.html#double-encoding-1",
    "href": "slides/06/slides06.html#double-encoding-1",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Double Encoding",
    "text": "Double Encoding\nUse both color and shape aesthetics\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = hourly_wage_median, color = state, shape = state)) +\n  geom_point(size = 2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(\n    x = \"Year\", y = \"Median hourly wage\", color = \"State\", shape = \"State\",\n    title = \"Median hourly wage of Registered Nurses\"\n  ) +\n  theme(\n    legend.position = c(0.15, 0.75),\n    legend.background = element_rect(fill = \"white\", color = \"white\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#direct-labeling",
    "href": "slides/06/slides06.html#direct-labeling",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Direct Labeling",
    "text": "Direct Labeling\nCould do “by hand” with annotate(). Alternatively, use geom_text()\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = annual_salary_median, color = state)) +\n  geom_line(show.legend = FALSE, linewidth = 2) +\n  geom_text(\n    data = nurses_subset |&gt; filter(year == max(year)),\n    aes(label = state), hjust = 0, nudge_x = 1,\n    show.legend = FALSE, size = 6\n  ) +\n  scale_y_continuous(labels = scales::label_dollar(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"Year\", y = \"Annual median salary\", color = \"State\",\n    title = \"Annual median salary of Registered Nurses\"\n  ) +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    plot.margin = margin(0.1, 0.9, 0.1, 0.1, \"in\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#direct-labeling-1",
    "href": "slides/06/slides06.html#direct-labeling-1",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Direct Labeling",
    "text": "Direct Labeling\nFirst, filter the data to include the endpoints only. Use the label aesthetic to map to the label in your data (in this case, state). geom_label by default will use the x and y aesthetics defined in ggplot()\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = annual_salary_median, color = state)) +\n  geom_line(show.legend = FALSE, linewidth = 2) +\n  geom_text(\n    data = nurses_subset |&gt; filter(year == max(year)),\n    aes(label = state)\n  ) +\n  scale_y_continuous(labels = scales::label_dollar(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"Year\", y = \"Annual median salary\", color = \"State\",\n    title = \"Annual median salary of Registered Nurses\"\n  ) +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    plot.margin = margin(0.1, 0.9, 0.1, 0.1, \"in\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#direct-labeling-2",
    "href": "slides/06/slides06.html#direct-labeling-2",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Direct Labeling",
    "text": "Direct Labeling\n(Here’s what it looks like if we don’t filter to the endpoints)\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = annual_salary_median, color = state)) +\n  geom_line(show.legend = FALSE, linewidth = 2) +\n  geom_text(\n    aes(label = state)\n  ) +\n  scale_y_continuous(labels = scales::label_dollar(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"Year\", y = \"Annual median salary\", color = \"State\",\n    title = \"Annual median salary of Registered Nurses\"\n  ) +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    plot.margin = margin(0.1, 0.9, 0.1, 0.1, \"in\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#direct-labeling-3",
    "href": "slides/06/slides06.html#direct-labeling-3",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Direct Labeling",
    "text": "Direct Labeling\nhjust=0 means “left justified”, or make the label start at the x-y coordinate you gave it. size = 6 makes the label bigger\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = annual_salary_median, color = state)) +\n  geom_line(show.legend = FALSE, linewidth = 2) +\n  geom_text(\n    data = nurses_subset |&gt; filter(year == max(year)),\n    aes(label = state), \n    hjust = 0, \n    size = 6\n  ) +\n  scale_y_continuous(labels = scales::label_dollar(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"Year\", y = \"Annual median salary\", color = \"State\",\n    title = \"Annual median salary of Registered Nurses\"\n  ) +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    plot.margin = margin(0.1, 0.9, 0.1, 0.1, \"in\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#direct-labeling-4",
    "href": "slides/06/slides06.html#direct-labeling-4",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Direct Labeling",
    "text": "Direct Labeling\nnudge_x = 1 “nudges” each label one unit in the x-direction (so each label is a small distance away from what it’s labeling). show.legend=FALSE tells ggplot not to include the aesthetics for geom_text in the legend\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = annual_salary_median, color = state)) +\n  geom_line(show.legend = FALSE, linewidth = 2) +\n  geom_text(\n    data = nurses_subset |&gt; filter(year == max(year)),\n    aes(label = state), \n    hjust = 0, \n    size = 6,\n    nudge_x = 1,\n    show.legend = FALSE,\n  ) +\n  scale_y_continuous(labels = scales::label_dollar(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"Year\", y = \"Annual median salary\", color = \"State\",\n    title = \"Annual median salary of Registered Nurses\"\n  ) +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    plot.margin = margin(0.1, 0.9, 0.1, 0.1, \"in\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#direct-labeling-5",
    "href": "slides/06/slides06.html#direct-labeling-5",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Direct Labeling",
    "text": "Direct Labeling\nFinally, we have to tell ggplot not to trim the plot, and leave room in the right margin for the labels themselves\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = annual_salary_median, color = state)) +\n  geom_line(show.legend = FALSE, linewidth = 2) +\n  geom_text(\n    data = nurses_subset |&gt; filter(year == max(year)),\n    aes(label = state), \n    hjust = 0, \n    size = 6,\n    nudge_x = 1,\n    show.legend = FALSE,\n  ) +\n  scale_y_continuous(labels = scales::label_dollar(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"Year\", y = \"Annual median salary\", color = \"State\",\n    title = \"Annual median salary of Registered Nurses\"\n  ) +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    plot.margin = margin(0.1, 0.9, 0.1, 0.1, \"in\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#add-whitespace",
    "href": "slides/06/slides06.html#add-whitespace",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Add whitespace",
    "text": "Add whitespace\nSet the color aesthetic to white\n\n\nnurses_subset |&gt;\n  filter(year %in% c(2000, 2010, 2020)) |&gt;\n  ggplot(aes(x = factor(year), y = total_employed_rn, fill = state)) +\n  geom_col(position = \"fill\", color = \"white\", linewidth = 1) +\n  labs(\n    x = \"Year\", y = \"Proportion of Registered Nurses\", fill = \"State\",\n    title = \"Total employed Registered Nurses\"\n  )"
  },
  {
    "objectID": "slides/08/slides08.html#the-college-scorecard",
    "href": "slides/08/slides08.html#the-college-scorecard",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "The College Scorecard",
    "text": "The College Scorecard\n\nThe College Scorecard is designed to increase transparency, putting the power in the hands of the public — from those choosing colleges to those improving college quality — to see how well different schools are serving their students.\n\n\n\nRows: 187\nColumns: 13\n$ unitid         &lt;dbl&gt; 228343, 177719, 367884, 149781, 135364, 212601, 133979,…\n$ school         &lt;chr&gt; \"Southwestern University\", \"Barnes-Jewish College Goldf…\n$ type           &lt;chr&gt; \"private\", \"private\", \"private\", \"private\", \"private\", …\n$ city           &lt;chr&gt; \"Georgetown\", \"Saint Louis\", \"Fort Myers\", \"Wheaton\", \"…\n$ state          &lt;chr&gt; \"TX\", \"MO\", \"FL\", \"IL\", \"GA\", \"PA\", \"FL\", \"CA\", \"IN\", \"…\n$ region         &lt;chr&gt; \"Southwest\", \"Plains\", \"Southeast\", \"Great Lakes\", \"Sou…\n$ admission_rate &lt;dbl&gt; 0.4903, NA, 0.6121, 0.8481, 0.5000, 0.7552, 0.3999, 0.5…\n$ act            &lt;dbl&gt; 26, NA, NA, 29, NA, 23, NA, 22, 25, 31, NA, NA, 20, 20,…\n$ undergrads     &lt;dbl&gt; 1507, 569, 832, 2358, 235, 2866, 1049, 4516, 2120, 1545…\n$ cost           &lt;dbl&gt; 55886, NA, 27425, 49214, NA, 44896, 27460, 58014, 46440…\n$ grad_rate      &lt;dbl&gt; 0.6945, NA, 0.2621, 0.8878, 0.5000, 0.6770, 0.3644, 0.7…\n$ fy_retention   &lt;dbl&gt; 0.8571, NA, 0.4783, 0.9262, NA, 0.8217, 0.6355, 0.8179,…\n$ fedloan        &lt;dbl&gt; 0.5105, 0.8185, 0.6213, 0.4902, 0.5529, 0.5524, 0.6755,…"
  },
  {
    "objectID": "slides/08/slides08.html#function-application-syntax",
    "href": "slides/08/slides08.html#function-application-syntax",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Function-application syntax",
    "text": "Function-application syntax\n\nmn_colleges &lt;- filter(colleges, state == \"MN\")\nmn_colleges &lt;- select(mn_colleges, school, city, admission_rate:fedloan)\nmn_colleges\n\n# A tibble: 3 × 9\n  school      city  admission_rate   act undergrads  cost grad_rate fy_retention\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 Macalester… Sain…          0.323    31       2079 68627     0.908        0.934\n2 North Cent… Minn…          0.899    21        955 36349     0.512        0.8  \n3 University… Croo…          0.684    NA       1839 23290     0.5          0.717\n# ℹ 1 more variable: fedloan &lt;dbl&gt;"
  },
  {
    "objectID": "slides/08/slides08.html#nested-function-calls",
    "href": "slides/08/slides08.html#nested-function-calls",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Nested function calls",
    "text": "Nested function calls\n\nselect(filter(colleges, state == \"MN\"), school, city, admission_rate:fedloan)\n\n# A tibble: 3 × 9\n  school      city  admission_rate   act undergrads  cost grad_rate fy_retention\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 Macalester… Sain…          0.323    31       2079 68627     0.908        0.934\n2 North Cent… Minn…          0.899    21        955 36349     0.512        0.8  \n3 University… Croo…          0.684    NA       1839 23290     0.5          0.717\n# ℹ 1 more variable: fedloan &lt;dbl&gt;"
  },
  {
    "objectID": "slides/08/slides08.html#section",
    "href": "slides/08/slides08.html#section",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "",
    "text": "“dataframe first, dataframe once”\nCombine multiple operations with the pipe\nThink “and then” when reading code"
  },
  {
    "objectID": "slides/08/slides08.html#using",
    "href": "slides/08/slides08.html#using",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Using %>%",
    "text": "Using %&gt;%\n\n%&gt;% passes result on left into first argument of function on right\nChaining functions together lets you read Left-to-right, top-to-bottom"
  },
  {
    "objectID": "slides/08/slides08.html#using-1",
    "href": "slides/08/slides08.html#using-1",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Using %>%",
    "text": "Using %&gt;%\nYou can build up a series of pipes:\n\nmn_colleges &lt;- colleges |&gt;                     # dataframe first and then... #&lt;&lt;\n  filter(state == \"MN\") |&gt;\n  select(school, city, admission_rate:fedloan)"
  },
  {
    "objectID": "slides/08/slides08.html#using-2",
    "href": "slides/08/slides08.html#using-2",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Using %>%",
    "text": "Using %&gt;%\nYou can build up a series of pipes:\n\nmn_colleges &lt;- colleges |&gt;                     # dataframe first and then... #&lt;&lt;\n  filter(state == \"MN\") |&gt;                     # filter out MN colleges and then...#&lt;&lt;\n  select(school, city, admission_rate:fedloan)"
  },
  {
    "objectID": "slides/08/slides08.html#using-3",
    "href": "slides/08/slides08.html#using-3",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Using %>%",
    "text": "Using %&gt;%\nYou can build up a series of pipes:\n\nmn_colleges &lt;- colleges |&gt;                     # dataframe first and then... #&lt;&lt;\n  filter(state == \"MN\") |&gt;                     # filter out MN colleges and then...#&lt;&lt;\n  select(school, city, admission_rate:fedloan) # select the columns of interest #&lt;&lt;"
  },
  {
    "objectID": "slides/08/slides08.html#warm-up",
    "href": "slides/08/slides08.html#warm-up",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Warm Up",
    "text": "Warm Up\n\nRewrite each code chunk as a single chain of commands using |&gt; or %&gt;%\n\nChunk 1:\n\nlog2(sqrt(16))\n\nChunk 2:\n\nlibrary(nycflights23) # need to load, not in pipeline\nmsp &lt;- filter(flights, dest == \"MSP\", carrier == \"DL\")\nmsp_narrow &lt;- select(msp, year, month, day, starts_with(\"sched\"), \n                     contains(\"delay\"), origin)\nmsp_narrow &lt;- relocate(msp_narrow, origin, everything())\n\n\n\n\n−+\n02:30"
  },
  {
    "objectID": "slides/08/slides08.html#the-base-pipe",
    "href": "slides/08/slides08.html#the-base-pipe",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "The |> (base) pipe",
    "text": "The |&gt; (base) pipe\n\n|&gt; pipe operator was introduced in R v4.1\nFor simple uses, acts the same as %&gt;% but is more rigid\nI’ll use both in class examples, but you can use |&gt; or %&gt;%"
  },
  {
    "objectID": "slides/08/slides08.html#your-turn",
    "href": "slides/08/slides08.html#your-turn",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Your turn",
    "text": "Your turn\n\nChain the last two parts together, so that the resulting dataset contains both avg_speed and delay_category. Pipe this new dataset into ggplot() to answer the question “is there a relationship between average speed and how late a flight is delayed?”\nIf you have time, create a new graph which only contains flights to MSP.\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/08/slides08.html#computing-statistics-summarize",
    "href": "slides/08/slides08.html#computing-statistics-summarize",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Computing statistics: summarize",
    "text": "Computing statistics: summarize\n\ncollapse many values down into a statistic\nsummarize(data, newstat = fun(var)) applies the fun function to var variable(s) and returns one value in newstat column"
  },
  {
    "objectID": "slides/08/slides08.html#computing-statistics-summarize-1",
    "href": "slides/08/slides08.html#computing-statistics-summarize-1",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Computing statistics: summarize",
    "text": "Computing statistics: summarize\n\ndplyrbase R\n\n\nAverage and SD of cost in a data frame format:\n\n\ncolleges %&gt;%\n  summarize(\n    avg_cost = mean(cost, na.rm = TRUE), \n    sd_cost = sd(cost , na.rm = TRUE)\n  )\n\n\n# A tibble: 1 × 2\n  avg_cost sd_cost\n     &lt;dbl&gt;   &lt;dbl&gt;\n1   36620.  16244.\n\n\n\n\n\nmean(colleges$cost, na.rm = TRUE)\n\n[1] 36619.72\n\nsd(colleges$cost, na.rm = TRUE)\n\n[1] 16243.9"
  },
  {
    "objectID": "slides/08/slides08.html#your-turn-1",
    "href": "slides/08/slides08.html#your-turn-1",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Your turn",
    "text": "Your turn\n\nUse summarize() to compute statistics about the data:\n\nThe lowest and highest distance traveled\nThe lowest and highest air_time\nThe median dep_delay\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/08/slides08.html#your-turn-2",
    "href": "slides/08/slides08.html#your-turn-2",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Your turn",
    "text": "Your turn\n\nExtract the rows for Delta flights. (Hint: look at the airlines dataset, which is also distributed in the {nycflights23} R package, to find the carrier shortcut code)\nThen use summarize() and a summary function to find:\n\nThe number of flights in this subset\nThe median dep_delay. How does it compare to the overall median?\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/08/slides08.html#across",
    "href": "slides/08/slides08.html#across",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "across()",
    "text": "across()\nIf you want to calculate the same summary statistics for many variables, across() can help!\n\ncolleges %&gt;%\n  summarize(across(admission_rate:fedloan, ~ mean(.x, na.rm = TRUE)))\n\n# A tibble: 1 × 7\n  admission_rate   act undergrads   cost grad_rate fy_retention fedloan\n           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;\n1          0.688  23.2      3559. 36620.     0.550        0.743   0.533"
  },
  {
    "objectID": "slides/08/slides08.html#across-where",
    "href": "slides/08/slides08.html#across-where",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "across() + where()",
    "text": "across() + where()\nwhere() can help you apply functions to all columns of a certain type (e.g., numeric)\n\ncolleges %&gt;%\n  summarize(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)))\n\n# A tibble: 1 × 8\n   unitid admission_rate   act undergrads   cost grad_rate fy_retention fedloan\n    &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;\n1 203732.          0.688  23.2      3559. 36620.     0.550        0.743   0.533\n\n\nBut make sure they make sense!"
  },
  {
    "objectID": "slides/08/slides08.html#group_by",
    "href": "slides/08/slides08.html#group_by",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "group_by()",
    "text": "group_by()\nGroups cases by common values of one or more columns\n\ncolleges %&gt;% \n  group_by(state)\n\n\n\n# A tibble: 187 × 13\n# Groups:   state [44]\n  unitid school   type  city  state region admission_rate   act undergrads  cost\n   &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 228343 Southwe… priv… Geor… TX    South…          0.490    26       1507 55886\n2 177719 Barnes-… priv… Sain… MO    Plains         NA        NA        569    NA\n3 367884 Hodges … priv… Fort… FL    South…          0.612    NA        832 27425\n# ℹ 184 more rows\n# ℹ 3 more variables: grad_rate &lt;dbl&gt;, fy_retention &lt;dbl&gt;, fedloan &lt;dbl&gt;\n\n\nHow does this help us?"
  },
  {
    "objectID": "slides/08/slides08.html#spit-apply-combine",
    "href": "slides/08/slides08.html#spit-apply-combine",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Spit-apply-combine",
    "text": "Spit-apply-combine"
  },
  {
    "objectID": "slides/08/slides08.html#statistics-by-group-group_by-summarize",
    "href": "slides/08/slides08.html#statistics-by-group-group_by-summarize",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Statistics by group: group_by + summarize",
    "text": "Statistics by group: group_by + summarize\nSummary statistics by state\n\n\ncolleges %&gt;%\n  group_by(state) %&gt;%\n  summarize(\n    n_schools = n(),\n    avg_cost = mean(cost, na.rm = TRUE),\n    min_size = min(undergrads, na.rm = TRUE),\n    max_size = max(undergrads, na.rm = TRUE)\n  )\n\n\n# A tibble: 44 × 5\n   state n_schools avg_cost min_size max_size\n   &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 AL            4   22242.      245     7785\n 2 AR            3   43816.      512     1447\n 3 AZ            2   33388.      803    33715\n 4 CA            9   42807.       43    23337\n 5 CO            2   45574      5755     8448\n 6 CT            3   29895.      174     4425\n 7 FL            5   34747.       39     2401\n 8 GA            6   27961       235     9742\n 9 HI            1   36765      1558     1558\n10 IA            1     NaN       339      339\n# ℹ 34 more rows"
  },
  {
    "objectID": "slides/08/slides08.html#your-turn-3",
    "href": "slides/08/slides08.html#your-turn-3",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Your turn",
    "text": "Your turn\n\nUse group_by(), summarize(), and slice_max() to display the five dest airports with the most flights from NYC airports in 2023. Your display should include the median flight delay for these airports.\n\n\n\n\n−+\n03:30"
  },
  {
    "objectID": "slides/08/slides08.html#calculating-counts",
    "href": "slides/08/slides08.html#calculating-counts",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Calculating counts",
    "text": "Calculating counts\ncount() can be used as a short cut to group_by() + summarize() if you are only calculating counts\n\ngroup_by()count()\n\n\n\n\ncolleges %&gt;% \n  group_by(state) %&gt;%\n  summarize(n = n())\n\n\n# A tibble: 44 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AL        4\n 2 AR        3\n 3 AZ        2\n 4 CA        9\n 5 CO        2\n 6 CT        3\n 7 FL        5\n 8 GA        6\n 9 HI        1\n10 IA        1\n# ℹ 34 more rows\n\n\n\n\n\n\ncolleges %&gt;% count(state)\n\n\n# A tibble: 44 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AL        4\n 2 AR        3\n 3 AZ        2\n 4 CA        9\n 5 CO        2\n 6 CT        3\n 7 FL        5\n 8 GA        6\n 9 HI        1\n10 IA        1\n# ℹ 34 more rows"
  },
  {
    "objectID": "slides/08/slides08.html#calculations-by-group-group_by-mutate",
    "href": "slides/08/slides08.html#calculations-by-group-group_by-mutate",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Calculations by group: group_by + mutate",
    "text": "Calculations by group: group_by + mutate\nCalculate z-scores within regions\n\n\ncolleges %&gt;%\n  group_by(region) %&gt;%\n  mutate(z_cost = (cost - mean(cost, na.rm = TRUE)) / sd(cost, na.rm = TRUE))\n\n\n# A tibble: 187 × 14\n# Groups:   region [10]\n   unitid school  type  city  state region admission_rate   act undergrads  cost\n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 228343 Southw… priv… Geor… TX    South…          0.490    26       1507 55886\n 2 177719 Barnes… priv… Sain… MO    Plains         NA        NA        569    NA\n 3 367884 Hodges… priv… Fort… FL    South…          0.612    NA        832 27425\n 4 149781 Wheato… priv… Whea… IL    Great…          0.848    29       2358 49214\n 5 135364 Luther… priv… Lith… GA    South…          0.5      NA        235    NA\n 6 212601 Gannon… priv… Erie  PA    Mid E…          0.755    23       2866 44896\n 7 133979 Florid… priv… Miam… FL    South…          0.400    NA       1049 27460\n 8 117140 Univer… priv… La V… CA    Far W…          0.548    22       4516 58014\n 9 152567 Trine … priv… Ango… IN    Great…          0.816    25       2120 46440\n10 237057 Whitma… priv… Wall… WA    Far W…          0.559    31       1545 68082\n# ℹ 177 more rows\n# ℹ 4 more variables: grad_rate &lt;dbl&gt;, fy_retention &lt;dbl&gt;, fedloan &lt;dbl&gt;,\n#   z_cost &lt;dbl&gt;"
  },
  {
    "objectID": "slides/08/slides08.html#ungroup",
    "href": "slides/08/slides08.html#ungroup",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "ungroup()",
    "text": "ungroup()\n\nOnce data are grouped, they remain grouped until you manually ungroup them\nSome summary functions ungroup them for you, e.g., count() and summarize()\n\n\n\ncolleges %&gt;%\n  group_by(region) %&gt;%\n  mutate(z_cost = (cost - mean(cost, na.rm = TRUE)) / sd(cost, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  select(school, city, cost, z_cost)\n\n\nWith ungroup()Without ungroup()\n\n\n\n\n# A tibble: 187 × 4\n   school                                           city           cost z_cost\n   &lt;chr&gt;                                            &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1 Southwestern University                          Georgetown    55886  1.51 \n 2 Barnes-Jewish College Goldfarb School of Nursing Saint Louis      NA NA    \n 3 Hodges University                                Fort Myers    27425 -0.467\n 4 Wheaton College                                  Wheaton       49214  1.06 \n 5 Luther Rice College & Seminary                   Lithonia         NA NA    \n 6 Gannon University                                Erie          44896  0.261\n 7 Florida Memorial University                      Miami Gardens 27460 -0.465\n 8 University of La Verne                           La Verne      58014  1.14 \n 9 Trine University                                 Angola        46440  0.849\n10 Whitman College                                  Walla Walla   68082  1.79 \n# ℹ 177 more rows\n\n\n\n\n\n\n# A tibble: 187 × 5\n# Groups:   region [10]\n   region      school                                         city   cost z_cost\n   &lt;chr&gt;       &lt;chr&gt;                                          &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Southwest   Southwestern University                        Geor… 55886  1.51 \n 2 Plains      Barnes-Jewish College Goldfarb School of Nurs… Sain…    NA NA    \n 3 Southeast   Hodges University                              Fort… 27425 -0.467\n 4 Great Lakes Wheaton College                                Whea… 49214  1.06 \n 5 Southeast   Luther Rice College & Seminary                 Lith…    NA NA    \n 6 Mid East    Gannon University                              Erie  44896  0.261\n 7 Southeast   Florida Memorial University                    Miam… 27460 -0.465\n 8 Far West    University of La Verne                         La V… 58014  1.14 \n 9 Great Lakes Trine University                               Ango… 46440  0.849\n10 Far West    Whitman College                                Wall… 68082  1.79 \n# ℹ 177 more rows"
  },
  {
    "objectID": "slides/08/slides08.html#aside-code-commenting",
    "href": "slides/08/slides08.html#aside-code-commenting",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Aside: code commenting",
    "text": "Aside: code commenting\nIn R, you can use # for adding comments to your code. Any text that follows the # will be printed as-is and won’t be run as code. This is useful for leaving comments in your code and for temporarily disabling certain lines of code for debugging.\n\n\ncolleges %&gt;%\n  group_by(state) %&gt;%\n  summarize(\n    n_schools = n(),                               # This is a reminder to me\n    # avg_cost = mean(cost, na.rm = TRUE),         # This line isn't run\n    min_size = min(undergrads, na.rm = TRUE),\n    max_size = max(undergrads, na.rm = TRUE)\n  )\n\n\n# A tibble: 44 × 4\n   state n_schools min_size max_size\n   &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 AL            4      245     7785\n 2 AR            3      512     1447\n 3 AZ            2      803    33715\n 4 CA            9       43    23337\n 5 CO            2     5755     8448\n 6 CT            3      174     4425\n 7 FL            5       39     2401\n 8 GA            6      235     9742\n 9 HI            1     1558     1558\n10 IA            1      339      339\n# ℹ 34 more rows"
  },
  {
    "objectID": "slides/08/slides08.html#aside-code-commenting-1",
    "href": "slides/08/slides08.html#aside-code-commenting-1",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Aside: code commenting",
    "text": "Aside: code commenting\nAnd it works especially well when you’ve used chaining in your code\n\n\ncolleges %&gt;%\n  #group_by(state) %&gt;%\n  summarize(\n    n_schools = n(),                               \n    avg_cost = mean(cost, na.rm = TRUE),         \n    min_size = min(undergrads, na.rm = TRUE),\n    max_size = max(undergrads, na.rm = TRUE)\n  )\n\n\n# A tibble: 1 × 4\n  n_schools avg_cost min_size max_size\n      &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1       187   36620.        0    33715"
  },
  {
    "objectID": "slides/08/slides08.html#which-is-easier-to-read",
    "href": "slides/08/slides08.html#which-is-easier-to-read",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Which is easier to read?",
    "text": "Which is easier to read?\n\nOption AOption B\n\n\n\ngroup_by(colleges, region) %&gt;% mutate(z_cost = (cost - mean(cost, na.rm = TRUE)) / sd(cost, na.rm = TRUE)) %&gt;% ungroup() \n\n# A tibble: 187 × 14\n   unitid school  type  city  state region admission_rate   act undergrads  cost\n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 228343 Southw… priv… Geor… TX    South…          0.490    26       1507 55886\n 2 177719 Barnes… priv… Sain… MO    Plains         NA        NA        569    NA\n 3 367884 Hodges… priv… Fort… FL    South…          0.612    NA        832 27425\n 4 149781 Wheato… priv… Whea… IL    Great…          0.848    29       2358 49214\n 5 135364 Luther… priv… Lith… GA    South…          0.5      NA        235    NA\n 6 212601 Gannon… priv… Erie  PA    Mid E…          0.755    23       2866 44896\n 7 133979 Florid… priv… Miam… FL    South…          0.400    NA       1049 27460\n 8 117140 Univer… priv… La V… CA    Far W…          0.548    22       4516 58014\n 9 152567 Trine … priv… Ango… IN    Great…          0.816    25       2120 46440\n10 237057 Whitma… priv… Wall… WA    Far W…          0.559    31       1545 68082\n# ℹ 177 more rows\n# ℹ 4 more variables: grad_rate &lt;dbl&gt;, fy_retention &lt;dbl&gt;, fedloan &lt;dbl&gt;,\n#   z_cost &lt;dbl&gt;\n\n\n\n\n\ncolleges %&gt;%\n  group_by(region) %&gt;%\n  mutate(z_cost = (cost - mean(cost, na.rm = TRUE)) / sd(cost, na.rm = TRUE)) %&gt;%\n  ungroup() #&lt;&lt;\n\n# A tibble: 187 × 14\n   unitid school  type  city  state region admission_rate   act undergrads  cost\n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 228343 Southw… priv… Geor… TX    South…          0.490    26       1507 55886\n 2 177719 Barnes… priv… Sain… MO    Plains         NA        NA        569    NA\n 3 367884 Hodges… priv… Fort… FL    South…          0.612    NA        832 27425\n 4 149781 Wheato… priv… Whea… IL    Great…          0.848    29       2358 49214\n 5 135364 Luther… priv… Lith… GA    South…          0.5      NA        235    NA\n 6 212601 Gannon… priv… Erie  PA    Mid E…          0.755    23       2866 44896\n 7 133979 Florid… priv… Miam… FL    South…          0.400    NA       1049 27460\n 8 117140 Univer… priv… La V… CA    Far W…          0.548    22       4516 58014\n 9 152567 Trine … priv… Ango… IN    Great…          0.816    25       2120 46440\n10 237057 Whitma… priv… Wall… WA    Far W…          0.559    31       1545 68082\n# ℹ 177 more rows\n# ℹ 4 more variables: grad_rate &lt;dbl&gt;, fy_retention &lt;dbl&gt;, fedloan &lt;dbl&gt;,\n#   z_cost &lt;dbl&gt;"
  },
  {
    "objectID": "slides/08/slides08.html#which-is-easier-to-read-1",
    "href": "slides/08/slides08.html#which-is-easier-to-read-1",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Which is easier to read?",
    "text": "Which is easier to read?\n\nOption AOption B\n\n\n\npalmerpenguins::penguins |&gt;\n  filter(species == \"Adelie\") |&gt;\n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point() + \n  scale_color_viridis_d(option = \"magma\",end = .75) + \n  theme_bw(base_family = \"Times\") + \n  theme(legend.position = \"none\",\n        panel.grid.minor = element_blank(),\n        panel.grid.major.x = element_blank(),\n        axis.title.x = element_text(color = \"darkred\"))\n\n\n\n\npalmerpenguins::penguins |&gt;\n  filter(species == \"Adelie\") |&gt;\n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point() + scale_color_viridis_d(option = \"magma\",end = .75) + \n  theme_bw(base_family = \"Times\") + \n  theme(legend.position = \"none\", panel.grid.minor = element_blank(), panel.grid.major.x = element_blank(),\n        axis.title.x = element_text(color = \"darkred\"))"
  },
  {
    "objectID": "slides/08/slides08.html#style.tidyverse.org",
    "href": "slides/08/slides08.html#style.tidyverse.org",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "<style.tidyverse.org>",
    "text": "&lt;style.tidyverse.org&gt;"
  },
  {
    "objectID": "slides/08/slides08.html#example-pipes-and-whitespace",
    "href": "slides/08/slides08.html#example-pipes-and-whitespace",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Example: Pipes and whitespace",
    "text": "Example: Pipes and whitespace\n|&gt; should always have a space before it, and should usually be followed by a new line. After the first step, each line should be indented by two spaces.\nGood:\n\niris |&gt;\n  summarize(across(where(is.numeric), mean), .by = Species) |&gt;\n  pivot_longer(!Species, names_to = \"measure\", values_to = \"value\") |&gt;\n  arrange(value)\n\nBad:\n\niris |&gt; summarize(across(where(is.numeric), mean), .by = Species) |&gt;\npivot_longer(!Species, names_to = \"measure\", values_to = \"value\") |&gt;\narrange(value)"
  },
  {
    "objectID": "slides/08/slides08.html#example-long-lines",
    "href": "slides/08/slides08.html#example-long-lines",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Example: long lines",
    "text": "Example: long lines\nIf the arguments to a function don’t all fit on one line, put each argument on its own line and indent:\nGood:\n\niris |&gt;\n  summarise(\n    Sepal.Length = mean(Sepal.Length),\n    Sepal.Width = mean(Sepal.Width),\n    .by = Species\n  )\n\nBad:\n\niris |&gt;\n  summarise(Sepal.Length = mean(Sepal.Length), Sepal.Width = mean(Sepal.Width), .by = Species)"
  },
  {
    "objectID": "slides/08/slides08.html#ggplot2-whitespace-and-indenting",
    "href": "slides/08/slides08.html#ggplot2-whitespace-and-indenting",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "ggplot2 whitespace and indenting",
    "text": "ggplot2 whitespace and indenting\n+ should always have a space before it, and should be followed by a new line. After the first step, each line should be indented by two spaces.\nIf you are creating a ggplot off of a dplyr pipeline, there should only be one level of indentation.\nGood:\n\niris |&gt;\n  filter(Species == \"setosa\") |&gt;\n  ggplot(aes(x = Sepal.Width, y = Sepal.Length)) +\n  geom_point()\n\nBad:\n\niris |&gt;\n  filter(Species == \"setosa\") |&gt;\n  ggplot(aes(x = Sepal.Width, y = Sepal.Length)) +\n    geom_point()\n\nBad:\n\niris |&gt;\n  filter(Species == \"setosa\") |&gt;\n  ggplot(aes(x = Sepal.Width, y = Sepal.Length)) + geom_point()"
  },
  {
    "objectID": "slides/08/slides08.html#ggplot2-long-lines",
    "href": "slides/08/slides08.html#ggplot2-long-lines",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "ggplot2 long lines",
    "text": "ggplot2 long lines\nIf the arguments to a ggplot2 layer don’t all fit on one line, put each argument on its own line and indent:\nGood:\n\niris |&gt;\n  ggplot(aes(x = Sepal.Width, y = Sepal.Length, color = Species)) +\n  geom_point() +\n  labs(\n    x = \"Sepal width, in cm\",\n    y = \"Sepal length, in cm\",\n    title = \"Sepal length vs. width of irises\"\n  )\n\nBad:\n\niris |&gt;\n  ggplot(aes(x = Sepal.Width, y = Sepal.Length, color = Species)) +\n  geom_point() +\n  labs(x = \"Sepal width, in cm\", y = \"Sepal length, in cm\", title = \"Sepal length vs. width of irises\")"
  },
  {
    "objectID": "slides/08/slides08.html#code-style-summary",
    "href": "slides/08/slides08.html#code-style-summary",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Code style summary",
    "text": "Code style summary\n\nAll code style guides are opinionated and subjective\nUsing consistent style makes it easier for collaborators (including future you!) to read and understand your code\nTry to follow the tidyverse style guide in this class"
  },
  {
    "objectID": "slides/08/slides08.html#a-shortcut",
    "href": "slides/08/slides08.html#a-shortcut",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "A shortcut",
    "text": "A shortcut\nIn RStudio,\n\nHighlight the code that you want to reformat\nGo to “code –&gt; reformat code”\nMarvel in wonder\n\n\nTry it\n\nReformat your code from the flights activity so far according to the tidyverse style guide"
  },
  {
    "objectID": "slides/07/slides07.html#dplyr",
    "href": "slides/07/slides07.html#dplyr",
    "title": "Data Wrangling: Verbs",
    "section": "{dplyr}",
    "text": "{dplyr}\n\n\n\nA package that transforms data\nImplements a grammar of transforming tabular data\nPart of the tidyverse"
  },
  {
    "objectID": "slides/07/slides07.html#warm-up",
    "href": "slides/07/slides07.html#warm-up",
    "title": "Data Wrangling: Verbs",
    "section": "Warm up",
    "text": "Warm up\n\nWith your neighbors, identify the data verb (function) that does the following:\n\nPicks rows by their values\nReorders the rows\nPicks variables by their names\nCreates new variables with functions of existing variables\n\n\n\n\n\n−+\n02:30"
  },
  {
    "objectID": "slides/07/slides07.html#logical-tests",
    "href": "slides/07/slides07.html#logical-tests",
    "title": "Data Wrangling: Verbs",
    "section": "Logical tests",
    "text": "Logical tests\n\n\nFor help:\n?Comparison\n\n\n\n\nSyntax\nDescription\n\n\n\n\nx &lt; y\nless than\n\n\nx &gt; y\ngreater than\n\n\nx &lt;= y\nless than or equal to\n\n\nx &gt;= y\ngreater than or equal to\n\n\nx == y\nequal to\n\n\nx != y\nnot equal to\n\n\nx %in% y\ngroup membership\n\n\nis.na(x)\nis NA (missing)\n\n\n!is.na(x)\nis not NA"
  },
  {
    "objectID": "slides/07/slides07.html#your-turn",
    "href": "slides/07/slides07.html#your-turn",
    "title": "Data Wrangling: Verbs",
    "section": "Your turn:",
    "text": "Your turn:\n\nWith your neighbors, use filter() to wrangle the nycflights23::flights data frame.\n\nFind all flights that had an arrival delay of two or more hours.\nFind all flights to MSP\nFind all flights that arrived more than two hours late, but left less than one hour late\n(if time) Find all flights that were delayed by at least an hour, but made up over 30 minutes in flight.\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/07/slides07.html#slice.data-...",
    "href": "slides/07/slides07.html#slice.data-...",
    "title": "Data Wrangling: Verbs",
    "section": "slice(.data, ...)",
    "text": "slice(.data, ...)\nExtract (omit) rows by row number"
  },
  {
    "objectID": "slides/07/slides07.html#slicing-flights-data",
    "href": "slides/07/slides07.html#slicing-flights-data",
    "title": "Data Wrangling: Verbs",
    "section": "Slicing flights data",
    "text": "Slicing flights data\nExtracting rows 10 to 20\n\nslice(flights, 10:20)\n\n# A tibble: 11 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1      547            545         2      845            852\n 2  2023     1     1      549            559       -10      905            901\n 3  2023     1     1      551            600        -9      846            859\n 4  2023     1     1      552            559        -7      857            911\n 5  2023     1     1      554            600        -6      914            920\n 6  2023     1     1      554            600        -6      725            735\n 7  2023     1     1      558            605        -7      719            750\n 8  2023     1     1      600            600         0      729            752\n 9  2023     1     1      600            600         0      745            755\n10  2023     1     1      600            600         0      810            840\n11  2023     1     1      603            605        -2      800            818\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#slicing-flights-data-1",
    "href": "slides/07/slides07.html#slicing-flights-data-1",
    "title": "Data Wrangling: Verbs",
    "section": "Slicing flights data",
    "text": "Slicing flights data\nOmitting rows 100 to 1000\n\nslice(flights, -c(100:1000))\n\n# A tibble: 434,451 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1        1           2038       203      328              3\n 2  2023     1     1       18           2300        78      228            135\n 3  2023     1     1       31           2344        47      500            426\n 4  2023     1     1       33           2140       173      238           2352\n 5  2023     1     1       36           2048       228      223           2252\n 6  2023     1     1      503            500         3      808            815\n 7  2023     1     1      520            510        10      948            949\n 8  2023     1     1      524            530        -6      645            710\n 9  2023     1     1      537            520        17      926            818\n10  2023     1     1      547            545         2      845            852\n# ℹ 434,441 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#select",
    "href": "slides/07/slides07.html#select",
    "title": "Data Wrangling: Verbs",
    "section": "select()",
    "text": "select()\nExtract columns by name or number\n\nselect(.data, ...)\n\n\n\n\nSource: software carpentry"
  },
  {
    "objectID": "slides/07/slides07.html#storms-data",
    "href": "slides/07/slides07.html#storms-data",
    "title": "Data Wrangling: Verbs",
    "section": "Storms data",
    "text": "Storms data\n\nglimpse(storms)\n\nRows: 19,537\nColumns: 13\n$ name                         &lt;chr&gt; \"Amy\", \"Amy\", \"Amy\", \"Amy\", \"Amy\", \"Amy\",…\n$ year                         &lt;dbl&gt; 1975, 1975, 1975, 1975, 1975, 1975, 1975,…\n$ month                        &lt;dbl&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,…\n$ day                          &lt;int&gt; 27, 27, 27, 27, 28, 28, 28, 28, 29, 29, 2…\n$ hour                         &lt;dbl&gt; 0, 6, 12, 18, 0, 6, 12, 18, 0, 6, 12, 18,…\n$ lat                          &lt;dbl&gt; 27.5, 28.5, 29.5, 30.5, 31.5, 32.4, 33.3,…\n$ long                         &lt;dbl&gt; -79.0, -79.0, -79.0, -79.0, -78.8, -78.7,…\n$ status                       &lt;fct&gt; tropical depression, tropical depression,…\n$ category                     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wind                         &lt;int&gt; 25, 25, 25, 25, 25, 25, 25, 30, 35, 40, 4…\n$ pressure                     &lt;int&gt; 1013, 1013, 1013, 1013, 1012, 1012, 1011,…\n$ tropicalstorm_force_diameter &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ hurricane_force_diameter     &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\n\n\nSubset of the NOAA Atlantic hurricane database best track data, https://www.nhc.noaa.gov/data/#hurda"
  },
  {
    "objectID": "slides/07/slides07.html#select-helpers",
    "href": "slides/07/slides07.html#select-helpers",
    "title": "Data Wrangling: Verbs",
    "section": "select() helpers",
    "text": "select() helpers\n\n:-starts_with()ends_with()contains()\n\n\nselect range of columns\n\nselect(storms, status:pressure)\n\n# A tibble: 19,537 × 4\n   status              category  wind pressure\n   &lt;fct&gt;                  &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 tropical depression       NA    25     1013\n 2 tropical depression       NA    25     1013\n 3 tropical depression       NA    25     1013\n 4 tropical depression       NA    25     1013\n 5 tropical depression       NA    25     1012\n 6 tropical depression       NA    25     1012\n 7 tropical depression       NA    25     1011\n 8 tropical depression       NA    30     1006\n 9 tropical storm            NA    35     1004\n10 tropical storm            NA    40     1002\n# ℹ 19,527 more rows\n\n\n\n\nselect every column but\n\nselect(storms, -c(status, pressure))\n\n# A tibble: 19,537 × 11\n   name   year month   day  hour   lat  long category  wind\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;\n 1 Amy    1975     6    27     0  27.5 -79         NA    25\n 2 Amy    1975     6    27     6  28.5 -79         NA    25\n 3 Amy    1975     6    27    12  29.5 -79         NA    25\n 4 Amy    1975     6    27    18  30.5 -79         NA    25\n 5 Amy    1975     6    28     0  31.5 -78.8       NA    25\n 6 Amy    1975     6    28     6  32.4 -78.7       NA    25\n 7 Amy    1975     6    28    12  33.3 -78         NA    25\n 8 Amy    1975     6    28    18  34   -77         NA    30\n 9 Amy    1975     6    29     0  34.4 -75.8       NA    35\n10 Amy    1975     6    29     6  34   -74.8       NA    40\n# ℹ 19,527 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;\n\n\n\n\nselect columns that start with…\n\nselect(storms, starts_with(\"w\"))\n\n# A tibble: 19,537 × 1\n    wind\n   &lt;int&gt;\n 1    25\n 2    25\n 3    25\n 4    25\n 5    25\n 6    25\n 7    25\n 8    30\n 9    35\n10    40\n# ℹ 19,527 more rows\n\n\n\n\nselect columns that end with…\n\nselect(storms, ends_with(\"e\"))\n\n# A tibble: 19,537 × 2\n   name  pressure\n   &lt;chr&gt;    &lt;int&gt;\n 1 Amy       1013\n 2 Amy       1013\n 3 Amy       1013\n 4 Amy       1013\n 5 Amy       1012\n 6 Amy       1012\n 7 Amy       1011\n 8 Amy       1006\n 9 Amy       1004\n10 Amy       1002\n# ℹ 19,527 more rows\n\n\n\n\nselect columns whose names contain…\n\nselect(storms, contains(\"d\"))\n\n# A tibble: 19,537 × 4\n     day  wind tropicalstorm_force_diameter hurricane_force_diameter\n   &lt;int&gt; &lt;int&gt;                        &lt;int&gt;                    &lt;int&gt;\n 1    27    25                           NA                       NA\n 2    27    25                           NA                       NA\n 3    27    25                           NA                       NA\n 4    27    25                           NA                       NA\n 5    28    25                           NA                       NA\n 6    28    25                           NA                       NA\n 7    28    25                           NA                       NA\n 8    28    30                           NA                       NA\n 9    29    35                           NA                       NA\n10    29    40                           NA                       NA\n# ℹ 19,527 more rows"
  },
  {
    "objectID": "slides/07/slides07.html#try-it",
    "href": "slides/07/slides07.html#try-it",
    "title": "Data Wrangling: Verbs",
    "section": "Try it:",
    "text": "Try it:\n\nBrainstorm as many ways as possible to select() the following columns from flight:\n\ndep_time\ndep_delay\narr_time\narr_delay\n\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/07/slides07.html#arrange",
    "href": "slides/07/slides07.html#arrange",
    "title": "Data Wrangling: Verbs",
    "section": "arrange()",
    "text": "arrange()\nOrder rows from smallest to largest"
  },
  {
    "objectID": "slides/07/slides07.html#arranging-by-wind-speed",
    "href": "slides/07/slides07.html#arranging-by-wind-speed",
    "title": "Data Wrangling: Verbs",
    "section": "Arranging by wind speed",
    "text": "Arranging by wind speed\nBy default, arrange orders in ascending order\n\nOriginal DataAscendingDescending\n\n\n\nstorms\n\n# A tibble: 19,537 × 13\n   name   year month   day  hour   lat  long status      category  wind pressure\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;          &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Amy    1975     6    27     0  27.5 -79   tropical d…       NA    25     1013\n 2 Amy    1975     6    27     6  28.5 -79   tropical d…       NA    25     1013\n 3 Amy    1975     6    27    12  29.5 -79   tropical d…       NA    25     1013\n 4 Amy    1975     6    27    18  30.5 -79   tropical d…       NA    25     1013\n 5 Amy    1975     6    28     0  31.5 -78.8 tropical d…       NA    25     1012\n 6 Amy    1975     6    28     6  32.4 -78.7 tropical d…       NA    25     1012\n 7 Amy    1975     6    28    12  33.3 -78   tropical d…       NA    25     1011\n 8 Amy    1975     6    28    18  34   -77   tropical d…       NA    30     1006\n 9 Amy    1975     6    29     0  34.4 -75.8 tropical s…       NA    35     1004\n10 Amy    1975     6    29     6  34   -74.8 tropical s…       NA    40     1002\n# ℹ 19,527 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;\n\n\n\n\n\narrange(storms, wind)\n\n# A tibble: 19,537 × 13\n   name      year month   day  hour   lat  long status   category  wind pressure\n   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Bonnie    1986     6    28     6  36.5 -91.3 tropica…       NA    10     1013\n 2 Bonnie    1986     6    28    12  37.2 -90   tropica…       NA    10     1012\n 3 Charley   1986     8    13    12  30.1 -84   subtrop…       NA    10     1009\n 4 Charley   1986     8    13    18  30.8 -84   subtrop…       NA    10     1012\n 5 Charley   1986     8    14     0  31.4 -83.6 subtrop…       NA    10     1013\n 6 Charley   1986     8    14     6  32   -83.1 subtrop…       NA    10     1014\n 7 Charley   1986     8    14    12  32.5 -82.5 subtrop…       NA    10     1015\n 8 Charley   1986     8    14    18  32.4 -82   subtrop…       NA    10     1015\n 9 AL031987  1987     8    16    18  30.9 -83.2 tropica…       NA    10     1014\n10 AL031987  1987     8    17     0  31.4 -82.9 tropica…       NA    10     1015\n# ℹ 19,527 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;\n\n\n\n\n\narrange(storms, desc(wind))\n\n# A tibble: 19,537 × 13\n   name     year month   day  hour   lat  long status    category  wind pressure\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;        &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Allen    1980     8     7    18  21.8 -86.4 hurricane        5   165      899\n 2 Gilbert  1988     9    14     0  19.7 -83.8 hurricane        5   160      888\n 3 Wilma    2005    10    19    12  17.3 -82.8 hurricane        5   160      882\n 4 Dorian   2019     9     1    16  26.5 -77   hurricane        5   160      910\n 5 Dorian   2019     9     1    18  26.5 -77.1 hurricane        5   160      910\n 6 Allen    1980     8     5    12  15.9 -70.5 hurricane        5   155      932\n 7 Allen    1980     8     7    12  21   -84.8 hurricane        5   155      910\n 8 Allen    1980     8     8     0  22.2 -87.9 hurricane        5   155      920\n 9 Allen    1980     8     9     6  25   -94.2 hurricane        5   155      909\n10 Gilbert  1988     9    14     6  19.9 -85.3 hurricane        5   155      889\n# ℹ 19,527 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#try-it-1",
    "href": "slides/07/slides07.html#try-it-1",
    "title": "Data Wrangling: Verbs",
    "section": "Try it:",
    "text": "Try it:\n\nUse arrange to answer the following questions:\n\nWhich flights traveled the farthest?\nWhich traveled the shortest?\nWhich flights lasted the longest?\nWhich lasted the shortest?\n\n\n\n\n\n−+\n02:30"
  },
  {
    "objectID": "slides/07/slides07.html#section-3",
    "href": "slides/07/slides07.html#section-3",
    "title": "Data Wrangling: Verbs",
    "section": "",
    "text": "slice_min(.data, order_by, n)\nselect rows with n smallest values of a variable\nslice_max(.data, order_by, n)\nselect rows with n largest values of a variable"
  },
  {
    "objectID": "slides/07/slides07.html#continuing-storms-example",
    "href": "slides/07/slides07.html#continuing-storms-example",
    "title": "Data Wrangling: Verbs",
    "section": "Continuing storms example",
    "text": "Continuing storms example\n\nslice_maxslice_min\n\n\nExtracting storms with 3 highest wind speeds\n\nslice_max(storms, wind, n = 3)\n\n# A tibble: 5 × 13\n  name     year month   day  hour   lat  long status    category  wind pressure\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;        &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n1 Allen    1980     8     7    18  21.8 -86.4 hurricane        5   165      899\n2 Gilbert  1988     9    14     0  19.7 -83.8 hurricane        5   160      888\n3 Wilma    2005    10    19    12  17.3 -82.8 hurricane        5   160      882\n4 Dorian   2019     9     1    16  26.5 -77   hurricane        5   160      910\n5 Dorian   2019     9     1    18  26.5 -77.1 hurricane        5   160      910\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;\n\n\n\n\nExtracting storms with the lowest wind speed\n\nslice_min(storms, wind, n = 1)\n\n# A tibble: 61 × 13\n   name      year month   day  hour   lat  long status   category  wind pressure\n   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Bonnie    1986     6    28     6  36.5 -91.3 tropica…       NA    10     1013\n 2 Bonnie    1986     6    28    12  37.2 -90   tropica…       NA    10     1012\n 3 Charley   1986     8    13    12  30.1 -84   subtrop…       NA    10     1009\n 4 Charley   1986     8    13    18  30.8 -84   subtrop…       NA    10     1012\n 5 Charley   1986     8    14     0  31.4 -83.6 subtrop…       NA    10     1013\n 6 Charley   1986     8    14     6  32   -83.1 subtrop…       NA    10     1014\n 7 Charley   1986     8    14    12  32.5 -82.5 subtrop…       NA    10     1015\n 8 Charley   1986     8    14    18  32.4 -82   subtrop…       NA    10     1015\n 9 AL031987  1987     8    16    18  30.9 -83.2 tropica…       NA    10     1014\n10 AL031987  1987     8    17     0  31.4 -82.9 tropica…       NA    10     1015\n# ℹ 51 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#star-wars-character-bmi",
    "href": "slides/07/slides07.html#star-wars-character-bmi",
    "title": "Data Wrangling: Verbs",
    "section": "Star Wars character BMI",
    "text": "Star Wars character BMI\n{dplyr} includes a starwars data frame with characteristics of 87 Star Wars characters\n\nglimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"A New Hope\", \"The Empire Strikes Back\", \"Return of the J…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…"
  },
  {
    "objectID": "slides/07/slides07.html#star-wars-character-bmi-1",
    "href": "slides/07/slides07.html#star-wars-character-bmi-1",
    "title": "Data Wrangling: Verbs",
    "section": "Star Wars character BMI",
    "text": "Star Wars character BMI\nSuppose we want to calculate the BMI for each character, \\(\\text{BMI} = \\dfrac{\\text{mass (kg)}}{\\text{height (m)}^2}\\)\n\nstarwars &lt;- mutate(starwars, bmi = mass / (height / 100)^2)\n\n\nselect(starwars, name, bmi, everything())\n\n# A tibble: 87 × 15\n   name        bmi height  mass hair_color skin_color eye_color birth_year sex  \n   &lt;chr&gt;     &lt;dbl&gt;  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;\n 1 Luke Sky…  26.0    172    77 blond      fair       blue            19   male \n 2 C-3PO      26.9    167    75 &lt;NA&gt;       gold       yellow         112   none \n 3 R2-D2      34.7     96    32 &lt;NA&gt;       white, bl… red             33   none \n 4 Darth Va…  33.3    202   136 none       white      yellow          41.9 male \n 5 Leia Org…  21.8    150    49 brown      light      brown           19   fema…\n 6 Owen Lars  37.9    178   120 brown, gr… light      blue            52   male \n 7 Beru Whi…  27.5    165    75 brown      light      blue            47   fema…\n 8 R5-D4      34.0     97    32 &lt;NA&gt;       white, red red             NA   none \n 9 Biggs Da…  25.1    183    84 black      light      brown           24   male \n10 Obi-Wan …  23.2    182    77 auburn, w… fair       blue-gray       57   male \n# ℹ 77 more rows\n# ℹ 6 more variables: gender &lt;chr&gt;, homeworld &lt;chr&gt;, species &lt;chr&gt;,\n#   films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#try-it-2",
    "href": "slides/07/slides07.html#try-it-2",
    "title": "Data Wrangling: Verbs",
    "section": "Try it",
    "text": "Try it\n\nCreate a new column in flights giving the average speed of the flight while it was in the air. What are the units of this variable? Make the variable in terms of miles per hour.\n\n\n\n\n−+\n02:30"
  },
  {
    "objectID": "slides/07/slides07.html#example",
    "href": "slides/07/slides07.html#example",
    "title": "Data Wrangling: Verbs",
    "section": "Example",
    "text": "Example\nThe Federal Aviation Administration (FAA) considers a flight to be delayed when it is 15 minutes later than its scheduled time.\n\nflights &lt;- mutate(\n  flights, \n  delayed = case_when(\n    dep_delay &gt;= 15 ~ \"Delayed\", \n    dep_delay &lt; 15 ~ \"On time\",\n    .default = \"other\")\n)"
  },
  {
    "objectID": "slides/07/slides07.html#your-turn-1",
    "href": "slides/07/slides07.html#your-turn-1",
    "title": "Data Wrangling: Verbs",
    "section": "Your turn",
    "text": "Your turn\n\nSuppose that you don’t think the FAA gives enough information in their definition of a delayed flight, so you come up with the following delay categories:\n\ndep_delay &lt;= 0 -&gt; none\ndep_delay between 1 and 15 minutes -&gt; minimal\ndep_delay between 16 and 30 minutes -&gt; delayed\ndep_delay between 31 and 60 minutes -&gt; major\ndep_delay over 60 minutes -&gt; extreme\n\nUse mutate() and case_when() to create a delay_category variable in the flights data frame."
  },
  {
    "objectID": "slides/07/slides07.html#section-7",
    "href": "slides/07/slides07.html#section-7",
    "title": "Data Wrangling: Verbs",
    "section": "",
    "text": "“dataframe first, dataframe once”\nCombine multiple operations with the pipe\nThink “and then” when reading code"
  },
  {
    "objectID": "slides/07/slides07.html#using",
    "href": "slides/07/slides07.html#using",
    "title": "Data Wrangling: Verbs",
    "section": "Using %>%",
    "text": "Using %&gt;%\n\n%&gt;% passes result on left into first argument of function on right\nChaining functions together lets you read Left-to-right, top-to-bottom"
  },
  {
    "objectID": "slides/07/slides07.html#using-1",
    "href": "slides/07/slides07.html#using-1",
    "title": "Data Wrangling: Verbs",
    "section": "Using %>%",
    "text": "Using %&gt;%\n\n\nfilter():\n\nfilter(storms, status == \"hurricane\")\n\nbecomes\n\nstorms %&gt;%\n  filter(status == \"hurricane\")\n\n\narrange():\n\narrange(storms, wind)\n\nbecomes\n\nstorms %&gt;%\n  arrange(wind)"
  },
  {
    "objectID": "slides/07/slides07.html#using-2",
    "href": "slides/07/slides07.html#using-2",
    "title": "Data Wrangling: Verbs",
    "section": "Using %>%",
    "text": "Using %&gt;%\nWe can also build up a series of pipes.\nWe’re interested in the storms with the lowest wind speed that were still classified as hurricanes.\n\nstorms %&gt;%\n  filter(status == \"hurricane\") %&gt;%\n  arrange(wind)\n\n# A tibble: 4,803 × 13\n   name      year month   day  hour   lat  long status   category  wind pressure\n   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Blanche   1975     7    27     6  35.9 -70   hurrica…        1    65      987\n 2 Caroline  1975     8    30     0  23.3 -94.2 hurrica…        1    65      990\n 3 Caroline  1975     8    30     6  23.5 -94.9 hurrica…        1    65      990\n 4 Caroline  1975     8    30    12  23.7 -95.6 hurrica…        1    65      989\n 5 Doris     1975     8    31     0  34.9 -46.3 hurrica…        1    65      990\n 6 Doris     1975     8    31     6  34.8 -45.7 hurrica…        1    65      990\n 7 Eloise    1975     9    16    18  19.5 -68.4 hurrica…        1    65     1002\n 8 Eloise    1975     9    17     0  19.6 -69.2 hurrica…        1    65      997\n 9 Eloise    1975     9    22     6  24.8 -89.4 hurrica…        1    65      993\n10 Faye      1975     9    26     0  26.5 -60   hurrica…        1    65      990\n# ℹ 4,793 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#using-3",
    "href": "slides/07/slides07.html#using-3",
    "title": "Data Wrangling: Verbs",
    "section": "Using %>%",
    "text": "Using %&gt;%\nWe’re interested in the storms with the lowest wind speed that were still classified as hurricanes, that reached category 2.\n\nstorms %&gt;%\n  filter(status == \"hurricane\") %&gt;%\n  filter(category &gt; 1) %&gt;%\n  arrange(wind)\n\n# A tibble: 2,255 × 13\n   name    year month   day  hour   lat  long status    category  wind pressure\n   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;        &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Eloise  1975     9    22    18  26.5 -89.4 hurricane        2    85      980\n 2 Faye    1975     9    26    18  31   -63.1 hurricane        2    85      985\n 3 Faye    1975     9    28     0  38.4 -63.7 hurricane        2    85      985\n 4 Gladys  1975    10     3     6  43.7 -57   hurricane        2    85      960\n 5 Gladys  1975    10     3    12  46.6 -50.6 hurricane        2    85      960\n 6 Emmy    1976     8    26    18  27.7 -54.8 hurricane        2    85      976\n 7 Emmy    1976     8    27    12  30.9 -53.7 hurricane        2    85      975\n 8 Emmy    1976     8    28    12  33.5 -56.6 hurricane        2    85      975\n 9 Emmy    1976     8    31    12  35.1 -44.9 hurricane        2    85      977\n10 Gloria  1976     9    30     6  32.2 -59.8 hurricane        2    85      971\n# ℹ 2,245 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#combining-with-ggplot",
    "href": "slides/07/slides07.html#combining-with-ggplot",
    "title": "Data Wrangling: Verbs",
    "section": "Combining with ggplot",
    "text": "Combining with ggplot\nPipes become especially useful when we combine them with ggplot():\n\n\nstorms %&gt;%\n  filter(status == \"hurricane\") %&gt;%\n  filter(category &gt; 1) %&gt;%\n  ggplot(aes(x = wind, y = hurricane_force_diameter)) + \n  geom_jitter()"
  },
  {
    "objectID": "slides/07/slides07.html#your-turn-2",
    "href": "slides/07/slides07.html#your-turn-2",
    "title": "Data Wrangling: Verbs",
    "section": "Your turn",
    "text": "Your turn\n\nChain the last two parts together, so that the resulting dataset contains both avg_speed and delay_category. Pipe this new dataset into ggplot() to answer the question “is there a relationship between average speed and how late a flight is delayed?”\nIf you have time, create a new graph which only contains flights to MSP.\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/11/slides11.html#today",
    "href": "slides/11/slides11.html#today",
    "title": "Data Import & Dates/Times",
    "section": "Today",
    "text": "Today\n\nProject 1 grading/questions\nIntro to Project 2\nHW 4 due tonight\nHW 5 + check-in survey\nNew stuff!"
  },
  {
    "objectID": "slides/11/slides11.html#readr-functions",
    "href": "slides/11/slides11.html#readr-functions",
    "title": "Data Import & Dates/Times",
    "section": "readr functions",
    "text": "readr functions\n\n\n\nfunction\nreads\n\n\n\n\nread_csv()\nComma separated values\n\n\nread_csv2()\nSemi-colon separated values\n\n\nread_delim()\nGeneral delimited files\n\n\nread_fwf()\nFixed width files\n\n\nread_log()\nApache log files\n\n\nread_table()\nSpace separated\n\n\nread_tsv()\nTab delimited values"
  },
  {
    "objectID": "slides/11/slides11.html#basic-syntax",
    "href": "slides/11/slides11.html#basic-syntax",
    "title": "Data Import & Dates/Times",
    "section": "Basic syntax",
    "text": "Basic syntax\nAll readr functions share a common syntax\n\ndf &lt;- read_csv(file = \"path/to/file.csv\", ...)"
  },
  {
    "objectID": "slides/11/slides11.html#whats-the-big-deal",
    "href": "slides/11/slides11.html#whats-the-big-deal",
    "title": "Data Import & Dates/Times",
    "section": "What’s the big deal?",
    "text": "What’s the big deal?\nCompared to read.table and its derivatives, readr functions are:\n\n~ 10 times faster\nReturn tibbles\nHave more intuitive defaults. No row names, no strings as factors."
  },
  {
    "objectID": "slides/11/slides11.html#tibbles-enhance-data-frames",
    "href": "slides/11/slides11.html#tibbles-enhance-data-frames",
    "title": "Data Import & Dates/Times",
    "section": "tibbles enhance data frames",
    "text": "tibbles enhance data frames\n\n\n\n\nSubsetting - [ always returns a new tibble, [[ and $ always return a new vector\nNo partial matching - You must use full column names when subsetting\nDisplay - When you print a tibble, R provides a concise view of the data that fits on one screen"
  },
  {
    "objectID": "slides/11/slides11.html#concise-printing",
    "href": "slides/11/slides11.html#concise-printing",
    "title": "Data Import & Dates/Times",
    "section": "Concise printing",
    "text": "Concise printing"
  },
  {
    "objectID": "slides/11/slides11.html#conversion",
    "href": "slides/11/slides11.html#conversion",
    "title": "Data Import & Dates/Times",
    "section": "Conversion",
    "text": "Conversion\n\nas_tibble() - convert a data frame to a tibble\nas.data.frame() - convert a tibble to a data frame"
  },
  {
    "objectID": "slides/11/slides11.html#desserts-data",
    "href": "slides/11/slides11.html#desserts-data",
    "title": "Data Import & Dates/Times",
    "section": "desserts data",
    "text": "desserts data\n\n\nContains results from series 1-8 of The Great British Bake Off\nCase defined by series, episode and baker\n\n\n\n\nSource: Allison Hill and the bakeoff package; compiled by Adam Loy"
  },
  {
    "objectID": "slides/11/slides11.html#warm-up",
    "href": "slides/11/slides11.html#warm-up",
    "title": "Data Import & Dates/Times",
    "section": "Warm up",
    "text": "Warm up\n\nUse read_csv() to import the desserts data set from  https://stat220-w25.github.io/data/desserts.csv\nStore the data in the desserts object\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/11/slides11.html#did-it-work-as-expected",
    "href": "slides/11/slides11.html#did-it-work-as-expected",
    "title": "Data Import & Dates/Times",
    "section": "Did it work as expected?",
    "text": "Did it work as expected?\n\ndesserts &lt;- read_csv(\"https://stat220-w25.github.io/data/desserts.csv\")\n\n\n\n\n\nRows: 549\nColumns: 16\n$ series                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ episode               &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, …\n$ baker                 &lt;chr&gt; \"Annetha\", \"David\", \"Edd\", \"Jasminder\", \"Jonatha…\n$ technical             &lt;chr&gt; \"2nd\", \"3rd\", \"1st\", \"N/A\", \"9th\", \"N/A\", \"8th\",…\n$ result                &lt;chr&gt; \"IN\", \"IN\", \"IN\", \"IN\", \"IN\", \"IN\", \"IN\", \"IN\", …\n$ uk_airdate            &lt;chr&gt; \"17 August 2010\", \"17 August 2010\", \"17 August 2…\n$ us_season             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ us_airdate            &lt;date&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ showstopper_chocolate &lt;chr&gt; \"chocolate\", \"chocolate\", \"no chocolate\", \"no ch…\n$ showstopper_dessert   &lt;chr&gt; \"other\", \"other\", \"other\", \"other\", \"other\", \"ca…\n$ showstopper_fruit     &lt;chr&gt; \"no fruit\", \"no fruit\", \"no fruit\", \"no fruit\", …\n$ showstopper_nut       &lt;chr&gt; \"no nut\", \"no nut\", \"no nut\", \"no nut\", \"almond\"…\n$ signature_chocolate   &lt;chr&gt; \"no chocolate\", \"chocolate\", \"no chocolate\", \"no…\n$ signature_dessert     &lt;chr&gt; \"cake\", \"cake\", \"cake\", \"cake\", \"cake\", \"cake\", …\n$ signature_fruit       &lt;chr&gt; \"no fruit\", \"fruit\", \"fruit\", \"fruit\", \"fruit\", …\n$ signature_nut         &lt;chr&gt; \"no nut\", \"no nut\", \"no nut\", \"no nut\", \"no nut\"…\n\n\n\nA couple issues…\n\ntechnical is character, not numeric\nuk_airdate is character, not date"
  },
  {
    "objectID": "slides/11/slides11.html#the-col_types-argument",
    "href": "slides/11/slides11.html#the-col_types-argument",
    "title": "Data Import & Dates/Times",
    "section": "The col_types argument",
    "text": "The col_types argument\nBy default, looks at first 1000 rows to guess variable data types (guess_max), but we can also tell R how to read column types\n\n\ndesserts &lt;- read_csv(\n  \"https://stat220-w25.github.io/data/desserts.csv\",\n  col_types = list( \n    technical = col_number(), \n    uk_airdate = col_date()   \n  ) \n)"
  },
  {
    "objectID": "slides/11/slides11.html#looking-for-problems",
    "href": "slides/11/slides11.html#looking-for-problems",
    "title": "Data Import & Dates/Times",
    "section": "Looking for problems",
    "text": "Looking for problems\nList of potential problems parsing the file\n\nproblems(desserts)\n\n# A tibble: 556 × 5\n     row   col expected        actual         file \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;\n 1     2     6 date in ISO8601 17 August 2010 \"\"   \n 2     3     6 date in ISO8601 17 August 2010 \"\"   \n 3     4     6 date in ISO8601 17 August 2010 \"\"   \n 4     5     4 a number        N/A            \"\"   \n 5     5     6 date in ISO8601 17 August 2010 \"\"   \n 6     6     6 date in ISO8601 17 August 2010 \"\"   \n 7     7     4 a number        N/A            \"\"   \n 8     7     6 date in ISO8601 17 August 2010 \"\"   \n 9     8     6 date in ISO8601 17 August 2010 \"\"   \n10     9     4 a number        N/A            \"\"   \n# ℹ 546 more rows"
  },
  {
    "objectID": "slides/11/slides11.html#date-formatting-woes",
    "href": "slides/11/slides11.html#date-formatting-woes",
    "title": "Data Import & Dates/Times",
    "section": "Date formatting woes",
    "text": "Date formatting woes\n\nprint(problems(desserts), n=5)\n\n# A tibble: 556 × 5\n    row   col expected        actual         file \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;\n1     2     6 date in ISO8601 17 August 2010 \"\"   \n2     3     6 date in ISO8601 17 August 2010 \"\"   \n3     4     6 date in ISO8601 17 August 2010 \"\"   \n4     5     4 a number        N/A            \"\"   \n5     5     6 date in ISO8601 17 August 2010 \"\"   \n# ℹ 551 more rows\n\n\nISO8601 format: 2010-08-17\nWhat we have: 17 August 2010"
  },
  {
    "objectID": "slides/11/slides11.html#section-1",
    "href": "slides/11/slides11.html#section-1",
    "title": "Data Import & Dates/Times",
    "section": "",
    "text": "Counting Stuff blog by Randy Au"
  },
  {
    "objectID": "slides/11/slides11.html#adding-format-instructions",
    "href": "slides/11/slides11.html#adding-format-instructions",
    "title": "Data Import & Dates/Times",
    "section": "Adding format instructions",
    "text": "Adding format instructions\n\ndesserts &lt;- read_csv(\n  \"https://stat220-w25.github.io/data/desserts.csv\",\n  col_types = list(\n    technical = col_number(), \n    uk_airdate = col_date(format = \"%d %B %Y\")  \n  ) \n)\n\n\nYear: \"%Y\" (4 digits). \"%y\" (2 digits)\nMonth: \"%m\" (2 digits), \"%b\" (abbreviated name in current locale), \"%B\" (full name in current locale).\nDay: \"%d\" (2 digits), \"%e\" (optional leading space)"
  },
  {
    "objectID": "slides/11/slides11.html#looking-for-problems-1",
    "href": "slides/11/slides11.html#looking-for-problems-1",
    "title": "Data Import & Dates/Times",
    "section": "Looking for problems",
    "text": "Looking for problems\nList of potential problems parsing the file\n\nproblems(desserts)\n\n# A tibble: 7 × 5\n    row   col expected actual file \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;\n1     5     4 a number N/A    \"\"   \n2     7     4 a number N/A    \"\"   \n3     9     4 a number N/A    \"\"   \n4    11     4 a number N/A    \"\"   \n5    35     4 a number N/A    \"\"   \n6    36     4 a number N/A    \"\"   \n7    37     4 a number N/A    \"\""
  },
  {
    "objectID": "slides/11/slides11.html#addressing-missing-values",
    "href": "slides/11/slides11.html#addressing-missing-values",
    "title": "Data Import & Dates/Times",
    "section": "Addressing missing values",
    "text": "Addressing missing values\nBy default na = c(\"\", \"NA\") are the recognized missing values\n\ndesserts &lt;- read_csv(\n  \"https://stat220-w25.github.io/data/desserts.csv\",\n  col_types = list(\n    technical = col_number(), \n    uk_airdate = col_date(format = \"%d %B %Y\")\n  ),\n  na = c(\"\", \"NA\", \"N/A\") \n)"
  },
  {
    "objectID": "slides/11/slides11.html#looking-for-problems-2",
    "href": "slides/11/slides11.html#looking-for-problems-2",
    "title": "Data Import & Dates/Times",
    "section": "Looking for problems",
    "text": "Looking for problems\nList of potential problems parsing the file\n\n\n# A tibble: 0 × 5\n# ℹ 5 variables: row &lt;int&gt;, col &lt;int&gt;, expected &lt;chr&gt;, actual &lt;chr&gt;, file &lt;chr&gt;"
  },
  {
    "objectID": "slides/11/slides11.html#section-2",
    "href": "slides/11/slides11.html#section-2",
    "title": "Data Import & Dates/Times",
    "section": "",
    "text": "desserts\n\n# A tibble: 549 × 16\n   series episode baker     technical result uk_airdate us_season us_airdate\n    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;  &lt;date&gt;         &lt;dbl&gt; &lt;date&gt;    \n 1      1       1 Annetha           2 IN     2010-08-17        NA NA        \n 2      1       1 David             3 IN     2010-08-17        NA NA        \n 3      1       1 Edd               1 IN     2010-08-17        NA NA        \n 4      1       1 Jasminder        NA IN     2010-08-17        NA NA        \n 5      1       1 Jonathan          9 IN     2010-08-17        NA NA        \n 6      1       1 Louise           NA IN     2010-08-17        NA NA        \n 7      1       1 Miranda           8 IN     2010-08-17        NA NA        \n 8      1       1 Ruth             NA IN     2010-08-17        NA NA        \n 9      1       1 Lea              10 OUT    2010-08-17        NA NA        \n10      1       1 Mark             NA OUT    2010-08-17        NA NA        \n# ℹ 539 more rows\n# ℹ 8 more variables: showstopper_chocolate &lt;chr&gt;, showstopper_dessert &lt;chr&gt;,\n#   showstopper_fruit &lt;chr&gt;, showstopper_nut &lt;chr&gt;, signature_chocolate &lt;chr&gt;,\n#   signature_dessert &lt;chr&gt;, signature_fruit &lt;chr&gt;, signature_nut &lt;chr&gt;"
  },
  {
    "objectID": "slides/11/slides11.html#column-casting-functions",
    "href": "slides/11/slides11.html#column-casting-functions",
    "title": "Data Import & Dates/Times",
    "section": "Column casting functions",
    "text": "Column casting functions\n\n\n\nType\ndplyr::glimpse()\nreadr::col_*()\n\n\n\n\nlogical\n&lt;lgl&gt;\ncol_logical\n\n\nnumeric\n&lt;int&gt; or &lt;dbl&gt;\ncol_number\n\n\ncharacter\n&lt;chr&gt;\ncol_character\n\n\nfactor\n&lt;fct&gt;\ncol_factor\n\n\ndate\n&lt;date&gt;\ncol_date"
  },
  {
    "objectID": "slides/11/slides11.html#read_csv",
    "href": "slides/11/slides11.html#read_csv",
    "title": "Data Import & Dates/Times",
    "section": "?read_csv",
    "text": "?read_csv\n\nread_csv(file, \n         col_names = TRUE,\n         col_types = NULL,\n         locale = default_locale(),\n         na = c(\"\", \"NA\"), \n         quoted_na = TRUE,\n         quote = \"\\\"\", \n         comment = \"\",\n         trim_ws = TRUE,\n         skip = 0,\n         n_max = Inf,\n         guess_max = min(1000, n_max),\n         progress = show_progress())"
  },
  {
    "objectID": "slides/11/slides11.html#your-turn",
    "href": "slides/11/slides11.html#your-turn",
    "title": "Data Import & Dates/Times",
    "section": "Your turn",
    "text": "Your turn\n\nUse the appropriate read_&lt;type&gt;() function to import the following data sets:\n\ndata-4.csv\ntricky-1.csv\ntricky2.csv\n\nThe full URLs are in the 11-import.Rmd activity\nIf you hit any errors/problems, be sure to explore them and identify the issue, even if you can’t “fix” it."
  },
  {
    "objectID": "slides/11/slides11.html#section-3",
    "href": "slides/11/slides11.html#section-3",
    "title": "Data Import & Dates/Times",
    "section": "",
    "text": "Help!\n\nI already imported data and now I have dates/times as character strings or numeric vectors!"
  },
  {
    "objectID": "slides/11/slides11.html#nycflights13-revisited",
    "href": "slides/11/slides11.html#nycflights13-revisited",
    "title": "Data Import & Dates/Times",
    "section": "nycflights13 revisited",
    "text": "nycflights13 revisited\nRecall that the departure and arrival times were in integer format\n\n\nflights %&gt;% select(contains(\"_time\"), hour, minute)\n\n\n# A tibble: 435,352 × 7\n   dep_time sched_dep_time arr_time sched_arr_time air_time  hour minute\n      &lt;int&gt;          &lt;int&gt;    &lt;int&gt;          &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1        1           2038      328              3      367    20     38\n 2       18           2300      228            135      108    23      0\n 3       31           2344      500            426      190    23     44\n 4       33           2140      238           2352      108    21     40\n 5       36           2048      223           2252       80    20     48\n 6      503            500      808            815      154     5      0\n 7      520            510      948            949      192     5     10\n 8      524            530      645            710      119     5     30\n 9      537            520      926            818      258     5     20\n10      547            545      845            852      157     5     45\n# ℹ 435,342 more rows"
  },
  {
    "objectID": "slides/11/slides11.html#section-4",
    "href": "slides/11/slides11.html#section-4",
    "title": "Data Import & Dates/Times",
    "section": "",
    "text": "A class for representing clock times\nPart of the tidyverse\nNeed to load separately"
  },
  {
    "objectID": "slides/11/slides11.html#creating-times-with-hms",
    "href": "slides/11/slides11.html#creating-times-with-hms",
    "title": "Data Import & Dates/Times",
    "section": "Creating times with hms()",
    "text": "Creating times with hms()\nWe can use the hour and minute column to create a clock time\n\n\nlibrary(hms)\nsched_dep_times &lt;- flights %&gt;% \n  mutate(sched_dep_time_hms = hms(hours = hour, minutes = minute)) %&gt;% \n  pull()\nhead(sched_dep_times)\n\n\n20:38:00\n23:00:00\n23:44:00\n21:40:00\n20:48:00\n05:00:00"
  },
  {
    "objectID": "slides/11/slides11.html#hms-creates-a-special-type-of-object",
    "href": "slides/11/slides11.html#hms-creates-a-special-type-of-object",
    "title": "Data Import & Dates/Times",
    "section": "hms() creates a special type of object",
    "text": "hms() creates a special type of object\n\n\nclass(sched_dep_times)\n\n\n[1] \"hms\"      \"difftime\""
  },
  {
    "objectID": "slides/11/slides11.html#creating-times-with-hms-1",
    "href": "slides/11/slides11.html#creating-times-with-hms-1",
    "title": "Data Import & Dates/Times",
    "section": "Creating times with hms()",
    "text": "Creating times with hms()\nIf we don’t already have hours, minutes, seconds separately, we’ll need to parse out that information\n\nInteger timeParse + hms()\n\n\n\n\ndep_time &lt;- flights %&gt;% pull(dep_time)\nhead(dep_time)\n\n\n[1]   1  18  31  33  36 503\n\n\n\n\n\n\ndep_time_hms &lt;- hms(hours = dep_time %/% 100, minutes = dep_time %% 100)\nhead(dep_time_hms)\n\n\n00:01:00\n00:18:00\n00:31:00\n00:33:00\n00:36:00\n05:03:00\n\n\n%/% divides first number by second number, returns the whole number (integer division)\n%% divides first number by second number, returns the remainder (modulo)"
  },
  {
    "objectID": "slides/11/slides11.html#ultramarathon-results",
    "href": "slides/11/slides11.html#ultramarathon-results",
    "title": "Data Import & Dates/Times",
    "section": "Ultramarathon results",
    "text": "Ultramarathon results\n\nUltra marathon = anything longer than 26.2 miles\nThe dates and times imported as character strings!\n\n\n\n## Rows: 392\n## Columns: 11\n## $ state            &lt;chr&gt; \"Minnesota\", \"Minnesota\", \"Minnesota\", \"Minnesota\", \"…\n## $ Event            &lt;chr&gt; \"Zumbro\", \"Zumbro\", \"Zumbro\", \"Zumbro\", \"Zumbro\", \"Zu…\n## $ City             &lt;chr&gt; \"Theilman\", \"Theilman\", \"Theilman\", \"Theilman\", \"Thei…\n## $ race_url         &lt;chr&gt; \"https://calendar.ultrarunning.com/event/zumbro\", \"ht…\n## $ date             &lt;chr&gt; \"04/08/21\", \"04/11/20\", \"04/13/19\", \"04/13/18\", \"04/0…\n## $ Finishers        &lt;chr&gt; \"121\", \"Race Cancelled\", \"Race Cancelled\", \"49\", \"149…\n## $ top_result_m     &lt;chr&gt; \"5:23:55\", \"Race Cancelled\", \"Race Cancelled\", \"9:13:…\n## $ top_result_f     &lt;chr&gt; \"6:30:42\", \"Race Cancelled\", \"Race Cancelled\", \"10:15…\n## $ distance         &lt;chr&gt; \"34 Miles\", \"50 Miles\", \"50 Miles\", \"50 Miles\", \"50 M…\n## $ elevation_rating &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…\n## $ surface_rating   &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…"
  },
  {
    "objectID": "slides/11/slides11.html#section-5",
    "href": "slides/11/slides11.html#section-5",
    "title": "Data Import & Dates/Times",
    "section": "",
    "text": "Functions for working with dates and time spans\nPart of the tidyverse\nNeed to load separately"
  },
  {
    "objectID": "slides/11/slides11.html#parsing-dates",
    "href": "slides/11/slides11.html#parsing-dates",
    "title": "Data Import & Dates/Times",
    "section": "Parsing dates",
    "text": "Parsing dates\n{lubridate} functions are intuitively named\n\nlibrary(lubridate)\nmdy(\"01/29/25\")\n\n[1] \"2025-01-29\"\n\n\n\ndmy(\"29-01-2025\")\n\n[1] \"2025-01-29\"\n\n\n\nymd(\"2025-01-29\")\n\n[1] \"2025-01-29\"\n\n\n\nymd_hm(\"2025-01-29 09:55\")\n\n[1] \"2025-01-29 09:55:00 UTC\""
  },
  {
    "objectID": "slides/11/slides11.html#ultramarathon-example",
    "href": "slides/11/slides11.html#ultramarathon-example",
    "title": "Data Import & Dates/Times",
    "section": "Ultramarathon example",
    "text": "Ultramarathon example\nDates are in the form 04/08/21, so use mdy() to parse\n\nmn_ultras &lt;- mn_ultras %&gt;% mutate(date = mdy(date))\nglimpse(mn_ultras)\n\nRows: 392\nColumns: 11\n$ state            &lt;chr&gt; \"Minnesota\", \"Minnesota\", \"Minnesota\", \"Minnesota\", \"…\n$ Event            &lt;chr&gt; \"Zumbro\", \"Zumbro\", \"Zumbro\", \"Zumbro\", \"Zumbro\", \"Zu…\n$ City             &lt;chr&gt; \"Theilman\", \"Theilman\", \"Theilman\", \"Theilman\", \"Thei…\n$ race_url         &lt;chr&gt; \"https://calendar.ultrarunning.com/event/zumbro\", \"ht…\n$ date             &lt;date&gt; 2021-04-08, 2020-04-11, 2019-04-13, 2018-04-13, 2017…\n$ Finishers        &lt;chr&gt; \"121\", \"Race Cancelled\", \"Race Cancelled\", \"49\", \"149…\n$ top_result_m     &lt;chr&gt; \"5:23:55\", \"Race Cancelled\", \"Race Cancelled\", \"9:13:…\n$ top_result_f     &lt;chr&gt; \"6:30:42\", \"Race Cancelled\", \"Race Cancelled\", \"10:15…\n$ distance         &lt;chr&gt; \"34 Miles\", \"50 Miles\", \"50 Miles\", \"50 Miles\", \"50 M…\n$ elevation_rating &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…\n$ surface_rating   &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…"
  },
  {
    "objectID": "slides/11/slides11.html#extract-info-from-a-datetime",
    "href": "slides/11/slides11.html#extract-info-from-a-datetime",
    "title": "Data Import & Dates/Times",
    "section": "Extract info from a date/time",
    "text": "Extract info from a date/time\n{lubridate} functions are intuitively named\n\n\n\n\n\n\n\nfunction\naction\n\n\n\n\nyear(), month()\nextract year/month\n\n\nweek()\nextract week of the year\n\n\nday(), wday()\nextract day of month/day of week\n\n\nhour(), minute(), second()\nextract hour/minute/second\n\n\n\nAdding label = TRUE creates an ordered factor (for month or wday)"
  },
  {
    "objectID": "slides/11/slides11.html#extract-info-from-a-datetime-1",
    "href": "slides/11/slides11.html#extract-info-from-a-datetime-1",
    "title": "Data Import & Dates/Times",
    "section": "Extract info from a date/time",
    "text": "Extract info from a date/time\nThe most recent race in the data set was on 2022-01-31\n\nmonth()day()wday()\n\n\nWhat month was that in?\n\nmonth(\"2022-01-31\", label = TRUE)\n\n[1] Jan\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\n\n\n\nWhat day of the month was it on?\n\nday(\"2022-01-31\")\n\n[1] 31\n\n\n\n\nWhat day of the week was it on?\n\nwday(\"2022-01-31\", label = TRUE)\n\n[1] Mon\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat"
  },
  {
    "objectID": "slides/11/slides11.html#measuring-time",
    "href": "slides/11/slides11.html#measuring-time",
    "title": "Data Import & Dates/Times",
    "section": "Measuring time",
    "text": "Measuring time\nHow long ago was the last race?\n\nrace &lt;- ymd(\"2022-01-31\")\ntoday() - race\n\nTime difference of 1095 days\n\n\n\nDifferences in date/time objects are difftime objects\ndifftimes use inconsistent units (sometimes weeks, days, hours, minutes, or seconds)"
  },
  {
    "objectID": "slides/11/slides11.html#measuring-time-durations",
    "href": "slides/11/slides11.html#measuring-time-durations",
    "title": "Data Import & Dates/Times",
    "section": "Measuring time: durations",
    "text": "Measuring time: durations\nA time span that is always measured in seconds\n\nas.duration(today() - race)\n\n[1] \"94608000s (~3 years)\"\n\n\nPlus, a better display"
  },
  {
    "objectID": "slides/11/slides11.html#measuring-time-periods",
    "href": "slides/11/slides11.html#measuring-time-periods",
    "title": "Data Import & Dates/Times",
    "section": "Measuring time: periods",
    "text": "Measuring time: periods\nTo do math with dates add and subtract periods\n\nymd_hms(\"2025-01-29 09:55:00\", tz = \"America/Chicago\") + days(1)\n\n[1] \"2025-01-30 09:55:00 CST\"\n\n\n\nymd_hms(\"2023-02-28 09:55:00\", tz = \"America/Chicago\") + days(1)\n\n[1] \"2023-03-01 09:55:00 CST\"\n\n\nPeriods are measured in clock units"
  },
  {
    "objectID": "slides/11/slides11.html#try-it",
    "href": "slides/11/slides11.html#try-it",
    "title": "Data Import & Dates/Times",
    "section": "Try it",
    "text": "Try it\n\nYour task is create a 1-columnn tibble containing all dates that our class meets this term using lubridate functions. You should only specify the first day of class (1/6/2025)\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/11/slides11.html#try-it-2",
    "href": "slides/11/slides11.html#try-it-2",
    "title": "Data Import & Dates/Times",
    "section": "Try it 2",
    "text": "Try it 2\n\nNow, create a second column where the dates have been formatted. (Hint: see ?stamp)\nYour dates should have the form “Wednesday: Jan 29 2025”\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/02/slides02.html#plan-for-today",
    "href": "slides/02/slides02.html#plan-for-today",
    "title": "Github +  Reproducible  Reporting",
    "section": "Plan for today:",
    "text": "Plan for today:\n\nQuestions from syllabus quiz\nGithub\n\nAccessing your private repos\nknit 🧶 commit ✅ push ⤴️\n\nReproducible Reporting"
  },
  {
    "objectID": "slides/02/slides02.html#questions-from-syllabus-quiz",
    "href": "slides/02/slides02.html#questions-from-syllabus-quiz",
    "title": "Github +  Reproducible  Reporting",
    "section": "Questions from syllabus quiz",
    "text": "Questions from syllabus quiz\n\nWill the course build off of Stat120 concepts?\nClarification of what gets submitted to gradescope and what to GitHub\nRMarkdown versus Quarto?\nExamples of previous final projects?\nInfo about portfolio projects?"
  },
  {
    "objectID": "slides/02/slides02.html#git-github",
    "href": "slides/02/slides02.html#git-github",
    "title": "Github +  Reproducible  Reporting",
    "section": "Git + GitHub",
    "text": "Git + GitHub\n\n\n\nGit is a version control system - like “Track Changes”, on steroids\nIt’s not the only version control system, but it’s a very popular one\n\n\n\nGitHub is the home for your Git-based projects on the internet—like DropBox but much, much better\nWe will use GitHub as a platform for web hosting and collaboration"
  },
  {
    "objectID": "slides/02/slides02.html#why-do-we-need-it",
    "href": "slides/02/slides02.html#why-do-we-need-it",
    "title": "Github +  Reproducible  Reporting",
    "section": "Why do we need it?",
    "text": "Why do we need it?"
  },
  {
    "objectID": "slides/02/slides02.html#versioning",
    "href": "slides/02/slides02.html#versioning",
    "title": "Github +  Reproducible  Reporting",
    "section": "Versioning",
    "text": "Versioning"
  },
  {
    "objectID": "slides/02/slides02.html#versioning-with-human-readable-messages",
    "href": "slides/02/slides02.html#versioning-with-human-readable-messages",
    "title": "Github +  Reproducible  Reporting",
    "section": "Versioning (with human-readable messages)",
    "text": "Versioning (with human-readable messages)"
  },
  {
    "objectID": "slides/02/slides02.html#how-does-it-work-for-stat220",
    "href": "slides/02/slides02.html#how-does-it-work-for-stat220",
    "title": "Github +  Reproducible  Reporting",
    "section": "How does it work for Stat220?",
    "text": "How does it work for Stat220?"
  },
  {
    "objectID": "slides/02/slides02.html#how-does-it-work-for-stat220-1",
    "href": "slides/02/slides02.html#how-does-it-work-for-stat220-1",
    "title": "Github +  Reproducible  Reporting",
    "section": "How does it work for Stat220?",
    "text": "How does it work for Stat220?"
  },
  {
    "objectID": "slides/02/slides02.html#how-does-it-work-for-stat220-2",
    "href": "slides/02/slides02.html#how-does-it-work-for-stat220-2",
    "title": "Github +  Reproducible  Reporting",
    "section": "How does it work for Stat220?",
    "text": "How does it work for Stat220?"
  },
  {
    "objectID": "slides/02/slides02.html#how-does-it-work-for-stat220-3",
    "href": "slides/02/slides02.html#how-does-it-work-for-stat220-3",
    "title": "Github +  Reproducible  Reporting",
    "section": "How does it work for Stat220?",
    "text": "How does it work for Stat220?"
  },
  {
    "objectID": "slides/02/slides02.html#lets-try-it",
    "href": "slides/02/slides02.html#lets-try-it",
    "title": "Github +  Reproducible  Reporting",
    "section": "Let’s try it!",
    "text": "Let’s try it!\n\n\n\nFollow the “Individual Assignment” directions at https://stat220-w25.github.io/computing/git-stat220.html to access your day02 repo and create an R project\nEdit the .Rmd file:\n\nChange “author” to your name\nUse # to add descriptive section headers for each code chunk\nAdd a sentence or two describing the summary statistics of the dataset\n\nknit 🧶 commit ✅ push ⤴️\nView on github.com/stat220-w25/day02yourusername and confirm you can see your changes\n\n\n\n\n\n\n−+\n15:00"
  },
  {
    "objectID": "slides/02/slides02.html#why-do-we-need-it-1",
    "href": "slides/02/slides02.html#why-do-we-need-it-1",
    "title": "Github +  Reproducible  Reporting",
    "section": "Why do we need it?",
    "text": "Why do we need it?\nOops! I gave you the wrong set of data."
  },
  {
    "objectID": "slides/02/slides02.html#why-do-we-need-it-2",
    "href": "slides/02/slides02.html#why-do-we-need-it-2",
    "title": "Github +  Reproducible  Reporting",
    "section": "Why do we need it?",
    "text": "Why do we need it?\n\nKarl – this is very interesting , however you used an old version of the data (n=143 rather than n=226). I’m really sorry you did all that work on the incomplete dataset.\nBruce\n\n\n\nAdapted from Karl Broman"
  },
  {
    "objectID": "slides/02/slides02.html#other-examples",
    "href": "slides/02/slides02.html#other-examples",
    "title": "Github +  Reproducible  Reporting",
    "section": "Other examples:",
    "text": "Other examples:\n\nThe results in Table 1 don’t seem to correspond to those in Figure 2.\nIn what order do I run these scripts?\nWhere did we get this data file?\nWhy did I omit those samples?\nHow did I make that figure?\n“Your script is now giving an error.”\n“The attached is similar to the code we used.”\n\n\n\nAdapted from Karl Broman"
  },
  {
    "objectID": "slides/02/slides02.html#reproducible-data-science",
    "href": "slides/02/slides02.html#reproducible-data-science",
    "title": "Github +  Reproducible  Reporting",
    "section": "Reproducible data science",
    "text": "Reproducible data science\n\n\nShort Term Impact\n\nAre the tables and figures reproducible from the code and data?\nDoes the code actually do what you think it does?\nIn addition to what was done, is it clear why it was done? (e.g., how were parameter settings chosen?)\n\n\nLong Term Impact\n\nCan the code be used for other data?\nCan you extend the code to other things?"
  },
  {
    "objectID": "slides/02/slides02.html#the-toolkit",
    "href": "slides/02/slides02.html#the-toolkit",
    "title": "Github +  Reproducible  Reporting",
    "section": "The toolkit",
    "text": "The toolkit\n\n\n\n\n\n\n\n\n\n\nScriptability \\(\\rightarrow\\) R\nCode environment \\(\\rightarrow\\) RStudio\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) R Markdown\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/02/slides02.html#what-is-r-markdown",
    "href": "slides/02/slides02.html#what-is-r-markdown",
    "title": "Github +  Reproducible  Reporting",
    "section": "What is R Markdown?",
    "text": "What is R Markdown?\n\nAn authoring framework for data science.\nA document format (.Rmd).\nAn R package named rmarkdown.\nA file format for making dynamic documents with R.\nA tool for integrating prose, code, and results.\nA computational document."
  },
  {
    "objectID": "slides/02/slides02.html#what-about-quarto",
    "href": "slides/02/slides02.html#what-about-quarto",
    "title": "Github +  Reproducible  Reporting",
    "section": "What about quarto?",
    "text": "What about quarto?\n\n“Next Gen” RMarkdown\nMore compatibility with other languages (python, observable.js, etc.)\nnot an R package/separate software\nI’m going to distribute HW, etc. via RMarkdown, but you are welcome to use either!"
  },
  {
    "objectID": "slides/02/slides02.html#the-setup-chunk",
    "href": "slides/02/slides02.html#the-setup-chunk",
    "title": "Github +  Reproducible  Reporting",
    "section": "The setup chunk",
    "text": "The setup chunk\n\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,   \n  comment = \"#&gt;\", \n  out.width = \"100%\" \n)\n```\n\n\nA special chunk label: setup\nTypically #1\nAll following chunks will use these options (i.e., sets global chunk options)\nTip: set include=FALSE\nYou can (and should) use individual chunk options too"
  },
  {
    "objectID": "slides/02/slides02.html#parameters",
    "href": "slides/02/slides02.html#parameters",
    "title": "Github +  Reproducible  Reporting",
    "section": "Parameters",
    "text": "Parameters\n\n\n---\ntitle: Survivor\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    theme: flatly\nparams:\n  season: '20'\n---"
  },
  {
    "objectID": "slides/02/slides02.html#your-task",
    "href": "slides/02/slides02.html#your-task",
    "title": "Github +  Reproducible  Reporting",
    "section": "Your Task",
    "text": "Your Task\n\n\nThere’s an example HTML report on the schedule\nYour task is to reproduce it in 02-example-lego.rmd (or .qmd, if you prefer).\nTo be as reproducible as possible, you’ll need to use:\n\nYAML metadata\nYAML parameters\nCode chunks with appropriate options\nInline R code"
  },
  {
    "objectID": "slides/02/slides02.html#hints",
    "href": "slides/02/slides02.html#hints",
    "title": "Github +  Reproducible  Reporting",
    "section": "Hints",
    "text": "Hints\n\n\nTo begin, use inline R code to replace “hard coding” the quantities that are highlighted below.\n\n\nFor example, instead of typing 19798 you would include nrow(sets) as an inline code chunk. Make sure the report knits and you get the right values.\n\nNext, add a parameter to your YAML header that stores the location of the data set. Make sure the report knits.\nChange the code chunk where you load the data set to use the data parameter you just defined rather than the hard-coded URL. Make sure the report knits.\nNow, let’s make a parameter for the source of the data set so you don’t have to search where every mention of it in the report, it will be with the other metadata (where it belongs). To do this, add a parameter that gives the source of your data (call it data_source) and set it equal to “the 2022-09-09 repository on Tidy Tuesday.” Make sure the report knits.\nAt this point it looks like everything is working—awesome job! To put it to the test, let’s update the parameters of your report and knit it to see if everything changes as we would expect. Here are the new parameter values:\n\ndata: \"http://math.carleton.edu/aluby/stat220/lego_subset.csv\"\ndata_source: \"Amanda's website\"\n\n(optional) If you have time, or would like to try outside of class, I’ve created a practice gradescope assignment space. First, add .pdf output to your document and knit to PDF. Commit the PDF and push to github. Then, log into gradescope (you may have to go through the link on moodle the first time) and link your github repo. You should then be able to submit your .pdf\n\noutput: \n  html_document:\n    default\n  pdf_document:\n    default"
  },
  {
    "objectID": "slides/04/slides04.html#today",
    "href": "slides/04/slides04.html#today",
    "title": "Plot design",
    "section": "Today",
    "text": "Today\n\nggplot2 review\ncustomizations in ggplot2\nSome guidelines for plot design"
  },
  {
    "objectID": "slides/04/slides04.html#what-we-know",
    "href": "slides/04/slides04.html#what-we-know",
    "title": "Plot design",
    "section": "What we know:",
    "text": "What we know:\n\n\n\nA basic set of geometries\n\n\ngeom_point()\ngeom_histogram()\ngeom_boxplot()\ngeom_violin()\ngeom_bar()\n\n\n\nHow to map variables to aesthetics\n\n\nx and y axis\ncolor\nshape\nalpha\nsize\n\n\n\nHow to change axis labels and titles\n\n\nlabs()"
  },
  {
    "objectID": "slides/04/slides04.html#what-next",
    "href": "slides/04/slides04.html#what-next",
    "title": "Plot design",
    "section": "What next?",
    "text": "What next?\n\nSetting aesthetics\nUsing facets\nChanging scales\nChanging coordinates\nChanging themes\nAdding annotations"
  },
  {
    "objectID": "slides/04/slides04.html#warm-up",
    "href": "slides/04/slides04.html#warm-up",
    "title": "Plot design",
    "section": "Warm Up",
    "text": "Warm Up\n\n\n\n\nLog into maize\n\nIf you have to type your PAT in everytime you push to GitHub, follow the directions at Getting Set up with Git and GitHub #4 to tell RStudio to save your credentials\n\nFind the .rmd template for today at the course website\nChoose your favorite way to open it up in maize/Rstudio\nWork with a neighbor to recreate this graph –&gt; (use 15 bins)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/04/slides04.html#polishing-plots",
    "href": "slides/04/slides04.html#polishing-plots",
    "title": "Plot design",
    "section": "Polishing plots",
    "text": "Polishing plots\n\n\n\n\n\n\n\n\n\n\n\n\nWe’re not quite satisfied….\n\nI want the bars to have a border that stands out\nLet’s try a facetted graph\nI don’t like the default color scheme\nI don’t like the gray background"
  },
  {
    "objectID": "slides/04/slides04.html#setting-aesthetics",
    "href": "slides/04/slides04.html#setting-aesthetics",
    "title": "Plot design",
    "section": "Setting aesthetics",
    "text": "Setting aesthetics\nSetting = choosing a certain value for an aesthetic\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    )"
  },
  {
    "objectID": "slides/04/slides04.html#facets",
    "href": "slides/04/slides04.html#facets",
    "title": "Plot design",
    "section": "Facets",
    "text": "Facets\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) +\n  facet_wrap(vars(day_of_week))"
  },
  {
    "objectID": "slides/04/slides04.html#changing-scales",
    "href": "slides/04/slides04.html#changing-scales",
    "title": "Plot design",
    "section": "Changing scales",
    "text": "Changing scales\n\nscale_&lt;aes&gt;_&lt;method&gt;()\n\n\n\nExamples:\n\nscale_fill_manual()\nscale_fill_brewer()\nscale_color_viridis()\nscale_shape_manual()\n\n\nRecommended reading:\n\nUsing colors in R\nTaking control of qualitative colors in ggplot2"
  },
  {
    "objectID": "slides/04/slides04.html#example-built-in-scale",
    "href": "slides/04/slides04.html#example-built-in-scale",
    "title": "Plot design",
    "section": "Example (built-in scale)",
    "text": "Example (built-in scale)\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_brewer(palette = \"Greens\")"
  },
  {
    "objectID": "slides/04/slides04.html#example-built-in-scale-1",
    "href": "slides/04/slides04.html#example-built-in-scale-1",
    "title": "Plot design",
    "section": "Example (built-in scale)",
    "text": "Example (built-in scale)\n\nRColorBrewer::display.brewer.all()"
  },
  {
    "objectID": "slides/04/slides04.html#example-built-in-scale-2",
    "href": "slides/04/slides04.html#example-built-in-scale-2",
    "title": "Plot design",
    "section": "Example (built-in scale)",
    "text": "Example (built-in scale)\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_viridis_d(option = \"mako\")\n\n\n\n\n\n\n\n\n\n\n\nTo see all the options built into R (or add-on packages): Color Palette Finder"
  },
  {
    "objectID": "slides/04/slides04.html#example-manual-color-palette",
    "href": "slides/04/slides04.html#example-manual-color-palette",
    "title": "Plot design",
    "section": "Example (manual color palette)",
    "text": "Example (manual color palette)\nLet’s make Wednesdays navyblue and Thursdays gold2\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\"))"
  },
  {
    "objectID": "slides/04/slides04.html#can-also-change-non-color-scales",
    "href": "slides/04/slides04.html#can-also-change-non-color-scales",
    "title": "Plot design",
    "section": "Can also change non-color scales",
    "text": "Can also change non-color scales\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  scale_x_continuous(limits = c(1,10))"
  },
  {
    "objectID": "slides/04/slides04.html#can-also-change-non-color-scales-1",
    "href": "slides/04/slides04.html#can-also-change-non-color-scales-1",
    "title": "Plot design",
    "section": "Can also change non-color scales",
    "text": "Can also change non-color scales\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  scale_x_log10(limits = c(1,10))"
  },
  {
    "objectID": "slides/04/slides04.html#can-also-change-non-color-scales-2",
    "href": "slides/04/slides04.html#can-also-change-non-color-scales-2",
    "title": "Plot design",
    "section": "Can also change non-color scales",
    "text": "Can also change non-color scales\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  scale_x_reverse()"
  },
  {
    "objectID": "slides/04/slides04.html#changing-themes",
    "href": "slides/04/slides04.html#changing-themes",
    "title": "Plot design",
    "section": "Changing Themes",
    "text": "Changing Themes\nTheme: The non-data ink on your plots\n\n\n\nbackground\ntick marks\ngrid lines\nfont\nlegend position\nlegend appearance"
  },
  {
    "objectID": "slides/04/slides04.html#prepackaged-themes",
    "href": "slides/04/slides04.html#prepackaged-themes",
    "title": "Plot design",
    "section": "Prepackaged themes",
    "text": "Prepackaged themes\n\n\nggplot2 themes\n\ntheme_grey()\ntheme_bw()\ntheme_linedraw()\ntheme_light()\ntheme_dark()\ntheme_minimal()\ntheme_classic()\ntheme_void()\ntheme_test()\n\n\nggthemes themes\n\ntheme_clean()\ntheme_economist()\ntheme_excel()\ntheme_fivethirtyeight()\ntheme_gdocs()\ntheme_solarized()\ntheme_stata()\ntheme_tufte()\ntheme_wsj()\nAnd more!"
  },
  {
    "objectID": "slides/04/slides04.html#using-a-prepackaged-theme",
    "href": "slides/04/slides04.html#using-a-prepackaged-theme",
    "title": "Plot design",
    "section": "Using a prepackaged theme",
    "text": "Using a prepackaged theme\n\nggplot(data = &lt;DATA&gt;) + \n  &lt;GEOM_FUNCTION&gt;(\n     mapping = aes(&lt;MAPPINGS&gt;)\n  ) +\n  &lt;FACET_FUNCTION&gt; +\n  theme_&lt;name&gt;()"
  },
  {
    "objectID": "slides/04/slides04.html#try-it",
    "href": "slides/04/slides04.html#try-it",
    "title": "Plot design",
    "section": "Try it",
    "text": "Try it\nApply theme_light() to the histogram\n\n\n\n\n\n\n\n\n\n\n\n\n−+\n00:30"
  },
  {
    "objectID": "slides/04/slides04.html#even-more-customizations",
    "href": "slides/04/slides04.html#even-more-customizations",
    "title": "Plot design",
    "section": "Even more customizations",
    "text": "Even more customizations\n\nMove legend\nClean up labels and title\nGet rid of .5’s in x-axis\nAnnotations"
  },
  {
    "objectID": "slides/04/slides04.html#theme",
    "href": "slides/04/slides04.html#theme",
    "title": "Plot design",
    "section": "?theme",
    "text": "?theme\n\ntheme(line, rect, text, title, aspect.ratio, axis.title, axis.title.x,\n  axis.title.x.top, axis.title.x.bottom, axis.title.y, axis.title.y.left,\n  axis.title.y.right, axis.text, axis.text.x, axis.text.x.top,\n  axis.text.x.bottom, axis.text.y, axis.text.y.left, axis.text.y.right,\n  axis.ticks, axis.ticks.x, axis.ticks.x.top, axis.ticks.x.bottom,\n  axis.ticks.y, axis.ticks.y.left, axis.ticks.y.right, axis.ticks.length,\n  axis.line, axis.line.x, axis.line.x.top, axis.line.x.bottom, axis.line.y,\n  axis.line.y.left, axis.line.y.right, legend.background, legend.margin,\n  legend.spacing, legend.spacing.x, legend.spacing.y, legend.key,\n  legend.key.size, legend.key.height, legend.key.width, legend.text,\n  legend.text.align, legend.title, legend.title.align, legend.position,\n  legend.direction, legend.justification, legend.box, legend.box.just,\n  legend.box.margin, legend.box.background, legend.box.spacing,\n  panel.background, panel.border, panel.spacing, panel.spacing.x,\n  panel.spacing.y, panel.grid, panel.grid.major, panel.grid.minor,\n  panel.grid.major.x, panel.grid.major.y, panel.grid.minor.x,\n  panel.grid.minor.y, panel.ontop, plot.background, plot.title,\n  plot.subtitle, plot.caption, plot.tag, plot.tag.position, plot.margin,\n  strip.background, strip.background.x, strip.background.y,\n  strip.placement, strip.text, strip.text.x, strip.text.y,\n  strip.switch.pad.grid, strip.switch.pad.wrap, ..., complete = FALSE,\n  validate = TRUE)\n\n\n\nTo see examples in action, see “Theme Elements” of the ggplot2 book"
  },
  {
    "objectID": "slides/04/slides04.html#move-legend-and-make-the-background-transparent",
    "href": "slides/04/slides04.html#move-legend-and-make-the-background-transparent",
    "title": "Plot design",
    "section": "Move legend and make the background transparent",
    "text": "Move legend and make the background transparent\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  theme_minimal() + \n  theme(\n    legend.position = c(.15, .85),\n    legend.background = element_blank()\n  )"
  },
  {
    "objectID": "slides/04/slides04.html#clean-up-labels-and-title",
    "href": "slides/04/slides04.html#clean-up-labels-and-title",
    "title": "Plot design",
    "section": "Clean up labels and title",
    "text": "Clean up labels and title\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  theme_minimal() + \n  theme(\n    legend.position = c(.15, .85),\n    legend.background = element_blank()\n  ) + \n  labs(\n    x = \"Season Average IMDB Rating\",\n    y = \"\",\n    fill = \"\",\n    title = \"Survivor is better on Thursdays\"\n  )"
  },
  {
    "objectID": "slides/04/slides04.html#remove-minor-gridlines",
    "href": "slides/04/slides04.html#remove-minor-gridlines",
    "title": "Plot design",
    "section": "Remove minor gridlines",
    "text": "Remove minor gridlines\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  theme_minimal() + \n  theme(\n    legend.position = c(.15, .85),\n    legend.background = element_blank(),\n    panel.grid.minor = element_blank()\n  ) + \n  labs(\n    x = \"Season Average IMDB Rating\",\n    y = \"\",\n    fill = \"\",\n    title = \"Survivor is better on Thursdays\"\n  )"
  },
  {
    "objectID": "slides/04/slides04.html#get-rid-of-.5s",
    "href": "slides/04/slides04.html#get-rid-of-.5s",
    "title": "Plot design",
    "section": "Get rid of .5’s",
    "text": "Get rid of .5’s\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  scale_x_continuous(breaks = c(6, 7, 8, 9)) +\n  theme_minimal() + \n  theme(\n    legend.position = c(.15, .85),\n    legend.background = element_blank(),\n    panel.grid.minor = element_blank()\n  ) + \n  labs(\n    x = \"Season Average IMDB Rating\",\n    y = \"\",\n    fill = \"\",\n    title = \"Survivor is better on Thursdays\"\n  )"
  },
  {
    "objectID": "slides/04/slides04.html#add-an-annotation",
    "href": "slides/04/slides04.html#add-an-annotation",
    "title": "Plot design",
    "section": "Add an annotation",
    "text": "Add an annotation\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  scale_x_continuous(breaks = c(6, 7, 8, 9)) +\n  theme_minimal() + \n  theme(\n    legend.position = c(.15, .85),\n    legend.background = element_blank(),\n    panel.grid.minor = element_blank()\n  ) + \n  labs(\n    x = \"Season Average IMDB Rating\",\n    y = \"\",\n    fill = \"\",\n    title = \"Survivor is better on Thursdays\"\n  ) +\n  annotate(\"text\", \n           x = 6, \n           y = 3, \n           label = \"Lowest ratings \\n occur on \\n Wednesdays\",\n           col = \"navyblue\")"
  },
  {
    "objectID": "slides/04/slides04.html#which-do-you-prefer",
    "href": "slides/04/slides04.html#which-do-you-prefer",
    "title": "Plot design",
    "section": "Which do you prefer?",
    "text": "Which do you prefer?\nPlot A:"
  },
  {
    "objectID": "slides/04/slides04.html#which-do-you-prefer-1",
    "href": "slides/04/slides04.html#which-do-you-prefer-1",
    "title": "Plot design",
    "section": "Which do you prefer?",
    "text": "Which do you prefer?\nPlot B:"
  },
  {
    "objectID": "slides/04/slides04.html#general-guidelines",
    "href": "slides/04/slides04.html#general-guidelines",
    "title": "Plot design",
    "section": "General guidelines",
    "text": "General guidelines\n\nShow the data, don’t distort it\nChoose the right plot\nUse color meaningfully and with restraint\nTell a story\nLeave out non-story details"
  },
  {
    "objectID": "slides/04/slides04.html#show-the-data-dont-distort-it",
    "href": "slides/04/slides04.html#show-the-data-dont-distort-it",
    "title": "Plot design",
    "section": "Show the data, don’t distort it",
    "text": "Show the data, don’t distort it"
  },
  {
    "objectID": "slides/04/slides04.html#show-the-data-dont-distort-it-1",
    "href": "slides/04/slides04.html#show-the-data-dont-distort-it-1",
    "title": "Plot design",
    "section": "Show the data, don’t distort it",
    "text": "Show the data, don’t distort it\n\n\nWhat a huge effect! \n\nBut it isn’t the whole story"
  },
  {
    "objectID": "slides/04/slides04.html#choose-the-right-plot",
    "href": "slides/04/slides04.html#choose-the-right-plot",
    "title": "Plot design",
    "section": "Choose the right plot",
    "text": "Choose the right plot\n\n\n\nWilke has good suggestions in chapters 5-16\nAlways stop and think about how easy it is to see the story\nTry a few different options"
  },
  {
    "objectID": "slides/04/slides04.html#example-which-slice-is-the-biggestsmallest",
    "href": "slides/04/slides04.html#example-which-slice-is-the-biggestsmallest",
    "title": "Plot design",
    "section": "Example: Which slice is the biggest/smallest?",
    "text": "Example: Which slice is the biggest/smallest?\n\n\n\n\n\n\n\n\n−+\n00:30\n\n\n\n\n\n\n\n\n\n\n\n\nThe issue with pie chart by Data to Viz"
  },
  {
    "objectID": "slides/04/slides04.html#use-color-meaningfully-and-with-restraint",
    "href": "slides/04/slides04.html#use-color-meaningfully-and-with-restraint",
    "title": "Plot design",
    "section": "Use color meaningfully and with restraint",
    "text": "Use color meaningfully and with restraint"
  },
  {
    "objectID": "slides/04/slides04.html#use-color-meaningfully-and-with-restraint-1",
    "href": "slides/04/slides04.html#use-color-meaningfully-and-with-restraint-1",
    "title": "Plot design",
    "section": "Use color meaningfully and with restraint",
    "text": "Use color meaningfully and with restraint"
  },
  {
    "objectID": "slides/04/slides04.html#tell-a-story",
    "href": "slides/04/slides04.html#tell-a-story",
    "title": "Plot design",
    "section": "Tell a story",
    "text": "Tell a story\nOne way to do this is by highlighting the important parts"
  },
  {
    "objectID": "slides/04/slides04.html#leave-out-non-story-details",
    "href": "slides/04/slides04.html#leave-out-non-story-details",
    "title": "Plot design",
    "section": "Leave out non-story details",
    "text": "Leave out non-story details\nIs this train schedule easy to read?"
  },
  {
    "objectID": "slides/04/slides04.html#avoid-distractions",
    "href": "slides/04/slides04.html#avoid-distractions",
    "title": "Plot design",
    "section": "Avoid distractions",
    "text": "Avoid distractions\nDoes removing gridlines make it somewhat easier?"
  },
  {
    "objectID": "slides/04/slides04.html#data-visualizations-have-an-aura-of-objectivity",
    "href": "slides/04/slides04.html#data-visualizations-have-an-aura-of-objectivity",
    "title": "Plot design",
    "section": "Data visualizations have an aura of objectivity",
    "text": "Data visualizations have an aura of objectivity\n\n\n\n“We focus on four conventions which imbue visualisations with a sense of objectivity, transparency and facticity. These include: a) two-dimensional viewpoints; b) clean layouts; c) geometric shapes and lines; d) the inclusion of data sources.”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Kennedy, Hill, Aiello & Allen. (2016) The work that visualisation conventions do. Information, Communication and Society, 19 (6). pp. 715-735. ISSN 1369-118X"
  },
  {
    "objectID": "slides/04/slides04.html#good-graphs-can-also-break-these-guidelines",
    "href": "slides/04/slides04.html#good-graphs-can-also-break-these-guidelines",
    "title": "Plot design",
    "section": "Good graphs can also break these guidelines",
    "text": "Good graphs can also break these guidelines\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mona Chalabi @monachalabi"
  },
  {
    "objectID": "slides/04/slides04.html#good-graphs-can-also-break-these-guidelines-1",
    "href": "slides/04/slides04.html#good-graphs-can-also-break-these-guidelines-1",
    "title": "Plot design",
    "section": "Good graphs can also break these guidelines",
    "text": "Good graphs can also break these guidelines\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mona Chalabi @monachalabi"
  },
  {
    "objectID": "slides/04/slides04.html#your-turn",
    "href": "slides/04/slides04.html#your-turn",
    "title": "Plot design",
    "section": "Your turn",
    "text": "Your turn\nNow that we have the toolkit to make customizations to our plots, and some “rules” for good graphs, let’s break them!\n\n\nChoose a graph (the one from class today, one from last class, one from homework, etc.)\nMake it ugly\n\n\nChange the color scale\nChoose a complete theme\nMake at least 3 custom tweaks to the theme options\n\n\nExplain why it’s ugly (what “rules” are you breaking? what makes it an ineffective graph?)\nPost to our slack #social channel when you’re done (you don’t have to post your explanation)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stat 220: Intro to Data Science",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the term. Note that this schedule will be updated as the term progresses and the timeline of topics and assignments might be updated. Any major changes to due dates will be announced in class and indicated in bold here.\n\n\n\n\n\n\nWEEK\nDOW\nDATE\nPREPARE\nTOPIC\nMATERIALS\nDUE\n\n\n\n1\nM\nMon, Jan 6\n📝complete welcome survey\n\nWelcome + data, R review\n\nslides01 01-example-unvotes\n\n\n\n\n1\nW\nWed, Jan 8\n📚 R basics  📚 R4DS 1e 27.1-27.4  📺 git and GitHub for poets  📝 Read syllabus and pass syllabus quiz to activate tokens\nGithub + reproducible reports\n\nslides02 02-reproducible-reports 02-lego-report\n\n\n\n\n1\nF\nFri, Jan 10\n📝 10 minute activity on markdown  📚 R4DS Ch1  📺 intro to ggplot\n\nggplot\n\nslides03 03-ggplot-intro and .rmd\n\nHW 1 (on moodle)\n\n\n2\nM\nMon, Jan 13\n📚 DataViz 17-21 \n\nTheming + Design\n\nslides04  04-customizing-plots .rmd\n\n\n\n\n2\nW\nWed, Jan 15\n📚 DataViz 15 \n\nMaps/spatial data\n\nslides05  05-maps .rmd\n\nHW 2\n\n\n2\nF\nFri, Jan 17\n📺 first 15 minutes of Accessible Data Science Beyond Visual Models  📚 Skim Writing Alt Text to Communicate the Meaning in Data Visualizations\n\nAccesibility for data viz\nslides06\n\n\n\n3\nM\nMon, Jan 20\n📚 R4DS 3.1-3.4 \n\nVerbs\n\nslides07 07-verbs\n\nPortfolio 1\n\n\n3\nW\nWed, Jan 22\n📚 R4DS 3.5  📚 R4DS 4 \n\nGroups and summarizing Code style\n\nslides08 08-dplyr2\n\nHW 3\n\n\n3\nF\nFri, Jan 24\n📚 R4DS 5.1-5.4 \n\nTidy data\n\nslides09 09-tidyr\n\nLab Quiz 1\n\n\n4\nM\nMon, Jan 27\n📚 R4DS 19.1-19.3\n\nCombining datasets\n\nslides10 10-combining\n\n\n\n\n4\nW\nWed, Jan 29\n📚 R4DS 7.1-7.4  📚 R4DS 17.1-17.3 \n\nImport data and dates/times\n\nslides11 11-import\n\nHW 4\n\n\n4\nF\nFri, Jan 31\n📚 R4DS 16 \n\nWorking with factors\n\nslides12 12-factors\n\n\n\n\n5\nM\nMon, Feb 3\n📚 R4DS 14  📚 R4DS 15.1-15.5\n\nWorking with strings and Regex\n\n\n\n\n5\nW\nWed, Feb 5\n📚 MDSR 19.2  🌎 Google ngram viewer\n\nText Analysis\n\nHW 5, Portfolio 2\n\n\n\n5\nF\nFri, Feb 7\nTBA\nTBA\n\nLab Quiz 2\n\n\n6\nM\nMon, Feb 10\n\n❌ Midterm Break; no class\n\n\n\n\n6\nW\nWed, Feb 12\n📚 R4DS 25\n\nFunctions\n\n\n\n\n6\nF\nFri, Feb 14\n📚 MDSR 7.1-7.3\n\nIteration\n\nHW6\n\n\n7\nM\nMon, Feb 17\n📚What is an API? 📚R4DS 23 📝 sign up for a census API key\n\nAPIs\n\n\n\n\n7\nW\nWed, Feb 19\nTBA\nScraping\n\nHW7  Final Project Proposal\n\n\n7\nF\nFri, Feb 21\n\nEthics III\n\nLab Quiz 3\n\n\n8\nM\nMon, Feb 24\nTBA\nIntro to Interactivity\n\n\n\n\n8\nW\nWed, Feb 26\nPick one:  📺 Shiny basics playlist  📚Ch 1-2 of Mastering Shiny\n\nShiny 1\n\nHW8, Portfolio 3\n\n\n\n8\nF\nFri, Feb 28\nPick one:  📺 Reactivity in shiny playlist  📚Ch 3 of Mastering Shiny\n\nShiny 2\n\n\n\n\n9\nM\nMon, Mar 3\n\nShiny 3\n\nFinal Project sketch draft\n\n\n9\nW\nWed, Mar 5\n📚MDSR 15.1-15.4\n\nSQL\n\n\n\n\n9\nF\nFri, Mar 7\n\nSQL\n\nPortfolio 4\n\n\n10\nM\nMon, Mar 10\n\nProject Demos\n\n\n\n\n10\nW\nWed, Mar 12\n\nProject Demos\n\nHW9",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio Server\n🔗 Carleton’s Maize Server\n\n\nCourse GitHub organization\n🔗 GitHub\n\n\nGradebook\n🔗 on Moodle\n\n\nSpend a Token\n🔗 Spend a token\n\n\nTextbooks\n🔗 Modern Data Science with R (MDS)\n🔗 R for Data Science (R4DS)\n🔗 Fundamentals of Data Visualization\n\n\nPackage documentation\n🔗 ggplot2: ggplot2.tidyverse.org\n🔗 dplyr: dplyr.tidyverse.org\n🔗 tidyr: tidyr.tidyverse.org\n🔗 forcats: forcats.tidyverse.org\n🔗 stringr: stringr.tidyverse.org\n🔗 lubridate: lubridate.tidyverse.org\n🔗 readr: readr.tidyverse.org",
    "crumbs": [
      "Course information",
      "Useful links"
    ]
  },
  {
    "objectID": "slides/03/slides03.html#plan-for-today",
    "href": "slides/03/slides03.html#plan-for-today",
    "title": "ggplot2",
    "section": "Plan for today:",
    "text": "Plan for today:\n\nSuper quick grammar of graphics recap\nSpeed Groupwork\nIntro to portfolio project 1"
  },
  {
    "objectID": "slides/03/slides03.html#what-are-the-essential-elements-of-this-scatterplot",
    "href": "slides/03/slides03.html#what-are-the-essential-elements-of-this-scatterplot",
    "title": "ggplot2",
    "section": "What are the essential elements of this scatterplot?",
    "text": "What are the essential elements of this scatterplot?"
  },
  {
    "objectID": "slides/03/slides03.html#data",
    "href": "slides/03/slides03.html#data",
    "title": "ggplot2",
    "section": "Data",
    "text": "Data\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007\n\n\nAdelie\nTorgersen\n38.9\n17.8\n181\n3625\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.2\n19.6\n195\n4675\nmale\n2007\n\n\nAdelie\nTorgersen\n34.1\n18.1\n193\n3475\nNA\n2007\n\n\nAdelie\nTorgersen\n42.0\n20.2\n190\n4250\nNA\n2007\n\n\nAdelie\nTorgersen\n37.8\n17.1\n186\n3300\nNA\n2007\n\n\nAdelie\nTorgersen\n37.8\n17.3\n180\n3700\nNA\n2007\n\n\nAdelie\nTorgersen\n41.1\n17.6\n182\n3200\nfemale\n2007\n\n\nAdelie\nTorgersen\n38.6\n21.2\n191\n3800\nmale\n2007\n\n\nAdelie\nTorgersen\n34.6\n21.1\n198\n4400\nmale\n2007\n\n\nAdelie\nTorgersen\n36.6\n17.8\n185\n3700\nfemale\n2007\n\n\nAdelie\nTorgersen\n38.7\n19.0\n195\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n42.5\n20.7\n197\n4500\nmale\n2007\n\n\nAdelie\nTorgersen\n34.4\n18.4\n184\n3325\nfemale\n2007\n\n\nAdelie\nTorgersen\n46.0\n21.5\n194\n4200\nmale\n2007\n\n\nAdelie\nBiscoe\n37.8\n18.3\n174\n3400\nfemale\n2007\n\n\nAdelie\nBiscoe\n37.7\n18.7\n180\n3600\nmale\n2007\n\n\nAdelie\nBiscoe\n35.9\n19.2\n189\n3800\nfemale\n2007\n\n\nAdelie\nBiscoe\n38.2\n18.1\n185\n3950\nmale\n2007\n\n\nAdelie\nBiscoe\n38.8\n17.2\n180\n3800\nmale\n2007\n\n\nAdelie\nBiscoe\n35.3\n18.9\n187\n3800\nfemale\n2007\n\n\nAdelie\nBiscoe\n40.6\n18.6\n183\n3550\nmale\n2007\n\n\nAdelie\nBiscoe\n40.5\n17.9\n187\n3200\nfemale\n2007\n\n\nAdelie\nBiscoe\n37.9\n18.6\n172\n3150\nfemale\n2007\n\n\nAdelie\nBiscoe\n40.5\n18.9\n180\n3950\nmale\n2007\n\n\nAdelie\nDream\n39.5\n16.7\n178\n3250\nfemale\n2007\n\n\nAdelie\nDream\n37.2\n18.1\n178\n3900\nmale\n2007\n\n\nAdelie\nDream\n39.5\n17.8\n188\n3300\nfemale\n2007\n\n\nAdelie\nDream\n40.9\n18.9\n184\n3900\nmale\n2007\n\n\nAdelie\nDream\n36.4\n17.0\n195\n3325\nfemale\n2007\n\n\nAdelie\nDream\n39.2\n21.1\n196\n4150\nmale\n2007\n\n\nAdelie\nDream\n38.8\n20.0\n190\n3950\nmale\n2007\n\n\nAdelie\nDream\n42.2\n18.5\n180\n3550\nfemale\n2007\n\n\nAdelie\nDream\n37.6\n19.3\n181\n3300\nfemale\n2007\n\n\nAdelie\nDream\n39.8\n19.1\n184\n4650\nmale\n2007\n\n\nAdelie\nDream\n36.5\n18.0\n182\n3150\nfemale\n2007\n\n\nAdelie\nDream\n40.8\n18.4\n195\n3900\nmale\n2007\n\n\nAdelie\nDream\n36.0\n18.5\n186\n3100\nfemale\n2007\n\n\nAdelie\nDream\n44.1\n19.7\n196\n4400\nmale\n2007\n\n\nAdelie\nDream\n37.0\n16.9\n185\n3000\nfemale\n2007\n\n\nAdelie\nDream\n39.6\n18.8\n190\n4600\nmale\n2007\n\n\nAdelie\nDream\n41.1\n19.0\n182\n3425\nmale\n2007\n\n\nAdelie\nDream\n37.5\n18.9\n179\n2975\nNA\n2007\n\n\nAdelie\nDream\n36.0\n17.9\n190\n3450\nfemale\n2007\n\n\nAdelie\nDream\n42.3\n21.2\n191\n4150\nmale\n2007\n\n\nAdelie\nBiscoe\n39.6\n17.7\n186\n3500\nfemale\n2008\n\n\nAdelie\nBiscoe\n40.1\n18.9\n188\n4300\nmale\n2008\n\n\nAdelie\nBiscoe\n35.0\n17.9\n190\n3450\nfemale\n2008\n\n\nAdelie\nBiscoe\n42.0\n19.5\n200\n4050\nmale\n2008\n\n\nAdelie\nBiscoe\n34.5\n18.1\n187\n2900\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.4\n18.6\n191\n3700\nmale\n2008\n\n\nAdelie\nBiscoe\n39.0\n17.5\n186\n3550\nfemale\n2008\n\n\nAdelie\nBiscoe\n40.6\n18.8\n193\n3800\nmale\n2008\n\n\nAdelie\nBiscoe\n36.5\n16.6\n181\n2850\nfemale\n2008\n\n\nAdelie\nBiscoe\n37.6\n19.1\n194\n3750\nmale\n2008\n\n\nAdelie\nBiscoe\n35.7\n16.9\n185\n3150\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.3\n21.1\n195\n4400\nmale\n2008\n\n\nAdelie\nBiscoe\n37.6\n17.0\n185\n3600\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.1\n18.2\n192\n4050\nmale\n2008\n\n\nAdelie\nBiscoe\n36.4\n17.1\n184\n2850\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.6\n18.0\n192\n3950\nmale\n2008\n\n\nAdelie\nBiscoe\n35.5\n16.2\n195\n3350\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.1\n19.1\n188\n4100\nmale\n2008\n\n\nAdelie\nTorgersen\n35.9\n16.6\n190\n3050\nfemale\n2008\n\n\nAdelie\nTorgersen\n41.8\n19.4\n198\n4450\nmale\n2008\n\n\nAdelie\nTorgersen\n33.5\n19.0\n190\n3600\nfemale\n2008\n\n\nAdelie\nTorgersen\n39.7\n18.4\n190\n3900\nmale\n2008\n\n\nAdelie\nTorgersen\n39.6\n17.2\n196\n3550\nfemale\n2008\n\n\nAdelie\nTorgersen\n45.8\n18.9\n197\n4150\nmale\n2008\n\n\nAdelie\nTorgersen\n35.5\n17.5\n190\n3700\nfemale\n2008\n\n\nAdelie\nTorgersen\n42.8\n18.5\n195\n4250\nmale\n2008\n\n\nAdelie\nTorgersen\n40.9\n16.8\n191\n3700\nfemale\n2008\n\n\nAdelie\nTorgersen\n37.2\n19.4\n184\n3900\nmale\n2008\n\n\nAdelie\nTorgersen\n36.2\n16.1\n187\n3550\nfemale\n2008\n\n\nAdelie\nTorgersen\n42.1\n19.1\n195\n4000\nmale\n2008\n\n\nAdelie\nTorgersen\n34.6\n17.2\n189\n3200\nfemale\n2008\n\n\nAdelie\nTorgersen\n42.9\n17.6\n196\n4700\nmale\n2008\n\n\nAdelie\nTorgersen\n36.7\n18.8\n187\n3800\nfemale\n2008\n\n\nAdelie\nTorgersen\n35.1\n19.4\n193\n4200\nmale\n2008\n\n\nAdelie\nDream\n37.3\n17.8\n191\n3350\nfemale\n2008\n\n\nAdelie\nDream\n41.3\n20.3\n194\n3550\nmale\n2008\n\n\nAdelie\nDream\n36.3\n19.5\n190\n3800\nmale\n2008\n\n\nAdelie\nDream\n36.9\n18.6\n189\n3500\nfemale\n2008\n\n\nAdelie\nDream\n38.3\n19.2\n189\n3950\nmale\n2008\n\n\nAdelie\nDream\n38.9\n18.8\n190\n3600\nfemale\n2008\n\n\nAdelie\nDream\n35.7\n18.0\n202\n3550\nfemale\n2008\n\n\nAdelie\nDream\n41.1\n18.1\n205\n4300\nmale\n2008\n\n\nAdelie\nDream\n34.0\n17.1\n185\n3400\nfemale\n2008\n\n\nAdelie\nDream\n39.6\n18.1\n186\n4450\nmale\n2008\n\n\nAdelie\nDream\n36.2\n17.3\n187\n3300\nfemale\n2008\n\n\nAdelie\nDream\n40.8\n18.9\n208\n4300\nmale\n2008\n\n\nAdelie\nDream\n38.1\n18.6\n190\n3700\nfemale\n2008\n\n\nAdelie\nDream\n40.3\n18.5\n196\n4350\nmale\n2008\n\n\nAdelie\nDream\n33.1\n16.1\n178\n2900\nfemale\n2008\n\n\nAdelie\nDream\n43.2\n18.5\n192\n4100\nmale\n2008\n\n\nAdelie\nBiscoe\n35.0\n17.9\n192\n3725\nfemale\n2009\n\n\nAdelie\nBiscoe\n41.0\n20.0\n203\n4725\nmale\n2009\n\n\nAdelie\nBiscoe\n37.7\n16.0\n183\n3075\nfemale\n2009\n\n\nAdelie\nBiscoe\n37.8\n20.0\n190\n4250\nmale\n2009\n\n\nAdelie\nBiscoe\n37.9\n18.6\n193\n2925\nfemale\n2009\n\n\nAdelie\nBiscoe\n39.7\n18.9\n184\n3550\nmale\n2009\n\n\nAdelie\nBiscoe\n38.6\n17.2\n199\n3750\nfemale\n2009\n\n\nAdelie\nBiscoe\n38.2\n20.0\n190\n3900\nmale\n2009\n\n\nAdelie\nBiscoe\n38.1\n17.0\n181\n3175\nfemale\n2009\n\n\nAdelie\nBiscoe\n43.2\n19.0\n197\n4775\nmale\n2009\n\n\nAdelie\nBiscoe\n38.1\n16.5\n198\n3825\nfemale\n2009\n\n\nAdelie\nBiscoe\n45.6\n20.3\n191\n4600\nmale\n2009\n\n\nAdelie\nBiscoe\n39.7\n17.7\n193\n3200\nfemale\n2009\n\n\nAdelie\nBiscoe\n42.2\n19.5\n197\n4275\nmale\n2009\n\n\nAdelie\nBiscoe\n39.6\n20.7\n191\n3900\nfemale\n2009\n\n\nAdelie\nBiscoe\n42.7\n18.3\n196\n4075\nmale\n2009\n\n\nAdelie\nTorgersen\n38.6\n17.0\n188\n2900\nfemale\n2009\n\n\nAdelie\nTorgersen\n37.3\n20.5\n199\n3775\nmale\n2009\n\n\nAdelie\nTorgersen\n35.7\n17.0\n189\n3350\nfemale\n2009\n\n\nAdelie\nTorgersen\n41.1\n18.6\n189\n3325\nmale\n2009\n\n\nAdelie\nTorgersen\n36.2\n17.2\n187\n3150\nfemale\n2009\n\n\nAdelie\nTorgersen\n37.7\n19.8\n198\n3500\nmale\n2009\n\n\nAdelie\nTorgersen\n40.2\n17.0\n176\n3450\nfemale\n2009\n\n\nAdelie\nTorgersen\n41.4\n18.5\n202\n3875\nmale\n2009\n\n\nAdelie\nTorgersen\n35.2\n15.9\n186\n3050\nfemale\n2009\n\n\nAdelie\nTorgersen\n40.6\n19.0\n199\n4000\nmale\n2009\n\n\nAdelie\nTorgersen\n38.8\n17.6\n191\n3275\nfemale\n2009\n\n\nAdelie\nTorgersen\n41.5\n18.3\n195\n4300\nmale\n2009\n\n\nAdelie\nTorgersen\n39.0\n17.1\n191\n3050\nfemale\n2009\n\n\nAdelie\nTorgersen\n44.1\n18.0\n210\n4000\nmale\n2009\n\n\nAdelie\nTorgersen\n38.5\n17.9\n190\n3325\nfemale\n2009\n\n\nAdelie\nTorgersen\n43.1\n19.2\n197\n3500\nmale\n2009\n\n\nAdelie\nDream\n36.8\n18.5\n193\n3500\nfemale\n2009\n\n\nAdelie\nDream\n37.5\n18.5\n199\n4475\nmale\n2009\n\n\nAdelie\nDream\n38.1\n17.6\n187\n3425\nfemale\n2009\n\n\nAdelie\nDream\n41.1\n17.5\n190\n3900\nmale\n2009\n\n\nAdelie\nDream\n35.6\n17.5\n191\n3175\nfemale\n2009\n\n\nAdelie\nDream\n40.2\n20.1\n200\n3975\nmale\n2009\n\n\nAdelie\nDream\n37.0\n16.5\n185\n3400\nfemale\n2009\n\n\nAdelie\nDream\n39.7\n17.9\n193\n4250\nmale\n2009\n\n\nAdelie\nDream\n40.2\n17.1\n193\n3400\nfemale\n2009\n\n\nAdelie\nDream\n40.6\n17.2\n187\n3475\nmale\n2009\n\n\nAdelie\nDream\n32.1\n15.5\n188\n3050\nfemale\n2009\n\n\nAdelie\nDream\n40.7\n17.0\n190\n3725\nmale\n2009\n\n\nAdelie\nDream\n37.3\n16.8\n192\n3000\nfemale\n2009\n\n\nAdelie\nDream\n39.0\n18.7\n185\n3650\nmale\n2009\n\n\nAdelie\nDream\n39.2\n18.6\n190\n4250\nmale\n2009\n\n\nAdelie\nDream\n36.6\n18.4\n184\n3475\nfemale\n2009\n\n\nAdelie\nDream\n36.0\n17.8\n195\n3450\nfemale\n2009\n\n\nAdelie\nDream\n37.8\n18.1\n193\n3750\nmale\n2009\n\n\nAdelie\nDream\n36.0\n17.1\n187\n3700\nfemale\n2009\n\n\nAdelie\nDream\n41.5\n18.5\n201\n4000\nmale\n2009\n\n\nGentoo\nBiscoe\n46.1\n13.2\n211\n4500\nfemale\n2007\n\n\nGentoo\nBiscoe\n50.0\n16.3\n230\n5700\nmale\n2007\n\n\nGentoo\nBiscoe\n48.7\n14.1\n210\n4450\nfemale\n2007\n\n\nGentoo\nBiscoe\n50.0\n15.2\n218\n5700\nmale\n2007\n\n\nGentoo\nBiscoe\n47.6\n14.5\n215\n5400\nmale\n2007\n\n\nGentoo\nBiscoe\n46.5\n13.5\n210\n4550\nfemale\n2007\n\n\nGentoo\nBiscoe\n45.4\n14.6\n211\n4800\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.7\n15.3\n219\n5200\nmale\n2007\n\n\nGentoo\nBiscoe\n43.3\n13.4\n209\n4400\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.8\n15.4\n215\n5150\nmale\n2007\n\n\nGentoo\nBiscoe\n40.9\n13.7\n214\n4650\nfemale\n2007\n\n\nGentoo\nBiscoe\n49.0\n16.1\n216\n5550\nmale\n2007\n\n\nGentoo\nBiscoe\n45.5\n13.7\n214\n4650\nfemale\n2007\n\n\nGentoo\nBiscoe\n48.4\n14.6\n213\n5850\nmale\n2007\n\n\nGentoo\nBiscoe\n45.8\n14.6\n210\n4200\nfemale\n2007\n\n\nGentoo\nBiscoe\n49.3\n15.7\n217\n5850\nmale\n2007\n\n\nGentoo\nBiscoe\n42.0\n13.5\n210\n4150\nfemale\n2007\n\n\nGentoo\nBiscoe\n49.2\n15.2\n221\n6300\nmale\n2007\n\n\nGentoo\nBiscoe\n46.2\n14.5\n209\n4800\nfemale\n2007\n\n\nGentoo\nBiscoe\n48.7\n15.1\n222\n5350\nmale\n2007\n\n\nGentoo\nBiscoe\n50.2\n14.3\n218\n5700\nmale\n2007\n\n\nGentoo\nBiscoe\n45.1\n14.5\n215\n5000\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.5\n14.5\n213\n4400\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.3\n15.8\n215\n5050\nmale\n2007\n\n\nGentoo\nBiscoe\n42.9\n13.1\n215\n5000\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.1\n15.1\n215\n5100\nmale\n2007\n\n\nGentoo\nBiscoe\n44.5\n14.3\n216\n4100\nNA\n2007\n\n\nGentoo\nBiscoe\n47.8\n15.0\n215\n5650\nmale\n2007\n\n\nGentoo\nBiscoe\n48.2\n14.3\n210\n4600\nfemale\n2007\n\n\nGentoo\nBiscoe\n50.0\n15.3\n220\n5550\nmale\n2007\n\n\nGentoo\nBiscoe\n47.3\n15.3\n222\n5250\nmale\n2007\n\n\nGentoo\nBiscoe\n42.8\n14.2\n209\n4700\nfemale\n2007\n\n\nGentoo\nBiscoe\n45.1\n14.5\n207\n5050\nfemale\n2007\n\n\nGentoo\nBiscoe\n59.6\n17.0\n230\n6050\nmale\n2007\n\n\nGentoo\nBiscoe\n49.1\n14.8\n220\n5150\nfemale\n2008\n\n\nGentoo\nBiscoe\n48.4\n16.3\n220\n5400\nmale\n2008\n\n\nGentoo\nBiscoe\n42.6\n13.7\n213\n4950\nfemale\n2008\n\n\nGentoo\nBiscoe\n44.4\n17.3\n219\n5250\nmale\n2008\n\n\nGentoo\nBiscoe\n44.0\n13.6\n208\n4350\nfemale\n2008\n\n\nGentoo\nBiscoe\n48.7\n15.7\n208\n5350\nmale\n2008\n\n\nGentoo\nBiscoe\n42.7\n13.7\n208\n3950\nfemale\n2008\n\n\nGentoo\nBiscoe\n49.6\n16.0\n225\n5700\nmale\n2008\n\n\nGentoo\nBiscoe\n45.3\n13.7\n210\n4300\nfemale\n2008\n\n\nGentoo\nBiscoe\n49.6\n15.0\n216\n4750\nmale\n2008\n\n\nGentoo\nBiscoe\n50.5\n15.9\n222\n5550\nmale\n2008\n\n\nGentoo\nBiscoe\n43.6\n13.9\n217\n4900\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.5\n13.9\n210\n4200\nfemale\n2008\n\n\nGentoo\nBiscoe\n50.5\n15.9\n225\n5400\nmale\n2008\n\n\nGentoo\nBiscoe\n44.9\n13.3\n213\n5100\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.2\n15.8\n215\n5300\nmale\n2008\n\n\nGentoo\nBiscoe\n46.6\n14.2\n210\n4850\nfemale\n2008\n\n\nGentoo\nBiscoe\n48.5\n14.1\n220\n5300\nmale\n2008\n\n\nGentoo\nBiscoe\n45.1\n14.4\n210\n4400\nfemale\n2008\n\n\nGentoo\nBiscoe\n50.1\n15.0\n225\n5000\nmale\n2008\n\n\nGentoo\nBiscoe\n46.5\n14.4\n217\n4900\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.0\n15.4\n220\n5050\nmale\n2008\n\n\nGentoo\nBiscoe\n43.8\n13.9\n208\n4300\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.5\n15.0\n220\n5000\nmale\n2008\n\n\nGentoo\nBiscoe\n43.2\n14.5\n208\n4450\nfemale\n2008\n\n\nGentoo\nBiscoe\n50.4\n15.3\n224\n5550\nmale\n2008\n\n\nGentoo\nBiscoe\n45.3\n13.8\n208\n4200\nfemale\n2008\n\n\nGentoo\nBiscoe\n46.2\n14.9\n221\n5300\nmale\n2008\n\n\nGentoo\nBiscoe\n45.7\n13.9\n214\n4400\nfemale\n2008\n\n\nGentoo\nBiscoe\n54.3\n15.7\n231\n5650\nmale\n2008\n\n\nGentoo\nBiscoe\n45.8\n14.2\n219\n4700\nfemale\n2008\n\n\nGentoo\nBiscoe\n49.8\n16.8\n230\n5700\nmale\n2008\n\n\nGentoo\nBiscoe\n46.2\n14.4\n214\n4650\nNA\n2008\n\n\nGentoo\nBiscoe\n49.5\n16.2\n229\n5800\nmale\n2008\n\n\nGentoo\nBiscoe\n43.5\n14.2\n220\n4700\nfemale\n2008\n\n\nGentoo\nBiscoe\n50.7\n15.0\n223\n5550\nmale\n2008\n\n\nGentoo\nBiscoe\n47.7\n15.0\n216\n4750\nfemale\n2008\n\n\nGentoo\nBiscoe\n46.4\n15.6\n221\n5000\nmale\n2008\n\n\nGentoo\nBiscoe\n48.2\n15.6\n221\n5100\nmale\n2008\n\n\nGentoo\nBiscoe\n46.5\n14.8\n217\n5200\nfemale\n2008\n\n\nGentoo\nBiscoe\n46.4\n15.0\n216\n4700\nfemale\n2008\n\n\nGentoo\nBiscoe\n48.6\n16.0\n230\n5800\nmale\n2008\n\n\nGentoo\nBiscoe\n47.5\n14.2\n209\n4600\nfemale\n2008\n\n\nGentoo\nBiscoe\n51.1\n16.3\n220\n6000\nmale\n2008\n\n\nGentoo\nBiscoe\n45.2\n13.8\n215\n4750\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.2\n16.4\n223\n5950\nmale\n2008\n\n\nGentoo\nBiscoe\n49.1\n14.5\n212\n4625\nfemale\n2009\n\n\nGentoo\nBiscoe\n52.5\n15.6\n221\n5450\nmale\n2009\n\n\nGentoo\nBiscoe\n47.4\n14.6\n212\n4725\nfemale\n2009\n\n\nGentoo\nBiscoe\n50.0\n15.9\n224\n5350\nmale\n2009\n\n\nGentoo\nBiscoe\n44.9\n13.8\n212\n4750\nfemale\n2009\n\n\nGentoo\nBiscoe\n50.8\n17.3\n228\n5600\nmale\n2009\n\n\nGentoo\nBiscoe\n43.4\n14.4\n218\n4600\nfemale\n2009\n\n\nGentoo\nBiscoe\n51.3\n14.2\n218\n5300\nmale\n2009\n\n\nGentoo\nBiscoe\n47.5\n14.0\n212\n4875\nfemale\n2009\n\n\nGentoo\nBiscoe\n52.1\n17.0\n230\n5550\nmale\n2009\n\n\nGentoo\nBiscoe\n47.5\n15.0\n218\n4950\nfemale\n2009\n\n\nGentoo\nBiscoe\n52.2\n17.1\n228\n5400\nmale\n2009\n\n\nGentoo\nBiscoe\n45.5\n14.5\n212\n4750\nfemale\n2009\n\n\nGentoo\nBiscoe\n49.5\n16.1\n224\n5650\nmale\n2009\n\n\nGentoo\nBiscoe\n44.5\n14.7\n214\n4850\nfemale\n2009\n\n\nGentoo\nBiscoe\n50.8\n15.7\n226\n5200\nmale\n2009\n\n\nGentoo\nBiscoe\n49.4\n15.8\n216\n4925\nmale\n2009\n\n\nGentoo\nBiscoe\n46.9\n14.6\n222\n4875\nfemale\n2009\n\n\nGentoo\nBiscoe\n48.4\n14.4\n203\n4625\nfemale\n2009\n\n\nGentoo\nBiscoe\n51.1\n16.5\n225\n5250\nmale\n2009\n\n\nGentoo\nBiscoe\n48.5\n15.0\n219\n4850\nfemale\n2009\n\n\nGentoo\nBiscoe\n55.9\n17.0\n228\n5600\nmale\n2009\n\n\nGentoo\nBiscoe\n47.2\n15.5\n215\n4975\nfemale\n2009\n\n\nGentoo\nBiscoe\n49.1\n15.0\n228\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n47.3\n13.8\n216\n4725\nNA\n2009\n\n\nGentoo\nBiscoe\n46.8\n16.1\n215\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n41.7\n14.7\n210\n4700\nfemale\n2009\n\n\nGentoo\nBiscoe\n53.4\n15.8\n219\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n43.3\n14.0\n208\n4575\nfemale\n2009\n\n\nGentoo\nBiscoe\n48.1\n15.1\n209\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n50.5\n15.2\n216\n5000\nfemale\n2009\n\n\nGentoo\nBiscoe\n49.8\n15.9\n229\n5950\nmale\n2009\n\n\nGentoo\nBiscoe\n43.5\n15.2\n213\n4650\nfemale\n2009\n\n\nGentoo\nBiscoe\n51.5\n16.3\n230\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n46.2\n14.1\n217\n4375\nfemale\n2009\n\n\nGentoo\nBiscoe\n55.1\n16.0\n230\n5850\nmale\n2009\n\n\nGentoo\nBiscoe\n44.5\n15.7\n217\n4875\nNA\n2009\n\n\nGentoo\nBiscoe\n48.8\n16.2\n222\n6000\nmale\n2009\n\n\nGentoo\nBiscoe\n47.2\n13.7\n214\n4925\nfemale\n2009\n\n\nGentoo\nBiscoe\nNA\nNA\nNA\nNA\nNA\n2009\n\n\nGentoo\nBiscoe\n46.8\n14.3\n215\n4850\nfemale\n2009\n\n\nGentoo\nBiscoe\n50.4\n15.7\n222\n5750\nmale\n2009\n\n\nGentoo\nBiscoe\n45.2\n14.8\n212\n5200\nfemale\n2009\n\n\nGentoo\nBiscoe\n49.9\n16.1\n213\n5400\nmale\n2009\n\n\nChinstrap\nDream\n46.5\n17.9\n192\n3500\nfemale\n2007\n\n\nChinstrap\nDream\n50.0\n19.5\n196\n3900\nmale\n2007\n\n\nChinstrap\nDream\n51.3\n19.2\n193\n3650\nmale\n2007\n\n\nChinstrap\nDream\n45.4\n18.7\n188\n3525\nfemale\n2007\n\n\nChinstrap\nDream\n52.7\n19.8\n197\n3725\nmale\n2007\n\n\nChinstrap\nDream\n45.2\n17.8\n198\n3950\nfemale\n2007\n\n\nChinstrap\nDream\n46.1\n18.2\n178\n3250\nfemale\n2007\n\n\nChinstrap\nDream\n51.3\n18.2\n197\n3750\nmale\n2007\n\n\nChinstrap\nDream\n46.0\n18.9\n195\n4150\nfemale\n2007\n\n\nChinstrap\nDream\n51.3\n19.9\n198\n3700\nmale\n2007\n\n\nChinstrap\nDream\n46.6\n17.8\n193\n3800\nfemale\n2007\n\n\nChinstrap\nDream\n51.7\n20.3\n194\n3775\nmale\n2007\n\n\nChinstrap\nDream\n47.0\n17.3\n185\n3700\nfemale\n2007\n\n\nChinstrap\nDream\n52.0\n18.1\n201\n4050\nmale\n2007\n\n\nChinstrap\nDream\n45.9\n17.1\n190\n3575\nfemale\n2007\n\n\nChinstrap\nDream\n50.5\n19.6\n201\n4050\nmale\n2007\n\n\nChinstrap\nDream\n50.3\n20.0\n197\n3300\nmale\n2007\n\n\nChinstrap\nDream\n58.0\n17.8\n181\n3700\nfemale\n2007\n\n\nChinstrap\nDream\n46.4\n18.6\n190\n3450\nfemale\n2007\n\n\nChinstrap\nDream\n49.2\n18.2\n195\n4400\nmale\n2007\n\n\nChinstrap\nDream\n42.4\n17.3\n181\n3600\nfemale\n2007\n\n\nChinstrap\nDream\n48.5\n17.5\n191\n3400\nmale\n2007\n\n\nChinstrap\nDream\n43.2\n16.6\n187\n2900\nfemale\n2007\n\n\nChinstrap\nDream\n50.6\n19.4\n193\n3800\nmale\n2007\n\n\nChinstrap\nDream\n46.7\n17.9\n195\n3300\nfemale\n2007\n\n\nChinstrap\nDream\n52.0\n19.0\n197\n4150\nmale\n2007\n\n\nChinstrap\nDream\n50.5\n18.4\n200\n3400\nfemale\n2008\n\n\nChinstrap\nDream\n49.5\n19.0\n200\n3800\nmale\n2008\n\n\nChinstrap\nDream\n46.4\n17.8\n191\n3700\nfemale\n2008\n\n\nChinstrap\nDream\n52.8\n20.0\n205\n4550\nmale\n2008\n\n\nChinstrap\nDream\n40.9\n16.6\n187\n3200\nfemale\n2008\n\n\nChinstrap\nDream\n54.2\n20.8\n201\n4300\nmale\n2008\n\n\nChinstrap\nDream\n42.5\n16.7\n187\n3350\nfemale\n2008\n\n\nChinstrap\nDream\n51.0\n18.8\n203\n4100\nmale\n2008\n\n\nChinstrap\nDream\n49.7\n18.6\n195\n3600\nmale\n2008\n\n\nChinstrap\nDream\n47.5\n16.8\n199\n3900\nfemale\n2008\n\n\nChinstrap\nDream\n47.6\n18.3\n195\n3850\nfemale\n2008\n\n\nChinstrap\nDream\n52.0\n20.7\n210\n4800\nmale\n2008\n\n\nChinstrap\nDream\n46.9\n16.6\n192\n2700\nfemale\n2008\n\n\nChinstrap\nDream\n53.5\n19.9\n205\n4500\nmale\n2008\n\n\nChinstrap\nDream\n49.0\n19.5\n210\n3950\nmale\n2008\n\n\nChinstrap\nDream\n46.2\n17.5\n187\n3650\nfemale\n2008\n\n\nChinstrap\nDream\n50.9\n19.1\n196\n3550\nmale\n2008\n\n\nChinstrap\nDream\n45.5\n17.0\n196\n3500\nfemale\n2008\n\n\nChinstrap\nDream\n50.9\n17.9\n196\n3675\nfemale\n2009\n\n\nChinstrap\nDream\n50.8\n18.5\n201\n4450\nmale\n2009\n\n\nChinstrap\nDream\n50.1\n17.9\n190\n3400\nfemale\n2009\n\n\nChinstrap\nDream\n49.0\n19.6\n212\n4300\nmale\n2009\n\n\nChinstrap\nDream\n51.5\n18.7\n187\n3250\nmale\n2009\n\n\nChinstrap\nDream\n49.8\n17.3\n198\n3675\nfemale\n2009\n\n\nChinstrap\nDream\n48.1\n16.4\n199\n3325\nfemale\n2009\n\n\nChinstrap\nDream\n51.4\n19.0\n201\n3950\nmale\n2009\n\n\nChinstrap\nDream\n45.7\n17.3\n193\n3600\nfemale\n2009\n\n\nChinstrap\nDream\n50.7\n19.7\n203\n4050\nmale\n2009\n\n\nChinstrap\nDream\n42.5\n17.3\n187\n3350\nfemale\n2009\n\n\nChinstrap\nDream\n52.2\n18.8\n197\n3450\nmale\n2009\n\n\nChinstrap\nDream\n45.2\n16.6\n191\n3250\nfemale\n2009\n\n\nChinstrap\nDream\n49.3\n19.9\n203\n4050\nmale\n2009\n\n\nChinstrap\nDream\n50.2\n18.8\n202\n3800\nmale\n2009\n\n\nChinstrap\nDream\n45.6\n19.4\n194\n3525\nfemale\n2009\n\n\nChinstrap\nDream\n51.9\n19.5\n206\n3950\nmale\n2009\n\n\nChinstrap\nDream\n46.8\n16.5\n189\n3650\nfemale\n2009\n\n\nChinstrap\nDream\n45.7\n17.0\n195\n3650\nfemale\n2009\n\n\nChinstrap\nDream\n55.8\n19.8\n207\n4000\nmale\n2009\n\n\nChinstrap\nDream\n43.5\n18.1\n202\n3400\nfemale\n2009\n\n\nChinstrap\nDream\n49.6\n18.2\n193\n3775\nmale\n2009\n\n\nChinstrap\nDream\n50.8\n19.0\n210\n4100\nmale\n2009\n\n\nChinstrap\nDream\n50.2\n18.7\n198\n3775\nfemale\n2009"
  },
  {
    "objectID": "slides/03/slides03.html#aesthetic",
    "href": "slides/03/slides03.html#aesthetic",
    "title": "ggplot2",
    "section": "Aesthetic",
    "text": "Aesthetic\n\n\nA visual property of the objects in the plot\n\nx → body mass\ny → flipper length\ncolor → species"
  },
  {
    "objectID": "slides/03/slides03.html#geometric-object",
    "href": "slides/03/slides03.html#geometric-object",
    "title": "ggplot2",
    "section": "Geometric Object",
    "text": "Geometric Object\n\n\nHow the data are represented\n\npoints!"
  },
  {
    "objectID": "slides/03/slides03.html#the-basic-ggplot-template",
    "href": "slides/03/slides03.html#the-basic-ggplot-template",
    "title": "ggplot2",
    "section": "The basic ggplot template:",
    "text": "The basic ggplot template:\n\nggplot(data = &lt;dataset_name&gt;) + \n  &lt;geom_function&gt;(mapping = aes(&lt;mappings&gt;))"
  },
  {
    "objectID": "slides/03/slides03.html#facets",
    "href": "slides/03/slides03.html#facets",
    "title": "ggplot2",
    "section": "Facets",
    "text": "Facets\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, col = species)) + \n  geom_point() + \n  facet_wrap(vars(species)) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/03/slides03.html#statistical-transformations",
    "href": "slides/03/slides03.html#statistical-transformations",
    "title": "ggplot2",
    "section": "Statistical Transformations",
    "text": "Statistical Transformations"
  },
  {
    "objectID": "slides/03/slides03.html#coordinates",
    "href": "slides/03/slides03.html#coordinates",
    "title": "ggplot2",
    "section": "Coordinates",
    "text": "Coordinates\n\n\nSource: Nathan Yau, Data Points"
  },
  {
    "objectID": "slides/03/slides03.html#scalesguides",
    "href": "slides/03/slides03.html#scalesguides",
    "title": "ggplot2",
    "section": "Scales/guides",
    "text": "Scales/guides\n\n\nSource: Nathan Yau, Data Points"
  },
  {
    "objectID": "slides/03/slides03.html#themes",
    "href": "slides/03/slides03.html#themes",
    "title": "ggplot2",
    "section": "Themes",
    "text": "Themes\nAll non-data ink (e.g. background color, appearance of grid lines)"
  },
  {
    "objectID": "slides/03/slides03.html#how-it-works",
    "href": "slides/03/slides03.html#how-it-works",
    "title": "ggplot2",
    "section": "How it works",
    "text": "How it works\n\nDraw a card\nFind your number’s location\nIntroduce yourselves\nGet to work!"
  },
  {
    "objectID": "slides/03/slides03.html#round-1-view-the-data-pipes",
    "href": "slides/03/slides03.html#round-1-view-the-data-pipes",
    "title": "ggplot2",
    "section": "Round 1: View the data + pipes",
    "text": "Round 1: View the data + pipes\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/03/slides03.html#round-2-scatterplots",
    "href": "slides/03/slides03.html#round-2-scatterplots",
    "title": "ggplot2",
    "section": "Round 2: Scatterplots",
    "text": "Round 2: Scatterplots\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/03/slides03.html#round-3-additional-aesthetics",
    "href": "slides/03/slides03.html#round-3-additional-aesthetics",
    "title": "ggplot2",
    "section": "Round 3: Additional Aesthetics",
    "text": "Round 3: Additional Aesthetics\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/03/slides03.html#round-4-visualizing-distributions",
    "href": "slides/03/slides03.html#round-4-visualizing-distributions",
    "title": "ggplot2",
    "section": "Round 4: Visualizing Distributions",
    "text": "Round 4: Visualizing Distributions\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/03/slides03.html#round-5-bar-and-column-charts-labeling",
    "href": "slides/03/slides03.html#round-5-bar-and-column-charts-labeling",
    "title": "ggplot2",
    "section": "Round 5: Bar and column charts + Labeling",
    "text": "Round 5: Bar and column charts + Labeling\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/05/slides05.html#today",
    "href": "slides/05/slides05.html#today",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Today",
    "text": "Today\n\ngit/GitHub\nIntro to Spatial Data\nMaking Maps in ggplot2"
  },
  {
    "objectID": "slides/05/slides05.html#section",
    "href": "slides/05/slides05.html#section",
    "title": "Intro to Maps  and Spatial Data",
    "section": "",
    "text": "Think of the state on GitHub as “worst case scenario”\nIf you screw things up, copy your important files (eg. hw.Rmd) to a safe place.\n\nUsually your files are JUST FINE. But it is easy to goof up the Git infrastructure when you’re new at this. And it can be hard to get that straightened out on your own.\n\nRename the existing local repo as a temporary measure, i.e. before you do something radical, like delete it.\nClone the original repo from GitHub to RStudio (follow the directions to create a new project). You are back to a happy state.\nCopy all relevant files back over from your safe space. The ones whose updated state you need to commit.\nKnit, commit, push\nCarry on with your life.\n\n\n\n\n\n\nBurn It All Down from Happy Git with R"
  },
  {
    "objectID": "slides/05/slides05.html#cholera",
    "href": "slides/05/slides05.html#cholera",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Cholera",
    "text": "Cholera\nIn 1854, a Cholera outbreak killed 127 people in 3 days in a London neighborhood, resulting in a mass exodus of local residents. At the time, people thought that Cholera w as an airborne disease. John Snow was a physician who was critical of the airborne theory, and set out to investigate.\n\nWhat might this data look like?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndate\nlast_name\nfirst_name\naddress\nage\ncause_of_death\n\n\n\n\nAug 31, 1854\nJones\nThomas\n26 Broad St.\n37\ncholera\n\n\nAug 31, 1854\nJones\nMary\n26 Broad St.\n11\ncholera\n\n\nSept 1, 1854\nWarwick\nMartin\n14 Broad St.\n23\ncholera\n\n\n\n\n\n\n\n\nSource: MDSR Ch17.1"
  },
  {
    "objectID": "slides/05/slides05.html#section-2",
    "href": "slides/05/slides05.html#section-2",
    "title": "Intro to Maps  and Spatial Data",
    "section": "",
    "text": "What makes “address” a useful variable is that it is linked to a specific location in the physical world. If we plot these addresses, we get something like the following:\n\n\n\n\n\n\n\n\n\n\n\nSource: MDSR Ch17.1"
  },
  {
    "objectID": "slides/05/slides05.html#section-3",
    "href": "slides/05/slides05.html#section-3",
    "title": "Intro to Maps  and Spatial Data",
    "section": "",
    "text": "While we can see patterns in the last plot, the underlying map of the London streets provides helpful context that makes it more intelligble:\n\n\n\n\n\n\n\nSource: MDSR Ch17.1"
  },
  {
    "objectID": "slides/05/slides05.html#section-4",
    "href": "slides/05/slides05.html#section-4",
    "title": "Intro to Maps  and Spatial Data",
    "section": "",
    "text": "Snow’s insight was driven by another set of data—the locations of the street-side water pumps (it’s kind of hard to see, but they are labelled on the map). Nearly all of the cases were clustered around a single pump on the center of Broad Street.\nJohn Snow’s map (and water pump) are now “famous” among epidemiologists and statisticians.\n\n\n\n\nJohn Snow’s water pump (and pub) from a 2019 visit\n\n\n\n\n\nSource: MDSR Ch17.1"
  },
  {
    "objectID": "slides/05/slides05.html#a-successful-data-science-episode",
    "href": "slides/05/slides05.html#a-successful-data-science-episode",
    "title": "Intro to Maps  and Spatial Data",
    "section": "A successful data science episode:",
    "text": "A successful data science episode:\n\nCombine three sources of data (Cholera deaths, water pump locations, and street map)\nWhile a model might have come to the same conclusion, simply plotting the data is much simpler (and more convincing to lots of people)\nThe problem was resolved when the data-based evidence was combined with a plausible model that explained the physical phenomenon.\n\n\n\nSource: MDSR Ch17.1"
  },
  {
    "objectID": "slides/05/slides05.html#what-is-a-map",
    "href": "slides/05/slides05.html#what-is-a-map",
    "title": "Intro to Maps  and Spatial Data",
    "section": "What is a map?",
    "text": "What is a map?\nA bunch of latitude longitude points…"
  },
  {
    "objectID": "slides/05/slides05.html#what-is-a-map-1",
    "href": "slides/05/slides05.html#what-is-a-map-1",
    "title": "Intro to Maps  and Spatial Data",
    "section": "What is a map?",
    "text": "What is a map?\n… that are connected with lines in a very specific order."
  },
  {
    "objectID": "slides/05/slides05.html#necessary-map-data",
    "href": "slides/05/slides05.html#necessary-map-data",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Necessary map data",
    "text": "Necessary map data\n\nlatitude/longitude points for all map boundaries\nwhich boundary group all lat/long points belong\nthe order to connect points within each group"
  },
  {
    "objectID": "slides/05/slides05.html#state-map-data",
    "href": "slides/05/slides05.html#state-map-data",
    "title": "Intro to Maps  and Spatial Data",
    "section": "State map data",
    "text": "State map data\nggplot2::map_data() provides the necessary information\n\nstates &lt;- map_data(\"state\")\nglimpse(states)\n\nRows: 15,537\nColumns: 6\n$ long      &lt;dbl&gt; -87.46201, -87.48493, -87.52503, -87.53076, -87.57087, -87.5…\n$ lat       &lt;dbl&gt; 30.38968, 30.37249, 30.37249, 30.33239, 30.32665, 30.32665, …\n$ group     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ order     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ region    &lt;chr&gt; \"alabama\", \"alabama\", \"alabama\", \"alabama\", \"alabama\", \"alab…\n$ subregion &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …"
  },
  {
    "objectID": "slides/05/slides05.html#using-geom_polygon",
    "href": "slides/05/slides05.html#using-geom_polygon",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Using geom_polygon()",
    "text": "Using geom_polygon()\nUsing geom_polygon() will treat states as solid shapes, making it easier to add color\n\n\nggplot(states, aes(x=long, y=lat, group=group)) + \n    geom_polygon(color=\"gold2\", fill=\"navyblue\")"
  },
  {
    "objectID": "slides/05/slides05.html#using-coord_fixed",
    "href": "slides/05/slides05.html#using-coord_fixed",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Using coord_fixed()",
    "text": "Using coord_fixed()\nUsing coord_fixed() forces x and y units to be equal\n\n\nggplot(states, aes(x=long, y=lat, group=group)) + \n    geom_polygon(color=\"gold2\", fill=\"navyblue\") +\n  coord_fixed()"
  },
  {
    "objectID": "slides/05/slides05.html#your-turn",
    "href": "slides/05/slides05.html#your-turn",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Your turn",
    "text": "Your turn\n\nggplot(states, aes(x=long, y=lat, group=group)) + \n    geom_polygon(color=\"gold2\", fill=\"navyblue\") +\n    coord_fixed()\n\n\n\nEdit this code so that each shape is colored in with a different color.\nYou only need the 3 variables used: long, lat, and group\n05-maps.Rmd file available in the activities repo\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/05/slides05.html#coordinate-systems-and-projections",
    "href": "slides/05/slides05.html#coordinate-systems-and-projections",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Coordinate Systems and Projections",
    "text": "Coordinate Systems and Projections"
  },
  {
    "objectID": "slides/05/slides05.html#section-5",
    "href": "slides/05/slides05.html#section-5",
    "title": "Intro to Maps  and Spatial Data",
    "section": "",
    "text": "Geospatial data exists on the globe and is generally described with a latitude and longitude. Any projection from the globe to euclidean space (X-Y plane) is going to cause some distortion."
  },
  {
    "objectID": "slides/05/slides05.html#section-6",
    "href": "slides/05/slides05.html#section-6",
    "title": "Intro to Maps  and Spatial Data",
    "section": "",
    "text": "From The West Wing Season 2 Episode 16"
  },
  {
    "objectID": "slides/05/slides05.html#changing-the-coordinate-system",
    "href": "slides/05/slides05.html#changing-the-coordinate-system",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Changing the coordinate system",
    "text": "Changing the coordinate system\ncoord_map function provides a Mercator projection (mapproj package has more options)\n\n\nggplot(states, aes(x=long, y=lat, group=group)) + \n  geom_polygon(color=\"gold2\", fill=\"navyblue\") + \n  coord_map() + \n  theme_map()"
  },
  {
    "objectID": "slides/05/slides05.html#changing-the-coordinate-system-1",
    "href": "slides/05/slides05.html#changing-the-coordinate-system-1",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Changing the coordinate system",
    "text": "Changing the coordinate system\ncoord_map function provides a Mercator projection (mapproj package has more options)\n\n\nggplot(states, aes(x=long, y=lat, group=group)) + \n  geom_polygon(color=\"gold2\", fill=\"navyblue\") + \n  coord_map(projection = \"sinusoidal\") + \n  theme_map()"
  },
  {
    "objectID": "slides/05/slides05.html#mercator-vs-sinusoidal-projection-world-map",
    "href": "slides/05/slides05.html#mercator-vs-sinusoidal-projection-world-map",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Mercator vs Sinusoidal projection (world map)",
    "text": "Mercator vs Sinusoidal projection (world map)\n\nworld &lt;- map_data(\"world\")\n\nggplot(world, aes(x=long, y=lat, group=group)) + \n  geom_polygon(color=\"gold2\", fill=\"navyblue\") + \n  coord_map(projection = \"mercator\", xlim = c(-180, 180)) + \n  theme_map()"
  },
  {
    "objectID": "slides/05/slides05.html#common-types-of-maps",
    "href": "slides/05/slides05.html#common-types-of-maps",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Common Types of Maps",
    "text": "Common Types of Maps\n\nChloropleth\nProportional Symbol\nCartograms/Geofacets"
  },
  {
    "objectID": "slides/05/slides05.html#chloropleth",
    "href": "slides/05/slides05.html#chloropleth",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Chloropleth",
    "text": "Chloropleth\nFill in regions with variable values\n\n\nNeed two data sources:\n\nmap data with lat, long, region\ndata with measurements for each region\n\nyou don’t need to join them!\n\n\n\n\n\nFundamentals of Data Visualization"
  },
  {
    "objectID": "slides/05/slides05.html#proportional-symbol",
    "href": "slides/05/slides05.html#proportional-symbol",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Proportional Symbol",
    "text": "Proportional Symbol\nOverlay symbols on an existing map, where the size of the shape is proportional to the variable\n\n\n\nMade with {ggmap} and {nycflights23}"
  },
  {
    "objectID": "slides/05/slides05.html#cartogram",
    "href": "slides/05/slides05.html#cartogram",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Cartogram",
    "text": "Cartogram\nUse approximate geographical position to encode information, but not lat/long directly\n\n\n\nFundamentals of Data Visualization"
  },
  {
    "objectID": "slides/05/slides05.html#your-task",
    "href": "slides/05/slides05.html#your-task",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Your task",
    "text": "Your task\nYour task is to use the American Community Survey data to make a chloropleth map of the US\n\nYou should:\n\nUse the starter code provided in 05-maps.rmd\nChoose a different variable\nChange the color scale\nUpdate the title, axis labels, and legend"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#columns",
    "href": "slides/slides-cheat-sheet.html#columns",
    "title": "Slides Cheat Sheet",
    "section": "Columns",
    "text": "Columns\n\n\n\nFirst year at Carleton!\nTaught at Swarthmore for 5 years before moving here this fall\nPhD in Statistics & Data Science from Carnegie Mellon University\nGrew up in Minnesota, went to St Ben’s as an undergrad"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#only-graph-from-code",
    "href": "slides/slides-cheat-sheet.html#only-graph-from-code",
    "title": "Slides Cheat Sheet",
    "section": "Only graph from code",
    "text": "Only graph from code"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#background-image-half",
    "href": "slides/slides-cheat-sheet.html#background-image-half",
    "title": "Slides Cheat Sheet",
    "section": "Background Image (half)",
    "text": "Background Image (half)\n\n\nWhat skills do you need?\n\nprogramming with data\nstatistical modeling\ndomain knowledge\ncommunication"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#full-size-image",
    "href": "slides/slides-cheat-sheet.html#full-size-image",
    "title": "Slides Cheat Sheet",
    "section": "Full size image",
    "text": "Full size image\n\n\n\nImage by Adam Loy  adapted from work of Joe Blitzstein, Hanspeter Pfister, and Hadley Wickham"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#background-image-full-size",
    "href": "slides/slides-cheat-sheet.html#background-image-full-size",
    "title": "Slides Cheat Sheet",
    "section": "Background image (full size)",
    "text": "Background image (full size)"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#countdown",
    "href": "slides/slides-cheat-sheet.html#countdown",
    "title": "Slides Cheat Sheet",
    "section": "Countdown",
    "text": "Countdown\n\nWith your neighbor(s):\nChoose two countries to compare to the U.S. voting record in the U.N. over the years.\nWhat did you learn?\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#table-column-widths",
    "href": "slides/slides-cheat-sheet.html#table-column-widths",
    "title": "Slides Cheat Sheet",
    "section": "table column widths",
    "text": "table column widths\n\n\n\n\n\n\n\n\nCollaboration Allowed\n\n\n\n\nHomework Problems\nYou are allowed and encouraged to collaborate on homework. You may also use outside resources, but your submitted work must be your own and reflect your own understanding .\n\n\nLab Quiz Problems\nNo collaboration is allowed at all . You may use your own notes for resubmissions, but should not use outside resources.\n\n\nPortfolio Projects\nYou are expected to collaborate with your group, but cannot rely on external sources other than to help motivate the questions or provide other background information. Getting answers on significant parts of solutions from outside resources is not allowed.\n\n\nFinal Project\nYou are expected to collaborate with your group, but cannot rely on external sources other than to help motivate the questions or provide other background information. Any outside resources should be properly cited."
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#use-of-generative-artificial-intelligence-ai",
    "href": "slides/slides-cheat-sheet.html#use-of-generative-artificial-intelligence-ai",
    "title": "Slides Cheat Sheet",
    "section": "Use of generative artificial intelligence (AI)",
    "text": "Use of generative artificial intelligence (AI)\n\nTreat generative AI, such as ChatGPT or Gemini, the same as other online resources.\nGuiding principles:\n\n(1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. AI should facilitate—rather than hinder—learning.\n(2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n❌ AI tools for writing code: You may not use generative AI to take a “first pass” at a coding task. Do not type coursework prompts directly into AI tools.\n✅ AI tools for debugging code: You may make use of the technology to get help with error messages or trying to fix issues\n❌ AI tools for narrative: Unless instructed otherwise, you may not use generative AI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you.\n\n\n\nAdapted from Mine Çetinkaya-Rundel"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#linktask",
    "href": "slides/slides-cheat-sheet.html#linktask",
    "title": "Slides Cheat Sheet",
    "section": "Link/task",
    "text": "Link/task\n\nhttps://github.com/stat220-w25\n\n\nFill out the Welcome Survey for collection of your account names, later this week you will be invited to the course organization."
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#handwriting-font",
    "href": "slides/slides-cheat-sheet.html#handwriting-font",
    "title": "Slides Cheat Sheet",
    "section": "handwriting font",
    "text": "handwriting font\n\nin case you don’t yet have a GitHub account…"
  },
  {
    "objectID": "slides/10/slides10.html#today",
    "href": "slides/10/slides10.html#today",
    "title": "Data Wrangling: Combining Data",
    "section": "Today",
    "text": "Today\nMore on wrangling:\n\nCombining datasets\nMore practice with pivot_"
  },
  {
    "objectID": "slides/10/slides10.html#peer-programming",
    "href": "slides/10/slides10.html#peer-programming",
    "title": "Data Wrangling: Combining Data",
    "section": "Peer programming",
    "text": "Peer programming\n\nWork on code in a small group (2-3)\nOne person does the typing, the others observe and support\nRules of thumb:\n\nno typing until your group has discussed a possible approach\nlet the typer finish their command/line/pipeline before pointing out any typos\neverybody should contribute ideas and understand the code that is written\n\nWhoever does the typing will share the completed .Rmd so you all have it"
  },
  {
    "objectID": "slides/10/slides10.html#warm-up",
    "href": "slides/10/slides10.html#warm-up",
    "title": "Data Wrangling: Combining Data",
    "section": "Warm up",
    "text": "Warm up\n\n\nFind your groupmates, introduce yourselves:\n\nName & topic of your first portfolio project\n\nChoose someone to be the “typer”. That person should open the 10-combining.rmd activity in RStudio\n\nCan’t decide? Choose the person who had the shortest walk to class today\n\nTake a look at the first 3 pairs of data together and talk through (conceptually! in words!) how you think they should be combined\n\n\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/10/slides10.html#example-1-star-wars-characters",
    "href": "slides/10/slides10.html#example-1-star-wars-characters",
    "title": "Data Wrangling: Combining Data",
    "section": "Example 1: Star Wars Characters",
    "text": "Example 1: Star Wars Characters\nDataset 1:\n\nstarwars_characters\n\n# A tibble: 87 × 6\n   name               height  mass homeworld species first_film\n   &lt;chr&gt;               &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;     \n 1 Luke Skywalker        172    77 Tatooine  Human   A New Hope\n 2 C-3PO                 167    75 Tatooine  Droid   A New Hope\n 3 R2-D2                  96    32 Naboo     Droid   A New Hope\n 4 Darth Vader           202   136 Tatooine  Human   A New Hope\n 5 Leia Organa           150    49 Alderaan  Human   A New Hope\n 6 Owen Lars             178   120 Tatooine  Human   A New Hope\n 7 Beru Whitesun Lars    165    75 Tatooine  Human   A New Hope\n 8 R5-D4                  97    32 Tatooine  Droid   A New Hope\n 9 Biggs Darklighter     183    84 Tatooine  Human   A New Hope\n10 Obi-Wan Kenobi        182    77 Stewjon   Human   A New Hope\n# ℹ 77 more rows\n\n\nDataset 2:\n\nstarwars_lastjedi\n\n# A tibble: 2 × 6\n  name         height mass  homeworld species first_film   \n  &lt;chr&gt;        &lt;lgl&gt;  &lt;lgl&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;        \n1 Rose Tico    NA     NA    Otomok    Human   The Last Jedi\n2 Amilyn Holdo NA     NA    &lt;NA&gt;      Human   The Last Jedi"
  },
  {
    "objectID": "slides/10/slides10.html#bind_rows",
    "href": "slides/10/slides10.html#bind_rows",
    "title": "Data Wrangling: Combining Data",
    "section": "bind_rows()",
    "text": "bind_rows()\n\n\n\ndata_1: our “starting” data\ndata_2 to data_n: additional rows of data that we want to add to data_1\n\n\n\nbind_rows(\n  data_1, \n  data_2, \n  ..., \n  data_n\n  )"
  },
  {
    "objectID": "slides/10/slides10.html#section",
    "href": "slides/10/slides10.html#section",
    "title": "Data Wrangling: Combining Data",
    "section": "",
    "text": "starwars_characters %&gt;%\n  bind_rows(starwars_lastjedi) %&gt;%\n  slice_tail(n=10)\n\n\n\n# A tibble: 10 × 6\n   name            height  mass homeworld species first_film          \n   &lt;chr&gt;            &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;               \n 1 Raymus Antilles    188    79 Alderaan  Human   A New Hope          \n 2 Sly Moore          178    48 Umbara    &lt;NA&gt;    Attack of the Clones\n 3 Tion Medon         206    80 Utapau    Pau'an  Revenge of the Sith \n 4 Finn                NA    NA &lt;NA&gt;      Human   The Force Awakens   \n 5 Rey                 NA    NA &lt;NA&gt;      Human   The Force Awakens   \n 6 Poe Dameron         NA    NA &lt;NA&gt;      Human   The Force Awakens   \n 7 BB8                 NA    NA &lt;NA&gt;      Droid   The Force Awakens   \n 8 Captain Phasma      NA    NA &lt;NA&gt;      Human   The Force Awakens   \n 9 Rose Tico           NA    NA Otomok    Human   The Last Jedi       \n10 Amilyn Holdo        NA    NA &lt;NA&gt;      Human   The Last Jedi"
  },
  {
    "objectID": "slides/10/slides10.html#example-2-stats-sections",
    "href": "slides/10/slides10.html#example-2-stats-sections",
    "title": "Data Wrangling: Combining Data",
    "section": "Example 2: Stats Sections",
    "text": "Example 2: Stats Sections\nDataset 1:\n\nstats_sections_fw\n\n# A tibble: 8 × 3\n  class    fall winter\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 stat120     3      3\n2 stat220     1      1\n3 stat230     1      1\n4 stat250     0      1\n5 stat270     1      0\n6 stat285     1      1\n7 stat320     0      0\n8 stat330     0      1\n\n\nDataset 2:\n\nstats_sections_s\n\n# A tibble: 8 × 1\n  spring\n   &lt;dbl&gt;\n1      4\n2      1\n3      1\n4      1\n5      0\n6      1\n7      1\n8      0"
  },
  {
    "objectID": "slides/10/slides10.html#bind_cols",
    "href": "slides/10/slides10.html#bind_cols",
    "title": "Data Wrangling: Combining Data",
    "section": "bind_cols()",
    "text": "bind_cols()\n\n\n\ndata_1: our “starting” data\ndata_2 to data_n: additional columns of data that we want to add to data_1\n\n\n\nbind_cols(\n  data_1, \n  data_2, \n  ..., \n  data_n\n  )"
  },
  {
    "objectID": "slides/10/slides10.html#section-1",
    "href": "slides/10/slides10.html#section-1",
    "title": "Data Wrangling: Combining Data",
    "section": "",
    "text": "stats_sections_fw %&gt;%\n  bind_cols(stats_sections_s)\n\n\n\n# A tibble: 8 × 4\n  class    fall winter spring\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 stat120     3      3      4\n2 stat220     1      1      1\n3 stat230     1      1      1\n4 stat250     0      1      1\n5 stat270     1      0      0\n6 stat285     1      1      1\n7 stat320     0      0      1\n8 stat330     0      1      0"
  },
  {
    "objectID": "slides/10/slides10.html#we-got-lucky",
    "href": "slides/10/slides10.html#we-got-lucky",
    "title": "Data Wrangling: Combining Data",
    "section": "We got lucky",
    "text": "We got lucky\n\n\nOur second dataset followed this structure:\n\n\n# A tibble: 8 × 2\n  class   spring\n  &lt;chr&gt;    &lt;dbl&gt;\n1 stat120      4\n2 stat220      1\n3 stat230      1\n4 stat250      1\n5 stat270      0\n6 stat285      1\n7 stat320      1\n8 stat330      0\n\n\n\nBut it could have also had this structure:\n\n\n# A tibble: 8 × 2\n  class   spring\n  &lt;chr&gt;    &lt;dbl&gt;\n1 stat270      0\n2 stat330      0\n3 stat220      1\n4 stat230      1\n5 stat250      1\n6 stat285      1\n7 stat320      1\n8 stat120      4"
  },
  {
    "objectID": "slides/10/slides10.html#example-3-survivor-castaways",
    "href": "slides/10/slides10.html#example-3-survivor-castaways",
    "title": "Data Wrangling: Combining Data",
    "section": "Example 3: Survivor castaways",
    "text": "Example 3: Survivor castaways\nDataset 1:\n\nus_castaway_results\n\n# A tibble: 870 × 7\n   castaway_id castaway season_name      season place jury  finalist\n   &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;   \n 1 US0001      Sonja    Survivor: Borneo      1    16 FALSE FALSE   \n 2 US0002      B.B.     Survivor: Borneo      1    15 FALSE FALSE   \n 3 US0003      Stacey   Survivor: Borneo      1    14 FALSE FALSE   \n 4 US0004      Ramona   Survivor: Borneo      1    13 FALSE FALSE   \n 5 US0005      Dirk     Survivor: Borneo      1    12 FALSE FALSE   \n 6 US0006      Joel     Survivor: Borneo      1    11 FALSE FALSE   \n 7 US0007      Gretchen Survivor: Borneo      1    10 FALSE FALSE   \n 8 US0008      Greg     Survivor: Borneo      1     9 TRUE  FALSE   \n 9 US0009      Jenna    Survivor: Borneo      1     8 TRUE  FALSE   \n10 US0010      Gervase  Survivor: Borneo      1     7 TRUE  FALSE   \n# ℹ 860 more rows\n\n\nDataset 2:\n\ncast_details\n\n# A tibble: 1,118 × 6\n   castaway_id full_name        date_of_birth gender occupation personality_type\n   &lt;chr&gt;       &lt;chr&gt;            &lt;date&gt;        &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;           \n 1 US0014      Rudy Boesch      1928-01-20    Male   Retired N… ISTJ            \n 2 US0002      B.B. Andersen    1936-01-18    Male   Real Esta… ESTJ            \n 3 US0001      Sonja Christoph… 1937-01-28    Female Musician   ENFP            \n 4 US0075      Jake Billingsley 1941-08-21    Male   Land Brok… ISFJ            \n 5 US0151      Jim Lynch        1942-01-07    Male   Retired F… ISTJ            \n 6 US0474      Joseph Del Campo 1943-07-04    Male   Former FB… ISTJ            \n 7 US0304      Jimmy Johnson    1943-07-16    Male   Former NF… ESFJ            \n 8 US0047      Kim Johnson      1944-09-18    Female Retired T… ISFJ            \n 9 US0128      Scout Cloud Lee  1944-11-08    Female Rancher    INFJ            \n10 US0061      Paschal English  1945-03-05    Male   Judge      ISFJ            \n# ℹ 1,108 more rows"
  },
  {
    "objectID": "slides/10/slides10.html#desired-output",
    "href": "slides/10/slides10.html#desired-output",
    "title": "Data Wrangling: Combining Data",
    "section": "Desired output",
    "text": "Desired output\n\n\n# A tibble: 870 × 12\n   castaway_id castaway season_name      season place jury  finalist full_name  \n   &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;    &lt;chr&gt;      \n 1 US0001      Sonja    Survivor: Borneo      1    16 FALSE FALSE    Sonja Chri…\n 2 US0002      B.B.     Survivor: Borneo      1    15 FALSE FALSE    B.B. Ander…\n 3 US0003      Stacey   Survivor: Borneo      1    14 FALSE FALSE    Stacey Sti…\n 4 US0004      Ramona   Survivor: Borneo      1    13 FALSE FALSE    Ramona Gray\n 5 US0005      Dirk     Survivor: Borneo      1    12 FALSE FALSE    Dirk Been  \n 6 US0006      Joel     Survivor: Borneo      1    11 FALSE FALSE    Joel Klug  \n 7 US0007      Gretchen Survivor: Borneo      1    10 FALSE FALSE    Gretchen C…\n 8 US0008      Greg     Survivor: Borneo      1     9 TRUE  FALSE    Greg Buis  \n 9 US0009      Jenna    Survivor: Borneo      1     8 TRUE  FALSE    Jenna Lewis\n10 US0010      Gervase  Survivor: Borneo      1     7 TRUE  FALSE    Gervase Pe…\n# ℹ 860 more rows\n# ℹ 4 more variables: date_of_birth &lt;date&gt;, gender &lt;chr&gt;, occupation &lt;chr&gt;,\n#   personality_type &lt;chr&gt;"
  },
  {
    "objectID": "slides/10/slides10.html#left_join",
    "href": "slides/10/slides10.html#left_join",
    "title": "Data Wrangling: Combining Data",
    "section": "left_join()",
    "text": "left_join()\n\nus_castaway_results %&gt;%\n  left_join(cast_details, by = \"castaway_id\") %&gt;%\n  select(-season_name)\n\n\n\n# A tibble: 870 × 11\n   castaway_id castaway season place jury  finalist full_name      date_of_birth\n   &lt;chr&gt;       &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;    &lt;chr&gt;          &lt;date&gt;       \n 1 US0001      Sonja         1    16 FALSE FALSE    Sonja Christo… 1937-01-28   \n 2 US0002      B.B.          1    15 FALSE FALSE    B.B. Andersen  1936-01-18   \n 3 US0003      Stacey        1    14 FALSE FALSE    Stacey Stillm… 1972-08-11   \n 4 US0004      Ramona        1    13 FALSE FALSE    Ramona Gray    1971-01-20   \n 5 US0005      Dirk          1    12 FALSE FALSE    Dirk Been      1976-06-15   \n 6 US0006      Joel          1    11 FALSE FALSE    Joel Klug      1972-04-13   \n 7 US0007      Gretchen      1    10 FALSE FALSE    Gretchen Cordy 1962-02-07   \n 8 US0008      Greg          1     9 TRUE  FALSE    Greg Buis      1975-12-31   \n 9 US0009      Jenna         1     8 TRUE  FALSE    Jenna Lewis    1977-07-16   \n10 US0010      Gervase       1     7 TRUE  FALSE    Gervase Peter… 1969-11-02   \n# ℹ 860 more rows\n# ℹ 3 more variables: gender &lt;chr&gt;, occupation &lt;chr&gt;, personality_type &lt;chr&gt;"
  },
  {
    "objectID": "slides/10/slides10.html#left_join-keeps-duplicate-rows-in-x",
    "href": "slides/10/slides10.html#left_join-keeps-duplicate-rows-in-x",
    "title": "Data Wrangling: Combining Data",
    "section": "left_join() keeps duplicate rows in x",
    "text": "left_join() keeps duplicate rows in x\n\nus_castaway_results %&gt;%\n  left_join(cast_details, by = \"castaway_id\") %&gt;%\n  filter(castaway == \"Sandra\") %&gt;%\n  select(-season_name)\n\n\n\n# A tibble: 4 × 11\n  castaway_id castaway season place jury  finalist full_name       date_of_birth\n  &lt;chr&gt;       &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;    &lt;chr&gt;           &lt;date&gt;       \n1 US0112      Sandra        7     1 FALSE TRUE     Sandra Diaz-Tw… 1974-07-30   \n2 US0112      Sandra       20     1 FALSE TRUE     Sandra Diaz-Tw… 1974-07-30   \n3 US0112      Sandra       34    15 FALSE FALSE    Sandra Diaz-Tw… 1974-07-30   \n4 US0112      Sandra       40    15 FALSE FALSE    Sandra Diaz-Tw… 1974-07-30   \n# ℹ 3 more variables: gender &lt;chr&gt;, occupation &lt;chr&gt;, personality_type &lt;chr&gt;"
  },
  {
    "objectID": "slides/10/slides10.html#other-types-of-_joins",
    "href": "slides/10/slides10.html#other-types-of-_joins",
    "title": "Data Wrangling: Combining Data",
    "section": "Other types of _joins",
    "text": "Other types of _joins\n\nleft_join(): all rows from x\nright_join(): all rows from y\nfull_join(): all rows from both x and y\ninner_join(): all rows from x where there are matching values in y, return all combination of multiple matches in the case of multiple matches\nsemi_join(): all rows from x where there are matching values in y, keeping just columns from x\nanti_join(): return all rows from x where there are not matching values in y, never duplicate rows of x\n…"
  },
  {
    "objectID": "slides/10/slides10.html#setup",
    "href": "slides/10/slides10.html#setup",
    "title": "Data Wrangling: Combining Data",
    "section": "Setup",
    "text": "Setup\nFor the next few slides…\n\n\n\nx\n\n# A tibble: 3 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2     \n3     3 x3     \n\n\n\n\ny\n\n# A tibble: 3 × 2\n     id value_y\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 y1     \n2     2 y2     \n3     4 y4"
  },
  {
    "objectID": "slides/10/slides10.html#left_join-1",
    "href": "slides/10/slides10.html#left_join-1",
    "title": "Data Wrangling: Combining Data",
    "section": "left_join()",
    "text": "left_join()\nKeep all rows from x\n\n\n\n\n\nleft_join(x, y, by = \"id\")\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;"
  },
  {
    "objectID": "slides/10/slides10.html#full_join",
    "href": "slides/10/slides10.html#full_join",
    "title": "Data Wrangling: Combining Data",
    "section": "full_join()",
    "text": "full_join()\nKeep all rows from both x and y\n\n\n\n\n\nfull_join(x, y)\n\n# A tibble: 4 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;   \n4     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "slides/10/slides10.html#semi_join",
    "href": "slides/10/slides10.html#semi_join",
    "title": "Data Wrangling: Combining Data",
    "section": "semi_join()",
    "text": "semi_join()\nKeep all rows from x where there are matching values in y, keeping just columns from x\n\n\n\n\n\nsemi_join(x, y)\n\n# A tibble: 2 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2     \n\n\n\nSimilar to filter()"
  },
  {
    "objectID": "slides/10/slides10.html#anti_join",
    "href": "slides/10/slides10.html#anti_join",
    "title": "Data Wrangling: Combining Data",
    "section": "anti_join()",
    "text": "anti_join()\nKeep all rows from x where there are not matching values in y, never duplicate rows of x\n\n\n\n\n\nanti_join(x, y)\n\n# A tibble: 1 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     3 x3     \n\n\n\nSimilar to filter() with !"
  },
  {
    "objectID": "slides/10/slides10.html#join-functions",
    "href": "slides/10/slides10.html#join-functions",
    "title": "Data Wrangling: Combining Data",
    "section": "*_join() functions",
    "text": "*_join() functions\n\nFrom dplyr\nIncredibly useful for bringing datasets with common information (e.g., unique identifier) together\nUse by argument\nAlways check that the numbers of rows and columns of the result dataset makes sense\nRefer to two-table verbs vignette when needed"
  },
  {
    "objectID": "slides/10/slides10.html#keys",
    "href": "slides/10/slides10.html#keys",
    "title": "Data Wrangling: Combining Data",
    "section": "keys",
    "text": "keys\nIn these examples, the colored boxes represent keys\n\n\n\n\n\nkeys uniquely identify the observation of interest\nAre present in both datasets and used to match the rows\nDepend on the context (e.g. could be castaway ID, could be season ID, could be epiosde number, etc.)\nCan be multiple columns\ndplyr will try to find them automatically, but it’s better to be explicit using the by argument"
  },
  {
    "objectID": "slides/10/slides10.html#lets-try-it-bakeoff-data-again",
    "href": "slides/10/slides10.html#lets-try-it-bakeoff-data-again",
    "title": "Data Wrangling: Combining Data",
    "section": "Let’s try it: Bakeoff data (again)",
    "text": "Let’s try it: Bakeoff data (again)\nOn Friday, we tidied data containing ratings from The Great British Bakeoff.\n\nBefore:\n\n\n# A tibble: 3 × 21\n  series e1_7day e1_28day e2_7day e2_28day e3_7day e3_28day e4_7day e4_28day\n   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1      1    2.24       NA    3          NA    3          NA    2.6        NA\n2      2    3.1        NA    3.53       NA    3.82       NA    3.6        NA\n3      3    3.85       NA    4.6        NA    4.53       NA    4.71       NA\n# ℹ 12 more variables: e5_7day &lt;dbl&gt;, e5_28day &lt;dbl&gt;, e6_7day &lt;dbl&gt;,\n#   e6_28day &lt;dbl&gt;, e7_7day &lt;dbl&gt;, e7_28day &lt;dbl&gt;, e8_7day &lt;dbl&gt;,\n#   e8_28day &lt;dbl&gt;, e9_7day &lt;dbl&gt;, e9_28day &lt;dbl&gt;, e10_7day &lt;dbl&gt;,\n#   e10_28day &lt;dbl&gt;\n\n\n\n\nAfter:\n\n\n# A tibble: 5 × 4\n  series episode period viewers\n   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1      1       1      7    2.24\n2      1       2      7    3   \n3      1       3      7    3   \n4      1       4      7    2.6 \n5      1       5      7    3.03"
  },
  {
    "objectID": "slides/10/slides10.html#lets-try-it-bakeoff-data-again-1",
    "href": "slides/10/slides10.html#lets-try-it-bakeoff-data-again-1",
    "title": "Data Wrangling: Combining Data",
    "section": "Let’s try it: Bakeoff data (again)",
    "text": "Let’s try it: Bakeoff data (again)\nBut that data only had through season 8. We now have a new dataset with seasons 9-14:\n\n\n# A tibble: 6 × 21\n  series e1_7day e1_28day e2_7day e2_28day e3_7day e3_28day e4_7day e4_28day\n   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1      9    9.55     9.92    9.31     9.76    8.91     9.35    8.88     9.41\n2     10    9.62    10.0     9.38     9.8     8.94     9.42    8.96     9.49\n3     11   11.2     11.8    10.8     11.4    10.7     11.2    10.6     11.2 \n4     12    9.57    10.2     8.98     9.64    8.69     9.39    8.75     9.13\n5     13    8.3      1       7.6      1       7.35     1       7.76     1   \n6     14    7.84     1       7.54     1       7.28     1       7.12     1   \n# ℹ 12 more variables: e5_7day &lt;dbl&gt;, e5_28day &lt;dbl&gt;, e6_7day &lt;dbl&gt;,\n#   e6_28day &lt;dbl&gt;, e7_7day &lt;dbl&gt;, e7_28day &lt;dbl&gt;, e8_7day &lt;dbl&gt;,\n#   e8_28day &lt;dbl&gt;, e9_7day &lt;dbl&gt;, e9_28day &lt;dbl&gt;, e10_7day &lt;dbl&gt;,\n#   e10_28day &lt;dbl&gt;\n\n\n\n\nYour task is to join these two datasets together using (1) bind_rows(), (2) _join() and (3) bind_cols() (you’ll also get some pivot_ practice along the way)"
  },
  {
    "objectID": "slides/10/slides10.html#part-ii-the-episodes-data",
    "href": "slides/10/slides10.html#part-ii-the-episodes-data",
    "title": "Data Wrangling: Combining Data",
    "section": "Part II: the episodes data",
    "text": "Part II: the episodes data\nThe episodes data has information about each episode of GBBO.\n\n\nIn particular, it includes:\n\nbaker: each baker that competed on that episode\nsignature: the name of the dessert they made for the signature challenge\ntechnical: the place the baker earned in the technical challenge\nshowstopper: the name of the dessert they made for the showstopper challenge\nresult: whether the baker was “Safe” or “Eliminated”\n\n\n\nepisodes\n\n# A tibble: 1,007 × 7\n   series episode baker     signature               technical showstopper result\n    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                       &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt; \n 1      1       1 Annetha   Light Jamaican Black C…         2 Red, White… Safe  \n 2      1       1 David     Chocolate Orange Cake           3 Black Fore… Safe  \n 3      1       1 Edd       Caramel Cinnamon and B…         1 &lt;NA&gt;        Safe  \n 4      1       1 Jasminder Fresh Mango and Passio…        NA &lt;NA&gt;        Safe  \n 5      1       1 Jonathan  Carrot Cake with Lime …         9 Three Tier… Safe  \n 6      1       1 Lea       Cranberry and Pistachi…        10 Raspberrie… Elimi…\n 7      1       1 Louise    Carrot and Orange Cake         NA Never Fail… Safe  \n 8      1       1 Mark      Sticky Marmalade Tea L…        NA Heart-shap… Elimi…\n 9      1       1 Miranda   Triple Layered Brownie…         8 Three Tier… Safe  \n10      1       1 Ruth      Lemon Drizzle Cakewith…        NA Classic Ch… Safe  \n# ℹ 997 more rows"
  },
  {
    "objectID": "slides/10/slides10.html#lets-try-it-bakeoff-data-episodes",
    "href": "slides/10/slides10.html#lets-try-it-bakeoff-data-episodes",
    "title": "Data Wrangling: Combining Data",
    "section": "Let’s try it: Bakeoff data (episodes)",
    "text": "Let’s try it: Bakeoff data (episodes)\n\nJoin the tidy dataset (all 14 seasons) with the episodes data.\nYour task is to print the “signature” desserts that were made on the 10 episodes that had the highest 7-day viewership."
  },
  {
    "objectID": "slides/09/slides09.html#bakeoff-ratings",
    "href": "slides/09/slides09.html#bakeoff-ratings",
    "title": "Data Wrangling: Tidy Data",
    "section": "Bakeoff ratings",
    "text": "Bakeoff ratings\n\nRatings data for each episodes in series 1-8\n\n\n\n\n# A tibble: 8 × 11\n  series    e1    e2    e3    e4    e5    e6    e7    e8    e9   e10\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      1  2.24  3     3     2.6   3.03  2.75 NA    NA    NA    NA   \n2      2  3.1   3.53  3.82  3.6   3.83  4.25  4.42  5.06 NA    NA   \n3      3  3.85  4.6   4.53  4.71  4.61  4.82  5.1   5.35  5.7   6.74\n4      4  6.6   6.65  7.17  6.82  6.95  7.32  7.76  7.41  7.41  9.45\n5      5  8.51  8.79  9.28 10.2   9.95 10.1  10.3   9.02 10.7  13.5 \n6      6 11.6  11.6  12.0  12.4  12.4  12    12.4  11.1  12.6  15.0 \n7      7 13.6  13.4  13.0  13.3  13.1  13.1  13.4  13.3  13.4  15.9 \n8      8  9.46  9.23  8.68  8.55  8.61  8.61  9.01  8.95  9.03 10.0 \n\n\n\n\n\nSource: bakeoff R package"
  },
  {
    "objectID": "slides/09/slides09.html#warm-up",
    "href": "slides/09/slides09.html#warm-up",
    "title": "Data Wrangling: Tidy Data",
    "section": "Warm up",
    "text": "Warm up\n\nIs this dataset in tidy format? Why or why not?\nIf not, what would a tidy data set look like? Sketch out the first few rows of this data set in tidy format\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/09/slides09.html#section-3",
    "href": "slides/09/slides09.html#section-3",
    "title": "Data Wrangling: Tidy Data",
    "section": "",
    "text": "Reshape the layout of tabular data\nPart of the tidyverse"
  },
  {
    "objectID": "slides/09/slides09.html#goal",
    "href": "slides/09/slides09.html#goal",
    "title": "Data Wrangling: Tidy Data",
    "section": "Goal",
    "text": "Goal\nWant to reshape the data to be in tidy format:\n\nCurrentTarget\n\n\n\n\n# A tibble: 8 × 11\n  series    e1    e2    e3    e4    e5    e6    e7    e8    e9   e10\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      1  2.24  3     3     2.6   3.03  2.75 NA    NA    NA    NA   \n2      2  3.1   3.53  3.82  3.6   3.83  4.25  4.42  5.06 NA    NA   \n3      3  3.85  4.6   4.53  4.71  4.61  4.82  5.1   5.35  5.7   6.74\n4      4  6.6   6.65  7.17  6.82  6.95  7.32  7.76  7.41  7.41  9.45\n5      5  8.51  8.79  9.28 10.2   9.95 10.1  10.3   9.02 10.7  13.5 \n6      6 11.6  11.6  12.0  12.4  12.4  12    12.4  11.1  12.6  15.0 \n7      7 13.6  13.4  13.0  13.3  13.1  13.1  13.4  13.3  13.4  15.9 \n8      8  9.46  9.23  8.68  8.55  8.61  8.61  9.01  8.95  9.03 10.0 \n\n\n\n\n\n\n# A tibble: 80 × 3\n   series epsiode rating\n    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1      1 e1        2.24\n 2      1 e2        3   \n 3      1 e3        3   \n 4      1 e4        2.6 \n 5      1 e5        3.03\n 6      1 e6        2.75\n 7      1 e7       NA   \n 8      1 e8       NA   \n 9      1 e9       NA   \n10      1 e10      NA   \n# ℹ 70 more rows"
  },
  {
    "objectID": "slides/09/slides09.html#pivot_longer",
    "href": "slides/09/slides09.html#pivot_longer",
    "title": "Data Wrangling: Tidy Data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\n\n\ndata (as usual)\n\n\n\npivot_longer(\n  data, \n  cols, \n  names_to = \"name\", \n  values_to = \"value\"\n  )"
  },
  {
    "objectID": "slides/09/slides09.html#pivot_longer-1",
    "href": "slides/09/slides09.html#pivot_longer-1",
    "title": "Data Wrangling: Tidy Data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\n\n\ndata (as usual)\ncols: columns to pivot into longer format\n\n\n\npivot_longer(\n  data, \n  cols, \n  names_to = \"name\", \n  values_to = \"value\"\n  )"
  },
  {
    "objectID": "slides/09/slides09.html#pivot_longer-2",
    "href": "slides/09/slides09.html#pivot_longer-2",
    "title": "Data Wrangling: Tidy Data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\n\n\ndata (as usual)\ncols: columns to pivot into longer format\nnames_to: name of the column where column names of pivoted variables go (character string)\n\n\n\npivot_longer(\n  data, \n  cols, \n  names_to = \"name\", \n  values_to = \"value\"\n  )"
  },
  {
    "objectID": "slides/09/slides09.html#pivot_longer-3",
    "href": "slides/09/slides09.html#pivot_longer-3",
    "title": "Data Wrangling: Tidy Data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\n\n\ndata (as usual)\ncols: columns to pivot into longer format\nnames_to: name of the column where column names of pivoted variables go (character string)\nvalues_to: name of the column where data in pivoted variables go (character string)\n\n\n\npivot_longer(\n  data, \n  cols, \n  names_to = \"name\", \n  values_to = \"value\"\n  )"
  },
  {
    "objectID": "slides/09/slides09.html#wider-rightarrow-longer-ratings",
    "href": "slides/09/slides09.html#wider-rightarrow-longer-ratings",
    "title": "Data Wrangling: Tidy Data",
    "section": "wider \\(\\rightarrow\\) longer ratings",
    "text": "wider \\(\\rightarrow\\) longer ratings\n\n\nlonger_ratings &lt;- bakeoff_ratings %&gt;%\n  pivot_longer( \n    cols = e1:e10, \n    names_to = \"episode\", \n    values_to = \"rating\" \n  )\nlonger_ratings\n\n\n# A tibble: 80 × 3\n   series episode rating\n    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1      1 e1        2.24\n 2      1 e2        3   \n 3      1 e3        3   \n 4      1 e4        2.6 \n 5      1 e5        3.03\n 6      1 e6        2.75\n 7      1 e7       NA   \n 8      1 e8       NA   \n 9      1 e9       NA   \n10      1 e10      NA   \n# ℹ 70 more rows"
  },
  {
    "objectID": "slides/09/slides09.html#parse_number",
    "href": "slides/09/slides09.html#parse_number",
    "title": "Data Wrangling: Tidy Data",
    "section": "parse_number()",
    "text": "parse_number()\n\n\nratings &lt;- longer_ratings %&gt;%\n  mutate(\n    episode = parse_number(episode) \n  )\nratings\n\n\n# A tibble: 80 × 3\n   series episode rating\n    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1      1       1   2.24\n 2      1       2   3   \n 3      1       3   3   \n 4      1       4   2.6 \n 5      1       5   3.03\n 6      1       6   2.75\n 7      1       7  NA   \n 8      1       8  NA   \n 9      1       9  NA   \n10      1      10  NA   \n# ℹ 70 more rows"
  },
  {
    "objectID": "slides/09/slides09.html#other-parsing-functions",
    "href": "slides/09/slides09.html#other-parsing-functions",
    "title": "Data Wrangling: Tidy Data",
    "section": "Other parsing functions",
    "text": "Other parsing functions\n\n\nparse_character\nparse_date\nparse_double\nparse_double\nparse_factor\n\nparse_integer\nparse_logical\nparse_number\nparse_time\n\n\n\nThe parse_* functions are from readr"
  },
  {
    "objectID": "slides/09/slides09.html#try-it-messy_ratings",
    "href": "slides/09/slides09.html#try-it-messy_ratings",
    "title": "Data Wrangling: Tidy Data",
    "section": "Try it: messy_ratings",
    "text": "Try it: messy_ratings\nTidy this data set by\n\nSelecting the series and e*_7day columns\nPivoting the data to add a column for episode and a column for rating (we’ll clean up the episode column later)\n\n\n\n# A tibble: 8 × 21\n  series e1_7day e1_28day e2_7day e2_28day e3_7day e3_28day e4_7day e4_28day\n   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1      1    2.24    NA       3       NA       3       NA       2.6     NA   \n2      2    3.1     NA       3.53    NA       3.82    NA       3.6     NA   \n3      3    3.85    NA       4.6     NA       4.53    NA       4.71    NA   \n4      4    6.6     NA       6.65    NA       7.17    NA       6.82    NA   \n5      5    8.51    NA       8.79    NA       9.28    NA      10.2     NA   \n6      6   11.6     11.7    11.6     11.8    12.0     NA      12.4     12.7 \n7      7   13.6     13.9    13.4     13.7    13.0     13.4    13.3     13.9 \n8      8    9.46     9.72    9.23     9.53    8.68     9.06    8.55     8.87\n# ℹ 12 more variables: e5_7day &lt;dbl&gt;, e5_28day &lt;dbl&gt;, e6_7day &lt;dbl&gt;,\n#   e6_28day &lt;dbl&gt;, e7_7day &lt;dbl&gt;, e7_28day &lt;dbl&gt;, e8_7day &lt;dbl&gt;,\n#   e8_28day &lt;dbl&gt;, e9_7day &lt;dbl&gt;, e9_28day &lt;dbl&gt;, e10_7day &lt;dbl&gt;,\n#   e10_28day &lt;dbl&gt;\n\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/09/slides09.html#cleaning-episode",
    "href": "slides/09/slides09.html#cleaning-episode",
    "title": "Data Wrangling: Tidy Data",
    "section": "Cleaning episode",
    "text": "Cleaning episode\n\n\nratings2 &lt;- messy_ratings2 %&gt;%\n  select(series, contains(\"7day\")) %&gt;%\n  pivot_longer(contains(\"7day\"), \n               names_to = \"episode\", \n               values_to = \"rating\")\nratings2\n\n\n# A tibble: 80 × 3\n   series episode  rating\n    &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1      1 e1_7day    2.24\n 2      1 e2_7day    3   \n 3      1 e3_7day    3   \n 4      1 e4_7day    2.6 \n 5      1 e5_7day    3.03\n 6      1 e6_7day    2.75\n 7      1 e7_7day   NA   \n 8      1 e8_7day   NA   \n 9      1 e9_7day   NA   \n10      1 e10_7day  NA   \n# ℹ 70 more rows"
  },
  {
    "objectID": "slides/09/slides09.html#separate",
    "href": "slides/09/slides09.html#separate",
    "title": "Data Wrangling: Tidy Data",
    "section": "separate()",
    "text": "separate()\n\n\n\ndata (as usual)\n\n\n\nseparate(\n  data, \n  col, \n  into = c(\"col1\", \"col2\"),\n  sep \n  )"
  },
  {
    "objectID": "slides/09/slides09.html#separate-1",
    "href": "slides/09/slides09.html#separate-1",
    "title": "Data Wrangling: Tidy Data",
    "section": "separate()",
    "text": "separate()\n\n\n\ndata (as usual)\ncol: column to separate\n\n\n\nseparate(\n  data, \n  col, \n  into = c(\"col1\", \"col2\"),\n  sep \n  )"
  },
  {
    "objectID": "slides/09/slides09.html#separate-2",
    "href": "slides/09/slides09.html#separate-2",
    "title": "Data Wrangling: Tidy Data",
    "section": "separate()",
    "text": "separate()\n\n\n\ndata (as usual)\ncol: column to separate\ninto: names of new columns to create\n\n\n\nseparate(\n  data, \n  col, \n  into = c(\"col1\", \"col2\"),\n  sep \n  )"
  },
  {
    "objectID": "slides/09/slides09.html#separate-3",
    "href": "slides/09/slides09.html#separate-3",
    "title": "Data Wrangling: Tidy Data",
    "section": "separate()",
    "text": "separate()\n\n\n\ndata (as usual)\ncol: column to separate\ninto: names of new columns to create\nsep: separator between columns\n\n\n\nseparate(\n  data, \n  col, \n  into = c(\"col1\", \"col2\"),\n  sep \n  )"
  },
  {
    "objectID": "slides/09/slides09.html#cleaning-episode-1",
    "href": "slides/09/slides09.html#cleaning-episode-1",
    "title": "Data Wrangling: Tidy Data",
    "section": "Cleaning episode",
    "text": "Cleaning episode\n\n\nratings2 %&gt;%\n  separate( \n    col = episode, \n    into = c(\"episode\", \"period\") \n  )\n\n\n# A tibble: 80 × 4\n   series episode period rating\n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n 1      1 e1      7day     2.24\n 2      1 e2      7day     3   \n 3      1 e3      7day     3   \n 4      1 e4      7day     2.6 \n 5      1 e5      7day     3.03\n 6      1 e6      7day     2.75\n 7      1 e7      7day    NA   \n 8      1 e8      7day    NA   \n 9      1 e9      7day    NA   \n10      1 e10     7day    NA   \n# ℹ 70 more rows"
  },
  {
    "objectID": "slides/09/slides09.html#wrap-it-up",
    "href": "slides/09/slides09.html#wrap-it-up",
    "title": "Data Wrangling: Tidy Data",
    "section": "Wrap it up",
    "text": "Wrap it up\n\n\nClean the episode and period column\nMake a line plot with episode on the x-axis, rating on the y-axis, colored by series. (You will also need to map the group aesthetic to series)"
  },
  {
    "objectID": "slides/01/slides01.html#about-me",
    "href": "slides/01/slides01.html#about-me",
    "title": "Welcome to Stat 220",
    "section": "About me",
    "text": "About me\n\n\n\nFirst year at Carleton!\nTaught at Swarthmore for 5 years before moving here this fall\nPhD in Statistics & Data Science from Carnegie Mellon University\nGrew up in Minnesota, went to St Ben’s as an undergrad"
  },
  {
    "objectID": "slides/01/slides01.html#what-is-data-science",
    "href": "slides/01/slides01.html#what-is-data-science",
    "title": "Welcome to Stat 220",
    "section": "What is “data science”?",
    "text": "What is “data science”?"
  },
  {
    "objectID": "slides/01/slides01.html#what-is-this-class-about",
    "href": "slides/01/slides01.html#what-is-this-class-about",
    "title": "Welcome to Stat 220",
    "section": "What is this class about?",
    "text": "What is this class about?\n\nDevelop research questions that can be answered with data\nAcquire data from multiple sources\nWrangle common types of data\nVisualize data to provide insight\nCommunicate your findings\nDocument your code and collaborate on coding projects"
  },
  {
    "objectID": "slides/01/slides01.html#section",
    "href": "slides/01/slides01.html#section",
    "title": "Welcome to Stat 220",
    "section": "",
    "text": "What skills do you need?\n\nprogramming with data\nstatistical modeling\ndomain knowledge\ncommunication"
  },
  {
    "objectID": "slides/01/slides01.html#what-is-this-class-all-about",
    "href": "slides/01/slides01.html#what-is-this-class-all-about",
    "title": "Welcome to Stat 220",
    "section": "What is this class all about?",
    "text": "What is this class all about?\n\n\n\nImage by Adam Loy  adapted from work of Joe Blitzstein, Hanspeter Pfister, and Hadley Wickham"
  },
  {
    "objectID": "slides/01/slides01.html#why-r",
    "href": "slides/01/slides01.html#why-r",
    "title": "Welcome to Stat 220",
    "section": "Why R?",
    "text": "Why R?\n\nAnd the second reason, which is both a huge strength of R and a bit of a weakness, is that R is not just a programming language. It was designed from day 1 to be an environment that can do data analysis. So, compared to the other options like Python, you can get up and running in R doing data science, learning much, much less about programming to get started. And that generally makes it like easier to get up and running if you don’t have formal training in computer science or software engineering.\n\n\n-Hadley Wickham, Advice to Young (and Old) Programmers: A Conversation with Hadley Wickham"
  },
  {
    "objectID": "slides/01/slides01.html#advice",
    "href": "slides/01/slides01.html#advice",
    "title": "Welcome to Stat 220",
    "section": "Advice",
    "text": "Advice\n\n\n\n\n\n\n\n\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n\n\n\nHadley Wickham, Advice to Young (and Old) Programmers: A Conversation with Hadley Wickham; Artwork by Allison Horst"
  },
  {
    "objectID": "slides/01/slides01.html#on-your-own",
    "href": "slides/01/slides01.html#on-your-own",
    "title": "Welcome to Stat 220",
    "section": "On your own:",
    "text": "On your own:\n\n\nLog into the maize server: maize.mathcs.carleton.edu\nFollow the directions at stat220-w25.github.io/computing/rstudio-stat220 to create a “content” folder\nLoad the .Rmd file with: download.file(     \"https://math.carleton.edu/aluby/stat220/01-example-unvotes.rmd\",      destfile = \"01-example-unvotes.rmd\")\nSkim the file without running any code:\n\nWhere is the code?\nWhere is the narrative?\n\nRun each code chunk in order. What does this analysis do?\n\n\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "slides/01/slides01.html#what-steps-went-into-this-analysis",
    "href": "slides/01/slides01.html#what-steps-went-into-this-analysis",
    "title": "Welcome to Stat 220",
    "section": "What steps went into this analysis?",
    "text": "What steps went into this analysis?\n\nRecording the original data\nAccessing data via an R package\nCombining multiple datasets into one\nData cleaning: filtering, creating new columns, grouping, summarizing\nMaking a graph\nFitting a smooth line model"
  },
  {
    "objectID": "slides/01/slides01.html#your-turn",
    "href": "slides/01/slides01.html#your-turn",
    "title": "Welcome to Stat 220",
    "section": "Your turn:",
    "text": "Your turn:\n\nWith your neighbor(s):\nChoose two countries to compare to the U.S. voting record in the U.N. over the years.\nWhat did you learn?\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/01/slides01.html#course-github",
    "href": "slides/01/slides01.html#course-github",
    "title": "Welcome to Stat 220",
    "section": "Course github",
    "text": "Course github\n\nhttps://github.com/stat220-w25/\n\n\naka “the one link to rule them all”\n\n\naccess slides\nsee schedule\naccess repositories for homework and projects"
  },
  {
    "objectID": "slides/01/slides01.html#office-hours-tentative",
    "href": "slides/01/slides01.html#office-hours-tentative",
    "title": "Welcome to Stat 220",
    "section": "Office hours (tentative)",
    "text": "Office hours (tentative)\n\n\n\nDay\nTime\nType\nLocation\n\n\n\n\nMonday\n11-12\nDrop-in\nCMC 307\n\n\nTuesday\n2-3\nDrop-in\nCMC 307\n\n\nWednesday\n4-5\nDrop-in\nCMC 307\n\n\nFriday\n11-12\nBy appt\nCMC 223"
  },
  {
    "objectID": "slides/01/slides01.html#where-is-amanda-in-january",
    "href": "slides/01/slides01.html#where-is-amanda-in-january",
    "title": "Welcome to Stat 220",
    "section": "Where is Amanda in January?",
    "text": "Where is Amanda in January?"
  },
  {
    "objectID": "slides/01/slides01.html#what-will-you-do-in-this-course",
    "href": "slides/01/slides01.html#what-will-you-do-in-this-course",
    "title": "Welcome to Stat 220",
    "section": "What will you do in this course?",
    "text": "What will you do in this course?\n\n\nGraded work:\n\nHomework\nLab Quizzes\nPortfolio Projects\nFinal Project\n\n\nUngraded work:\n\nDaily prep for class: read/watch/review/try\nIn-class exercises and group work\nEngagement in small and large group discussions"
  },
  {
    "objectID": "slides/01/slides01.html#what-will-a-typical-dayweek-look-like",
    "href": "slides/01/slides01.html#what-will-a-typical-dayweek-look-like",
    "title": "Welcome to Stat 220",
    "section": "What will a typical day/week look like?",
    "text": "What will a typical day/week look like?\n\n\nBefore class:\n\nWatch a video or read a chapter\nCome with questions\nBe prepared to try what was covered\n\n\nIn class:\n\nMini lecture\n\nSometimes review\nSometimes new\n\nHands-on coding in R\n\n\nAfter class:\n\nFinish any in-class exercises\nWork on homework and portfolio projects"
  },
  {
    "objectID": "slides/01/slides01.html#grading-system",
    "href": "slides/01/slides01.html#grading-system",
    "title": "Welcome to Stat 220",
    "section": "Grading system",
    "text": "Grading system\nHomework and lab quiz problems will be graded as successful or not successful. Projects will be graded as excellent, successful, or retry. You will have the opportunity to resubmit the lab quizzes outside of class.\nTo earn a course grade, you must meet all of the requirements in a given row:\n\n\n\n\n\n\n\n\n\n\n\nHomework Problems\nLab Quiz Problems\nPortfolio Projects (4 total)\nFinal Project\n\n\n\n\nA\n85%\n90%\n2 Excellent\nExcellent\n\n\nB\n75%\n80%\n4 Successful\nSuccessful\n\n\nC\n65%\n70%\n3 Successful\nSuccessful\n\n\nD\n55%\n50%\n2 Successful\nSuccessful\n\n\n\n“+” and “-” grades are determined by partially meeting the requirements in a given row."
  },
  {
    "objectID": "slides/01/slides01.html#benefits",
    "href": "slides/01/slides01.html#benefits",
    "title": "Welcome to Stat 220",
    "section": "Benefits",
    "text": "Benefits\n\nYou decide what grade you’re aiming for, and what you have to do to earn it\nClear guidelines for “successful” and “excellent” marks\nOpportunity to revise and resubmit"
  },
  {
    "objectID": "slides/01/slides01.html#possible-drawbacks",
    "href": "slides/01/slides01.html#possible-drawbacks",
    "title": "Welcome to Stat 220",
    "section": "Possible drawbacks",
    "text": "Possible drawbacks\n\nNo partial credit!\nRevisions take time\nCategories don’t “average out”"
  },
  {
    "objectID": "slides/01/slides01.html#tokens",
    "href": "slides/01/slides01.html#tokens",
    "title": "Welcome to Stat 220",
    "section": "Tokens",
    "text": "Tokens\nYou can use a token to:\n\nRevise a portfolio project that did not earn a “successful”\n72-hour extension on a homework assignment (the request must be submitted before the deadline)\n72-hour extension on lab quiz resubmissions (the request must be submitted before the deadline)\nBy passing the syllabus quiz, you’ll activate your 5 tokens for the term. I will track token balances in the moodle gradebook (updated weekly)"
  },
  {
    "objectID": "slides/01/slides01.html#collaboration-policy",
    "href": "slides/01/slides01.html#collaboration-policy",
    "title": "Welcome to Stat 220",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\n\n\n\n\n\n\n\nCollaboration Allowed\n\n\n\n\nHomework Problems\nYou are allowed and encouraged to collaborate on homework. You may also use outside resources, but your submitted work must be your own and reflect your own understanding .\n\n\nLab Quiz Problems\nNo collaboration is allowed at all . You may use your own notes for resubmissions, but should not use outside resources.\n\n\nPortfolio Projects\nYou are expected to collaborate with your group, but cannot rely on external sources other than to help motivate the questions or provide other background information. Getting answers on significant parts of solutions from outside resources is not allowed.\n\n\nFinal Project\nYou are expected to collaborate with your group, but cannot rely on external sources other than to help motivate the questions or provide other background information. Any outside resources should be properly cited."
  },
  {
    "objectID": "slides/01/slides01.html#use-of-generative-artificial-intelligence-ai",
    "href": "slides/01/slides01.html#use-of-generative-artificial-intelligence-ai",
    "title": "Welcome to Stat 220",
    "section": "Use of generative artificial intelligence (AI)",
    "text": "Use of generative artificial intelligence (AI)\n\nTreat generative AI, such as ChatGPT or Gemini, the same as other online resources.\nGuiding principles:\n\n(1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. AI should facilitate—rather than hinder—learning.\n(2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n❌ AI tools for writing code: You may not use generative AI to take a “first pass” at a coding task. Do not type coursework prompts directly into AI tools.\n✅ AI tools for debugging code: You may make use of the technology to get help with error messages or trying to fix issues\n❌ AI tools for narrative: Unless instructed otherwise, you may not use generative AI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you.\n\n\n\nAdapted from Mine Çetinkaya-Rundel"
  },
  {
    "objectID": "slides/01/slides01.html#tools",
    "href": "slides/01/slides01.html#tools",
    "title": "Welcome to Stat 220",
    "section": "Tools",
    "text": "Tools\n\nhttps://maize.mathcs.carleton.edu\n\n\nBrowser based RStudio instance(s) provided by Carleton\nRequires internet connection to access\nProvides consistency in hardware and software environments\nLocal R installations are also fine! But it may be harder for me to provide support"
  },
  {
    "objectID": "slides/01/slides01.html#github",
    "href": "slides/01/slides01.html#github",
    "title": "Welcome to Stat 220",
    "section": "GitHub",
    "text": "GitHub\n\nhttps://github.com/stat220-w25\n\n\nGitHub organization for the course\nAll of your work and your membership (enrollment) in the organization is private\nEach assignment is a private repo on GitHub, I distribute the assignments on GitHub.\nYou will work on your assignment, then “knit 🧶 commit ✅ push ⤴️”\nYou’ll then be able to submit your PDF via gradescope\n\n\n\nFill out the Welcome Survey for collection of your account names, later this week you will be invited to the course organization."
  },
  {
    "objectID": "slides/01/slides01.html#username-advice",
    "href": "slides/01/slides01.html#username-advice",
    "title": "Welcome to Stat 220",
    "section": "Username advice",
    "text": "Username advice\n\nin case you don’t yet have a GitHub account…\n\nSome brief advice about selecting your account names (particularly for GitHub),\n\nIncorporate your actual name! People like to know who they’re dealing with and makes your username easier for people to guess or remember\nReuse your username from other contexts, e.g., Twitter or Slack\nPick a username you will be comfortable revealing to your future boss\nShorter is better than longer, but be as unique as possible\nMake it timeless. Avoid highlighting your current university, employer, or place of residence"
  },
  {
    "objectID": "slides/01/slides01.html#your-tasks-before-next-class",
    "href": "slides/01/slides01.html#your-tasks-before-next-class",
    "title": "Welcome to Stat 220",
    "section": "Your tasks before next class",
    "text": "Your tasks before next class\n\nCreate a GitHub account if you don’t have one\nComplete the welcome survey if you haven’t already\nRead the syllabus and pass syllabus quiz\nMake sure you can login in to the maize server or update your local R/RStudio versions\nComplete the readings for next class"
  },
  {
    "objectID": "slides/12/slides12.html#today",
    "href": "slides/12/slides12.html#today",
    "title": "Working with Factors",
    "section": "Today",
    "text": "Today\n\nsetup chunk and alt-text\nHW5 and Portfolio 2 grace period\nNew stuff!"
  },
  {
    "objectID": "slides/12/slides12.html#survivor-castaways-data",
    "href": "slides/12/slides12.html#survivor-castaways-data",
    "title": "Working with Factors",
    "section": "Survivor castaways data",
    "text": "Survivor castaways data\n\n\n# A tibble: 1,351 × 29\n   version version_season season_name      season full_name castaway_id castaway\n   &lt;fct&gt;   &lt;chr&gt;          &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;   \n 1 US      US01           Survivor: Borneo      1 Sonja Ch… US0001      Sonja   \n 2 US      US01           Survivor: Borneo      1 B.B. And… US0002      B.B.    \n 3 US      US01           Survivor: Borneo      1 Stacey S… US0003      Stacey  \n 4 US      US01           Survivor: Borneo      1 Ramona G… US0004      Ramona  \n 5 US      US01           Survivor: Borneo      1 Dirk Been US0005      Dirk    \n 6 US      US01           Survivor: Borneo      1 Joel Klug US0006      Joel    \n 7 US      US01           Survivor: Borneo      1 Gretchen… US0007      Gretchen\n 8 US      US01           Survivor: Borneo      1 Greg Buis US0008      Greg    \n 9 US      US01           Survivor: Borneo      1 Jenna Le… US0009      Jenna   \n10 US      US01           Survivor: Borneo      1 Gervase … US0010      Gervase \n# ℹ 1,341 more rows\n# ℹ 22 more variables: age &lt;dbl&gt;, city &lt;chr&gt;, state &lt;chr&gt;, episode &lt;dbl&gt;,\n#   day &lt;dbl&gt;, order &lt;dbl&gt;, result &lt;chr&gt;, place &lt;dbl&gt;, jury_status &lt;chr&gt;,\n#   original_tribe &lt;chr&gt;, jury &lt;lgl&gt;, finalist &lt;lgl&gt;, winner &lt;lgl&gt;,\n#   acknowledge &lt;lgl&gt;, ack_look &lt;lgl&gt;, ack_speak &lt;lgl&gt;, ack_gesture &lt;lgl&gt;,\n#   ack_smile &lt;lgl&gt;, ack_quote &lt;chr&gt;, ack_score &lt;dbl&gt;, jury1 &lt;dbl&gt;, jury2 &lt;fct&gt;"
  },
  {
    "objectID": "slides/12/slides12.html#both-of-these-are-categorical-variables",
    "href": "slides/12/slides12.html#both-of-these-are-categorical-variables",
    "title": "Working with Factors",
    "section": "Both of these are categorical variables",
    "text": "Both of these are categorical variables\n\nunique(castaways$version)\n\n[1] US AU SA UK NZ\nLevels: AU NZ SA UK US\n\n\n\nunique(castaways$season_name) %&gt;% head()\n\n[1] \"Survivor: Borneo\"                 \"Survivor: The Australian Outback\"\n[3] \"Survivor: Africa\"                 \"Survivor: Marquesas\"             \n[5] \"Survivor: Thailand\"               \"Survivor: The Amazon\"            \n\n\n\nBut are stored as different types\n\nclass(castaways$version)\n\n[1] \"factor\"\n\n\n\nclass(castaways$season_name) \n\n[1] \"character\""
  },
  {
    "objectID": "slides/12/slides12.html#same-graph-colored-by-the-same-categorical-variable",
    "href": "slides/12/slides12.html#same-graph-colored-by-the-same-categorical-variable",
    "title": "Working with Factors",
    "section": "Same graph, colored by the same categorical variable",
    "text": "Same graph, colored by the same categorical variable"
  },
  {
    "objectID": "slides/12/slides12.html#factors",
    "href": "slides/12/slides12.html#factors",
    "title": "Working with Factors",
    "section": "Factors",
    "text": "Factors\nR’s representation of categorical data. Consists of:\n\nA set of values\nAn ordered set of valid levels\n\n\n\neyes &lt;- factor(x = c(\"blue\", \"green\", \"green\"), \n               levels = c(\"blue\", \"brown\", \"green\"))\neyes\n\n[1] blue  green green\nLevels: blue brown green"
  },
  {
    "objectID": "slides/12/slides12.html#factors-1",
    "href": "slides/12/slides12.html#factors-1",
    "title": "Working with Factors",
    "section": "Factors",
    "text": "Factors\nStored as an integer vector with a levels attribute\n\nunclass(eyes)\n\n[1] 1 3 3\nattr(,\"levels\")\n[1] \"blue\"  \"brown\" \"green\""
  },
  {
    "objectID": "slides/12/slides12.html#section",
    "href": "slides/12/slides12.html#section",
    "title": "Working with Factors",
    "section": "",
    "text": "Simple functions for working with factors.\nPart of the tidyverse\n\n\n# loaded with tidyverse\nlibrary(forcats)"
  },
  {
    "objectID": "slides/12/slides12.html#gss_cat",
    "href": "slides/12/slides12.html#gss_cat",
    "title": "Working with Factors",
    "section": "gss_cat",
    "text": "gss_cat\nA sample of data from the General Social Survey, a long-running US survey conducted by NORC at the University of Chicago.\n\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Not str r… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Strong de… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Ind,near … Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n10  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n# ℹ 21,473 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#warm-up",
    "href": "slides/12/slides12.html#warm-up",
    "title": "Working with Factors",
    "section": "Warm up",
    "text": "Warm up\n\nUse gss_cat to answer the following questions.\n\nWhich religions watch the least TV?\nDo married people watch more or less TV than single people?\n\n\n\n\n\n\n−&plus;\n\n04:00"
  },
  {
    "objectID": "slides/12/slides12.html#which-religions-watch-the-least-tv",
    "href": "slides/12/slides12.html#which-religions-watch-the-least-tv",
    "title": "Working with Factors",
    "section": "Which religions watch the least TV?",
    "text": "Which religions watch the least TV?\n\n\n\ngss_cat\n\n\n\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Not str r… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Strong de… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Ind,near … Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n10  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n# ℹ 21,473 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#which-religions-watch-the-least-tv-1",
    "href": "slides/12/slides12.html#which-religions-watch-the-least-tv-1",
    "title": "Working with Factors",
    "section": "Which religions watch the least TV?",
    "text": "Which religions watch the least TV?\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours)\n\n\n\n\n# A tibble: 11,337 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 3  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 4  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 5  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 6  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n 7  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n 8  2000 Married          53 White $25000 or more Not str d… Prot… Other       2\n 9  2000 Married          52 White $25000 or more Strong de… Prot… Sout…       1\n10  2000 Divorced         52 White $25000 or more Ind,near … None  Not …       1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#which-religions-watch-the-least-tv-2",
    "href": "slides/12/slides12.html#which-religions-watch-the-least-tv-2",
    "title": "Working with Factors",
    "section": "Which religions watch the least TV?",
    "text": "Which religions watch the least TV?\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  group_by(relig)\n\n\n\n\n# A tibble: 11,337 × 9\n# Groups:   relig [15]\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 3  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 4  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 5  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 6  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n 7  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n 8  2000 Married          53 White $25000 or more Not str d… Prot… Other       2\n 9  2000 Married          52 White $25000 or more Strong de… Prot… Sout…       1\n10  2000 Divorced         52 White $25000 or more Ind,near … None  Not …       1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#which-religions-watch-the-least-tv-3",
    "href": "slides/12/slides12.html#which-religions-watch-the-least-tv-3",
    "title": "Working with Factors",
    "section": "Which religions watch the least TV?",
    "text": "Which religions watch the least TV?\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  group_by(relig) %&gt;%\n  summarize(tvhours = mean(tvhours))\n\n\n\n\n# A tibble: 15 × 2\n   relig                   tvhours\n   &lt;fct&gt;                     &lt;dbl&gt;\n 1 No answer                  2.72\n 2 Don't know                 4.62\n 3 Inter-nondenominational    2.87\n 4 Native american            3.46\n 5 Christian                  2.79\n 6 Orthodox-christian         2.42\n 7 Moslem/islam               2.44\n 8 Other eastern              1.67\n 9 Hinduism                   1.89\n10 Buddhism                   2.38\n11 Other                      2.73\n12 None                       2.71\n13 Jewish                     2.52\n14 Catholic                   2.96\n15 Protestant                 3.15"
  },
  {
    "objectID": "slides/12/slides12.html#which-religions-watch-the-least-tv-4",
    "href": "slides/12/slides12.html#which-religions-watch-the-least-tv-4",
    "title": "Working with Factors",
    "section": "Which religions watch the least TV?",
    "text": "Which religions watch the least TV?\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  group_by(relig) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, relig))"
  },
  {
    "objectID": "slides/12/slides12.html#which-religions-watch-the-least-tv-5",
    "href": "slides/12/slides12.html#which-religions-watch-the-least-tv-5",
    "title": "Working with Factors",
    "section": "Which religions watch the least TV?",
    "text": "Which religions watch the least TV?\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  group_by(relig) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, relig)) +\n    geom_point()"
  },
  {
    "objectID": "slides/12/slides12.html#which-do-you-prefer",
    "href": "slides/12/slides12.html#which-do-you-prefer",
    "title": "Working with Factors",
    "section": "Which do you prefer?",
    "text": "Which do you prefer?"
  },
  {
    "objectID": "slides/12/slides12.html#why-is-the-y-axis-in-this-order",
    "href": "slides/12/slides12.html#why-is-the-y-axis-in-this-order",
    "title": "Working with Factors",
    "section": "Why is the y-axis in this order?",
    "text": "Why is the y-axis in this order?"
  },
  {
    "objectID": "slides/12/slides12.html#levels",
    "href": "slides/12/slides12.html#levels",
    "title": "Working with Factors",
    "section": "levels()",
    "text": "levels()\nUse levels() to access a factor’s levels\n\ngss_cat %&gt;% pull(relig) %&gt;% levels()\n\n [1] \"No answer\"               \"Don't know\"             \n [3] \"Inter-nondenominational\" \"Native american\"        \n [5] \"Christian\"               \"Orthodox-christian\"     \n [7] \"Moslem/islam\"            \"Other eastern\"          \n [9] \"Hinduism\"                \"Buddhism\"               \n[11] \"Other\"                   \"None\"                   \n[13] \"Jewish\"                  \"Catholic\"               \n[15] \"Protestant\"              \"Not applicable\""
  },
  {
    "objectID": "slides/12/slides12.html#most-useful-factor-skills",
    "href": "slides/12/slides12.html#most-useful-factor-skills",
    "title": "Working with Factors",
    "section": "Most useful factor skills:",
    "text": "Most useful factor skills:\n1. Reorder the levels\n2. Recode the levels\n3. Collapse levels"
  },
  {
    "objectID": "slides/12/slides12.html#fct_reorder",
    "href": "slides/12/slides12.html#fct_reorder",
    "title": "Working with Factors",
    "section": "fct_reorder",
    "text": "fct_reorder\n\n\n\n\n.f factor vector\n\n.x variable to reorder by (in conjunction with .fun)\n\n.fun function to reorder by\n\n.desc put levels in descending order?\n\n\n\nfct_reorder(\n  .f, \n  .x, \n  .fun = median, \n  ...,\n  .desc = FALSE \n  )"
  },
  {
    "objectID": "slides/12/slides12.html#reorder-relig-by-tvhours",
    "href": "slides/12/slides12.html#reorder-relig-by-tvhours",
    "title": "Working with Factors",
    "section": "Reorder relig by tvhours",
    "text": "Reorder relig by tvhours\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  group_by(relig) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(\n    x = tvhours,\n    y = relig\n  )) +\n    geom_point()"
  },
  {
    "objectID": "slides/12/slides12.html#reorder-relig-by-tvhours-1",
    "href": "slides/12/slides12.html#reorder-relig-by-tvhours-1",
    "title": "Working with Factors",
    "section": "Reorder relig by tvhours",
    "text": "Reorder relig by tvhours\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  group_by(relig) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(\n    x = tvhours,\n    y = fct_reorder(relig, tvhours)                 #ROTATE\n  )) +\n    geom_point()"
  },
  {
    "objectID": "slides/12/slides12.html#try-it",
    "href": "slides/12/slides12.html#try-it",
    "title": "Working with Factors",
    "section": "Try it",
    "text": "Try it\n\nUse rincome_summary to construct a dotplot of rincome against age.\nReorder rincome by age\n\n\nrincome_summary &lt;- gss_cat %&gt;%\n  group_by(rincome) %&gt;%\n  summarize(\n    age = mean(age, na.rm = TRUE),\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\n\n\n\n\n−&plus;\n\n02:30"
  },
  {
    "objectID": "slides/12/slides12.html#which-do-you-prefer-1",
    "href": "slides/12/slides12.html#which-do-you-prefer-1",
    "title": "Working with Factors",
    "section": "Which do you prefer?",
    "text": "Which do you prefer?"
  },
  {
    "objectID": "slides/12/slides12.html#fct_reorder2",
    "href": "slides/12/slides12.html#fct_reorder2",
    "title": "Working with Factors",
    "section": "fct_reorder2",
    "text": "fct_reorder2\nReorders the levels of a factor by the Y values associated with the largest X values.\n\n\n\n\n.f factor vector\n\n.x X variable\n\n.y Y variable\n\n.fun function to reorder by\n\n.desc put levels in descending order?\n\n\n\nfct_reorder2(\n  .f, \n  .x, \n  .y, \n  .fun = median, \n  ...,\n  .desc = FALSE\n  )"
  },
  {
    "objectID": "slides/12/slides12.html#reorder-marital",
    "href": "slides/12/slides12.html#reorder-marital",
    "title": "Working with Factors",
    "section": "Reorder marital",
    "text": "Reorder marital\n\n\n\ngss_cat %&gt;%\n  drop_na(age) %&gt;%\n  count(age, marital) %&gt;%\n  group_by(age) %&gt;%\n  mutate(prop = n / sum(n)) %&gt;%\n  ggplot(\n    aes(age,\n        prop,\n        color = marital )) +\n\n  geom_line() +\n  scale_color_colorblind(\"\")"
  },
  {
    "objectID": "slides/12/slides12.html#reorder-marital-1",
    "href": "slides/12/slides12.html#reorder-marital-1",
    "title": "Working with Factors",
    "section": "Reorder marital",
    "text": "Reorder marital\n\n\n\ngss_cat %&gt;%\n  drop_na(age) %&gt;%\n  count(age, marital) %&gt;%\n  group_by(age) %&gt;%\n  mutate(prop = n / sum(n)) %&gt;%\n  ggplot(\n    aes(age,\n        prop,\n        color = fct_reorder2(marital, .x = age, .y = prop))) + #ROTATE\n\n  geom_line() +\n  scale_color_colorblind(\"\")"
  },
  {
    "objectID": "slides/12/slides12.html#other-reordering-functions",
    "href": "slides/12/slides12.html#other-reordering-functions",
    "title": "Working with Factors",
    "section": "Other reordering functions",
    "text": "Other reordering functions\n\n\n\ngss_cat %&gt;%\n  ggplot() +\n  geom_bar(aes(x = marital))"
  },
  {
    "objectID": "slides/12/slides12.html#other-reordering-functions-1",
    "href": "slides/12/slides12.html#other-reordering-functions-1",
    "title": "Working with Factors",
    "section": "Other reordering functions",
    "text": "Other reordering functions\n\n\n\ngss_cat %&gt;%\n  ggplot() +\n  geom_bar(aes(x = fct_infreq(marital)))"
  },
  {
    "objectID": "slides/12/slides12.html#other-reordering-functions-2",
    "href": "slides/12/slides12.html#other-reordering-functions-2",
    "title": "Working with Factors",
    "section": "Other reordering functions",
    "text": "Other reordering functions\n\n\n\ngss_cat %&gt;%\n  ggplot() +\n  geom_bar(aes(x = fct_rev(fct_infreq(marital))))"
  },
  {
    "objectID": "slides/12/slides12.html#which-political-leaning-watches-more-tv",
    "href": "slides/12/slides12.html#which-political-leaning-watches-more-tv",
    "title": "Working with Factors",
    "section": "Which political leaning watches more TV?",
    "text": "Which political leaning watches more TV?\n\n\n\n\n\n\n\n\nHow could we improve the partyid labels?"
  },
  {
    "objectID": "slides/12/slides12.html#fct_reorder2-1",
    "href": "slides/12/slides12.html#fct_reorder2-1",
    "title": "Working with Factors",
    "section": "fct_reorder2",
    "text": "fct_reorder2\nChanges values of levels\n\n\n\n\n.f factor vector\n\n... new level = old level pairs (as a named character vector)\n\n\n\nfct_recode(.f, ...)"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid",
    "href": "slides/12/slides12.html#recoding-partyid",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat\n\n\n\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Not str r… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Strong de… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Ind,near … Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n10  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n# ℹ 21,473 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-1",
    "href": "slides/12/slides12.html#recoding-partyid-1",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours)\n\n\n\n\n# A tibble: 11,337 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 3  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 4  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 5  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 6  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n 7  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n 8  2000 Married          53 White $25000 or more Not str d… Prot… Other       2\n 9  2000 Married          52 White $25000 or more Strong de… Prot… Sout…       1\n10  2000 Divorced         52 White $25000 or more Ind,near … None  Not …       1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-2",
    "href": "slides/12/slides12.html#recoding-partyid-2",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours)\n\n\n\n\n# A tibble: 11,337 × 2\n   partyid            tvhours\n   &lt;fct&gt;                &lt;int&gt;\n 1 Ind,near rep            12\n 2 Independent              2\n 3 Ind,near rep             4\n 4 Not str democrat         1\n 5 Not str republican       3\n 6 Not str democrat         0\n 7 Strong republican        3\n 8 Not str democrat         2\n 9 Strong democrat          1\n10 Ind,near dem             1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-3",
    "href": "slides/12/slides12.html#recoding-partyid-3",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n    mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\"))\n\n\n\n\n# A tibble: 11,337 × 2\n   partyid               tvhours\n   &lt;fct&gt;                   &lt;int&gt;\n 1 Independent, near rep      12\n 2 Independent                 2\n 3 Independent, near rep       4\n 4 Democrat, weak              1\n 5 Republican, weak            3\n 6 Democrat, weak              0\n 7 Republican, strong          3\n 8 Democrat, weak              2\n 9 Democrat, strong            1\n10 Independent, near dem       1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-4",
    "href": "slides/12/slides12.html#recoding-partyid-4",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n    mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\")) %&gt;%\n  group_by(partyid)\n\n\n\n\n# A tibble: 11,337 × 2\n# Groups:   partyid [10]\n   partyid               tvhours\n   &lt;fct&gt;                   &lt;int&gt;\n 1 Independent, near rep      12\n 2 Independent                 2\n 3 Independent, near rep       4\n 4 Democrat, weak              1\n 5 Republican, weak            3\n 6 Democrat, weak              0\n 7 Republican, strong          3\n 8 Democrat, weak              2\n 9 Democrat, strong            1\n10 Independent, near dem       1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-5",
    "href": "slides/12/slides12.html#recoding-partyid-5",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n    mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\")) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours))\n\n\n\n\n# A tibble: 10 × 2\n   partyid               tvhours\n   &lt;fct&gt;                   &lt;dbl&gt;\n 1 No answer                3.22\n 2 Don't know               2   \n 3 Other party              2.79\n 4 Republican, strong       2.72\n 5 Republican, weak         2.63\n 6 Independent, near rep    2.77\n 7 Independent              3.08\n 8 Independent, near dem    2.80\n 9 Democrat, weak           3.04\n10 Democrat, strong         3.52"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-6",
    "href": "slides/12/slides12.html#recoding-partyid-6",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n    mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\")) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, fct_reorder(partyid, tvhours)))"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-7",
    "href": "slides/12/slides12.html#recoding-partyid-7",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n    mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\")) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, fct_reorder(partyid, tvhours))) +\n  geom_point()"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-8",
    "href": "slides/12/slides12.html#recoding-partyid-8",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n    mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\")) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, fct_reorder(partyid, tvhours))) +\n  geom_point() +\n  labs(y = \"partyid\")"
  },
  {
    "objectID": "slides/12/slides12.html#how-can-we-combine-these-factor-levels",
    "href": "slides/12/slides12.html#how-can-we-combine-these-factor-levels",
    "title": "Working with Factors",
    "section": "How can we combine these factor levels?",
    "text": "How can we combine these factor levels?"
  },
  {
    "objectID": "slides/12/slides12.html#fct_collapse",
    "href": "slides/12/slides12.html#fct_collapse",
    "title": "Working with Factors",
    "section": "fct_collapse()",
    "text": "fct_collapse()\nChanges multiple levels into single levels\n\n\n\n\n.f factor vector\n\n... named arguments set to a character vector (levels in the vector will be collapsed to the name of the argument)\n\n\n\nfct_collapse(.f, ...)"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid",
    "href": "slides/12/slides12.html#collapsing-partyid",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat\n\n\n\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Not str r… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Strong de… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Ind,near … Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n10  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n# ℹ 21,473 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-1",
    "href": "slides/12/slides12.html#collapsing-partyid-1",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours)\n\n\n\n\n# A tibble: 11,337 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 3  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 4  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 5  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 6  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n 7  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n 8  2000 Married          53 White $25000 or more Not str d… Prot… Other       2\n 9  2000 Married          52 White $25000 or more Strong de… Prot… Sout…       1\n10  2000 Divorced         52 White $25000 or more Ind,near … None  Not …       1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-2",
    "href": "slides/12/slides12.html#collapsing-partyid-2",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours)\n\n\n\n\n# A tibble: 11,337 × 2\n   partyid            tvhours\n   &lt;fct&gt;                &lt;int&gt;\n 1 Ind,near rep            12\n 2 Independent              2\n 3 Ind,near rep             4\n 4 Not str democrat         1\n 5 Not str republican       3\n 6 Not str democrat         0\n 7 Strong republican        3\n 8 Not str democrat         2\n 9 Strong democrat          1\n10 Ind,near dem             1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-3",
    "href": "slides/12/slides12.html#collapsing-partyid-3",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n  mutate(\n    partyid =\n      fct_collapse(\n        partyid,\n        conservative = c(\"Strong republican\",\n                         \"Not str republican\",\n                         \"Ind,near rep\"),\n        liberal = c(\"Strong democrat\",\n                    \"Not str democrat\",\n                    \"Ind,near dem\"))\n  )\n\n\n\n\n# A tibble: 11,337 × 2\n   partyid      tvhours\n   &lt;fct&gt;          &lt;int&gt;\n 1 conservative      12\n 2 Independent        2\n 3 conservative       4\n 4 liberal            1\n 5 conservative       3\n 6 liberal            0\n 7 conservative       3\n 8 liberal            2\n 9 liberal            1\n10 liberal            1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-4",
    "href": "slides/12/slides12.html#collapsing-partyid-4",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n  mutate(\n    partyid =\n      fct_collapse(\n        partyid,\n        conservative = c(\"Strong republican\",\n                         \"Not str republican\",\n                         \"Ind,near rep\"),\n        liberal = c(\"Strong democrat\",\n                    \"Not str democrat\",\n                    \"Ind,near dem\"))\n  ) %&gt;%\n  group_by(partyid)\n\n\n\n\n# A tibble: 11,337 × 2\n# Groups:   partyid [6]\n   partyid      tvhours\n   &lt;fct&gt;          &lt;int&gt;\n 1 conservative      12\n 2 Independent        2\n 3 conservative       4\n 4 liberal            1\n 5 conservative       3\n 6 liberal            0\n 7 conservative       3\n 8 liberal            2\n 9 liberal            1\n10 liberal            1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-5",
    "href": "slides/12/slides12.html#collapsing-partyid-5",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n  mutate(\n    partyid =\n      fct_collapse(\n        partyid,\n        conservative = c(\"Strong republican\",\n                         \"Not str republican\",\n                         \"Ind,near rep\"),\n        liberal = c(\"Strong democrat\",\n                    \"Not str democrat\",\n                    \"Ind,near dem\"))\n  ) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours))\n\n\n\n\n# A tibble: 6 × 2\n  partyid      tvhours\n  &lt;fct&gt;          &lt;dbl&gt;\n1 No answer       3.22\n2 Don't know      2   \n3 Other party     2.79\n4 conservative    2.69\n5 Independent     3.08\n6 liberal         3.15"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-6",
    "href": "slides/12/slides12.html#collapsing-partyid-6",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n  mutate(\n    partyid =\n      fct_collapse(\n        partyid,\n        conservative = c(\"Strong republican\",\n                         \"Not str republican\",\n                         \"Ind,near rep\"),\n        liberal = c(\"Strong democrat\",\n                    \"Not str democrat\",\n                    \"Ind,near dem\"))\n  ) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, fct_reorder(partyid, tvhours)))"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-7",
    "href": "slides/12/slides12.html#collapsing-partyid-7",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n  mutate(\n    partyid =\n      fct_collapse(\n        partyid,\n        conservative = c(\"Strong republican\",\n                         \"Not str republican\",\n                         \"Ind,near rep\"),\n        liberal = c(\"Strong democrat\",\n                    \"Not str democrat\",\n                    \"Ind,near dem\"))\n  ) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, fct_reorder(partyid, tvhours))) +\n  geom_point()"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-8",
    "href": "slides/12/slides12.html#collapsing-partyid-8",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n  mutate(\n    partyid =\n      fct_collapse(\n        partyid,\n        conservative = c(\"Strong republican\",\n                         \"Not str republican\",\n                         \"Ind,near rep\"),\n        liberal = c(\"Strong democrat\",\n                    \"Not str democrat\",\n                    \"Ind,near dem\"))\n  ) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, fct_reorder(partyid, tvhours))) +\n  geom_point() +\n  labs(y = \"partyid\")"
  },
  {
    "objectID": "slides/12/slides12.html#your-turn",
    "href": "slides/12/slides12.html#your-turn",
    "title": "Working with Factors",
    "section": "Your turn",
    "text": "Your turn\n\nCollapse the marital variable to have levels Married, not_married, and No answer\nInclude \"Never married\", \"Divorced\", and “Widowed\" in not_married\n\n\n\n\n\n−&plus;\n\n02:00"
  },
  {
    "objectID": "slides/12/slides12.html#there-are-relatively-few-points-in-each-of-these-groups",
    "href": "slides/12/slides12.html#there-are-relatively-few-points-in-each-of-these-groups",
    "title": "Working with Factors",
    "section": "There are relatively few points in each of these groups",
    "text": "There are relatively few points in each of these groups"
  },
  {
    "objectID": "slides/12/slides12.html#fct_lump",
    "href": "slides/12/slides12.html#fct_lump",
    "title": "Working with Factors",
    "section": "fct_lump()",
    "text": "fct_lump()\nCollapses levels with fewest values into a single level.\nBy default collapses as many levels as possible such that the new level is still the smallest.\n\n\n\n\nf factor vector\n\nn preserve the most common n levels\nother_level = \"Other\"\n\n\n\nfct_lump(\n  f, \n  n, \n  other_level = \"Other\", \n  ...\n)"
  },
  {
    "objectID": "slides/12/slides12.html#lumping-parytid",
    "href": "slides/12/slides12.html#lumping-parytid",
    "title": "Working with Factors",
    "section": "Lumping parytid",
    "text": "Lumping parytid\n\n\n\ngss_cat %&gt;%\n  mutate(partyid = partyid) %&gt;%\n  ggplot(aes(partyid)) +\n  geom_bar() +\n  labs(x = \"partyid\")"
  },
  {
    "objectID": "slides/12/slides12.html#lumping-parytid-1",
    "href": "slides/12/slides12.html#lumping-parytid-1",
    "title": "Working with Factors",
    "section": "Lumping parytid",
    "text": "Lumping parytid\n\n\n\ngss_cat %&gt;%\n  mutate(partyid = fct_lump(partyid, n = 2)) %&gt;%\n  ggplot(aes(partyid)) +\n  geom_bar() +\n  labs(x = \"partyid\")"
  },
  {
    "objectID": "slides/12/slides12.html#lumping-parytid-2",
    "href": "slides/12/slides12.html#lumping-parytid-2",
    "title": "Working with Factors",
    "section": "Lumping parytid",
    "text": "Lumping parytid\n\n\n\ngss_cat %&gt;%\n  mutate(partyid = fct_lump(partyid, n = 3)) %&gt;%\n  ggplot(aes(partyid)) +\n  geom_bar() +\n  labs(x = \"partyid\")"
  },
  {
    "objectID": "notes/02-full-lego-report.html",
    "href": "notes/02-full-lego-report.html",
    "title": "An Overview of Lego Sets on Rebrickable",
    "section": "",
    "text": "Rebrickable is a website that shows you which LEGO sets you can build from the LEGO sets and parts that you already own. To do this, Rebrickable maintains a database of the entire LEGO catalog. In this document, we’ll summarize the LEGO sets in this database.\nThe data set was originally obtained from the 2022-09-09 repository on Tidy Tuesday.\n\nIn the data set consists of 19798 LEGO sets (i.e., rows) and 6 variables (i.e., columns). The data set includes LEGO sets from 1949 to 2022. The average number of parts in a set was 161.1 with a standard deviation of 402.62. However, there are 3630 in the data set with 0 parts, making these summary statistics inaccurate.\nBelow is a scatterplot with smoother describing how the typical number of parts in a set has changed from 1949 to 2022.\n\nlibrary(tidyverse)\n\nggplot(sets, aes(year, num_parts)) +\n    geom_jitter(alpha = 0.2, size = .5) +\n    geom_smooth(color = \"skyblue\") +\n    scale_y_continuous(trans = \"log10\") +\n    coord_fixed(ratio = 10) +\n    labs(x = \"Year\", y = \"Number of parts\",\n             title = \"LEGO sets are getting larger over the years\",\n             caption = \"Data source: brickable.com\") +\n    theme_light()"
  },
  {
    "objectID": "notes/02-full-lego-report.html#summarizing-the-lego-dataset",
    "href": "notes/02-full-lego-report.html#summarizing-the-lego-dataset",
    "title": "An Overview of Lego Sets on Rebrickable",
    "section": "",
    "text": "In the data set consists of 19798 LEGO sets (i.e., rows) and 6 variables (i.e., columns). The data set includes LEGO sets from 1949 to 2022. The average number of parts in a set was 161.1 with a standard deviation of 402.62. However, there are 3630 in the data set with 0 parts, making these summary statistics inaccurate.\nBelow is a scatterplot with smoother describing how the typical number of parts in a set has changed from 1949 to 2022.\n\nlibrary(tidyverse)\n\nggplot(sets, aes(year, num_parts)) +\n    geom_jitter(alpha = 0.2, size = .5) +\n    geom_smooth(color = \"skyblue\") +\n    scale_y_continuous(trans = \"log10\") +\n    coord_fixed(ratio = 10) +\n    labs(x = \"Year\", y = \"Number of parts\",\n             title = \"LEGO sets are getting larger over the years\",\n             caption = \"Data source: brickable.com\") +\n    theme_light()"
  },
  {
    "objectID": "portfolio/portfolio-2.html",
    "href": "portfolio/portfolio-2.html",
    "title": "Portfolio Project 2",
    "section": "",
    "text": "For your second portfolio project, you’ll apply what you’ve learned about wrangling data using the tidyverse. Your goal is to learn which areas of the U.S. struggle with weather prediction and explore possible reasons why. Speciﬁcally, you will focus on the error in high and low temperature forecasting, and may wish to also consider precipitation and outlook.\nYou should write a short report describing your ﬁndings. I envision an introductory paragraph that provides some context to your data, and a couple paragraphs outlining your ﬁndings. That’s it. I’m looking for something that is insightful and well-crafted, rather than long and exhaustive.\nYou should write your blog post in R Markdown, create any graphics using ggplot2, and use tools from this class for data wrangling. To submit your work, push both your R Markdown (.Rmd) ﬁle and knitted output document to GitHub. Do not forget to give your post an informative title!",
    "crumbs": [
      "Portfolio Projects",
      "Portfolio Project 2"
    ]
  },
  {
    "objectID": "portfolio/portfolio-2.html#weather-forecasts.csv",
    "href": "portfolio/portfolio-2.html#weather-forecasts.csv",
    "title": "Portfolio Project 2",
    "section": "weather-forecasts.csv",
    "text": "weather-forecasts.csv\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\ndate\ndate\ndate described by the forecast\n\n\ncity\nfactor\nobservation city\n\n\nstate\nfactor\nstate or territory\n\n\nhigh_or_low\nfactor\nwhether the forecast is for the high temperature of the low temperature\n\n\nforecast_hours_before\ninteger\nthe number of hours before the observation (one of 12, 24, 36, or 48)\n\n\nobserved_temp\ninteger\nthe actual observed temperature on that date (high or low)\n\n\nforecast_temp\ninteger\nthe predicted temperature on that date (high or low)\n\n\nobserved_precip\ndouble\nthe observed precipitation on that date, in inches; note that some observations lack an indication of precipitation, while others explicitly report 0\n\n\nforecast_outlook\nfactor\nan abbreviation for the general outlook, such as precipitation type\n\n\npossible_error\nfactor\neither (1) “none” if the row contains no potential errors or (2) thename of the variable that is the cause of the potential error",
    "crumbs": [
      "Portfolio Projects",
      "Portfolio Project 2"
    ]
  },
  {
    "objectID": "portfolio/portfolio-2.html#forecast_cities.csv",
    "href": "portfolio/portfolio-2.html#forecast_cities.csv",
    "title": "Portfolio Project 2",
    "section": "forecast_cities.csv",
    "text": "forecast_cities.csv\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\ncity\ncharacter\ncity\n\n\nstate\ncharacter\nstate or territory\n\n\nlon lat\ndouble\nlongitude\n\n\nlat\ndouble\nlatitude\n\n\nkoppen\ncharacter\nKöppen climate classiﬁcation\n\n\nelevation\ndouble\nelevation in meters\n\n\ndistance_to_coast\ndouble\ndistance_to_coast in miles\n\n\nwind\ndouble\nmean wind speed\n\n\nelevation_change_four\ndouble\ngreatest elevation change in meters out of the four closest points to this city in a collection of elevations used by the team at Saint Louis University\n\n\nelevation_change_eight\ndouble\ngreatest elevation change in meters out of the eight closest points to this city in a collection of elevations used by the team at Saint Louis University\n\n\navg_annual_precip\ndouble\naverage annual precipitation in inches",
    "crumbs": [
      "Portfolio Projects",
      "Portfolio Project 2"
    ]
  },
  {
    "objectID": "portfolio/portfolio-2.html#outlook_meanings.csv",
    "href": "portfolio/portfolio-2.html#outlook_meanings.csv",
    "title": "Portfolio Project 2",
    "section": "outlook_meanings.csv",
    "text": "outlook_meanings.csv\n\n\n\nvariable\nclass\n\n\n\n\nforecast_outlook\ncharacter\n\n\nmeaning\ncharacter",
    "crumbs": [
      "Portfolio Projects",
      "Portfolio Project 2"
    ]
  },
  {
    "objectID": "activities/11-import.html",
    "href": "activities/11-import.html",
    "title": "Data import and dates/times",
    "section": "",
    "text": "Click the “code” button above to copy and paste the source code, or pull a fresh version of the “activities” repo from GitHub."
  },
  {
    "objectID": "activities/11-import.html#data-4.csv",
    "href": "activities/11-import.html#data-4.csv",
    "title": "Data import and dates/times",
    "section": "data-4.csv",
    "text": "data-4.csv\n\n# your code here"
  },
  {
    "objectID": "activities/11-import.html#tricky-1.csv",
    "href": "activities/11-import.html#tricky-1.csv",
    "title": "Data import and dates/times",
    "section": "tricky-1.csv",
    "text": "tricky-1.csv\n\n# your code here"
  },
  {
    "objectID": "activities/11-import.html#tricky-2.csv",
    "href": "activities/11-import.html#tricky-2.csv",
    "title": "Data import and dates/times",
    "section": "tricky-2.csv",
    "text": "tricky-2.csv\n\n# your code here"
  },
  {
    "objectID": "activities/11-import.html#task-1",
    "href": "activities/11-import.html#task-1",
    "title": "Data import and dates/times",
    "section": "Task 1",
    "text": "Task 1\nCreate a vector of dates that our class meets this term\n\n# your code here"
  },
  {
    "objectID": "activities/11-import.html#task-2",
    "href": "activities/11-import.html#task-2",
    "title": "Data import and dates/times",
    "section": "Task 2",
    "text": "Task 2\nNext, print them in the format “Wednesday: Jan 29 2025”\nHint: see ?stamp or the lubridate cheatsheet\n\n# your code here"
  },
  {
    "objectID": "activities/10-combining.html",
    "href": "activities/10-combining.html",
    "title": "\nbind_ and _join: Combining Data",
    "section": "",
    "text": "Click the “code” button above to copy and paste the source code, or pull a fresh version of the “activities” repo from GitHub."
  },
  {
    "objectID": "activities/10-combining.html#example-1-star-wars-characters",
    "href": "activities/10-combining.html#example-1-star-wars-characters",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Example 1: Star Wars Characters",
    "text": "Example 1: Star Wars Characters\nDataset 1:\n\nEach row in the dataset corresponds to a star wars character\nThe columns include their name, height, mass, homeworld, species, and the first_film they appeared in\n\n\nstarwars_characters\n\n# A tibble: 87 × 6\n   name               height  mass homeworld species first_film\n   &lt;chr&gt;               &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;     \n 1 Luke Skywalker        172    77 Tatooine  Human   A New Hope\n 2 C-3PO                 167    75 Tatooine  Droid   A New Hope\n 3 R2-D2                  96    32 Naboo     Droid   A New Hope\n 4 Darth Vader           202   136 Tatooine  Human   A New Hope\n 5 Leia Organa           150    49 Alderaan  Human   A New Hope\n 6 Owen Lars             178   120 Tatooine  Human   A New Hope\n 7 Beru Whitesun Lars    165    75 Tatooine  Human   A New Hope\n 8 R5-D4                  97    32 Tatooine  Droid   A New Hope\n 9 Biggs Darklighter     183    84 Tatooine  Human   A New Hope\n10 Obi-Wan Kenobi        182    77 Stewjon   Human   A New Hope\n# ℹ 77 more rows\n\n\nDataset 2:\nThe dataset is formatted the same, but includes two characters that were first introduced in *The Last Jedi, a Star Wars movie that came out after the first datset was released.\n\nstarwars_lastjedi\n\n# A tibble: 2 × 6\n  name         height mass  homeworld species first_film   \n  &lt;chr&gt;        &lt;lgl&gt;  &lt;lgl&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;        \n1 Rose Tico    NA     NA    Otomok    Human   The Last Jedi\n2 Amilyn Holdo NA     NA    &lt;NA&gt;      Human   The Last Jedi\n\n\nHow should these datasets be combined?"
  },
  {
    "objectID": "activities/10-combining.html#example-2-stats-sections",
    "href": "activities/10-combining.html#example-2-stats-sections",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Example 2: Stats Sections",
    "text": "Example 2: Stats Sections\nDataset 1:\nThis dataset includes the number of sections of stats courses offered in Fall 2024 and Winter 2025 terms.\n\nstats_sections_fw\n\n# A tibble: 8 × 3\n  class    fall winter\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 stat120     3      3\n2 stat220     1      1\n3 stat230     1      1\n4 stat250     0      1\n5 stat270     1      0\n6 stat285     1      1\n7 stat320     0      0\n8 stat330     0      1\n\n\nDataset 2:\nThis dataset includes the number of sections of stats courses offered in the Spring 2025 term.\n\nstats_sections_s\n\n# A tibble: 8 × 1\n  spring\n   &lt;dbl&gt;\n1      4\n2      1\n3      1\n4      1\n5      0\n6      1\n7      1\n8      0\n\n\nHow should these datasets be combined?"
  },
  {
    "objectID": "activities/10-combining.html#example-3-survivor-castaways",
    "href": "activities/10-combining.html#example-3-survivor-castaways",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Example 3: Survivor castaways",
    "text": "Example 3: Survivor castaways\nDataset 1:\n\nThis dataset includes information about each castaway’s performance in a given season of Survivor (US seasons)\nIt includes a castaway ID, first name, season name and number, and the results for that castaway in that season (their overall place, whether they made the jury, and whether they were a finalist)\n\n\nus_castaway_results\n\n# A tibble: 870 × 7\n   castaway_id castaway season_name      season place jury  finalist\n   &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;   \n 1 US0001      Sonja    Survivor: Borneo      1    16 FALSE FALSE   \n 2 US0002      B.B.     Survivor: Borneo      1    15 FALSE FALSE   \n 3 US0003      Stacey   Survivor: Borneo      1    14 FALSE FALSE   \n 4 US0004      Ramona   Survivor: Borneo      1    13 FALSE FALSE   \n 5 US0005      Dirk     Survivor: Borneo      1    12 FALSE FALSE   \n 6 US0006      Joel     Survivor: Borneo      1    11 FALSE FALSE   \n 7 US0007      Gretchen Survivor: Borneo      1    10 FALSE FALSE   \n 8 US0008      Greg     Survivor: Borneo      1     9 TRUE  FALSE   \n 9 US0009      Jenna    Survivor: Borneo      1     8 TRUE  FALSE   \n10 US0010      Gervase  Survivor: Borneo      1     7 TRUE  FALSE   \n# ℹ 860 more rows\n\n\nDataset 2:\n\nThis dataset includes information about each castaway who has appeared on Survivor (including non-US seasons)\nIt includes a castaway ID, their full name, date of birth, gender and occupation as presented in the show, and their Myers-Briggs personality type.\n\n\ncast_details\n\n# A tibble: 1,118 × 6\n   castaway_id full_name        date_of_birth gender occupation personality_type\n   &lt;chr&gt;       &lt;chr&gt;            &lt;date&gt;        &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;           \n 1 US0014      Rudy Boesch      1928-01-20    Male   Retired N… ISTJ            \n 2 US0002      B.B. Andersen    1936-01-18    Male   Real Esta… ESTJ            \n 3 US0001      Sonja Christoph… 1937-01-28    Female Musician   ENFP            \n 4 US0075      Jake Billingsley 1941-08-21    Male   Land Brok… ISFJ            \n 5 US0151      Jim Lynch        1942-01-07    Male   Retired F… ISTJ            \n 6 US0474      Joseph Del Campo 1943-07-04    Male   Former FB… ISTJ            \n 7 US0304      Jimmy Johnson    1943-07-16    Male   Former NF… ESFJ            \n 8 US0047      Kim Johnson      1944-09-18    Female Retired T… ISFJ            \n 9 US0128      Scout Cloud Lee  1944-11-08    Female Rancher    INFJ            \n10 US0061      Paschal English  1945-03-05    Male   Judge      ISFJ            \n# ℹ 1,108 more rows\n\n\nWe are interested in exploring the relationship between overall place on a Survivor season and personality type. How should these datasets be combined?\nStop here"
  },
  {
    "objectID": "activities/10-combining.html#task-line-plot",
    "href": "activities/10-combining.html#task-line-plot",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Task: line plot",
    "text": "Task: line plot\nFinish the code to make a line plot of viewers against episode, colored and grouped by series. (remember to remove #| eval: false)\n\ntidy_ratings2 %&gt;%\n  ggplot(aes(x = _____, y = _____, col = _____, group = _____)) +\n  geom_line() + \n  scale_color_viridis_c(option = \"plasma\", end = .8)"
  },
  {
    "objectID": "activities/10-combining.html#task-add-series-9-14-to-the-dataset",
    "href": "activities/10-combining.html#task-add-series-9-14-to-the-dataset",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Task: Add series 9-14 to the dataset",
    "text": "Task: Add series 9-14 to the dataset\nThe code chunk below loads the new dataset\n\nmessy_ratings2b &lt;- read_csv(\"https://stat220-w25.github.io/data/messy_ratings2_9_14.csv\")\nmessy_ratings2b\n\n# A tibble: 6 × 21\n  series e1_7day e1_28day e2_7day e2_28day e3_7day e3_28day e4_7day e4_28day\n   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1      9    9.55     9.92    9.31     9.76    8.91     9.35    8.88     9.41\n2     10    9.62    10.0     9.38     9.8     8.94     9.42    8.96     9.49\n3     11   11.2     11.8    10.8     11.4    10.7     11.2    10.6     11.2 \n4     12    9.57    10.2     8.98     9.64    8.69     9.39    8.75     9.13\n5     13    8.3      1       7.6      1       7.35     1       7.76     1   \n6     14    7.84     1       7.54     1       7.28     1       7.12     1   \n# ℹ 12 more variables: e5_7day &lt;dbl&gt;, e5_28day &lt;dbl&gt;, e6_7day &lt;dbl&gt;,\n#   e6_28day &lt;dbl&gt;, e7_7day &lt;dbl&gt;, e7_28day &lt;dbl&gt;, e8_7day &lt;dbl&gt;,\n#   e8_28day &lt;dbl&gt;, e9_7day &lt;dbl&gt;, e9_28day &lt;dbl&gt;, e10_7day &lt;dbl&gt;,\n#   e10_28day &lt;dbl&gt;\n\n\nCombine with bind_rows()\n\nCombine the two messy datasets by using bind_rows(). Be sure to look at your resulting dataset and make sure it has the right format\n\n# your code here\n\nCombine with join()\n\nWe’ll practice joining with the tidy versions of the data. First, create tidy_ratings2b using the new dataset. Follow the same steps as what was used to create tidy_ratings2\n\n# your code here\n\nOnce you’re satisfied, that the two tidy datasets look similar enough to combine, remove #| eval: false from the following code chunk and run it. Did it work? Why or why not?\n\ntidy_ratings = tidy_ratings2 %&gt;%\n  left_join(tidy_ratings2b)\n\nUse the correction _join function here. Save your dataset to the tidy_ratings object.\n\n# your code here\n\nCombine with bind_cols\n\nTo join the two datasets using bind_cols, you’ll first have to un-tidy your tidy datasets, so that each episode number is in a row and each series number is in a column. After using bind_cols() the first few rows of your final dataset should look like this:\n# A tibble: 10 × 16\n   episode period    s1    s2    s3    s4    s5    s6    s7    s8    s9   s10   s11   s12   s13   s14\n     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1       1      7  2.24  3.1   3.85  6.6   8.51  11.6  13.6  9.46  9.55  9.62  11.2  9.57  8.3   7.84\n 2       2      7  3     3.53  4.6   6.65  8.79  11.6  13.4  9.23  9.31  9.38  10.8  8.98  7.6   7.54\n 3       3      7  3     3.82  4.53  7.17  9.28  12.0  13.0  8.68  8.91  8.94  10.7  8.69  7.35  7.28\nStop here and let Amanda know you’ve finished"
  },
  {
    "objectID": "activities/10-combining.html#footnotes",
    "href": "activities/10-combining.html#footnotes",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Footnotes",
    "text": "Footnotes\n\nTalk it over: does everybody remember what makes a dataset “tidy”?↩︎"
  },
  {
    "objectID": "activities/05-maps.html",
    "href": "activities/05-maps.html",
    "title": "Maps",
    "section": "",
    "text": "states &lt;- map_data(\"state\")\nggplot(states, aes(x=long, y=lat, group=group)) + \n    geom_polygon(color=\"gold2\", fill=\"navyblue\")\n\n\n\n\n\n\n\n\nEdit the code so that each state is a different color\n\nstates &lt;- map_data(\"state\")\nggplot(states, aes(x=long, y=lat, group=group)) + \n    geom_polygon(color=\"gold2\", fill=\"navyblue\")"
  },
  {
    "objectID": "activities/05-maps.html#your-turn",
    "href": "activities/05-maps.html#your-turn",
    "title": "Maps",
    "section": "",
    "text": "Edit the code so that each state is a different color\n\nstates &lt;- map_data(\"state\")\nggplot(states, aes(x=long, y=lat, group=group)) + \n    geom_polygon(color=\"gold2\", fill=\"navyblue\")"
  },
  {
    "objectID": "activities/10-combining-solutions.html",
    "href": "activities/10-combining-solutions.html",
    "title": "\nbind_ and _join: Combining Data",
    "section": "",
    "text": "Click the “code” button above to copy and paste the source code, or pull a fresh version of the “activities” repo from GitHub."
  },
  {
    "objectID": "activities/10-combining-solutions.html#task",
    "href": "activities/10-combining-solutions.html#task",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Task",
    "text": "Task\n\nmessy_ratings2b &lt;- read_csv(here(here(), \"data/messy_ratings2_9_14.csv\"))\n\nCombine with bind_rows()\n\n\nmessy_ratings2 %&gt;%\n  bind_rows(messy_ratings2b)\n\n# A tibble: 14 × 21\n   series e1_7day e1_28day e2_7day e2_28day e3_7day e3_28day e4_7day e4_28day\n    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1      1    2.24    NA       3       NA       3       NA       2.6     NA   \n 2      2    3.1     NA       3.53    NA       3.82    NA       3.6     NA   \n 3      3    3.85    NA       4.6     NA       4.53    NA       4.71    NA   \n 4      4    6.6     NA       6.65    NA       7.17    NA       6.82    NA   \n 5      5    8.51    NA       8.79    NA       9.28    NA      10.2     NA   \n 6      6   11.6     11.7    11.6     11.8    12.0     NA      12.4     12.7 \n 7      7   13.6     13.9    13.4     13.7    13.0     13.4    13.3     13.9 \n 8      8    9.46     9.72    9.23     9.53    8.68     9.06    8.55     8.87\n 9      9    9.55     9.92    9.31     9.76    8.91     9.35    8.88     9.41\n10     10    9.62    10.0     9.38     9.8     8.94     9.42    8.96     9.49\n11     11   11.2     11.8    10.8     11.4    10.7     11.2    10.6     11.2 \n12     12    9.57    10.2     8.98     9.64    8.69     9.39    8.75     9.13\n13     13    8.3      1       7.6      1       7.35     1       7.76     1   \n14     14    7.84     1       7.54     1       7.28     1       7.12     1   \n# ℹ 12 more variables: e5_7day &lt;dbl&gt;, e5_28day &lt;dbl&gt;, e6_7day &lt;dbl&gt;,\n#   e6_28day &lt;dbl&gt;, e7_7day &lt;dbl&gt;, e7_28day &lt;dbl&gt;, e8_7day &lt;dbl&gt;,\n#   e8_28day &lt;dbl&gt;, e9_7day &lt;dbl&gt;, e9_28day &lt;dbl&gt;, e10_7day &lt;dbl&gt;,\n#   e10_28day &lt;dbl&gt;\n\n\nCombine with join()\n\nFirst, create tidy_ratings2b\n\ntidy_ratings2b &lt;- messy_ratings2b %&gt;%\n  select(series, contains(\"7day\")) %&gt;%\n  pivot_longer(-series, names_to = \"episode\", values_to = \"viewers\") %&gt;%\n  separate(episode, into = c(\"episode\", \"period\")) %&gt;%\n  mutate(\n    episode = parse_number(episode),\n    period = parse_number(period)\n  )\n\nWhy doesn’t left_join() work?\n\ntidy_ratings2 %&gt;%\n  left_join(tidy_ratings2b)\n\n# A tibble: 80 × 4\n   series episode period viewers\n    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1      1       1      7    2.24\n 2      1       2      7    3   \n 3      1       3      7    3   \n 4      1       4      7    2.6 \n 5      1       5      7    3.03\n 6      1       6      7    2.75\n 7      1       7      7   NA   \n 8      1       8      7   NA   \n 9      1       9      7   NA   \n10      1      10      7   NA   \n# ℹ 70 more rows\n\n\nWhich _join do we use?\n\ntidy_ratings2 %&gt;%\n  full_join(tidy_ratings2b)\n\n# A tibble: 140 × 4\n   series episode period viewers\n    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1      1       1      7    2.24\n 2      1       2      7    3   \n 3      1       3      7    3   \n 4      1       4      7    2.6 \n 5      1       5      7    3.03\n 6      1       6      7    2.75\n 7      1       7      7   NA   \n 8      1       8      7   NA   \n 9      1       9      7   NA   \n10      1      10      7   NA   \n# ℹ 130 more rows\n\n\nCombine with bind_cols\n\nWhy doesn’t this work?\n\nseasoncols_ratings2 = tidy_ratings2 %&gt;%\n  pivot_wider(names_from = series, \n              values_from = viewers, \n              names_prefix = \"s\")\n\nseasoncols_ratings2b = tidy_ratings2b %&gt;%\n  pivot_wider(names_from = series, values_from = viewers)\n\nseasoncols_ratings2 %&gt;%\n  bind_cols(seasoncols_ratings2b)\n\n# A tibble: 10 × 18\n   episode...1 period...2    s1    s2    s3    s4    s5    s6    s7    s8\n         &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1           1          7  2.24  3.1   3.85  6.6   8.51  11.6  13.6  9.46\n 2           2          7  3     3.53  4.6   6.65  8.79  11.6  13.4  9.23\n 3           3          7  3     3.82  4.53  7.17  9.28  12.0  13.0  8.68\n 4           4          7  2.6   3.6   4.71  6.82 10.2   12.4  13.3  8.55\n 5           5          7  3.03  3.83  4.61  6.95  9.95  12.4  13.1  8.61\n 6           6          7  2.75  4.25  4.82  7.32 10.1   12    13.1  8.61\n 7           7          7 NA     4.42  5.1   7.76 10.3   12.4  13.4  9.01\n 8           8          7 NA     5.06  5.35  7.41  9.02  11.1  13.3  8.95\n 9           9          7 NA    NA     5.7   7.41 10.7   12.6  13.4  9.03\n10          10          7 NA    NA     6.74  9.45 13.5   15.0  15.9 10.0 \n# ℹ 8 more variables: episode...11 &lt;dbl&gt;, period...12 &lt;dbl&gt;, `9` &lt;dbl&gt;,\n#   `10` &lt;dbl&gt;, `11` &lt;dbl&gt;, `12` &lt;dbl&gt;, `13` &lt;dbl&gt;, `14` &lt;dbl&gt;\n\n\nSolve it by removing the episode/period\n\nseasoncols_ratings2b = tidy_ratings2b %&gt;%\n  pivot_wider(names_from = series, \n              values_from = viewers, \n              names_prefix = \"s\") %&gt;%\n  select(-c(episode, period))\n\nseasoncols_ratings2 %&gt;%\n  bind_cols(seasoncols_ratings2b)\n\n# A tibble: 10 × 16\n   episode period    s1    s2    s3    s4    s5    s6    s7    s8    s9   s10\n     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1       1      7  2.24  3.1   3.85  6.6   8.51  11.6  13.6  9.46  9.55  9.62\n 2       2      7  3     3.53  4.6   6.65  8.79  11.6  13.4  9.23  9.31  9.38\n 3       3      7  3     3.82  4.53  7.17  9.28  12.0  13.0  8.68  8.91  8.94\n 4       4      7  2.6   3.6   4.71  6.82 10.2   12.4  13.3  8.55  8.88  8.96\n 5       5      7  3.03  3.83  4.61  6.95  9.95  12.4  13.1  8.61  8.67  9.26\n 6       6      7  2.75  4.25  4.82  7.32 10.1   12    13.1  8.61  8.91  8.7 \n 7       7      7 NA     4.42  5.1   7.76 10.3   12.4  13.4  9.01  9.22  8.98\n 8       8      7 NA     5.06  5.35  7.41  9.02  11.1  13.3  8.95  9.69  9.19\n 9       9      7 NA    NA     5.7   7.41 10.7   12.6  13.4  9.03  9.5   9.34\n10      10      7 NA    NA     6.74  9.45 13.5   15.0  15.9 10.0  10.3  10.0 \n# ℹ 4 more variables: s11 &lt;dbl&gt;, s12 &lt;dbl&gt;, s13 &lt;dbl&gt;, s14 &lt;dbl&gt;\n\n\nStop here and let Amanda know you’ve finished"
  },
  {
    "objectID": "activities/04-customizing-plots.html",
    "href": "activities/04-customizing-plots.html",
    "title": "Customizing plots",
    "section": "",
    "text": "Note: This code reads the same dataset in that we used last time and then creates two new columns based on an old one. Make sure to run this chunk before trying to make your graph!\n\nseason_summary = readr::read_csv(\"https://math.carleton.edu/aluby/stat220/survivor_season_summary.csv\") |&gt;\n  separate(timeslot, into = c(\"day_of_week\", \"time\"))\n\nRows: 47 Columns: 30\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (13): version, version_season, season_name, location, country, tribe_se...\ndbl  (13): season, n_cast, n_tribes, n_finalists, n_jury, viewers_reunion, v...\ndate  (4): premiered, ended, filming_started, filming_ended\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: Expected 2 pieces. Additional pieces discarded in 42 rows [1, 2, 3, 4, 5, 6, 7,\n8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]."
  },
  {
    "objectID": "activities/04-customizing-plots.html#load-data",
    "href": "activities/04-customizing-plots.html#load-data",
    "title": "Customizing plots",
    "section": "",
    "text": "Note: This code reads the same dataset in that we used last time and then creates two new columns based on an old one. Make sure to run this chunk before trying to make your graph!\n\nseason_summary = readr::read_csv(\"https://math.carleton.edu/aluby/stat220/survivor_season_summary.csv\") |&gt;\n  separate(timeslot, into = c(\"day_of_week\", \"time\"))\n\nRows: 47 Columns: 30\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (13): version, version_season, season_name, location, country, tribe_se...\ndbl  (13): season, n_cast, n_tribes, n_finalists, n_jury, viewers_reunion, v...\ndate  (4): premiered, ended, filming_started, filming_ended\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: Expected 2 pieces. Additional pieces discarded in 42 rows [1, 2, 3, 4, 5, 6, 7,\n8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]."
  },
  {
    "objectID": "activities/04-customizing-plots.html#make-histogram",
    "href": "activities/04-customizing-plots.html#make-histogram",
    "title": "Customizing plots",
    "section": "Make histogram",
    "text": "Make histogram\n\n# Include your code here"
  },
  {
    "objectID": "activities/11-import-solutions.html",
    "href": "activities/11-import-solutions.html",
    "title": "Data import and dates/times – Solutions",
    "section": "",
    "text": "Click the “code” button above to copy and paste the source code, or pull a fresh version of the “activities” repo from GitHub.\nWarm Up\nUse read_csv() to import the desserts data set from\nhttps://stat220-w25.github.io/data/desserts.csv\n\ndesserts &lt;- read_csv(here::here(here::here(), \"data/desserts.csv\"))\n\nYour turn\nUse the appropriate read_&lt;type&gt;() function to import the following data sets:\n\nhttps://stat220-w25.github.io/data/data-4.csv\nhttps:/stat220-w25.github.io/data/tricky-1.csv\nhttps://stat220-w25.github.io/data/tricky-2.csv\n\nIf you hit any errors/problems, be sure to explore them and identify the issue, even if you can’t “fix” it.\ndata-4.csv\nOpening the URL for data-4.csv you see that the delimiter is |, so you should use read_delim():\n\ndata4 &lt;- read_delim(here::here(here::here(),\"data/data-4.csv\"), delim = \"|\")\n\ntricky-1.csv\nAt first glance it isn’t obvious what is tricky about tricky-1.csv; however, if you try to use read_csv() you’ll hit the following problem:\n\ntricky1 &lt;- read_csv(\"https:/stat220-w25.github.io/data/tricky-1.csv\")\nproblems(tricky1)\n\nThe output of problems() here is that in rows 4 and 7 read_csv only finds 4 columns, but 5 are expected. Looking at the imported data set we see that the city is missing in rows three and 6 (the 4th and 7th rows of the original data file).\n\ntricky1\n\nWe can fix this with post processing:\n\ntricky1[3, ] &lt;- c(tricky1[3, 1:2], NA, tricky1[3, 3:4])\ntricky1[6, ] &lt;- c(tricky1[4, 1], NA, tricky1[4, 3:5])\n\ntricky-2.csv\nTo begin, we can attempt to read in the tricky-2.csv file:\n\ntricky2 &lt;- read_csv(here::here(here::here(),\"data/tricky-2.csv\"))\nproblems(tricky2)\n\nThis looks like a missing value problem again! Let’s look at the rows with missing values:\n\ntricky2 %&gt;% slice(8:21)\n\nWhy are there state abbreviations in the latitude column?!? (Because not all the rows put quotes around the “City, State” so it added an extra column!)\nOne solution is to parse the file in pieces. First, we can import the first 7 rows of the file:\n\ntricky2_part1 &lt;- read_csv(\n  \"https://aloy.rbind.io/data/tricky-2.csv\",\n  n_max = 7\n)\n\nNext, we parse the other rows, and manually specify the column names, since we are skipping the first row:\n\ntricky2_part2 &lt;- read_csv(\n  \"https://aloy.rbind.io/data/tricky-2.csv\",\n  skip = 8, \n  col_names = c(\"iata\", \"airport\", \"city\", \"state\",  \"latitude\", \"longitude\")\n)\n\nNow, we have to use some data wrangling skills to combine everything. First, we must create a state column in tricky2_part1\n\ntricky2_part1 &lt;- tricky2_part1 %&gt;%\n  separate(city, into = c(\"city\", \"state\"), sep = \",\")\n\nThen, we need to bind the two sets of rows together using bind_rows():\n\ntricky2 &lt;- bind_rows(tricky2_part1, tricky2_part2)\n\nTime – plot\nDays – make a list of class days\nStart by printing the dates only\nNext, print them in the format “Week 4 Wednesday: Jan 29 2025”"
  },
  {
    "objectID": "computing/git-stat220.html",
    "href": "computing/git-stat220.html",
    "title": "GitHub Classroom Guide for Stat 220",
    "section": "",
    "text": "Jump to… Individual assignments | Group work | Additional resources\nThis is a guide for students to setup Git and GitHub for use in Stat 220.\nIf you are using the maize RStudio server, then you can connect to GitHub without any extra software downloads. If you are using RStudio on your computer, then you will need to download Git software (as directed in Computing Access) to use GitHub connected projects.\nI will host all of our course materials on GitHub, and you will use GitHub to submit homework and collaborate on projects.",
    "crumbs": [
      "Computing",
      "Git/Github in Stat 220"
    ]
  },
  {
    "objectID": "computing/git-stat220.html#getting-setup-with-git-and-github",
    "href": "computing/git-stat220.html#getting-setup-with-git-and-github",
    "title": "GitHub Classroom Guide for Stat 220",
    "section": "Getting setup with Git and GitHub",
    "text": "Getting setup with Git and GitHub\nIf you are not working on the maize RStudio server, then make sure that you have installed all of the software mentioned in Computing Access. In addition, you should install the usethis and gitcreds R packages.\nEveryone needs to connect Git and GitHub by doing the following:\n\nRegister for account on GitHub (https://github.com/). I recommend using a username that incorporates your name (e.g. aluby). Please use your Carleton email with this account (you can connect multiple emails to a single GitHub account)\n\nSetup options in Git by running the following code chunk in your console:\nlibrary(usethis)\nuse_git_config(user.name = \"Jane Doe\", user.email = \"jane@example.org\")\nchanging the first two lines to your own name and email (this should be the email associated with your GitHub account).\n\n\nIn order to commit and push to GitHub via R, you need to create a PAT (Personal Access Token). This is like a Password 2.0. When RStudio prompts you for your GitHub username and password, use your PAT instead.\n\nComplete the steps in Happy Git with R Ch 9.3 to get a personal access token. I recommend using the “classic” token, but either should work. You will need workflow, user, and repo scopes (permissions) for this class, and I recommend setting it for 90 days so you won’t need a new one through the end of the term. Make sure to save this somewhere safe!\n\n\nIt will be annoying to type your PAT in anytime you want to push to github. Instead, tell R to store your git credentials. First, save your name and email:\n\nuse_git_config(user.name = \"Jane Doe\", user.email = \"jane@example.org\")\nThen, run the following command:\ngitcreds::gitcreds_set()\nWhen prompted for your password, use your PAT from Step 3.\n&gt; gitcreds::gitcreds_set()\n\n? Enter password or token: ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n-&gt; Adding new credentials...\n-&gt; Removing credentials from cache...\n-&gt; Done.\nTo see if things are set up correctly, run\nusethis::git_sitrep()\nand one of the results should be something like the following:\n── GitHub user \n• Default GitHub host: \"https://github.com\"\n• Personal access token for \"https://github.com\": &lt;discovered&gt;\n• GitHub user: \"aluby\"\n• Token scopes: \"admin:org\", \"repo\", \"user\", and \"workflow\"\n• Email(s): \"aluby@carleton.edu\"\nif instead of &lt;discovered&gt; you see &lt;unset&gt;, you may need to enter your PAT again. (I have no idea why it sometimes needs it twice)",
    "crumbs": [
      "Computing",
      "Git/Github in Stat 220"
    ]
  },
  {
    "objectID": "computing/git-stat220.html#individual-assignments",
    "href": "computing/git-stat220.html#individual-assignments",
    "title": "GitHub Classroom Guide for Stat 220",
    "section": "Individual assignments",
    "text": "Individual assignments\nIf you followed the suggestions in the Using Rstudio in Stat 220 page, then you should already have an assignments folder on your computer or maize account.\nEach new assignment/project will be posted as a repository on GitHub and added directly to your account (within the Stat220 organization). This repository will contain assignment details (README, .Rmd).\nCreating an individual assignment repo and project\n\nGo to our course GitHub organization page and find your homework repo, such as hw-1-username (where your username is attached).\nEnter the online assignment repository on GitHub. Click the green “Code” button. Most of you should just use the default setting which is to “clone” (copy) using HTTPS. Click the clipboard to the right of the URL to copy the repo location. (If you are using SSH, make sure it says “Clone with SSH” in bold in the top left of the pop-up box. If not, click the “SSH” button and copy the link in the box to your clipboard.)\nNow open up RStudio and create a project as follows:\n\n\nClick the Project button in the upper right corner of your RStudio window and select New Project….\n\n \n\n\n\n\n\n\n\n\n\nSelect Version Control and then New Project\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaste the link you just copied into the Repository URL box. Leave the Project directory name blank (or keep the auto-filled name). Use the Browse button to find your assignments folder, then click Create Project\n\n\n\n\n\n\n\n\n\n\n   \nWarning: If you received an error in the above steps, you may have to clone with HTTPS instead of SSH (or vice versa). You can do this by again clicking on the “Clone or Download” button in the repository page, then clicking “Use HTTPS” in the top right of the pop-up box. Now copy the link and repeat this step.\nWorking on your assignment\nAn RStudio project should now open, which will allow you to start working on your homework assignment. You should see the project assignment name in the top right side of Rstudio. You will probably see a blank console screen when you open a new project. Look in the Files tab for your homework .Rmd file. Click on whatever file you want to edit (probably the .Rmd file) and edit away. Make sure that your current assignment’s project is the one open and showing in the upper rightproject name. To open a project, click on the .Rproj file or use the Open Project… option available in the upper right project link.\nCommits\nAfter you make changes to the homework assignment, commit them. What are commits you ask? Commits are essentially taking a snapshot of your projects. Commits save this snapshot to your local version of Git (located on your hard drive or the maize server). For example, if I make changes to a code so that it prints “Hello world”, and then commit them with an informative message, I can look at the history of my commits and view the code that I wrote at that time. If I made some more changes to the function that resulted in an error, I could go back to the commit where the code was originally working. This prevents you from creating several versions of your homework (homework-v1, homework-v2, …) or from trying to remember what your code originally looked like.\nYou can make commits in the Git tab in RStudio.\n\n\n\n\n\n\n\n\nClick the Commit button in the Git tab. Check the boxes of the files that you want to commit, enter your commit message (briefly state what changes have been made), then hit Commit. You can read how to do this in RStudio in more detail here: http://r-pkgs.had.co.nz/git.html#git-commit.\nTwo things about committing.\n\nYou should commit somewhat frequently. At minimum, if you’re doing a homework assignment, you should make a commit each time that you’ve finished a question.\nLeave informative commit messages. “Added stuff” will not help you if you’re looking at your commit history in a year. A message like “Added initial version of hello-world function” will be more useful.\nPushing changes to Github\nAt some point you’ll want to get the updated version of the assignment back onto GitHub, either so that we can help you with your code or so that it can be graded. You will also want to push work frequently when you have a shared GitHub repo for project collaborations (i.e. more than one person is working on a project and code). If you are ready to push, you can again click on the “Up” Push arrow in the Git tab or in the Commit pop-up window or in the Git tab (shown above).\nTo “turn in” an assignment, all you need to do is push all your relevant files to Github by the deadline.",
    "crumbs": [
      "Computing",
      "Git/Github in Stat 220"
    ]
  },
  {
    "objectID": "computing/git-stat220.html#group-work",
    "href": "computing/git-stat220.html#group-work",
    "title": "GitHub Classroom Guide for Stat 220",
    "section": "Group work",
    "text": "Group work\nCollaborative Github assignments are pretty similar to individual assignments.\nCreating a group/partner assignment repo and project\nGo to our course GitHub organization page and find the repo for your group, for example if your group name is “team01” the you might find the mp1-team01 repo. Clone this repo to your computer/maize account using the same steps done for an individual assignment (see steps 2-3).\nWorking with collaborative repos\nFor group homework, I suggest that only the recorder edit the group-homework-x.Rmd file to avoid merge conflicts! Other group members can create a new Markdown doc to run and save commands. Only the recorder needs to push changes (answers) to the Github repo and all others can then pull these changes (i.e. the final answers) after the HW is submitted.\nWhen you are working together on a Github project, you should commit and push your modifications frequently. You will also need to frequently pull updates from Github down to your local version of RStudio. These updates are changes that your teammates have made since your last pull. To pull in changes, click the “Down” Pull arrow in the Git tab (shown above).\nIf you get an error about conflict after pulling or pushing, don’t freak out! This can happen if you edit a file (usually an .Rmd or .R file) in a location that was also changed by a teammate. When this happens you should attempt to fix the merge conflict. Take a look at this resource site and try to fix the merge conflict in Rstudio. If that doesn’t work contact me!",
    "crumbs": [
      "Computing",
      "Git/Github in Stat 220"
    ]
  },
  {
    "objectID": "computing/git-stat220.html#additional-resources",
    "href": "computing/git-stat220.html#additional-resources",
    "title": "GitHub Classroom Guide for Stat 220",
    "section": "Additional resources",
    "text": "Additional resources\n\nHappy Git and GitHub for the useR\nRstudio, Git and GitHub\nInteractive learning guide for Git\nGitHub Guides\nGit setup for Windows (video)\nGit setup for Mac (video)\nHow to clone, edit, and push homework assignments with GitHub Classroom (video)\n\n\nAcknowledgements\nMost of this content in this guide was taken from https://github.com/jfiksel/github-classroom-for-students and edited by Adam Loy for our classroom use. and is licensed under the CC BY-NC 3.0 Creative Commons License.",
    "crumbs": [
      "Computing",
      "Git/Github in Stat 220"
    ]
  },
  {
    "objectID": "computing/computing-access.html",
    "href": "computing/computing-access.html",
    "title": "Computing Access",
    "section": "",
    "text": "I expect you to use RStudio to run R in this course. You have two options for using RStudio:\n\nWe have a Carleton server hosting Rstudio at https://maize.mathcs.carleton.edu/. Your files on this account will be accessible as long as you are a student at Carleton. Use your Carleton credentials to access your account and you need to be running the Carleton VPN (below) to access this server. Use this option if\n\nyour personal computer is old and/or slow\nyou prefer to use school computers (lab or library computers)\n\nYou can also run R/RStudio from your personal computer. If you use a local version of R/RStudio this term, make sure that you have recently updated both R and RStudio.\nTo check your version of R, run the command getRversion() and compare your version to the newest version posted on https://cran.r-project.org/. If you need an update, then install the newer version using the installation directions above.\nIn RStudio, check for updates with the menu option Help &gt; Check for updates. Follow directions if an update is needed.\nFor a fresh download:\n\nDownload the latest version of R for your operating system from https://cran.r-project.org/\nDownload the free RStudio desktop version from https://posit.co/download/rstudio-desktop/\n\nUse the default download and install options for each. For R, download the “precompiled binary” distribution rather than the source code.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing/computing-access.html#rrstudio",
    "href": "computing/computing-access.html#rrstudio",
    "title": "Computing Access",
    "section": "",
    "text": "I expect you to use RStudio to run R in this course. You have two options for using RStudio:\n\nWe have a Carleton server hosting Rstudio at https://maize.mathcs.carleton.edu/. Your files on this account will be accessible as long as you are a student at Carleton. Use your Carleton credentials to access your account and you need to be running the Carleton VPN (below) to access this server. Use this option if\n\nyour personal computer is old and/or slow\nyou prefer to use school computers (lab or library computers)\n\nYou can also run R/RStudio from your personal computer. If you use a local version of R/RStudio this term, make sure that you have recently updated both R and RStudio.\nTo check your version of R, run the command getRversion() and compare your version to the newest version posted on https://cran.r-project.org/. If you need an update, then install the newer version using the installation directions above.\nIn RStudio, check for updates with the menu option Help &gt; Check for updates. Follow directions if an update is needed.\nFor a fresh download:\n\nDownload the latest version of R for your operating system from https://cran.r-project.org/\nDownload the free RStudio desktop version from https://posit.co/download/rstudio-desktop/\n\nUse the default download and install options for each. For R, download the “precompiled binary” distribution rather than the source code.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing/computing-access.html#vpn",
    "href": "computing/computing-access.html#vpn",
    "title": "Computing Access",
    "section": "VPN",
    "text": "VPN\nIf you plan to use the maize server and you plan to do any work off campus this term (e.g., while on a field trip, travel for athletics, or just sitting in Little Joy) you need to install Carleton’s VPN to have access.\nTo install the GlobalProtect VPN follow directions provided by ITS.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing/computing-access.html#git-and-github",
    "href": "computing/computing-access.html#git-and-github",
    "title": "Computing Access",
    "section": "Git and GitHub",
    "text": "Git and GitHub\nGit is version control software that you install locally on your computer. Git is already installed on the maize RStudio server.\nGithub is a cloud-based service for hosting git projects. It allows multiple users to share and contribute to projects and it is how you will be submitting homework assignments and projects for this class. More information about Github for this class is found on Moodle.\nIf you are using a local install of R/RStudio, then you will need to install Git.\nInstalling Git\nDirections for both Windows & Mac here at http://happygitwithr.com/install-git.html.\n\nIf you are using maize, then there is nothing you need to install.\nWindows users should follow Option 1 in 6.2.\nMac users can follow Option 1 in 6.3 if comfortable, otherwise follow Option 2\nLinux users can follow 6.4.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing/computing-access.html#latex",
    "href": "computing/computing-access.html#latex",
    "title": "Computing Access",
    "section": "LaTeX",
    "text": "LaTeX\nYou need a LaTeX compiler to create a pdf document from a R Markdown file. If you use the maize server, you don’t need to install anything (the server already has a LaTeX compiler). If you are using a local RStudio, you should install a Latex compiler.\nInstalling LaTeX (not needed if you are using the maize server)\nIf you don’t already have a tex package installed on your computer, the easiest option to create pdf’s is to use the tinytex R package. This can be installed with the following R commands:\n\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()  # install TinyTeX\n\nIf you’d like a stand alone LaTeX package, you could install the basic installations of either:\n\nMacTeX for Mac (3.2GB!)\nMiKTeX for Windows (190MB)\n\n\nAcknowledgements\nThis installation guide was written by Adam Loy and is based on the guide from stat545.com and is licensed under the CC BY-NC 3.0 Creative Commons License.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing/r-basics-refresher.html",
    "href": "computing/r-basics-refresher.html",
    "title": "R Basics",
    "section": "",
    "text": "In your previous statistics course at Carleton, you likely loaded at least one add-on R package. In this course, we’ll use a lot of tools found in the tidyverse of R packages. To load many of these packages at once, you can use the library(&lt;package_name&gt;) command. So to load the tidyverse we run:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\nNote\n\n\n\nAbove we see a lot of extra info printed when we load the tidyverse. These messages are just telling you what packages are now available to you and warning you that a few functions (e.g., filter) has been replaced by the tidyverse version. We’ll see how to suppress these messages later."
  },
  {
    "objectID": "computing/r-basics-refresher.html#loading-r-packages",
    "href": "computing/r-basics-refresher.html#loading-r-packages",
    "title": "R Basics",
    "section": "",
    "text": "In your previous statistics course at Carleton, you likely loaded at least one add-on R package. In this course, we’ll use a lot of tools found in the tidyverse of R packages. To load many of these packages at once, you can use the library(&lt;package_name&gt;) command. So to load the tidyverse we run:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\nNote\n\n\n\nAbove we see a lot of extra info printed when we load the tidyverse. These messages are just telling you what packages are now available to you and warning you that a few functions (e.g., filter) has been replaced by the tidyverse version. We’ll see how to suppress these messages later."
  },
  {
    "objectID": "computing/r-basics-refresher.html#creating-and-naming-objects",
    "href": "computing/r-basics-refresher.html#creating-and-naming-objects",
    "title": "R Basics",
    "section": "Creating and naming objects",
    "text": "Creating and naming objects\nAll R statements where you create objects have the form:\n\nobject_name &lt;- value\n\nAt first, we’ll be creating a lot of data objects. For example, we an load a data set containing the ratings for each episode of The Office using the code\n\noffice_ratings &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-17/office_ratings.csv\")\n\nIn this class you will be creating a lot of objects, so you’ll need to come up with names for those objects. Trying to think of informative/meaningful names for objects is hard, but necessary work! Below are the fundamental rules for naming objects in R:\n\nnames can’t start with a number\nnames are case-sensitive\nsome common letters are used internally by R and should be avoided as variable names (c, q, t, C, D, F, T, I)\nThere are reserved words that R won’t let you use for variable names (for, in, while, if, else, repeat, break, next)\nR will let you use the name of a predefined function—but don’t do it!\n\nYou can always check to see if you the name you want to use is already taken via exists():\nFor example lm exists\n\nexists(\"lm\")\n\n[1] TRUE\n\n\nbut carleton_college doesn’t.\n\nexists(\"carleton_college\")\n\n[1] FALSE\n\n\nThere are also a lot of naming styles out there, and if you have coded in another language, you may have already developed a preference. Below is an illustration by Allison Horst\n\n\n\n\n\n\n\n\nI generally following the tidyverse style guide, so you’ll see that I use only lowercase letters, numbers, and _ (snake case)."
  },
  {
    "objectID": "computing/r-basics-refresher.html#overviews-of-data-frames",
    "href": "computing/r-basics-refresher.html#overviews-of-data-frames",
    "title": "R Basics",
    "section": "Overviews of data frames",
    "text": "Overviews of data frames\nAbove, you loaded in a data set called office_ratings. Data sets are stored as a special data structure called a data frame. Data frames are the most-commonly used data structure for data analysis in R. For now, think of them like spreadsheets.\nOnce you have your data frame, you can get a quick overview of it using a few commands (below I use data_set as a generic placeholder for the data frame’s name):\n\n\n\n\n\n\nCommand\nDescription\n\n\n\nhead(data_set)\nprint the first 6 rows\n\n\ntail(data_set)\nprint the last 6 rows\n\n\nglimpse(data_set)\na quick overview where columns run down the screen and the data values run across. This allows you to see every column in the data frame.\n\n\nstr(data_set)\na quick overview like glimpse(), but without some of the formatting\n\n\nsummary(data_set)\nquick summary statistics for each column\n\n\ndim(data_set)\nthe number of rows and columns\n\n\nnrow(data_set)\nthe number of rows\n\n\nncol(data_set)\nthe number of columns"
  },
  {
    "objectID": "computing/r-basics-refresher.html#tibbles",
    "href": "computing/r-basics-refresher.html#tibbles",
    "title": "R Basics",
    "section": "Tibbles",
    "text": "Tibbles\nA tibble, or a tbl_df is another version of a data frame which is used by default in a lot of the tidyverse packages that we’ll use.\n\nTibbles are data.frames that are lazy and surly: they do less (i.e. they don’t change variable names or types, and don’t do partial matching) and complain more (e.g. when a variable does not exist). This forces you to confront problems earlier, typically leading to cleaner, more expressive code. Tibbles also have an enhanced print() method which makes them easier to use with large datasets containing complex objects.\n\n\n\n\n\n\n\n Check point\n\n\n\nRun the above commands on the office_ratings data set. Compare and contrast the information returned by each command.\n\n\n\n\n\n\n\n\nGetting a spreadsheet\n\n\n\nIn RStudio, you can run the command View(data_set) to pull up a spreadsheet representation of a data frame. You can also click on the name of the data frame in the Environment pane. This can be a great way help you think about the data, and even has some interactive functions (e.g., filtering and searching); however, never include View(data_set) in an .Rmd file!!\n\n\n\n\n\n\n\n\nReview from intro stats\n\n\n\nIn intro stats we used the terms cases (or observations) and variables to describe the rows and columns of a data frame, respectively."
  },
  {
    "objectID": "computing/r-basics-refresher.html#extracting-pieces-of-data-frames",
    "href": "computing/r-basics-refresher.html#extracting-pieces-of-data-frames",
    "title": "R Basics",
    "section": "Extracting pieces of data frames",
    "text": "Extracting pieces of data frames\nSince data frames are the fundamental data structure for most analyses in R, it’s important to know how to work with them. You already know how to get an overview of a data frame, but that isn’t always very informative. Often, you want to extract pieces of a data frame, such as a specific column or row.\nExtracting rows\nData frames can be indexed by their row/column numbers. To extract elements of a data frame, the basic syntax is data_set[row.index, column.index]. So, to extract the 10th row of office_ratings we run\n\noffice_ratings[10, ]\n\n# A tibble: 1 × 6\n  season episode title    imdb_rating total_votes air_date  \n   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n1      2       4 The Fire         8.4        2713 2005-10-11\n\n\nNotice that to extract an entire row, we leave the column index position blank.\nWe can also extract multiple rows by creating a vector of row indices. For example, we can extract the first 5 rows via\n\noffice_ratings[1:5, ]\n\n# A tibble: 5 × 6\n  season episode title         imdb_rating total_votes air_date  \n   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n1      1       1 Pilot                 7.6        3706 2005-03-24\n2      1       2 Diversity Day         8.3        3566 2005-03-29\n3      1       3 Health Care           7.9        2983 2005-04-05\n4      1       4 The Alliance          8.1        2886 2005-04-12\n5      1       5 Basketball            8.4        3179 2005-04-19\n\n\nHere, 1:5 create a sequence of integers from 1 to 5.\nWe could also specify arbitrary row index values by combing the values into a vector. For example, we could extract the 1st, 13th, 64th, and 128th rows via\n\noffice_ratings[c(1, 13, 64, 128), ]\n\n# A tibble: 4 × 6\n  season episode title            imdb_rating total_votes air_date  \n   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n1      1       1 Pilot                    7.6        3706 2005-03-24\n2      2       7 The Client               8.6        2631 2005-11-08\n3      4      13 Job Fair                 7.9        1977 2008-05-08\n4      7      11 Classy Christmas         8.9        2138 2010-12-09\n\n\nExtracting columns\nSimilar to extracting rows, we can use a numeric index to extract the columns of a data frame. For example, to extract the 3rd column, we can run\n\noffice_ratings[,3]\n\n# A tibble: 188 × 1\n   title            \n   &lt;chr&gt;            \n 1 Pilot            \n 2 Diversity Day    \n 3 Health Care      \n 4 The Alliance     \n 5 Basketball       \n 6 Hot Girl         \n 7 The Dundies      \n 8 Sexual Harassment\n 9 Office Olympics  \n10 The Fire         \n# ℹ 178 more rows\n\n\nAlternatively, we can pass in the column name in quotes instead of the column number\n\noffice_ratings[,\"title\"]\n\n# A tibble: 188 × 1\n   title            \n   &lt;chr&gt;            \n 1 Pilot            \n 2 Diversity Day    \n 3 Health Care      \n 4 The Alliance     \n 5 Basketball       \n 6 Hot Girl         \n 7 The Dundies      \n 8 Sexual Harassment\n 9 Office Olympics  \n10 The Fire         \n# ℹ 178 more rows\n\n\nNotice that the extracted column is still formatted as a data frame (or tibble). If you want to extract the contents of the column and just have a vector of titles, you have a few options.\n\nYou could use double brackets with the column number:\n\n\noffice_ratings[[3]]\n\n\nYou could use double brackets with the column name in quotes:\n\n\noffice_ratings[[\"title\"]]\n\n\nYou could use the $ extractor with the column name (not in quotes):\n\n\noffice_ratings$title\n\n\n\n\n\n\n\n Check point\n\n\n\n\nExtract the 35th row of office_ratings.\nExtract rows 35, 36, 37, and 38 of office_ratings.\nExtract the imdb_rating column from office ratings using the column index number.\nExtract the imdb_rating column from office ratings using the column name."
  },
  {
    "objectID": "computing/r-basics-refresher.html#lists",
    "href": "computing/r-basics-refresher.html#lists",
    "title": "R Basics",
    "section": "Lists",
    "text": "Lists\nIt turns out that data frames are special cases of lists, a more general data structure. In a data frame, each column is an element of the data list and each column must be of the same length. In general, lists can be comprised of elements of vastly different lengths and data types.\nAs an example, let’s construct a list of the faculty in the MAST department and what is being taught this winter.\n\nstat_faculty &lt;- c(\"Kelling\", \"Loy\", \"Luby\", \"Poppick\", \"St. Clair\", \"Wadsworth\")\nstat_courses &lt;- c(120, 220, 230, 250, 285, 330)\nmath_faculty &lt;- c(\"Brooke\", \"Davis\", \"Egge\", \"Gomez-Gonzales\", \"Haunsperger\", \"Johnson\", \n                  \"Meyer\", \"Montee\", \"Shrestha\",\"Terry\", \"Thompson\", \"Turnage-Butterbaugh\")\nmath_courses &lt;- c(101, 106, 111, 120, 210, 211, 232, 236, 240, 241, 251, 321, 333, 395)\n\nmast &lt;- list(stat_faculty = stat_faculty, stat_courses = stat_courses, \n             math_faculty = math_faculty, math_courses = math_courses)\n\nOverview of a list\nYou can get an overview of a list a few ways:\n\n\nglimpse(list_name) and str(list_name) list the elements of the list and the first few entries of each element.\n\n\nglimpse(mast)\n\nList of 4\n $ stat_faculty: chr [1:6] \"Kelling\" \"Loy\" \"Luby\" \"Poppick\" ...\n $ stat_courses: num [1:6] 120 220 230 250 285 330\n $ math_faculty: chr [1:12] \"Brooke\" \"Davis\" \"Egge\" \"Gomez-Gonzales\" ...\n $ math_courses: num [1:14] 101 106 111 120 210 211 232 236 240 241 ...\n\n\n\n\nlength(list_name) will tell you how many elements are in the list\n\n\nlength(mast)\n\n[1] 4\n\n\nExtracting elements of a list\nSince data frames are lists, you’ve already seen how to extract elements of a list. For example, to extract the stat_faculty you could run\n\nmast[[1]]\n\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n\nor\n\nmast[[\"stat_faculty\"]]\n\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you had only used a single bracket above, the returned object would still be a list, which is typically not what we would want.\n\nmast[1]\n\n$stat_faculty\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n\n\n\n\n\n\n\n\n\n Check point\n\n\n\nExtract the statistics courses offered this term."
  },
  {
    "objectID": "computing/r-basics-refresher.html#vectors",
    "href": "computing/r-basics-refresher.html#vectors",
    "title": "R Basics",
    "section": "Vectors",
    "text": "Vectors\nThe columns of the office_ratings data frame and the elements of the mast list were comprised of (atomic) vectors. Unlike lists, all elements within a vector share the same type. For example, all names in the stat_faculty vector were character strings and all ratings in the imdb_rating column were numeric. We’ll deal with a variety of types of vectors in this course, including:\n\nnumeric\ncharacter (text)\nlogical (TRUE/FALSE)\n\nExtracting elements of a vector\nJust like with lists (and therefore data frames), we use brackets to extract elements from a vector. As an example, let’s work with the title column from office_ratings.\n\ntitle &lt;- office_ratings$title # vector of titles\n\nTo extract the 111th title, we run\n\ntitle[111]\n\n[1] \"New Leads\"\n\n\nor two extract the 100th through 111th titles, we run\n\ntitle[100:111]\n\n [1] \"Double Date\"          \"Murder\"               \"Shareholder Meeting\" \n [4] \"Scott's Tots\"         \"Secret Santa\"         \"The Banker\"          \n [7] \"Sabre\"                \"Manager and Salesman\" \"The Delivery: Part 1\"\n[10] \"The Delivery: Part 2\" \"St. Patrick's Day\"    \"New Leads\"           \n\n\nNegative indices\nSometimes, we want to “kick out” elements of our vector. To do this, we can use a negative index value. For example,\n\ntitle[-1]\n\nreturns all but the first title—that is, it kicks out the first title. To kick out multiple elements, we need to negate a vector of indices. For example, below we kick out the first 10 titles\n\ntitle[-c(1:10)]\n\nAnd now we kick out the 5th, 50th, and 150th titles\n\ntitle[-c(5, 50, 150)]\n\nThis idea can be adapted to lists and data frames. For example, to kick out the first row of office_ratings, we run\n\noffice_ratings[-1,]\n\n# A tibble: 187 × 6\n   season episode title             imdb_rating total_votes air_date  \n    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n 1      1       2 Diversity Day             8.3        3566 2005-03-29\n 2      1       3 Health Care               7.9        2983 2005-04-05\n 3      1       4 The Alliance              8.1        2886 2005-04-12\n 4      1       5 Basketball                8.4        3179 2005-04-19\n 5      1       6 Hot Girl                  7.8        2852 2005-04-26\n 6      2       1 The Dundies               8.7        3213 2005-09-20\n 7      2       2 Sexual Harassment         8.2        2736 2005-09-27\n 8      2       3 Office Olympics           8.4        2742 2005-10-04\n 9      2       4 The Fire                  8.4        2713 2005-10-11\n10      2       5 Halloween                 8.2        2561 2005-10-18\n# ℹ 177 more rows\n\n\nor to kick out the math courses from the mast list we run\n\nmast[-4]\n\n$stat_faculty\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n$stat_courses\n[1] 120 220 230 250 285 330\n\n$math_faculty\n [1] \"Brooke\"              \"Davis\"               \"Egge\"               \n [4] \"Gomez-Gonzales\"      \"Haunsperger\"         \"Johnson\"            \n [7] \"Meyer\"               \"Montee\"              \"Shrestha\"           \n[10] \"Terry\"               \"Thompson\"            \"Turnage-Butterbaugh\"\n\n\nLogical indices\nIt’s great to be able to extract (or omit) elements using indices, but sometimes we don’t know what index value we should use. For example, if you wanted to extract all of the 300-level statistics courses from the stat_courses vector, you would need to manually determine that positions 2:5 meet that requirement. That’s a lot of work! A better alternative is to allow R to find the elements meeting that requirement using logical operators. Below is a table summarizing common logical operators in R.\n\n\nComparison\nMeaning\n\n\n\n&lt;\nless than\n\n\n&gt;\ngreater than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;=\ngreater than or equal to\n\n\n==\nis equal to\n\n\n!=\nnot equal to\n\n\n\nIn order to extract the 300-level statistics courses, we’ll take two steps:\n\nWe’ll determine whether each course is numbered at least 300,\nthen we’ll use that sequence of TRUEs/FALSEs to extract the course.\n\nSo, first we use the logical operator &gt;= to compare stat_courses and 300. This returns TRUE if the element meets the specification and FALSE otherwise.\n\nstat_courses &gt;= 300\n\n[1] FALSE FALSE FALSE FALSE FALSE  TRUE\n\n\nNow, we can use this vector as our index. Only the TRUE elements will be extracted:\n\nstat_courses[stat_courses &gt;= 300]\n\n[1] 330\n\n\nThe same idea can be used with data frames and lists, just remember how to format the brackets and indices!\n\n\n\n\n\n\n Check point\n\n\n\n\nExtract all statistics courses below 250 from stat_courses.\nExtract all math courses except for 240 (probability) from math_courses.\nExtract all rows from season 3 of The Office.\n\n\n\ns"
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Public Syllabus",
    "section": "",
    "text": "Note: This is a partial syllabus designed to be public-facing. Carleton students should see the version on Moodle for all course details.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#meetings",
    "href": "course-syllabus.html#meetings",
    "title": "Public Syllabus",
    "section": "Meetings",
    "text": "Meetings\nThere will be three course meetings per week (Mondays, Wednesdays, and Fridays). Daily attendance and active participation is expected. Course meetings will combine demonstrations/lecture and in-class group exercises. On most days, I’ll ask you to complete a reading or watch a short video before class.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#assignments",
    "href": "course-syllabus.html#assignments",
    "title": "Public Syllabus",
    "section": "Assignments",
    "text": "Assignments\nHomework will be assigned once-ish per week, distributed via GitHub. You will submit homework assignments via gradescope. You will use quarto for all assignments and submit all necessary work for each assignment on GitHub.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#portfolio-projects",
    "href": "course-syllabus.html#portfolio-projects",
    "title": "Public Syllabus",
    "section": "Portfolio Projects",
    "text": "Portfolio Projects\nPortfolio project require you to integrate several smaller computational tasks and require clear communication of the proposed solution or findings to a broader audience. You will typically work in pairs or triples.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#lab-quizzes",
    "href": "course-syllabus.html#lab-quizzes",
    "title": "Public Syllabus",
    "section": "Lab Quizzes",
    "text": "Lab Quizzes\nPart of being proficient in data science is being able to do basic data analysis “on the fly”, without access to class resources. There will be 3 short (~30 minute) in-class lab quizzes to assess your ability to do basic tasks in R. I recognize that “in the real world”, you will almost always have access to your resources, so you will also have 48 hours to re-submit.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#final-project",
    "href": "course-syllabus.html#final-project",
    "title": "Public Syllabus",
    "section": "Final Project",
    "text": "Final Project\nThe final project is a capstone experience synthesizing everything you’ve learned over the course of the term. This is an opportunity for you to exercise your creativity and create something meaningful. The final project is wildly open-ended and more details will follow.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#communication",
    "href": "course-syllabus.html#communication",
    "title": "Public Syllabus",
    "section": "Communication",
    "text": "Communication\nAssignments and slides will be shared publicly on our course website. Grades will be posted on Moodle. Please use our github discussion page for any homework or course content questions; email me privately with any personal matters (grade discussions, illness, emergency, etc.). Any time-sensitive announcements will be sent via email. It is your responsibility to make sure that your notification settings allow time-sensitive announcements to reach you.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#textbook",
    "href": "course-syllabus.html#textbook",
    "title": "Public Syllabus",
    "section": "Textbook",
    "text": "Textbook\nThere is no “perfect” data science textbook. We will use excerpts from the following texts:\n\nR for Data Science 2e\nModern Data Science with R 3e\nFundamentals of Data Visualization\n\nThese books are all freely available online. If you prefer a hard copy, they are also available for purchase through the publisher.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#software",
    "href": "course-syllabus.html#software",
    "title": "Public Syllabus",
    "section": "Software",
    "text": "Software\nThe use of the R programming language, with the RStudio interface is an essential component of this course.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  }
]