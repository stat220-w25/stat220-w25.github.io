[
  {
    "objectID": "lab-quiz/lab-quiz-03.html",
    "href": "lab-quiz/lab-quiz-03.html",
    "title": "Lab Quiz 03 Info",
    "section": "",
    "text": "Our third lab quiz is scheduled for Friday of Week 7. The first half of class will cover new content, and the second half of class you will complete the in-person portion of the lab quiz. The format of this lab quiz will remain the same as Lab Quiz 2."
  },
  {
    "objectID": "lab-quiz/lab-quiz-03.html#strings",
    "href": "lab-quiz/lab-quiz-03.html#strings",
    "title": "Lab Quiz 03 Info",
    "section": "Strings",
    "text": "Strings\n\nGiven a string, subset some portion of it\n\n\nstr_sub, str_subset, str_extract,\n\n\nGiven two strings, use str_c to concatenate them\nGiven a simple regular expression, state what will be matched\n\nLiteral characters, special characters (\\\\d, \\\\w, [:alpha:], \\\\n, \\\\), anchors for start/end characters (^ and $), quantifiers (+, *, {n}, {n,}, {n,m})"
  },
  {
    "objectID": "lab-quiz/lab-quiz-03.html#functions",
    "href": "lab-quiz/lab-quiz-03.html#functions",
    "title": "Lab Quiz 03 Info",
    "section": "Functions",
    "text": "Functions\n\nUse function() to build an R function\nSpecify required arguments and default values\nUnderstand how to return a value or object\nUse a logical statement to control the flow of the function"
  },
  {
    "objectID": "lab-quiz/lab-quiz-03.html#iteration",
    "href": "lab-quiz/lab-quiz-03.html#iteration",
    "title": "Lab Quiz 03 Info",
    "section": "Iteration",
    "text": "Iteration\n\nBe able to write a for loop to accomplish an iterative task\n\nPreallocate storage\nDefine an index to iterate through\n\n\nBe able to read a for loop and determine what it’s doing\nUse across() and where() to apply {dplyr} functions to columns in a dataset\nExplain what a map command is doing\nWrite a basic map command for group-wise data operations"
  },
  {
    "objectID": "lab-quiz/lab-quiz-03.html#resubmission",
    "href": "lab-quiz/lab-quiz-03.html#resubmission",
    "title": "Lab Quiz 03 Info",
    "section": "Resubmission",
    "text": "Resubmission\nYou may resubmit the lab quiz by 11am on Sunday (48 hours). Resubmissions will be submitted through Gradescope."
  },
  {
    "objectID": "lab-quiz/lab-quiz-03.html#rules",
    "href": "lab-quiz/lab-quiz-03.html#rules",
    "title": "Lab Quiz 03 Info",
    "section": "Rules",
    "text": "Rules\n\nYour solutions must be written up in the R Markdown (Rmd) file called lab-quiz-03.Rmd. This file must include your code and write up for each task. Your “submission” will be whatever is in your exam repository at the deadline. Commit and push the Rmd and outputs of that file.\nThis exam is limited notes, closed internet, closed other people.\n\nYou have until 10:45am to complete this exam and turn it in via your personal Github repo - late work will not be accepted. Technical difficulties are not an excuse for late work - do not wait until the last minute to knit / commit / push.\n\nIf you do have technical issues, you will be able to solve them for the resubmission, but if you do not turn in the in-class portion you will not receive any points\n\nExample: I run into a knitting issue and don’t leave myself time to commit to github, so I’m not able to turn anything in for the in-class portion. I work hard over the weekend to make sure everything is correct for the resubmission. I earn 0/10 on the in-class and 10/10 on the resubmission, so my score for the lab quiz is 10/20.\nExample: I run into a knitting issue 2 minutes before the deadline, but make sure to commit my .rmd and submit to gradescope before trying to solve the issue. I fix the knitting issue over over the weekend, and also find an error in one of my problems I submitted. I earn 8/10 on the in-class (1 unsuccessful problem + no output file) and 10/10 on the resubmission, so my score for the lab quiz is 18/20.\n\n\n\n\nEven if the answer seems obvious from the R output, make sure to state it in your narrative as well. For example, if the question is asking what is 2 + 2, and you have the code in your document, you should additionally have a sentence that states “2 + 2 is 4.”\nYou may only use the packages provided in the initial .rmd file for this assignment. Your solutions may not use any other R packages."
  },
  {
    "objectID": "lab-quiz/lab-quiz-03.html#data",
    "href": "lab-quiz/lab-quiz-03.html#data",
    "title": "Lab Quiz 03 Info",
    "section": "Data",
    "text": "Data\nThe nycflights23 package contains information about all flights that departed from NYC (e.g. EWR, JFK and LGA) in 2023. The main data is in the flights data frame, but there are additional data sets which may help understand what causes delays, specifically:\n\n\nweather: hourly meteorological data for each airport\n\nplanes: construction information about each plane\n\nairports: airport names and locations\n\nairlines: translation between two letter carrier codes and names\n\n\nlibrary(tidyverse)\nlibrary(nycflights23)\nq &lt;- 0"
  },
  {
    "objectID": "lab-quiz/lab-quiz-03.html#questions",
    "href": "lab-quiz/lab-quiz-03.html#questions",
    "title": "Lab Quiz 03 Info",
    "section": "Questions",
    "text": "Questions\nQuestion 1\nOne of the columns in the airport dataset is the name of the airport. Most airports with international flights have the word “International” in them. Create a new logical column called international based on whether the name of the airport contains the word “international”.\nQuestion 2\n\nairport_names &lt;- airports$name\n\nYour output document should print the words, don’t use the viewer to show them. For example, if I was looking for every word in the words vector that contained a “q”, my output would look like:\n [1] \"equal\"    \"quality\"  \"quarter\"  \"question\" \"quick\"    \"quid\"     \"quiet\"   \n [8] \"quite\"    \"require\"  \"square\"  \na\nFind all airport names that contain a “Z”\nb\nFind all airport names that start with the word “Red”\nc\nFind all airport names that contain a period (.)\nQuestion 3\nUse across to find the minimum and maximum for each of the quantitative columns in airports.\nQuestion 4\na\nGive a 1 sentence description of what the following function does.\n\nmy_function = function(x){\n  flights |&gt;\n    filter(dest == x) |&gt;\n    count() |&gt;\n    pull(n)\n}\n\nb\nEdit this function so that the default value of x is “MSP”.\nQuestion 5\nThe following code chunk creates a vector of some airports in Minnesota.\n\nmn_airports = c(\"Bemidji Regional Airport\", \n                \"Brainerd Lakes Regional Airport\", \n                \"Duluth International Airport\", \n                \"Ely Municipal Airport\", \n                \"Redwood Falls Municipal Airport\", \n                \"Rochester International Airport\", \n                \"Thief River Falls Regional Airport\",\n                \"Minneapolis-St Paul International/Wold-Chamberlain Airport\")\n\n\nWhat is the purpose of results = numeric(length(mn_airports)) in the code chunk below?\nWhat does seq_along(mn_airports) do?\nWhat is saved in the x object?\nWhat is saved in the results object?\n\n\nresults = numeric(length(mn_airports))\n\nfor(k in seq_along(mn_airports)){\n  x &lt;- airports |&gt;\n    filter(name == mn_airports[k]) |&gt;\n    pull(faa)\n  \n  results[k] = my_function(x)\n}\n\nresults\n\n[1]    0    0    0    0    0    0    0 5938\n\n\nQuestion 6\nI’m attempting to use a map solution instead of my for loop above. Does the map code below accomplish the task? If yes, explain how you can tell. If no, explain what you think the issue is.\n\nmap(mn_airports, my_function)\n\n[[1]]\n[1] 0\n\n[[2]]\n[1] 0\n\n[[3]]\n[1] 0\n\n[[4]]\n[1] 0\n\n[[5]]\n[1] 0\n\n[[6]]\n[1] 0\n\n[[7]]\n[1] 0\n\n[[8]]\n[1] 0"
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html",
    "href": "lab-quiz/lab-quiz-01.html",
    "title": "Lab Quiz 01 Info",
    "section": "",
    "text": "Our first lab quiz is scheduled for Friday of Week 3. The first half of class will cover new content, and the second half of class you will complete the in-person portion of the lab quiz."
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#r-basics",
    "href": "lab-quiz/lab-quiz-01.html#r-basics",
    "title": "Lab Quiz 01 Info",
    "section": "R Basics",
    "text": "R Basics\n\nGiven a vector, list, or data frame, extract an element of interest.\n\nKnow how to use each extractor (x$__, x[__], x[[__]]) and what they return\nConstruct logical vectors to use as an index to subset a vector or data frame\nConstruct integer vectors to use as an index to subset a vector or data frame\n\n\nGiven a vector, list, or data frame, obtain a quick summary such as the length, dimension, or type of each element\n\nFunctions to know: length(), nrow(), ncol(), dim(), summary(), glimpse(), class(), typeof(), head(), tail()."
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#data-visualization",
    "href": "lab-quiz/lab-quiz-01.html#data-visualization",
    "title": "Lab Quiz 01 Info",
    "section": "Data Visualization",
    "text": "Data Visualization\n\nIdentify the appropriate layer to add to a static graphic in order to display specific information\n\nYou should know the geom (and associated aesthetics) for the following charts: bar/column chart, histograms, boxplots, density plots, violin plots, scatterplots, time series line plots, map, chloropleth map\n\n\nGiven a graphical summary and data set, recreate the graphic\n\nbase layers\naxis labels, titles, captions\n\nscale_x functions for aesthetics\n\nfacet_wrap() and facet_grid()\n\n\n\nGiven a question of interest and data set, construct an appropriate graphic to address/answer the question\n\nYou should know when the graphs mentioned above are appropriate\n\n\nGiven a graphic, describe the strengths and weaknesses of it from a design perspective\n\nCore principles:\nAccessibility considerations: color, alt text, …."
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#data-wrangling",
    "href": "lab-quiz/lab-quiz-01.html#data-wrangling",
    "title": "Lab Quiz 01 Info",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nKnow how the following verbs act on a data set: filter, distinct, slice, slice_min, slice_max, mutate, select, arrange\n\nSyntax for using\nDescribe what the output would look like\n\n\nGiven a data set and goal, identify and utilize the appropriate verb to create the data set of interest"
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#resubmission",
    "href": "lab-quiz/lab-quiz-01.html#resubmission",
    "title": "Lab Quiz 01 Info",
    "section": "Resubmission",
    "text": "Resubmission\nYou may resubmit the lab quiz by 11am on Sunday (48 hours). All questions and grading will remain the same, except I will look at your output file instead of your .rmd when grading."
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#rules",
    "href": "lab-quiz/lab-quiz-01.html#rules",
    "title": "Lab Quiz 01 Info",
    "section": "Rules",
    "text": "Rules\n\nYour solutions must be written up in the R Markdown (Rmd) file called lab-quiz-01.Rmd. This file must include your code and write up for each task. Your “submission” will be whatever is in your exam repository at the deadline. Commit and push the Rmd and outputs of that file.\nThis exam is closed notes, closed internet, closed other people.\n\nYou have until 10:45am to complete this exam and turn it in via gradescope and your personal Github repo - late work will not be accepted. Technical difficulties are not an excuse for late work - do not wait until the last minute to knit / commit / push.\n\nIf you do have technical issues, you will be able to solve them for the resubmission, but if you do not turn in the in-class portion you will not receive any points\n\nExample: I run into a knitting issue and don’t leave myself time to commit to github and submit to gradescope, so I’m not able to turn anything in for the in-class portion. I work hard over the weekend to make sure everything is correct for the resubmission. I earn 0/10 on the in-class and 10/10 on the resubmission, so my score for the lab quiz is 10/20.\nExample: I run into a knitting issue 2 minutes before the deadline, but make sure to commit my .rmd and submit to gradescope before trying to solve the issue. I fix the knitting issue over over the weekend, and also find an error in one of my problems I submitted. I earn 8/10 on the in-class (1 unsuccessful problem + no output file) and 10/10 on the resubmission, so my score for the lab quiz is 18/20.\n\n\n\n\nEven if the answer seems obvious from the R output, make sure to state it in your narrative as well. For example, if the question is asking what is 2 + 2, and you have the code in your document, you should additionally have a sentence that states “2 + 2 is 4.”\nYou may only use tidyverse and nycflights13 (and its dependencies) for this assignment. Your solutions may not use any other R packages."
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#data",
    "href": "lab-quiz/lab-quiz-01.html#data",
    "title": "Lab Quiz 01 Info",
    "section": "Data",
    "text": "Data\nThe nycflights23 package contains information about all flights that departed from NYC (e.g. EWR, JFK and LGA) in 2023. The main data is in the flights data frame, but there are additional data sets which may help understand what causes delays, specifically:\n\n\nweather: hourly meteorological data for each airport\n\nplanes: construction information about each plane\n\nairports: airport names and locations\n\nairlines: translation between two letter carrier codes and names\n\nFor this lab quiz, we’re going to work with a random sample of this data (called `flights_sampl)\n\nlibrary(tidyverse)\nlibrary(nycflights23)\nq &lt;- 0"
  },
  {
    "objectID": "lab-quiz/lab-quiz-01.html#questions",
    "href": "lab-quiz/lab-quiz-01.html#questions",
    "title": "Lab Quiz 01 Info",
    "section": "Questions",
    "text": "Questions\nQuestion 1\nWrite out two different ways to access the dep_delay variable in the flights dataset. Save each to an object called dep_delay1 and dep_delay2.\nQuestion 2\nThe code below creates a new dataset called delayed_flights, which consists of all flights that had a departure delay of more than 5 minutes. Show me a second way to create this dataset. (One option is to create a logical vector, and then index the flights data using that vector)\n\ndelayed_flights = flights %&gt;%\n  filter(dep_delay &gt; 5)\n\nQuestion 3\nIs there a relationship between departure delay (among flights that departed at least 5 minutes late) and which NYC airport the flight departed from? Create an appropriate visualization to answer this question. (use the delayed_flights dataset)\nQuestion 4\nRecreate the plot included below using the flights data. Once you have created the visualization, in no more than one paragraph, describe what you think the point of this visualization might be.\n\n\nWarning: Removed 12534 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nQuestion 5\nIs this a chloropleth map? Explain how you can tell.\n\nQuestion 6\nIn the map above, what is the geom(s) used? What about the aesthetics?"
  },
  {
    "objectID": "carleton-only-syllabus.html",
    "href": "carleton-only-syllabus.html",
    "title": "Stat 220: Introduction to Data Science",
    "section": "",
    "text": "Meetings\nMWF 3a\n9:50-11 MW | 9:40-10:40 F\nCMC 102\n\n\nProfessor\nAmanda Luby\nCMC 223\n\n\n\naluby@carleton.edu\n\n\n\nOffice Hours\nMon 11-12 | Tues 2-3 | Wed 4-5 | Fri 11-12 (appt)\nBy appt through my Google Calendar\nCMC 307\n\n\nWebsite\ngithub.com/stat220-w25\n\n\n\nTexts\nR for Data Science (2nd Ed)\nhttps://r4ds.hadley.nz/\nWickham, Çetinkaya-Rundel, Grolemund\n\n\n\n\nModern Data Science with R (3rd Ed)\nhttps://mdsr-book.github.io/mdsr3e/\nBaumer, Kaplan, Horton\n\n\n\n\nFundamentals of Data Visualization\nhttps://clauswilke.com/dataviz/\nWilke\n\n\n\nSoftware\nMaize RStudio Server maize.mathcs.carleton.edu\n\n\n\n\nR (optional) free from r-project.org\n\n\n\n\nRStudio (optional) free from rstudio.com/downloads"
  },
  {
    "objectID": "carleton-only-syllabus.html#meetings",
    "href": "carleton-only-syllabus.html#meetings",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Meetings",
    "text": "Meetings\nThere will be three course meetings per week (Mondays, Wednesdays, and Fridays). Daily attendance and active participation is expected. Course meetings will combine demonstrations/lecture and in-class group exercises. On most days, I’ll ask you to complete a reading or watch a short video before class."
  },
  {
    "objectID": "carleton-only-syllabus.html#assignments",
    "href": "carleton-only-syllabus.html#assignments",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Assignments",
    "text": "Assignments\nHomework will be assigned once-ish per week, distributed via GitHub. You will submit homework assignments via gradescope. You will use quarto for all assignments and submit all necessary work for each assignment on GitHub."
  },
  {
    "objectID": "carleton-only-syllabus.html#portfolio-projects",
    "href": "carleton-only-syllabus.html#portfolio-projects",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Portfolio Projects",
    "text": "Portfolio Projects\nPortfolio project require you to integrate several smaller computational tasks and require clear communication of the proposed solution or findings to a broader audience. You will typically work in pairs or triples."
  },
  {
    "objectID": "carleton-only-syllabus.html#lab-quizzes",
    "href": "carleton-only-syllabus.html#lab-quizzes",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Lab Quizzes",
    "text": "Lab Quizzes\nPart of being proficient in data science is being able to do basic data analysis “on the fly”, without access to class resources. There will be 3 short (~30 minute) in-class lab quizzes to assess your ability to do basic tasks in R. I recognize that “in the real world”, you will almost always have access to your resources, so you will also have 48 hours to re-submit."
  },
  {
    "objectID": "carleton-only-syllabus.html#final-project",
    "href": "carleton-only-syllabus.html#final-project",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Final Project",
    "text": "Final Project\nThe final project is a capstone experience synthesizing everything you’ve learned over the course of the term. This is an opportunity for you to exercise your creativity and create something meaningful. The final project is wildly open-ended and more details will follow."
  },
  {
    "objectID": "carleton-only-syllabus.html#communication",
    "href": "carleton-only-syllabus.html#communication",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Communication",
    "text": "Communication\nAssignments and slides will be shared publicly on our course website. Grades will be posted on Moodle. Please use our github discussion page for any homework or course content questions; email me privately with any personal matters (grade discussions, illness, emergency, etc.). Any time-sensitive announcements will be sent via email. It is your responsibility to make sure that your notification settings allow time-sensitive announcements to reach you."
  },
  {
    "objectID": "carleton-only-syllabus.html#how-each-assignment-is-graded",
    "href": "carleton-only-syllabus.html#how-each-assignment-is-graded",
    "title": "Stat 220: Introduction to Data Science",
    "section": "How each assignment is graded",
    "text": "How each assignment is graded\nEach assignment will include a short rubric with the specifications of how I will evaluate your work. In general, these are the “marks” that you can receive on each course component:\n\n\n\n\n\n\n\n\n\nHow it’s evaluated\nHow it’s recorded\n\n\n\n\nHomework Problems\nCompleteness, Correctness, and Effort\nSuccessful or Not Successful\n\n\nLab Quiz Problems\nCompleteness and Correctness\nSuccessful or Not Successful\n\n\nPortfolio Projects\nCompleteness, effort, correctness, and communication quality\nExcellent, Successful, or Retry\n\n\nFinal Project\nCompleteness, effort, correctness, and communication quality\nExcellent, Succesful, or Not Successful"
  },
  {
    "objectID": "carleton-only-syllabus.html#earning-a-course-grade",
    "href": "carleton-only-syllabus.html#earning-a-course-grade",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Earning a course grade",
    "text": "Earning a course grade\nYour course grade is assigned using the table below. Each row indicates the minimum percentage of “Successful” results needed to satisfy the requirement of that grade. To earn a grade, complete all requirements listed in the row for that grade.\n\n\n\n\n\n\n\n\n\n\n\nHomework Problems\nLab Quiz Problems\nPortfolio Projects (4 total)\nFinal Project\n\n\n\n\nA\n85%\n90%\n2 Excellent\nExcellent\n\n\nB\n75%\n80%\n4 Successful\nSuccessful\n\n\nC\n65%\n70%\n3 Successful\nSuccessful\n\n\nD\n55%\n50%\n2 Successful\nSuccessful\n\n\n\nExample: Ben finishes the course with 82% of homework problems successfully completed, 85% of lab quiz problems successfully completed, 2/4 portfolio projects marked “excellent”, and a “Successful” final project. Ben satisfies everything in the “B” row and earns a “B” in the course."
  },
  {
    "objectID": "carleton-only-syllabus.html#plusminus-grades",
    "href": "carleton-only-syllabus.html#plusminus-grades",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Plus/minus grades",
    "text": "Plus/minus grades\n“Plus” and “minus” grades will be given if you complete all the requirements for a base letter grade and make sufficient progress toward the next grade. Below is an overview:\n\nIf “B” base grade:\n\nand A in two bins: “B+”\nand A in three bins: “A-”\n\nIf “C” base grade:\n\nand at least B in two bins: “C+”\nand at least B in three bins: “B-”\n\nIf “D” base grade:\n\nand at least C in two bins: “D+”\nand at least C in three bins: “C-”\n\nIf “F” base grade:\n\nand at least D in two bins: “D-”\n\n\nExample: Mira finishes the course with 88% of homework problems successfully completed, 85% of lab quiz problems successfully completed, 3/4 portfolio projects marked “excellent”, and a “Successful” final project. Mira satisfies everything in the “B” row, and meets the “A” threshold for two bins (homework and portfolio projects). Mira earns a B+. If Mira instead receives “excellent” marks on the final project, Mira earns an A-."
  },
  {
    "objectID": "carleton-only-syllabus.html#how-lab-quiz-resubmissions-work",
    "href": "carleton-only-syllabus.html#how-lab-quiz-resubmissions-work",
    "title": "Stat 220: Introduction to Data Science",
    "section": "How lab quiz resubmissions work",
    "text": "How lab quiz resubmissions work\nWhen you resubmit a lab quiz, you change the denominator for your quiz bin. Let’s say you earn a successful mark on 7/10 problems on the in-class version and 9/10 on the resubmission. Your ultimate score is (7+9)/(10+10). You are not required to do resubmissions."
  },
  {
    "objectID": "carleton-only-syllabus.html#important-points-about-this-grading-system",
    "href": "carleton-only-syllabus.html#important-points-about-this-grading-system",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Important points about this grading system",
    "text": "Important points about this grading system\n\nDifferent categories of coursework do not “average together”: you can’t make up for less-than-great work on portfolio projects by doing very well on quizzes, for instance. Each course grade requires consistent quality across all bins to earn the grade\nYou do not have to do everything. If you want an “A” in the class, for example, you don’t have to complete every quiz question correctly, only 90% of them."
  },
  {
    "objectID": "carleton-only-syllabus.html#tokens",
    "href": "carleton-only-syllabus.html#tokens",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Tokens",
    "text": "Tokens\n\nTurning in a token provides either (a) a 72-hour extension on a homework assignment, or (b) a revision on a portfolio project\nTokens may be used for extensions on the final project milestone check-ins, but not for the final due-date. Milestone check-ins cannot be revised\nYou may use a token for an extension on the lab quiz resubmission, but not on the in-class portion. You do not need to use a token to resubmit each lab quiz.\nYou can revise the same portfolio project multiple times, if needed, but you must spend a token each time.\nA portfolio project must be completed with a good-faith effort to be eligible for revision. If I deem a submission to be “not assessable” due to a lack of effort, then it cannot be revised.\nAll revisions must be submitted by 11:59pm on the last day of class."
  },
  {
    "objectID": "carleton-only-syllabus.html#textbook",
    "href": "carleton-only-syllabus.html#textbook",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Textbook",
    "text": "Textbook\nThere is no “perfect” data science textbook. We will use excerpts from the following texts:\n\nR for Data Science 2e\nModern Data Science with R 3e\nFundamentals of Data Visualization\n\nThese books are all freely available online. If you prefer a hard copy, they are also available for purchase through the publisher."
  },
  {
    "objectID": "carleton-only-syllabus.html#software",
    "href": "carleton-only-syllabus.html#software",
    "title": "Stat 220: Introduction to Data Science",
    "section": "Software",
    "text": "Software\nThe use of the R programming language, with the RStudio interface is an essential component of this course. You have two options for using RStudio:\n\nThe server version of RStudio on the web at https://maize.mathcs.carleton.edu. The advantage of using the server version is that all of your work will be stored in the cloud, where it is automatically saved and backed up. This means that you can access your work from any computer on campus using a web browser. The downside is that you have to share limited computational resources with each other!\nA local version of RStudio installed on your machine.The downside to this approach is that your work is only stored locally, but I get around this problem by keeping all of my work on GitHub. You will learn how to use GitHub throughout the course.\n\nNote that you do not have to choose one or the other, you may use both. However, it is important that you understand the distinction so that you can keep track of your work. Both R and RStudio are free and open-source."
  },
  {
    "objectID": "computing/computing-cheatsheets.html",
    "href": "computing/computing-cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://posit.co/resources/cheatsheets. We haven’t covered every function and functionality listed on them, but you might still find them useful as references.",
    "crumbs": [
      "Computing",
      "Cheatsheets"
    ]
  },
  {
    "objectID": "computing/rstudio-stat220.html",
    "href": "computing/rstudio-stat220.html",
    "title": "Using RStudio in Stat 220",
    "section": "",
    "text": "There will be a lot of RStudio content thrown your way this term, most in the form of .Rmd (R Markdown) files. To stay organized, I strongly suggest you create a stat220 folder that contains the following subfolders:\nTo get started with this organization, follow the steps below.",
    "crumbs": [
      "Computing",
      "Rstudio in Stat 220"
    ]
  },
  {
    "objectID": "computing/rstudio-stat220.html#file-organization-using-maize",
    "href": "computing/rstudio-stat220.html#file-organization-using-maize",
    "title": "Using RStudio in Stat 220",
    "section": "File organization: Using maize",
    "text": "File organization: Using maize\nThe server (online) version of RStudio is run from a Unix server. You can navigate this file system using Unix commands, but I assume that most or all of you will just use RStudio to access your files on this server.\n1. In RStudio, click the Files tab in the lower right-hand window. Note: this is not the same as the File menu option.\n\n\n\n\n\n\n\n\n2. Verify that you are in your HOME folder (should simply say Home right under the New Folder button). To navigate to your Home folder (if somehow you are not in it), click the … button (far right side of the Files tab) and enter a ~ (tilde) symbol\n\n\n\n\n\n\n\n\n3. Click the New Folder button and name the folder stat220.\n\n\n\n\n\n\n\n\n4. Click on this newly created (empty) stat220 folder. Within the folder create another New Folder and name it assignments.\n\n\n\n\n\n\n\n\n5. Within the stat220 folder, create an RStudio project called content with the following steps:\n\n\na. Click the Project button in the upper right corner of your RStudio window and select New Project….\n\n\n\n\n\n\n\n\n\n\n\nb. Select New Directory and then New Project\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nc. Enter content as the Directory name and use the Browse button to find your stat220 folder. Then click Create Project.\n\n\n\n\n\n\n\n\n\n\n\nd. You should now have a new folder called content in your stat220 folder and this folder will contain an RStudio project .Rproj. Feel free to add subfolders to this content folder (e.g. slides, examples, etc).\n\n\n\n\n\n\n\n\n\nWarning: Do not create an RStudio project in the main stat220 folder because it is not good practice to have RStudio projects in subfolders of another project (e.g. a project within a project is not recommended).",
    "crumbs": [
      "Computing",
      "Rstudio in Stat 220"
    ]
  },
  {
    "objectID": "computing/rstudio-stat220.html#file-organization-using-your-own-rstudio",
    "href": "computing/rstudio-stat220.html#file-organization-using-your-own-rstudio",
    "title": "Using RStudio in Stat 220",
    "section": "File organization: Using your own RStudio",
    "text": "File organization: Using your own RStudio\nCreate a folder called stat220 somewhere on your computer. Within this folder create an assignments subfolder. Then complete step 5 from above to create a content RStudio project folder.",
    "crumbs": [
      "Computing",
      "Rstudio in Stat 220"
    ]
  },
  {
    "objectID": "computing/rstudio-stat220.html#rstudio-projects",
    "href": "computing/rstudio-stat220.html#rstudio-projects",
    "title": "Using RStudio in Stat 220",
    "section": "RStudio projects",
    "text": "RStudio projects\nOnce you’ve created a project, your R session should be running within that project folder. You can check which project you are in by checking the project name in the upper right part of your RStudio window. Here we see the content project is open:\n\n\n\n\n\n\n\n\nRunning R from an RStudio project sets your working directory to the project folder:\n\n\n\n\n\n\n\n\nThis allows for easy file path access to all files related to this project.\nTo start a project, click on the .Rproj file or use the Open Project… option shown in step 5 above.",
    "crumbs": [
      "Computing",
      "Rstudio in Stat 220"
    ]
  },
  {
    "objectID": "computing/rstudio-stat220.html#best-practices-or-what-not-to-do",
    "href": "computing/rstudio-stat220.html#best-practices-or-what-not-to-do",
    "title": "Using RStudio in Stat 220",
    "section": "Best practices (or what not to do)",
    "text": "Best practices (or what not to do)\n\nNever save files to a lab computer hard drive (e.g. desktop, downloads, etc). They will be erased when you log off.\nDo not use gmail as a file storage system! Avoid emailing yourself files that you created (and saved) on a lab computer. Eventually you will lose work this way.\nAvoid using online versions of google drive and dropbox. Similar to gmail, downloading, editing a doc, then uploading it back to drive/dropbox is another great way to lose work.\nAvoid this and this.",
    "crumbs": [
      "Computing",
      "Rstudio in Stat 220"
    ]
  },
  {
    "objectID": "computing/rstudio-stat220.html#acknowledgments",
    "href": "computing/rstudio-stat220.html#acknowledgments",
    "title": "Using RStudio in Stat 220",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis guide is based on the guide from Katie St. Clair and is licensed under the CC BY-NC 3.0 Creative Commons License.",
    "crumbs": [
      "Computing",
      "Rstudio in Stat 220"
    ]
  },
  {
    "objectID": "activities/14-text-case-study.html",
    "href": "activities/14-text-case-study.html",
    "title": "14-text-case-study",
    "section": "",
    "text": "library(tidyverse)\nlibrary(mdsr) # loads data\nlibrary(tidytext) # functions for doing text analysis\n\nLoad the Data\n\nDataSciencePapers &lt;- DataSciencePapers |&gt;\n  mutate(\n    submitted = lubridate::ymd_hms(submitted), \n    updated = lubridate::ymd_hms(updated)\n  )\nglimpse(DataSciencePapers)\n\nRows: 1,089\nColumns: 15\n$ id               &lt;chr&gt; \"astro-ph/0701361v1\", \"0901.2805v1\", \"0901.3118v2\", \"…\n$ submitted        &lt;dttm&gt; 2007-01-12 03:28:11, 2009-01-19 10:38:33, 2009-01-20…\n$ updated          &lt;dttm&gt; 2007-01-12 03:28:11, 2009-01-19 10:38:33, 2009-01-24…\n$ title            &lt;chr&gt; \"How to Make the Dream Come True: The Astronomers' Da…\n$ abstract         &lt;chr&gt; \"  Astronomy is one of the most data-intensive of the…\n$ authors          &lt;chr&gt; \"Ray P Norris\", \"Heinz Andernach\", \"O. V. Verkhodanov…\n$ affiliations     &lt;chr&gt; \"\", \"\", \"Special Astrophysical Observatory, Nizhnij A…\n$ link_abstract    &lt;chr&gt; \"http://arxiv.org/abs/astro-ph/0701361v1\", \"http://ar…\n$ link_pdf         &lt;chr&gt; \"http://arxiv.org/pdf/astro-ph/0701361v1\", \"http://ar…\n$ link_doi         &lt;chr&gt; \"\", \"http://dx.doi.org/10.2481/dsj.8.41\", \"http://dx.…\n$ comment          &lt;chr&gt; \"Submitted to Data Science Journal Presented at CODAT…\n$ journal_ref      &lt;chr&gt; \"\", \"\", \"\", \"\", \"EPJ Data Science, 1:9, 2012\", \"\", \"E…\n$ doi              &lt;chr&gt; \"\", \"10.2481/dsj.8.41\", \"10.2481/dsj.8.34\", \"\", \"10.1…\n$ primary_category &lt;chr&gt; \"astro-ph\", \"astro-ph.IM\", \"astro-ph.IM\", \"astro-ph.I…\n$ categories       &lt;chr&gt; \"astro-ph\", \"astro-ph.IM|astro-ph.CO\", \"astro-ph.IM|a…\n\n\nClean the data\n\nDataSciencePapers = DataSciencePapers |&gt;\n  separate(primary_category, into = c(\"broad\", \"specific\"), sep = \"\\\\.\") |&gt;\n  mutate(\n    year = year(submitted),\n    month = month(submitted, label = TRUE)\n  ) \n\nMost common words\n\nDataSciencePapers |&gt;\n  unnest_tokens(word, abstract) |&gt;\n  anti_join(get_stopwords(source = \"stopwords-iso\"), by = \"word\") %&gt;%\n  group_by(broad) %&gt;%\n  count(word) %&gt;%\n  slice_max(n, n = 15) %&gt;%\n  filter(broad %in% c(\"physics\", \"cs\", \"stat\", \"math\")) %&gt;%\n  ggplot(aes(x = n, y = fct_reorder(word, n))) + \n  geom_col() + \n  facet_wrap(~broad, scales = \"free_y\") + \n  labs(\n    y = \"Word\"\n  )\n\n\n\n\n\n\n\nn-grams\nThe n-grams analysis from the slides uses a “clean” version of the abstracts, which has removed the stopwords. This data is named arxiv_abstracts\n\narxiv_abstracts &lt;- DataSciencePapers |&gt;\n  unnest_tokens(word, abstract) |&gt;\n  anti_join(get_stopwords(source = \"stopwords-iso\"), by = \"word\") |&gt;\n  group_by(id) |&gt;\n  summarize(abstract_clean = paste(word, collapse = \" \"))\n\narxiv_papers &lt;- DataSciencePapers |&gt;\n  left_join(arxiv_abstracts, by = \"id\")\n\n\narxiv_papers |&gt;\n  unnest_tokens(bigram, abstract_clean, token = \"ngrams\", n = 2) |&gt;\n  group_by(broad) %&gt;%\n  count(bigram) %&gt;%\n  slice_max(n, n = 10) %&gt;%\n  filter(broad %in% c(\"physics\", \"cs\", \"stat\", \"math\")) %&gt;%\n  ggplot(aes(x = n, y = fct_reorder(bigram, n))) + \n  geom_col() + \n  facet_wrap(~broad, scales = \"free_y\") + \n  labs(\n    y = \"2-gram\"\n  )"
  },
  {
    "objectID": "activities/07-dplyr1.html",
    "href": "activities/07-dplyr1.html",
    "title": "\ndplyr 1: Verbs",
    "section": "",
    "text": "Click the “code” button above to copy and paste the source code, or pull a fresh version of the “activities” repo from GitHub."
  },
  {
    "objectID": "activities/07-dplyr1.html#part-1",
    "href": "activities/07-dplyr1.html#part-1",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 1",
    "text": "Part 1\n\nFind all flights that had an arrival delay of two or more hours.\nFind all flights to MSP\nFind all flights that arrived more than two hours late, but left less than one hour late\n(if time) Find all flights that were delayed by at least an hour, but made up over 30 minutes in flight"
  },
  {
    "objectID": "activities/07-dplyr1.html#part-2",
    "href": "activities/07-dplyr1.html#part-2",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 2",
    "text": "Part 2\nUse arrange to answer the following questions:\n\nWhich flights traveled the farthest?\nWhich traveled the shortest?\nWhich flights lasted the longest?\nWhich lasted the shortest?"
  },
  {
    "objectID": "activities/07-dplyr1.html#part-3",
    "href": "activities/07-dplyr1.html#part-3",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 3",
    "text": "Part 3\nCreate a new column in flights giving the average speed of the flight while it was in the air. What are the units of this variable? Make the variable in terms of miles per hour."
  },
  {
    "objectID": "activities/07-dplyr1.html#part-5",
    "href": "activities/07-dplyr1.html#part-5",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 5",
    "text": "Part 5\nSuppose that you don’t think the FAA gives enough information in their definition of a delayed flight, so you come up with the following delay categories:\n\n\ndep_delay &lt;= 0 -&gt; none\n\ndep_delay between 1 and 15 minutes -&gt; minimal\n\ndep_delay between 16 and 30 minutes -&gt; delayed\n\ndep_delay between 31 and 60 minutes -&gt; major\n\ndep_delay over 60 minutes -&gt; extreme\n\nUse mutate() and case_when() to create a delay_category variable in the flights data frame.\nand we can check with select():"
  },
  {
    "objectID": "activities/07-dplyr1.html#part-6",
    "href": "activities/07-dplyr1.html#part-6",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 6",
    "text": "Part 6\nChain the last two parts together, so that the resulting dataset contains both avg_speed and delay_category. Pipe this new dataset into ggplot() to answer the question “is there a relationship between average speed and how late a flight is delayed?”\nIf you have time, create a new graph which only contains flights to MSP.\n\n\n\n\n\n\nAdapted from Adam Loy’s materials"
  },
  {
    "objectID": "activities/19-apis.html",
    "href": "activities/19-apis.html",
    "title": "19-apis",
    "section": "",
    "text": "Install tidycensus if not on maize:\n\ninstall.packages(\"tidycensus\")\n\n\nlibrary(tidycensus)\nlibrary(tidyverse)\n\n\n\nacs_mn_2020 &lt;- tidycensus::get_acs(\n    year = 2020,\n    state = \"MN\",\n    geography = \"tract\",\n    variables = c(\"B01003_001\", \"B19013_001\"),\n    output = \"wide\",\n    geometry = TRUE\n)\n\n\n\nCreate a new text file in the same folder as your .rmd\nCopy and paste your census key into the empty file\nSave the file as census_api_key.txt\n\n\n\nmy_key &lt;- readLines(\"census_api_key.txt\")\n\nand tell tidycensus what your API key is with:\n\ncensus_api_key(my_key)\n\nDo not commit and push census_api_key.txt to github\n\n\nSearch for two new variables using load_variables (Can you explain what they are?)\nRun another call to tidycensus::get_acs using your two variables"
  },
  {
    "objectID": "activities/19-apis.html#example-call",
    "href": "activities/19-apis.html#example-call",
    "title": "19-apis",
    "section": "",
    "text": "acs_mn_2020 &lt;- tidycensus::get_acs(\n    year = 2020,\n    state = \"MN\",\n    geography = \"tract\",\n    variables = c(\"B01003_001\", \"B19013_001\"),\n    output = \"wide\",\n    geometry = TRUE\n)"
  },
  {
    "objectID": "activities/19-apis.html#storing-your-api-key",
    "href": "activities/19-apis.html#storing-your-api-key",
    "title": "19-apis",
    "section": "",
    "text": "Create a new text file in the same folder as your .rmd\nCopy and paste your census key into the empty file\nSave the file as census_api_key.txt\n\n\n\nmy_key &lt;- readLines(\"census_api_key.txt\")\n\nand tell tidycensus what your API key is with:\n\ncensus_api_key(my_key)\n\nDo not commit and push census_api_key.txt to github"
  },
  {
    "objectID": "activities/19-apis.html#your-turn",
    "href": "activities/19-apis.html#your-turn",
    "title": "19-apis",
    "section": "",
    "text": "Search for two new variables using load_variables (Can you explain what they are?)\nRun another call to tidycensus::get_acs using your two variables"
  },
  {
    "objectID": "activities/19-apis.html#example-call-1",
    "href": "activities/19-apis.html#example-call-1",
    "title": "19-apis",
    "section": "Example call",
    "text": "Example call\n\nhmong_state_request &lt;- request(\"https://api.census.gov/data\") %&gt;% \n    req_url_path_append(\"2019\") %&gt;% \n    req_url_path_append(\"acs\") %&gt;% \n    req_url_path_append(\"acs1\") %&gt;% \n    req_url_query(get = c(\"NAME\", \"B02015_009E\", \"B02015_009M\"), `for` = I(\"state:*\"), key = census_api_key, .multi = \"comma\")\n\n\nhmong_state_response &lt;- req_perform(hmong_state_request)\n\n\nhmong_state_tbl &lt;- hmong_state_response %&gt;%\n  resp_body_json(simplifyVector = TRUE) %&gt;%\n  janitor::row_to_names(1) %&gt;%\n  as_tibble()\n\nhmong_state_tbl"
  },
  {
    "objectID": "activities/19-apis.html#your-turn-1",
    "href": "activities/19-apis.html#your-turn-1",
    "title": "19-apis",
    "section": "Your Turn",
    "text": "Your Turn\n\nEdit the httr code to access a new variable of your choice\nMake a httr request to access the 1-year ACS data from 2018, 2019, 2021, and 2022. Make sure to save your results from each call!\nCombine all years into a single dataset\nMake a time series plot with your chosen variable on the y-axis, year on the x-axis, colored by state.\n\nYou may want to first filter to only a few states\nYou will need to do some cleaning of the data"
  },
  {
    "objectID": "activities/03-ggplot-intro.html",
    "href": "activities/03-ggplot-intro.html",
    "title": "Intro to ggplot2\n",
    "section": "",
    "text": "Note: the setup chunk includes the line eval = FALSE. Make sure to delete this when you are ready to knit your file.\nThe data we’re using today contains information about all seasons of Survivor and comes from the survivoR R package. In the show, a group of people (called castaways) are placed in an isolated location, where they must provide food, fire, and shelter for themselves. The castaways compete in challenges testing the contestants’ physical abilities like running and swimming or their mental abilities like puzzles and endurance challenges for rewards and immunity from elimination. The castaways are progressively eliminated from the game as they are voted out by their fellow contestants until only two or three remain. At that point, the players who were eliminated (the “jury”) vote for the winner. The winner is given the title of “Sole Survivor” and is awarded the grand prize of $1,000,000\nseason_summary = readr::read_csv(\"https://math.carleton.edu/aluby/stat220/survivor_season_summary.csv\")\n#&gt; Rows: 47 Columns: 30\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr  (13): version, version_season, season_name, location, country, tribe_se...\n#&gt; dbl  (13): season, n_cast, n_tribes, n_finalists, n_jury, viewers_reunion, v...\n#&gt; date  (4): premiered, ended, filming_started, filming_ended\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "activities/03-ggplot-intro.html#round-1-view-the-data-pipes",
    "href": "activities/03-ggplot-intro.html#round-1-view-the-data-pipes",
    "title": "Intro to ggplot2\n",
    "section": "Round 1: View the data + pipes",
    "text": "Round 1: View the data + pipes\n1. To get started, load the tidyverse and and take a glimpse at the dataset. How many rows and columns are there? What does each row represent?\nLoading the tidyverse loads 8 packages, one of which is ggplot2. You can certainly load each package individually, but it has become common to simply load the tidyverse.\n2. The code below filters season_summary to include only survivor seasons that aired in the US. What does |&gt; do? (Try to answer this with your group, then run ?\"|&gt;\" in the console to load the help page if you need to)\n\nseason_summary |&gt;\n  filter(season == \"US\")"
  },
  {
    "objectID": "activities/03-ggplot-intro.html#round-2-scatterplots",
    "href": "activities/03-ggplot-intro.html#round-2-scatterplots",
    "title": "Intro to ggplot2\n",
    "section": "Round 2: Scatterplots",
    "text": "Round 2: Scatterplots\nFirst, let’s create a scatterplot of imdb_mean vs. viewers_mean.\nA note on wording: when we say imdb_mean vs. viewers_mean, this should be interpreted as “variable on the y-axis” vs. “variable on the x-axis”.\n3. Fill in the data and aesthetic mapping in the below code chunk. What is returned? What’s missing?\n\n# Fill in the blanks\nggplot(data = ___, mapping = aes(x = ___, y = ___))\n\n4. Add the appropriate geometric object to create the scatterplot. This is called adding a layer to a plot. Remember to always put the + at the end of a line, never at the start.\n\n# Copy your code from the previous chunk and add a geom\n\nWhat do you notice? Write a sentence or two describing your findings\n5. You must remember to put the aesthetic mappings in the aes() function! What happens if you forget?\n\n# Add a layer and see what happens\nggplot(data = ___, x = ___, y = ___)\n\n6. The aesthetic mappings can be specified in the geom layer if you prefer, instead of the main ggplot() call. Give it a try:\n\n# Rebuild the scatterplot with your aesthetic mapping in the geom layer\nggplot(data = ___)"
  },
  {
    "objectID": "activities/03-ggplot-intro.html#round-3-additional-aesthetics",
    "href": "activities/03-ggplot-intro.html#round-3-additional-aesthetics",
    "title": "Intro to ggplot2\n",
    "section": "Round 3: Additional Aesthetics",
    "text": "Round 3: Additional Aesthetics\nx and y are not the only aesthetic mappings possible. In this section you’ll explore the color, size, shape, and alpha (i.e. transparency) aesthetics.\n7. Create a scatterplot of imdb_mean vs. viewers_mean. Add the color aesthetic to map country2 to the point color.\n\nggplot(data = ___) +\n  geom_point(aes(x = ___, y = ___, color = ___))\n\n8. Create a scatterplot of imdb_mean vs. viewers_mean. Use shape to represent country2. Is this plot easier or harder to interpret than the previous plot?\n9. Create a scatterplot of imdb_mean vs. viewers_mean. Use both shape and color to represent the four_regions. Is this plot easier or harder to interpret than the previous two plots?\n10. Create a scatterplot of imdb_mean vs. viewers_mean. Use color to represent the season. What did you learn from the plot?\n11. Create a scatterplot of imdb_mean vs. viewers_mean. Use size to represent the season.\n12. Look back at your scatterplots from the last few questions. Explain the differences when you map aesthetics to discrete and continuous variables.\n13. Create a scatterplot of imdb_mean vs. viewers_mean. Use alpha to represent the season."
  },
  {
    "objectID": "activities/03-ggplot-intro.html#round-4-visualizing-distributions",
    "href": "activities/03-ggplot-intro.html#round-4-visualizing-distributions",
    "title": "Intro to ggplot2\n",
    "section": "Round 4: Visualizing Distributions",
    "text": "Round 4: Visualizing Distributions\n14. Build a histogram of viewers_mean using geom_histogram(). Don’t hesitate to look at the ggplot2 cheat sheet for help!\n\n# Fill in the blanks\nggplot(___) +\n  geom_histogram(aes(x = ___))\n\nWhat have you learned about the distribution of average viewership?\n15. By default, ggplot2 uses 30 bins. To change the number of bins, to say 15, add the argument bins = 15 to geom_histogram(). Note: this is not an aesthetic mapping.\n\n# Fill in the blanks\nggplot(___) +\n  geom_histogram(aes(x = ___), bins = ___)\n\n16. Instead of a histogram, let’s create a kernel density plot. To do this, substitute geom_density() into your code for question 14.\n17. Now, let’s make side-by-side boxplots of viewers_mean for each country2.\n\n# Fill in the blanks\nggplot(___) +\n  geom_boxplot(aes(x = ___, y = ___))\n\n18. A violin plot is a kernel density on its side, made symmetric. Change your code from question 17 to use geom_violin(). Which plot do you prefer, boxplots or violin plots? Why?\n\n# Put your violin plot code here"
  },
  {
    "objectID": "activities/03-ggplot-intro.html#round-5-bar-and-column-charts-labeling",
    "href": "activities/03-ggplot-intro.html#round-5-bar-and-column-charts-labeling",
    "title": "Intro to ggplot2\n",
    "section": "Round 5: Bar and column charts + Labeling",
    "text": "Round 5: Bar and column charts + Labeling\nHow many seasons were filmed in each country? Let’s find out!\n19. Make a bar chart of the number of seasons filmed in each country2 using geom_bar()\n\n# Fill in the blanks\nggplot(___) +\n  geom_bar(aes(x = ___))\n\n20. country2 has a category called “other”. Make a bar chart of country (which includes all individual countries) instead.\n\n# Fill in the blanks\nggplot(___) +\n  geom_bar(aes(x = ___))\n\n21. When you have lots of categories, it’s sometimes hard to read the labels on the x-axis. One trick is to flip the axes. Change geom_bar() to use the y aesthetic from your code in question 20 instead.\n22. In ggplot2 you can add/change the title, subtitle, caption, and x- and y-axis labels by adding a labs() layer. Below is an example illustrating it’s use. Choose one graph from today and add all labels.\n\nggplot(data = mpg) +\n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  labs(\n    title = \"Put your informative title here\",\n    subtitle = \"and your subtitle here\",\n    x = \"New x label\",\n    y = \"New y label\",\n    caption = \"Put a caption here\"\n  )"
  },
  {
    "objectID": "activities/15-sentiment.html",
    "href": "activities/15-sentiment.html",
    "title": "15-sentiment",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidytext) # functions for doing text analysis"
  },
  {
    "objectID": "activities/15-sentiment.html#bing",
    "href": "activities/15-sentiment.html#bing",
    "title": "15-sentiment",
    "section": "“bing”",
    "text": "“bing”\n\nbing_sentiments = get_sentiments(\"bing\") %&gt;%\n  slice_sample(n = 20)"
  },
  {
    "objectID": "activities/15-sentiment.html#afinn",
    "href": "activities/15-sentiment.html#afinn",
    "title": "15-sentiment",
    "section": "“afinn”",
    "text": "“afinn”\n\nlibrary(textdata)\nget_sentiments(\"afinn\") %&gt;%\n  slice_sample(n = 20)\n\n# A tibble: 20 × 2\n   word       value\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 abducted      -2\n 2 fuckhead      -4\n 3 bliss          3\n 4 hysteria      -3\n 5 mandatory     -1\n 6 violate       -2\n 7 slash         -2\n 8 frowning      -1\n 9 abhorred      -3\n10 threats       -2\n11 promoted       1\n12 agonizing     -3\n13 skeptic       -2\n14 darkest       -2\n15 cleaner        2\n16 obstacle      -2\n17 undecided     -1\n18 obstinate     -2\n19 nasty         -3\n20 conspiracy    -3"
  },
  {
    "objectID": "activities/08-dplyr2.html",
    "href": "activities/08-dplyr2.html",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "",
    "text": "Note: continue using your 07-dplyr.rmd file for this activity. You can copy and paste code chunks using the “code” button above. We will continue to use the nycflights23 dataset."
  },
  {
    "objectID": "activities/08-dplyr2.html#chunk-1",
    "href": "activities/08-dplyr2.html#chunk-1",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "Chunk 1",
    "text": "Chunk 1\n\nlog2(sqrt(16))"
  },
  {
    "objectID": "activities/08-dplyr2.html#chunk-2",
    "href": "activities/08-dplyr2.html#chunk-2",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "Chunk 2:",
    "text": "Chunk 2:\n\nlibrary(nycflights23) # need to load, not in pipeline\nmsp &lt;- filter(flights, dest == \"MSP\", carrier == \"DL\")\nmsp_narrow &lt;- select(msp, year, month, day, starts_with(\"sched\"), \n                     contains(\"delay\"), origin)\nmsp_narrow &lt;- relocate(msp_narrow, origin, everything())"
  },
  {
    "objectID": "activities/08-dplyr2.html#your-turn-from-last-time",
    "href": "activities/08-dplyr2.html#your-turn-from-last-time",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "“Your turn” from last time",
    "text": "“Your turn” from last time\nChain the last two parts together, so that the resulting dataset contains both avg_speed and delay_category. Pipe this new dataset into ggplot() to answer the question “is there a relationship between average speed and how late a flight is delayed?”\nIf you have time, create a new graph which only contains flights to MSP."
  },
  {
    "objectID": "activities/08-dplyr2.html#summarize",
    "href": "activities/08-dplyr2.html#summarize",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "summarize()",
    "text": "summarize()\nUse summarize() to compute statistics about the data:\n\nThe lowest and highest distance traveled\nThe lowest and highest air_time\nThe median dep_delay"
  },
  {
    "objectID": "activities/08-dplyr2.html#summarize-ii",
    "href": "activities/08-dplyr2.html#summarize-ii",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "\nsummarize() II",
    "text": "summarize() II\nExtract the rows for Delta flights. (Hint: look at the airlines dataset, which is also distributed in the {nycflights23} R package, to find the carrier shortcut code)\nThen use summarize() and a summary function to find:\n\nThe number of flights in this subset\nThe median dep_delay. How does it compare to the overall median?"
  },
  {
    "objectID": "activities/08-dplyr2.html#group_by",
    "href": "activities/08-dplyr2.html#group_by",
    "title": "\ndplyr 2: Pipes and Groups",
    "section": "group_by()",
    "text": "group_by()\nUse group_by(), summarize(), and slice_max() to display the five dest airports with the most flights from NYC airports in 2023. Your display should include the median flight delay for these airports."
  },
  {
    "objectID": "activities/13-strings-regex.html",
    "href": "activities/13-strings-regex.html",
    "title": "13: Intro to Strings/Regex",
    "section": "",
    "text": "No code needed, just think about what it returns\n\nFill in the blanks of the .Rmd file to…\n\nIsolate the last letter of every name\nand create a logical variable that displays whether the last letter is one of “a”, “e”, “i”, “o”, “u”, or “y”.\nUse a weighted mean to calculate the proportion of children whose name ends in a vowel, by year (see ?weighted.mean).\nand then display the results as a line plot.\n\n\nbabynames %&gt;%\n  mutate(last = ___, \n         vowel = ___) %&gt;%\n  group_by(___) %&gt;%\n  ___(p_vowel = weighted.mean(vowel, n)) %&gt;%\n  ___ +\n  ___\n\n\nThe below code chunk imports a data set of the 6-credit courses offered at Carleton in Winter 2021. All three columns are character vectors.\n\ncourses &lt;- read_csv(\"https://stat220-w25.github.io/data/winter2023_course_tbl.csv\", col_types = list(course = col_character()))\n\n\nHow many of the course numbers end in .00? Use str_detect() or str_count() to help you answer this question.\nNote that . is a special character in strings, so use \\\\. to get the literal period.\n\nThe section number appears after the decimal point. Use mutate() and str_sub() to create a section column containing this number.\n\nHow many courses contain the word Introduction? Does case matter here?\n\nWhat is the longest course name (in terms of characters)? What is the shortest course name? Use str_length() to help you answer this question.\n\nUse str_subset() to return the course names that contain exclamation points (!)."
  },
  {
    "objectID": "activities/13-strings-regex.html#your-turn-1",
    "href": "activities/13-strings-regex.html#your-turn-1",
    "title": "13: Intro to Strings/Regex",
    "section": "",
    "text": "No code needed, just think about what it returns"
  },
  {
    "objectID": "activities/13-strings-regex.html#your-turn-2",
    "href": "activities/13-strings-regex.html#your-turn-2",
    "title": "13: Intro to Strings/Regex",
    "section": "",
    "text": "Fill in the blanks of the .Rmd file to…\n\nIsolate the last letter of every name\nand create a logical variable that displays whether the last letter is one of “a”, “e”, “i”, “o”, “u”, or “y”.\nUse a weighted mean to calculate the proportion of children whose name ends in a vowel, by year (see ?weighted.mean).\nand then display the results as a line plot.\n\n\nbabynames %&gt;%\n  mutate(last = ___, \n         vowel = ___) %&gt;%\n  group_by(___) %&gt;%\n  ___(p_vowel = weighted.mean(vowel, n)) %&gt;%\n  ___ +\n  ___"
  },
  {
    "objectID": "activities/13-strings-regex.html#example-carleton-courses",
    "href": "activities/13-strings-regex.html#example-carleton-courses",
    "title": "13: Intro to Strings/Regex",
    "section": "",
    "text": "The below code chunk imports a data set of the 6-credit courses offered at Carleton in Winter 2021. All three columns are character vectors.\n\ncourses &lt;- read_csv(\"https://stat220-w25.github.io/data/winter2023_course_tbl.csv\", col_types = list(course = col_character()))\n\n\nHow many of the course numbers end in .00? Use str_detect() or str_count() to help you answer this question.\nNote that . is a special character in strings, so use \\\\. to get the literal period.\n\nThe section number appears after the decimal point. Use mutate() and str_sub() to create a section column containing this number.\n\nHow many courses contain the word Introduction? Does case matter here?\n\nWhat is the longest course name (in terms of characters)? What is the shortest course name? Use str_length() to help you answer this question.\n\nUse str_subset() to return the course names that contain exclamation points (!)."
  },
  {
    "objectID": "activities/13-strings-regex.html#your-turn-1-1",
    "href": "activities/13-strings-regex.html#your-turn-1-1",
    "title": "13: Intro to Strings/Regex",
    "section": "Your turn 1",
    "text": "Your turn 1\nDetect either “.” or “-” in the info vector.\n\na1 &lt;- \"Home: 507-645-5489\"\na2 &lt;- \"Cell: 219.917.9871\"\na3 &lt;- \"My work phone is 507-202-2332\"\na4 &lt;- \"I don't have a phone\"\ninfo &lt;- c(a1, a2, a3, a4)"
  },
  {
    "objectID": "activities/13-strings-regex.html#your-turn-ends-with-a-vowel",
    "href": "activities/13-strings-regex.html#your-turn-ends-with-a-vowel",
    "title": "13: Intro to Strings/Regex",
    "section": "Your turn: ends with a vowel",
    "text": "Your turn: ends with a vowel\nFill in the code to determine how many baby names in 2015 ended with a vowel.\n\nbabynames %&gt;% \n  ___(___ == ___) %&gt;%                       # extract year 2015\n  ___(ends_with_vowel = ___(___, ___)) %&gt;%  # create logical column\n  count(ends_with_vowel)                    # create a frequency table"
  },
  {
    "objectID": "activities/13-strings-regex.html#additional-practice-if-time",
    "href": "activities/13-strings-regex.html#additional-practice-if-time",
    "title": "13: Intro to Strings/Regex",
    "section": "Additional practice (if time)",
    "text": "Additional practice (if time)\nA vector called words is loaded with stringr and contains a corpus of 980 words used in text analysis. Use stringr functions and regular expressions to find the words that satisfy the following descriptions.\n1. Find all words that start with y.\n\npattern &lt;- \"type your pattern here\"\nstr_subset(words, pattern)\n\ncharacter(0)\n\n\n2. Find all words that end with x.\n3. Find all words that are exactly three letters long.\n4. Find all words that start with a vowel.\n5. Find all words that start with consonants.\n7. Find all words that end with ing or ise.\n8. Find all words that have seven letters or more.\n9. Find all words that start with three consonants."
  },
  {
    "objectID": "activities/07-dplyr1-sols.html",
    "href": "activities/07-dplyr1-sols.html",
    "title": "\ndplyr 1: Verbs",
    "section": "",
    "text": "Identify the verb (function) that does the following:\n\nPicks rows by their values\nReorders the rows\nPicks variables by their names\nCreates new variables with functions of existing variables"
  },
  {
    "objectID": "activities/07-dplyr1-sols.html#part-1",
    "href": "activities/07-dplyr1-sols.html#part-1",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 1",
    "text": "Part 1\n\nFind all flights that had an arrival delay of two or more hours.\nFind all flights to MSP\nFind all flights that arrived more than two hours late, but left less than one hour late\n(if time) Find all flights that were delayed by at least an hour, but made up over 30 minutes in flight\n\n\nfilter(flights, dep_delay &gt;= 120)\n\n# A tibble: 15,367 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1        1           2038       203      328              3\n 2  2023     1     1       33           2140       173      238           2352\n 3  2023     1     1       36           2048       228      223           2252\n 4  2023     1     1      831            600       151     1044            838\n 5  2023     1     1      925            700       145     1214           1005\n 6  2023     1     1     1000            700       180     1322           1019\n 7  2023     1     1     1017            817       120     1454           1311\n 8  2023     1     1     1056            700       236     1345           1027\n 9  2023     1     1     1109            735       214     1417           1048\n10  2023     1     1     1110            829       161     1412           1211\n# ℹ 15,357 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\nfilter(flights, dest == \"MSP\")\n\n# A tibble: 5,938 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1      603            605        -2      800            818\n 2  2023     1     1      655            700        -5      841            907\n 3  2023     1     1      657            700        -3      902            927\n 4  2023     1     1      749            750        -1      938           1006\n 5  2023     1     1      951           1000        -9     1159           1237\n 6  2023     1     1     1207           1217       -10     1430           1445\n 7  2023     1     1     1312           1059       133     1518           1319\n 8  2023     1     1     1314           1153        81     1518           1357\n 9  2023     1     1     1506           1500         6     1712           1717\n10  2023     1     1     1513           1512         1     1724           1721\n# ℹ 5,928 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\nfilter(flights, (dep_delay &gt;=120) & (arr_delay &lt; 60))\n\n# A tibble: 5 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2023     4    10     2158           1955       123       12           2316\n2  2023     4    30     2130           1930       120     2358           2259\n3  2023     5     1     1212            955       137     1617           1528\n4  2023     6     1     1201           1000       121     1425           1326\n5  2023     7    26     2135           1929       126       21           2335\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "activities/07-dplyr1-sols.html#part-2",
    "href": "activities/07-dplyr1-sols.html#part-2",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 2",
    "text": "Part 2\nUse arrange to answer the following questions:\n\nWhich flights traveled the farthest?\nWhich traveled the shortest?\nWhich flights lasted the longest?\nWhich lasted the shortest?\n\n\narrange(flights, desc(distance))\n\n# A tibble: 435,352 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1      949            900        49       NA           1525\n 2  2023     1     1     1023           1000        23     1637           1610\n 3  2023     1     2      919            900        19     1543           1525\n 4  2023     1     2      951           1000        -9     1620           1610\n 5  2023     1     3      922            900        22     1535           1525\n 6  2023     1     3     1007           1000         7     1630           1610\n 7  2023     1     4      912            900        12     1511           1525\n 8  2023     1     4     1001           1000         1     1630           1610\n 9  2023     1     5      854            900        -6     1454           1525\n10  2023     1     5      949           1000       -11     1600           1610\n# ℹ 435,342 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\narrange(flights, distance)\n\n# A tibble: 435,352 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1      816            820        -4      910            921\n 2  2023     1     2      820            820         0      907            921\n 3  2023     1     2     2324           2159        85       41           2300\n 4  2023     1     3       14           2158       136      104           2259\n 5  2023     1     3      815            820        -5      913            921\n 6  2023     1     4      756            759        -3      903            900\n 7  2023     1     4     1353           1347         6     1449           1448\n 8  2023     1     5      804            759         5      908            900\n 9  2023     1     5     1346           1347        -1     1444           1447\n10  2023     1     6      817            759        18      926            900\n# ℹ 435,342 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\narrange(flights, desc(air_time))\n\n# A tibble: 435,352 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     3     9     1009           1000         9     1720           1605\n 2  2023     1    10      913            900        13     1615           1525\n 3  2023     3    10      852            900        -8     1616           1537\n 4  2023     3     8      853            900        -7     1608           1525\n 5  2023     1    31      858            900        -2     1627           1525\n 6  2023     4     2     1104           1000        64     1702           1510\n 7  2023     1    28     1121            900       141     1820           1525\n 8  2023     3    23      851            900        -9     1451           1437\n 9  2023     2     4     1005           1000         5     1649           1605\n10  2023     3     7     1345            900       285     2100           1525\n# ℹ 435,342 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\narrange(flights, air_time)\n\n# A tibble: 435,352 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1    12     2151           2155        -4     2247           2256\n 2  2023     1     3     1155           1200        -5     1235           1311\n 3  2023     1    12     1452           1455        -3     1540           1607\n 4  2023     1    15      757            759        -2      839            900\n 5  2023     1    19     1450           1455        -5     1536           1607\n 6  2023     2     5     1422           1430        -8     1511           1538\n 7  2023     3     1     1438           1440        -2     1524           1548\n 8  2023     3    17      825            835       -10      911            945\n 9  2023     4     6     1201           1109        52     1255           1218\n10  2023     6     8     2211           2149        22     2256           2242\n# ℹ 435,342 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "activities/07-dplyr1-sols.html#part-3",
    "href": "activities/07-dplyr1-sols.html#part-3",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 3",
    "text": "Part 3\nCreate a new column in flights giving the average speed of the flight while it was in the air. What are the units of this variable? Make the variable in terms of miles per hour.\n\nmutate(flights, avg_speed = distance/air_time)\n\n# A tibble: 435,352 × 20\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1        1           2038       203      328              3\n 2  2023     1     1       18           2300        78      228            135\n 3  2023     1     1       31           2344        47      500            426\n 4  2023     1     1       33           2140       173      238           2352\n 5  2023     1     1       36           2048       228      223           2252\n 6  2023     1     1      503            500         3      808            815\n 7  2023     1     1      520            510        10      948            949\n 8  2023     1     1      524            530        -6      645            710\n 9  2023     1     1      537            520        17      926            818\n10  2023     1     1      547            545         2      845            852\n# ℹ 435,342 more rows\n# ℹ 12 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, avg_speed &lt;dbl&gt;"
  },
  {
    "objectID": "activities/07-dplyr1-sols.html#part-5",
    "href": "activities/07-dplyr1-sols.html#part-5",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 5",
    "text": "Part 5\nSuppose that you don’t think the FAA gives enough information in their definition of a delayed flight, so you come up with the following delay categories:\n\n\ndep_delay &lt;= 0 -&gt; none\n\ndep_delay between 1 and 15 minutes -&gt; minimal\n\ndep_delay between 16 and 30 minutes -&gt; delayed\n\ndep_delay between 31 and 60 minutes -&gt; major\n\ndep_delay over 60 minutes -&gt; extreme\n\nUse mutate() and case_when() to create a delay_category variable in the flights data frame.\n\nmutate(flights, delay_category = case_when(\n  dep_delay &lt;= 0 ~ \"none\",\n  dep_delay &lt;= 15 ~ \"minimal\",\n  dep_delay &lt;= 30 ~ \"delayed\",\n  dep_delay &lt;= 60 ~ \"major\",\n  dep_delay &gt; 60 ~ \"extreme\"\n))\n\n# A tibble: 435,352 × 20\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1        1           2038       203      328              3\n 2  2023     1     1       18           2300        78      228            135\n 3  2023     1     1       31           2344        47      500            426\n 4  2023     1     1       33           2140       173      238           2352\n 5  2023     1     1       36           2048       228      223           2252\n 6  2023     1     1      503            500         3      808            815\n 7  2023     1     1      520            510        10      948            949\n 8  2023     1     1      524            530        -6      645            710\n 9  2023     1     1      537            520        17      926            818\n10  2023     1     1      547            545         2      845            852\n# ℹ 435,342 more rows\n# ℹ 12 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, delay_category &lt;chr&gt;\n\n\nand we can check with select():\n\nmutate(flights, delay_category = case_when(\n  dep_delay &lt;= 0 ~ \"none\",\n  dep_delay &lt;= 15 ~ \"minimal\",\n  dep_delay &lt;= 30 ~ \"delayed\",\n  dep_delay &lt;= 60 ~ \"major\",\n  dep_delay &gt; 60 ~ \"extreme\"\n)) %&gt;%\n  select(dep_delay, delay_category)\n\n# A tibble: 435,352 × 2\n   dep_delay delay_category\n       &lt;dbl&gt; &lt;chr&gt;         \n 1       203 extreme       \n 2        78 extreme       \n 3        47 major         \n 4       173 extreme       \n 5       228 extreme       \n 6         3 minimal       \n 7        10 minimal       \n 8        -6 none          \n 9        17 delayed       \n10         2 minimal       \n# ℹ 435,342 more rows"
  },
  {
    "objectID": "activities/07-dplyr1-sols.html#part-6",
    "href": "activities/07-dplyr1-sols.html#part-6",
    "title": "\ndplyr 1: Verbs",
    "section": "Part 6",
    "text": "Part 6\nChain the last two parts together, so that the resulting dataset contains both avg_speed and delay_category. Pipe this new dataset into ggplot() to answer the question “is there a relationship between average speed and how late a flight is delayed?”\nIf you have time, create a new graph which only contains flights to MSP.\n\nflights %&gt;%\n  mutate(\n    delay_category = case_when(\n      dep_delay &lt;= 0 ~ \"none\",\n      dep_delay &lt;= 15 ~ \"minimal\",\n      dep_delay &lt;= 30 ~ \"delayed\",\n      dep_delay &lt;= 60 ~ \"major\",\n      dep_delay &gt; 60 ~ \"extreme\"\n    ),\n    avg_speed = distance/air_time\n  ) %&gt;%\n  ggplot(aes(y = delay_category, x = avg_speed, fill = delay_category)) + \n  geom_boxplot() + \n  theme(legend.position = \"none\")\n\nWarning: Removed 12534 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nflights %&gt;%\n  filter(dest == \"MSP\") %&gt;%\n  mutate(\n    delay_category = case_when(\n      dep_delay &lt;= 0 ~ \"none\",\n      dep_delay &lt;= 15 ~ \"minimal\",\n      dep_delay &lt;= 30 ~ \"delayed\",\n      dep_delay &lt;= 60 ~ \"major\",\n      dep_delay &gt; 60 ~ \"extreme\"\n    ),\n    avg_speed = distance/air_time\n  ) %&gt;%\n  ggplot(aes(y = delay_category, x = avg_speed, fill = delay_category)) + \n  geom_boxplot() + \n  theme(legend.position = \"none\")\n\nWarning: Removed 133 rows containing non-finite outside the scale range\n(`stat_boxplot()`)."
  },
  {
    "objectID": "activities/12-factors.html",
    "href": "activities/12-factors.html",
    "title": "12-factors",
    "section": "",
    "text": "gss_cat gets loaded with the forcats package in the tidyverse use gss_cat to answer the following questions (I’d use a graph, but do whatever you’d like!)\n\ngss_cat\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Not str r… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Strong de… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Ind,near … Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n10  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n# ℹ 21,473 more rows\n\n\n\nWhich religions watch the least TV?\nDo married people watch more or less TV than single people?"
  },
  {
    "objectID": "activities/12-factors.html#hotel-bookings-by-month",
    "href": "activities/12-factors.html#hotel-bookings-by-month",
    "title": "12-factors",
    "section": "Hotel bookings by month",
    "text": "Hotel bookings by month\n\n# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md\nhotels &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\", show_col_types = FALSE)\n\n\nRun the code and examine the plot. How are the months ordered? What would be a better order?\n\n\nhotels %&gt;%\n  group_by(hotel, arrival_date_month) %&gt;%   # group by hotel type and arrival month\n  summarize(mean_adr = mean(adr)) %&gt;%       # calculate mean adr for each group\n  ggplot(aes(\n    x = arrival_date_month,                 # x-axis = arrival_date_month\n    y = mean_adr,                           # y-axis = mean_adr calculated above\n    group = hotel,                          # group lines by hotel type\n    color = hotel)                          # and color by hotel type\n    ) +\n  geom_line() +                             # use lines to represent data\n  theme_minimal() +                         # use a minimal theme\n  labs(\n    x = \"Arrival month\",                    # customize labels\n    y = \"Mean ADR (average daily rate)\",\n    title = \"Comparison of resort and city hotel prices across months\",\n    subtitle = \"Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year\",\n    color = \"Hotel type\"\n    )\n\n\n\n\n\n\n\n\nReorder the months on the x-axis (levels of arrival_date_month) in a way that makes more sense. Use a function from the forcats package."
  },
  {
    "objectID": "activities/12-factors.html#more-hotel-bookings-by-room-type",
    "href": "activities/12-factors.html#more-hotel-bookings-by-room-type",
    "title": "12-factors",
    "section": "More hotel bookings by room type",
    "text": "More hotel bookings by room type\n\nCreate a bar chart of the reserved_room_type.\nCreate another bar chart where you have bars for the top three room types and an “other” category lumping the other room types together."
  },
  {
    "objectID": "activities/12-factors.html#more-hotel-bookings-by-room-type-1",
    "href": "activities/12-factors.html#more-hotel-bookings-by-room-type-1",
    "title": "12-factors",
    "section": "More hotel bookings by room type",
    "text": "More hotel bookings by room type\n\nRun the code and examine the plot. How are the months ordered? What would be a better order?\n\n\nhotels %&gt;%\n  group_by(meal, arrival_date_month) %&gt;%   # group by meal type and arrival month\n  summarize(mean_adr = mean(adr)) %&gt;%       # calculate mean adr for each group\n  ggplot(aes(\n    x = arrival_date_month,                 # x-axis = arrival_date_month\n    y = mean_adr,                           # y-axis = mean_adr calculated above\n    group = meal,                          # group lines by meal type\n    color = meal)                          # and color by meal type\n    ) +\n  geom_line() +                             # use lines to represent data\n  theme_minimal() +                         # use a minimal theme\n  labs(\n    x = \"Arrival month\",                    # customize labels\n    y = \"Mean ADR (average daily rate)\",\n    color = \"Meal type\"\n    ) +\n  ggthemes::scale_color_colorblind()\n\n\n\n\n\n\n\n\nReorder the levels of meal type in a way that makes more sense. Use a function from the forcats package to do this."
  },
  {
    "objectID": "activities/09-tidyr.html",
    "href": "activities/09-tidyr.html",
    "title": "\ntidyr: Reshaping Data",
    "section": "",
    "text": "Click the “code” button above to copy and paste the source code, or pull a fresh version of the “activities” repo from GitHub."
  },
  {
    "objectID": "activities/09-tidyr.html#task-1",
    "href": "activities/09-tidyr.html#task-1",
    "title": "\ntidyr: Reshaping Data",
    "section": "Task 1",
    "text": "Task 1\n\nTidy this data set by\n\nSelecting the series and e*_7day columns\nPivoting the data to add a column for episode and a column for rating (we’ll clean up the episode column later)\n\n\n\n# include your code here"
  },
  {
    "objectID": "activities/09-tidyr.html#task-2",
    "href": "activities/09-tidyr.html#task-2",
    "title": "\ntidyr: Reshaping Data",
    "section": "Task 2",
    "text": "Task 2\n\n\nClean the episode and period column\nMake a line plot with episode on the x-axis, rating on the y-axis, colored by series. (You will also need to map the group aesthetic to series)"
  },
  {
    "objectID": "activities/09-tidyr.html#relig_income",
    "href": "activities/09-tidyr.html#relig_income",
    "title": "\ntidyr: Reshaping Data",
    "section": "relig_income",
    "text": "relig_income\nThe relig_income dataset in the {tidyr} package stores counts based on a survey which (among other things) asked people about their religion and annual income:\n\nrelig_income\n\n# A tibble: 18 × 11\n   religion `&lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k`\n   &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 Agnostic      27        34        60        81        76       137        122\n 2 Atheist       12        27        37        52        35        70         73\n 3 Buddhist      27        21        30        34        33        58         62\n 4 Catholic     418       617       732       670       638      1116        949\n 5 Don’t k…      15        14        15        11        10        35         21\n 6 Evangel…     575       869      1064       982       881      1486        949\n 7 Hindu          1         9         7         9        11        34         47\n 8 Histori…     228       244       236       238       197       223        131\n 9 Jehovah…      20        27        24        24        21        30         15\n10 Jewish        19        19        25        25        30        95         69\n11 Mainlin…     289       495       619       655       651      1107        939\n12 Mormon        29        40        48        51        56       112         85\n13 Muslim         6         7         9        10         9        23         16\n14 Orthodox      13        17        23        32        32        47         38\n15 Other C…       9         7        11        13        13        14         18\n16 Other F…      20        33        40        46        49        63         46\n17 Other W…       5         2         3         4         2         7          3\n18 Unaffil…     217       299       374       365       341       528        407\n# ℹ 3 more variables: `$100-150k` &lt;dbl&gt;, `&gt;150k` &lt;dbl&gt;,\n#   `Don't know/refused` &lt;dbl&gt;\n\n\nUse pivot_longer() to tidy this dataset."
  },
  {
    "objectID": "activities/09-tidyr.html#anscombe",
    "href": "activities/09-tidyr.html#anscombe",
    "title": "\ntidyr: Reshaping Data",
    "section": "anscombe",
    "text": "anscombe\nAnscombe’s quartet is a built-in dataset in R.\n\nanscombe\n\n   x1 x2 x3 x4    y1   y2    y3    y4\n1  10 10 10  8  8.04 9.14  7.46  6.58\n2   8  8  8  8  6.95 8.14  6.77  5.76\n3  13 13 13  8  7.58 8.74 12.74  7.71\n4   9  9  9  8  8.81 8.77  7.11  8.84\n5  11 11 11  8  8.33 9.26  7.81  8.47\n6  14 14 14  8  9.96 8.10  8.84  7.04\n7   6  6  6  8  7.24 6.13  6.08  5.25\n8   4  4  4 19  4.26 3.10  5.39 12.50\n9  12 12 12  8 10.84 9.13  8.15  5.56\n10  7  7  7  8  4.82 7.26  6.42  7.91\n11  5  5  5  8  5.68 4.74  5.73  6.89\n\n\nThis dataset contains four pairs of variables (x1 and y1, x2 and y2, etc) that underlie Anscombe’s quartet, a collection of four datasets that have the same summary statistics (mean, sd, correlation etc), but have quite different data. We want to produce a dataset with columns set, x and y:\n# A tibble: 44 × 3\n   set       x     y\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 1        10  8.04\n 2 2        10  9.14\n 3 3        10  7.46\nThere are (at least) two ways to do this. The first is a little more intuitive, but not as efficient:\n\nFirst, we’ll create a new “index” column, so we don’t lose track of which x values map to which y values.\n\n\nanscombe &lt;- anscombe %&gt;%\n  mutate(\n    index = 1:nrow(anscombe)\n  )\n\n\nNext, use pivot_longer() on all of the columns but index. Use the default for names_to and values_to. The first few rows of your result should look like this:\n\n# A tibble: 88 × 3\n   index name  value\n   &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;\n 1     1 x1    10   \n 2     1 x2    10   \n 3     1 x3    10  \n\nNext, separate name into variable and set. This is a little tricky, since there’s no separator character (the values of name are x1 and x2 instead of x_1 or x_2). Instead, set sep = 1, which tells R to split the column after the first character. The first few rows of your result should look like this:\n\n# A tibble: 88 × 4\n   index variable set   value\n   &lt;int&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n 1     1 x        1     10   \n 2     1 x        2     10   \n 3     1 x        3     10   \n\nFinally, use pivot_wider() with names_from variable and values_from value. Call your tidy dataset anscombe_tidy.\n\nIf all went well, you should be able to run the following two chunks to generate the summary statistics and scatterplots for Anscombe’s quartet.\n\nanscombe_tidy %&gt;%\n  group_by(set) %&gt;%\n  summarize(\n    mean_x = mean(x),\n    mean_y = mean(y),\n    sd_x = sd(x),\n    sd_y = sd(y),\n    cor = cor(x,y)\n  )\n\n\nanscombe_tidy %&gt;%\n  ggplot(aes(x = x, y = y)) + \n  geom_point() + \n  facet_wrap(~set)\n\nThe second way to do this is directly within pivot_longer():\n\nanscombe %&gt;%\n  pivot_longer(\n    -index,\n    names_to = c(\".value\", \"set\"),\n    names_pattern = \"(.)(.)\"\n  )\n\n# A tibble: 44 × 4\n   index set       x     y\n   &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1 1        10  8.04\n 2     1 2        10  9.14\n 3     1 3        10  7.46\n 4     1 4         8  6.58\n 5     2 1         8  6.95\n 6     2 2         8  8.14\n 7     2 3         8  6.77\n 8     2 4         8  5.76\n 9     3 1        13  7.58\n10     3 2        13  8.74\n# ℹ 34 more rows\n\n\npull up the help page for pivot_longer and try to explain the new arguments."
  },
  {
    "objectID": "activities/11-import.html",
    "href": "activities/11-import.html",
    "title": "Data import and dates/times",
    "section": "",
    "text": "Click the “code” button above to copy and paste the source code, or pull a fresh version of the “activities” repo from GitHub."
  },
  {
    "objectID": "activities/11-import.html#data-4.csv",
    "href": "activities/11-import.html#data-4.csv",
    "title": "Data import and dates/times",
    "section": "data-4.csv",
    "text": "data-4.csv\n\n# your code here"
  },
  {
    "objectID": "activities/11-import.html#tricky-1.csv",
    "href": "activities/11-import.html#tricky-1.csv",
    "title": "Data import and dates/times",
    "section": "tricky-1.csv",
    "text": "tricky-1.csv\n\n# your code here"
  },
  {
    "objectID": "activities/11-import.html#tricky-2.csv",
    "href": "activities/11-import.html#tricky-2.csv",
    "title": "Data import and dates/times",
    "section": "tricky-2.csv",
    "text": "tricky-2.csv\n\n# your code here"
  },
  {
    "objectID": "activities/11-import.html#task-1",
    "href": "activities/11-import.html#task-1",
    "title": "Data import and dates/times",
    "section": "Task 1",
    "text": "Task 1\nCreate a vector of dates that our class meets this term\n\n# your code here"
  },
  {
    "objectID": "activities/11-import.html#task-2",
    "href": "activities/11-import.html#task-2",
    "title": "Data import and dates/times",
    "section": "Task 2",
    "text": "Task 2\nNext, print them in the format “Wednesday: Jan 29 2025”\nHint: see ?stamp or the lubridate cheatsheet\n\n# your code here"
  },
  {
    "objectID": "portfolio/portfolio-3.html",
    "href": "portfolio/portfolio-3.html",
    "title": "Portfolio Project 3",
    "section": "",
    "text": "Overview\nFor your third portfolio project, you’ll apply what you’ve learned about iteration and programming. We’ll work with data from the NOAA on Billion Dollar Disasters in the U.S.\nYour task is to create an improved version of the graph below:\n\nYou should create two plots:\n\nA bar graph of disaster type in each year\nA time series line plot of the combined (adjusted) cost for each year\n\nTo do so, you will need to programmatically read in a different CSV file for each year of the data, and combine them into a single dataset. This should include:\n\nWriting a function called read_disaster_data that takes a file path and correctly reads in the corresponding data. You should pay attention to variable types (factors should be treated as factors, dates should be treated as dates, etc.)\nUsing iteration (either map or a for-loop) to apply your function to each data set in the “data” folder\nUsing write_csv to save your final dataset in your repo. (You likely do not want to save it in the data/ folder)\n\nIf you get stuck, R for Data Science has a helpful section on Reading Multiple Files that you may refer to.\nYou should write your code in R Markdown, create any graphics using ggplot2, and use tools from this class for data reading, wrangling, and iteration. To submit your work, push your repo to GitHub and submit to gradescope.\n\n\nData\nThe data for this portfolio problem is from the National Centers for Environmental Information at the National Oceanic and Atmospheric Administration.\nYour repos will contain the following files:\n\ndata/1980.csv\ndata/1981.csv\n…\ndata/2024.csv\n\nWhere each dataset has the following variables:\n\n\n\nvariable\nclass\n\n\n\n\nName\ncharacter\n\n\nDisaster\nfactor\n\n\nBegin Date\ndate\n\n\nEnd Date\ndate\n\n\nCPI-Adjusted Cost\nnumeric\n\n\nUnadjusted Cost\nnumeric\n\n\nDeaths\nnumeric\n\n\n\nThere are also two header rows that contain information about the dataset, but do not need to be read in to R.\n\n\nSubmission\nYour submission will be an .Rmd file that creates your two graphs. You should include a paragraph at the beginning that outlines what your code does.\n\n\nRubric\nA successful project will:\n\nInclude all necessary components pushed to GitHub and linked to gradescope\nContain code, plots, and written summary in a single .rmd document\nThe .rmd has all necessary and no unnecessary code\nCreate the bar plot and time-series plot\nYour file contains a function called read_disaster_data that:\n\nImports a user-specified file\nParses all variable types correctly (e.g. dates are treated as dates, factors are treated as factors)\nEdits the “Name” column to remove the date information\n\nData sets were correctly combined\nAll wrangling was implemented correctly\nSaves the combined data as a new file\nMeet minimum submission quality standards\n\nVery few grammatical mistakes, spelling mistakes, or typos\nInformative title for your report is included\nAny graphs are readable with appropriate titles and labels\nThe rendered document does not contain any unnecessary content (package loading messages, warnings, etc.)\n\n\nAn excellent project will meet all of the requirements for a successful project, plus\n\nIncludes your knitted report as the GitHub readme of your repo (e.g. when I open your repo, the initial page should be your final report) – see github_document\nMeet high submission quality standards\n\nNo grammatical mistakes, spelling mistakes, or typos\nGraphs have been customized (theme, color palette, scales, etc.)\n\n\n\n\nCan I work with someone?\nYes! You can work individually or in pairs for this project. If you’d like to work in a pair, you must notify me by noon on Friday of Week 7 so I can create your group repo.\nFrom the syllabus: You are expected to collaborate with your group, but cannot rely on external sources other than to help motivate the questions or provide other background information (including online forums like StackExchange or Reddit). You may use any resources from class and package documentation, but getting answers on significant parts of solutions from outside resources is not allowed.\nThere are lots of ways to do this task! I am looking for evidence that you can correctly implement the tools that we’ve discussed in class. If I notice code that looks very different than what we’ve used in course materials, I won’t be able to assess whether you’ve learned the tools from the class. I will refer extreme cases to the ASC.\n\n\nFAQ\nIf you have any questions, please post them to the #portfolio-projects channel on slack.",
    "crumbs": [
      "Portfolio Projects",
      "Portfolio Project 3"
    ]
  },
  {
    "objectID": "portfolio/final.html",
    "href": "portfolio/final.html",
    "title": "Final Project",
    "section": "",
    "text": "🚧 Under construction 🚧",
    "crumbs": [
      "Final Project",
      "Final Project"
    ]
  },
  {
    "objectID": "portfolio/final.html#acquire",
    "href": "portfolio/final.html#acquire",
    "title": "Final Project",
    "section": "Acquire",
    "text": "Acquire\n\nAcquire data from at least 2 sources\nAcquire data using one of the advanced techniques discussed in class\nConsider the who, what, when, why, and how of your datasets, with particular attention given to the ethical considerations\nWork with a type of data that was not accessible to you as a Stat120, 230, or 250 student (eg text, spatial, network, etc.)",
    "crumbs": [
      "Final Project",
      "Final Project"
    ]
  },
  {
    "objectID": "portfolio/final.html#wrangle",
    "href": "portfolio/final.html#wrangle",
    "title": "Final Project",
    "section": "Wrangle",
    "text": "Wrangle\n\nDemonstrate proficiency with joining data\nDemonstrate proficiency with tidying data\nDemonstrate proficiency using non-numeric data types\n\nGeospatial data\nText data\nDate/time data\nFactors",
    "crumbs": [
      "Final Project",
      "Final Project"
    ]
  },
  {
    "objectID": "portfolio/final.html#visualize",
    "href": "portfolio/final.html#visualize",
    "title": "Final Project",
    "section": "Visualize",
    "text": "Visualize\n\nCreate high-quality, customized graphics using R/ggplot",
    "crumbs": [
      "Final Project",
      "Final Project"
    ]
  },
  {
    "objectID": "portfolio/final.html#communicate",
    "href": "portfolio/final.html#communicate",
    "title": "Final Project",
    "section": "Communicate",
    "text": "Communicate\nYou’ll communicate your findings through a final product produced in R:\n\nWebsite\nInteractive shiny app\nSlideshow\netc.\n\nWhatever product form you choose, I’ll be looking for a high degree of professionalism and polish.",
    "crumbs": [
      "Final Project",
      "Final Project"
    ]
  },
  {
    "objectID": "portfolio/final.html#document",
    "href": "portfolio/final.html#document",
    "title": "Final Project",
    "section": "Document",
    "text": "Document\n\nAll group members have a commit history on GitHub\nCode is well-documented and clean\nProject is organized and I can navigate your repo",
    "crumbs": [
      "Final Project",
      "Final Project"
    ]
  },
  {
    "objectID": "portfolio/final.html#can-i-work-with-someone",
    "href": "portfolio/final.html#can-i-work-with-someone",
    "title": "Final Project",
    "section": "Can I work with someone?",
    "text": "Can I work with someone?\nYes! You will work in teams of 2-3 for this project. I will be forming groups, but you can sign up as an individual or a pair.",
    "crumbs": [
      "Final Project",
      "Final Project"
    ]
  },
  {
    "objectID": "notes/02-full-lego-report.html",
    "href": "notes/02-full-lego-report.html",
    "title": "An Overview of Lego Sets on Rebrickable",
    "section": "",
    "text": "Rebrickable is a website that shows you which LEGO sets you can build from the LEGO sets and parts that you already own. To do this, Rebrickable maintains a database of the entire LEGO catalog. In this document, we’ll summarize the LEGO sets in this database.\nThe data set was originally obtained from the 2022-09-09 repository on Tidy Tuesday.\n\nIn the data set consists of 19798 LEGO sets (i.e., rows) and 6 variables (i.e., columns). The data set includes LEGO sets from 1949 to 2022. The average number of parts in a set was 161.1 with a standard deviation of 402.62. However, there are 3630 in the data set with 0 parts, making these summary statistics inaccurate.\nBelow is a scatterplot with smoother describing how the typical number of parts in a set has changed from 1949 to 2022.\n\nlibrary(tidyverse)\n\nggplot(sets, aes(year, num_parts)) +\n    geom_jitter(alpha = 0.2, size = .5) +\n    geom_smooth(color = \"skyblue\") +\n    scale_y_continuous(trans = \"log10\") +\n    coord_fixed(ratio = 10) +\n    labs(x = \"Year\", y = \"Number of parts\",\n             title = \"LEGO sets are getting larger over the years\",\n             caption = \"Data source: brickable.com\") +\n    theme_light()"
  },
  {
    "objectID": "notes/02-full-lego-report.html#summarizing-the-lego-dataset",
    "href": "notes/02-full-lego-report.html#summarizing-the-lego-dataset",
    "title": "An Overview of Lego Sets on Rebrickable",
    "section": "",
    "text": "In the data set consists of 19798 LEGO sets (i.e., rows) and 6 variables (i.e., columns). The data set includes LEGO sets from 1949 to 2022. The average number of parts in a set was 161.1 with a standard deviation of 402.62. However, there are 3630 in the data set with 0 parts, making these summary statistics inaccurate.\nBelow is a scatterplot with smoother describing how the typical number of parts in a set has changed from 1949 to 2022.\n\nlibrary(tidyverse)\n\nggplot(sets, aes(year, num_parts)) +\n    geom_jitter(alpha = 0.2, size = .5) +\n    geom_smooth(color = \"skyblue\") +\n    scale_y_continuous(trans = \"log10\") +\n    coord_fixed(ratio = 10) +\n    labs(x = \"Year\", y = \"Number of parts\",\n             title = \"LEGO sets are getting larger over the years\",\n             caption = \"Data source: brickable.com\") +\n    theme_light()"
  },
  {
    "objectID": "slides/22/slides22.html#today",
    "href": "slides/22/slides22.html#today",
    "title": "Intro to Interactivity in R",
    "section": "Today",
    "text": "Today\n\nRMarkdown outputs\nDashboards\nIntro to interactive toolkit"
  },
  {
    "objectID": "slides/22/slides22.html#rmarkdown-outputs-pdf",
    "href": "slides/22/slides22.html#rmarkdown-outputs-pdf",
    "title": "Intro to Interactivity in R",
    "section": "rmarkdown outputs: pdf",
    "text": "rmarkdown outputs: pdf\n\n\n\n---\ntitle: \"Example Document\"\nauthor: \"Amanda Luby\"\ndate: \"2025-02-26\"\noutput:\n  pdf_document\n---"
  },
  {
    "objectID": "slides/22/slides22.html#rmarkdown-outputs-html",
    "href": "slides/22/slides22.html#rmarkdown-outputs-html",
    "title": "Intro to Interactivity in R",
    "section": "rmarkdown outputs: html",
    "text": "rmarkdown outputs: html\n\n\n\n---\ntitle: \"Example Document\"\nauthor: \"Amanda Luby\"\ndate: \"2025-02-26\"\noutput:\n  html_document\n---"
  },
  {
    "objectID": "slides/22/slides22.html#rmarkdown-outputs-html-custom-theme",
    "href": "slides/22/slides22.html#rmarkdown-outputs-html-custom-theme",
    "title": "Intro to Interactivity in R",
    "section": "rmarkdown outputs: html, custom theme",
    "text": "rmarkdown outputs: html, custom theme\n\n\n\n---\ntitle: \"Example Document\"\nauthor: \"Amanda Luby\"\ndate: \"2025-02-26\"\noutput:\n  html_document:\n    theme: darkly\n---"
  },
  {
    "objectID": "slides/22/slides22.html#rmarkdown-outputs-github-flavored-markdown",
    "href": "slides/22/slides22.html#rmarkdown-outputs-github-flavored-markdown",
    "title": "Intro to Interactivity in R",
    "section": "rmarkdown outputs: github-flavored markdown",
    "text": "rmarkdown outputs: github-flavored markdown\n\n\n\n---\ntitle: \"Example Document\"\nauthor: \"Amanda Luby\"\ndate: \"2025-02-26\"\noutput:\n  github_document\n---"
  },
  {
    "objectID": "slides/22/slides22.html#rmarkdown-outputs-html-theme-in-a-package",
    "href": "slides/22/slides22.html#rmarkdown-outputs-html-theme-in-a-package",
    "title": "Intro to Interactivity in R",
    "section": "rmarkdown outputs: html theme in a package",
    "text": "rmarkdown outputs: html theme in a package\n\n\n\n---\ntitle: \"Example Document\"\nauthor: \"Amanda Luby\"\ndate: \"2025-02-26\"\noutput:\n prettydoc::html_pretty:\n    theme: hpstr\n---"
  },
  {
    "objectID": "slides/22/slides22.html#dashboards",
    "href": "slides/22/slides22.html#dashboards",
    "title": "Intro to Interactivity in R",
    "section": "Dashboards",
    "text": "Dashboards\n\n\n\nlibrary(flexdashboard)\n\n\n---\ntitle: \"Recent Earthquakes in Aotearoa New Zealand\"\nsubtitle: \"Of Weak Intensity or Greater\"\noutput: \n  flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\n---"
  },
  {
    "objectID": "slides/22/slides22.html#components-of-a-dashboard",
    "href": "slides/22/slides22.html#components-of-a-dashboard",
    "title": "Intro to Interactivity in R",
    "section": "Components of a dashboard",
    "text": "Components of a dashboard\n\nNavigation Bar and Pages — Title and author along with links to sub-pages (if more than one page is defined).\nSidebars, Rows & Columns, and Tabsets — Rows and columns using markdown heading (with optional attributes to control height, width, etc.). Sidebars for interactive inputs. Tabsets to further divide content.\nSections – Sections are containers for cell outputs and free form markdown text. The content of sections typically maps to cells in your notebook or source document."
  },
  {
    "objectID": "slides/22/slides22.html#navigation-bar-and-pages",
    "href": "slides/22/slides22.html#navigation-bar-and-pages",
    "title": "Intro to Interactivity in R",
    "section": "Navigation bar and pages",
    "text": "Navigation bar and pages\n---\ntitle: \"Palmer Penguins\"\nauthor: \"Amanda Luby\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\n    navbar:\n      - { title: \"Data Source\", href: \"https://allisonhorst.github.io/palmerpenguins/\", align: right }\n---\n\nGraphs\n===================================== \n      \nData \n====================================="
  },
  {
    "objectID": "slides/22/slides22.html#rows-and-columns",
    "href": "slides/22/slides22.html#rows-and-columns",
    "title": "Intro to Interactivity in R",
    "section": "Rows and columns",
    "text": "Rows and columns\n\n\n\nGraphs\n===================================== \n\nColumn {data-width=650}\n-----------------------------------------------------------------------\n\n### Chart 1\n\nColumn {data-width=350}\n-----------------------------------------------------------------------\n\n### Chart 2\n\n### Chart 3"
  },
  {
    "objectID": "slides/22/slides22.html#sections",
    "href": "slides/22/slides22.html#sections",
    "title": "Intro to Interactivity in R",
    "section": "Sections",
    "text": "Sections\n\n\n\nColumn {data-width=350}\n-----------------------------------------------------------------------\n\n### Chart 2\n\n### Chart 3"
  },
  {
    "objectID": "slides/22/slides22.html#interactive-graphics-add-dimensions-to-static-visualizations-via-features-that-the-user-controls",
    "href": "slides/22/slides22.html#interactive-graphics-add-dimensions-to-static-visualizations-via-features-that-the-user-controls",
    "title": "Intro to Interactivity in R",
    "section": "Interactive Graphics add dimensions to static visualizations via features that the user controls",
    "text": "Interactive Graphics add dimensions to static visualizations via features that the user controls"
  },
  {
    "objectID": "slides/22/slides22.html#features-well-focus-on-in-this-class",
    "href": "slides/22/slides22.html#features-well-focus-on-in-this-class",
    "title": "Intro to Interactivity in R",
    "section": "Features we’ll focus on in this class:",
    "text": "Features we’ll focus on in this class:\n\nHovering\n\nDisplay additional information about an observation or group via cursor\n\n\nChanging the representation of the data\n\nUser decides if they want to see the data in a table or a graph\nOption to select variables\nOption to select graph\nOption to tweak parameters of graphs\n\n\nFiltering/subsetting\n\nAllow user to control which subset of the data is shown"
  },
  {
    "objectID": "slides/22/slides22.html#workflow",
    "href": "slides/22/slides22.html#workflow",
    "title": "Intro to Interactivity in R",
    "section": "Workflow",
    "text": "Workflow\n\nStart with a static graph, describe what insights it offers, then build up\nDemonstrate how the interactive features allow you to obtain additional insight that you would not otherwise be able to\n\nJust because you can doesn’t mean you should\n\n\n\nDocument how to use the features (“click on the drop down menu to choose a variable”)"
  },
  {
    "objectID": "slides/22/slides22.html#explanation-to-exploration",
    "href": "slides/22/slides22.html#explanation-to-exploration",
    "title": "Intro to Interactivity in R",
    "section": "Explanation \\(\\to\\) Exploration",
    "text": "Explanation \\(\\to\\) Exploration\nI like to think of interactive components as somewhere on the “Explanation/Exploration” spectrum\n\nExploration: Open-ended; the user decides what the story is\n\n\nNCAA Swimming Data Explorer\nEconomic Census Industry Data\n\n\nExplanation: fully static; the story is the same regardless of what the user does\n\nShadow Peace\nEuro Final"
  },
  {
    "objectID": "slides/22/slides22.html#plotly",
    "href": "slides/22/slides22.html#plotly",
    "title": "Intro to Interactivity in R",
    "section": "plotly",
    "text": "plotly\n\nVisualization library for interactive and dynamic web-based graphics\n\nPlots work in multiple formats\n\nviewer windows\nR Markdown documents\nshiny apps"
  },
  {
    "objectID": "slides/22/slides22.html#static-plot",
    "href": "slides/22/slides22.html#static-plot",
    "title": "Intro to Interactivity in R",
    "section": "Static plot",
    "text": "Static plot\n\n\ngap2021 &lt;- gapminder %&gt;% \n  filter(year == 2021) %&gt;%\n  ggplot(aes(x = income, y = life, color = four_regions, size = population)) +\n    geom_point() +\n  labs(\n    x = \"GDP per capita\",\n    y = \"Life expectancy\",\n    color = \"Region\"\n  ) +\n  scale_x_continuous(labels = scales::dollar_format()) +\n  theme_minimal()\n\ngap2021"
  },
  {
    "objectID": "slides/22/slides22.html#static-to-interactive",
    "href": "slides/22/slides22.html#static-to-interactive",
    "title": "Intro to Interactivity in R",
    "section": "Static \\(\\to\\) interactive",
    "text": "Static \\(\\to\\) interactive\n\nlibrary(plotly)\nggplotly(gap2021)"
  },
  {
    "objectID": "slides/22/slides22.html#wouldnt-it-be-nice-if-we-could-see-the-country-name-when-we-hover",
    "href": "slides/22/slides22.html#wouldnt-it-be-nice-if-we-could-see-the-country-name-when-we-hover",
    "title": "Intro to Interactivity in R",
    "section": "Wouldn’t it be nice if we could see the country name when we hover?",
    "text": "Wouldn’t it be nice if we could see the country name when we hover?\n\n\ngap2021 &lt;- gapminder %&gt;% \n  filter(year == 2021) %&gt;%\n  ggplot(aes(x = income, \n             y = life, \n             color = four_regions, \n             size = population,\n             text = country)) +\n    geom_point() +\n  labs(\n    x = \"GDP per capita\",\n    y = \"Life expectancy\",\n    color = \"Region\"\n  ) +\n  scale_x_continuous(labels = scales::dollar_format()) +\n  theme_minimal()\n\nggplotly(gap2021)"
  },
  {
    "objectID": "slides/22/slides22.html#wouldnt-it-be-nice-if-we-could-see-the-country-name-when-we-hover-output",
    "href": "slides/22/slides22.html#wouldnt-it-be-nice-if-we-could-see-the-country-name-when-we-hover-output",
    "title": "Intro to Interactivity in R",
    "section": "Wouldn’t it be nice if we could see the country name when we hover?",
    "text": "Wouldn’t it be nice if we could see the country name when we hover?"
  },
  {
    "objectID": "slides/22/slides22.html#wouldnt-it-be-nice-if-we-could-see-only-the-country-name-when-we-hover",
    "href": "slides/22/slides22.html#wouldnt-it-be-nice-if-we-could-see-only-the-country-name-when-we-hover",
    "title": "Intro to Interactivity in R",
    "section": "Wouldn’t it be nice if we could see only the country name when we hover?",
    "text": "Wouldn’t it be nice if we could see only the country name when we hover?\n\n\nggplotly(gap2021, tooltip = \"text\")"
  },
  {
    "objectID": "slides/22/slides22.html#your-turn",
    "href": "slides/22/slides22.html#your-turn",
    "title": "Intro to Interactivity in R",
    "section": "Your turn",
    "text": "Your turn\n\nLoad the palmerpenguins data set and create a scatterplot of body_mass_g vs. flipper_length_mm from the penguins data set. Use color and shape to specify the species.\nOnce you have a static graphic you’re happy with, load plotly and convert it to an interactive graphic.\n\nWhat tools tips are included by default?\nChange the default tooltip to include “Species”\n(If time) use stringr so that the tooltip shows: “Species: Adelie” instead of just “Adelie”\n\n\n\n\n\n\n−&plus;\n\n05:00"
  },
  {
    "objectID": "slides/22/slides22.html#your-turn-2",
    "href": "slides/22/slides22.html#your-turn-2",
    "title": "Intro to Interactivity in R",
    "section": "Your turn 2",
    "text": "Your turn 2\n\nCreate a bar chart of species from the penguins data set, then convert it to an interactive bar chart.\n\nWhat tools tips are included by default?\nWhat would you change?\n\n\n\n\n\n\n−&plus;\n\n03:00"
  },
  {
    "objectID": "slides/22/slides22.html#leaflet-1",
    "href": "slides/22/slides22.html#leaflet-1",
    "title": "Intro to Interactivity in R",
    "section": "Leaflet",
    "text": "Leaflet\n\nLeaflet is a javascript library AND an R package\nFully open source\nCan make chloropleths (non-ggplot-syntax) or proportional symbol maps"
  },
  {
    "objectID": "slides/22/slides22.html#create-a-default-leaflet-map",
    "href": "slides/22/slides22.html#create-a-default-leaflet-map",
    "title": "Intro to Interactivity in R",
    "section": "Create a default leaflet map",
    "text": "Create a default leaflet map\n\nlibrary(leaflet)\nm = leaflet() %&gt;% \n  addTiles()\nm"
  },
  {
    "objectID": "slides/22/slides22.html#zoom-into-a-specific-latlong-coordinate",
    "href": "slides/22/slides22.html#zoom-into-a-specific-latlong-coordinate",
    "title": "Intro to Interactivity in R",
    "section": "Zoom into a specific lat/long coordinate",
    "text": "Zoom into a specific lat/long coordinate\n\nm = m %&gt;% setView(-93.1560, 44.4614, zoom = 10)\nm"
  },
  {
    "objectID": "slides/22/slides22.html#zoom-into-a-specific-latlong-coordinate-1",
    "href": "slides/22/slides22.html#zoom-into-a-specific-latlong-coordinate-1",
    "title": "Intro to Interactivity in R",
    "section": "Zoom into a specific lat/long coordinate",
    "text": "Zoom into a specific lat/long coordinate\n\nm = m %&gt;% setView(-93.1560, 44.4614, zoom = 16)\nm"
  },
  {
    "objectID": "slides/22/slides22.html#annotate-with-markers",
    "href": "slides/22/slides22.html#annotate-with-markers",
    "title": "Intro to Interactivity in R",
    "section": "Annotate with markers",
    "text": "Annotate with markers\n\nm %&gt;% \n  addMarkers(-93.153617, \n            44.462511)"
  },
  {
    "objectID": "slides/22/slides22.html#or-add-a-popup",
    "href": "slides/22/slides22.html#or-add-a-popup",
    "title": "Intro to Interactivity in R",
    "section": "Or add a popup",
    "text": "Or add a popup\n\nm %&gt;% \n  addPopups(-93.153617, \n            44.462511, \n            'Here is the &lt;b&gt;Math & Stat Dept&lt;/b&gt; &lt;br&gt;')"
  },
  {
    "objectID": "slides/22/slides22.html#your-turn-1",
    "href": "slides/22/slides22.html#your-turn-1",
    "title": "Intro to Interactivity in R",
    "section": "Your turn",
    "text": "Your turn\n\n\nFind the names of the 3 islands in penguins\n\nFind appropriate lat/long locations for each of the islands in penguins using the internet\nCreate a leaflet map with markers for each island (Tip: Start with the world map with no zoom)\nInclude a popup with the island name\n\n\n\n\n\n\n−&plus;\n\n05:00"
  },
  {
    "objectID": "slides/22/slides22.html#printing-tables",
    "href": "slides/22/slides22.html#printing-tables",
    "title": "Intro to Interactivity in R",
    "section": "Printing tables",
    "text": "Printing tables\nBy default, R prints the tibble using typical code formatting:\n\ngapminder2021\n\n# A tibble: 195 × 17\n   country         year  life income population geo   four_regions eight_regions\n   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;        \n 1 Afghanistan     2021  64.3   1990   40800000 afg   asia         asia_west    \n 2 Angola          2021  66.1   5980   35000000 ago   africa       africa_sub_s…\n 3 Albania         2021  78.8  14700    2870000 alb   europe       europe_east  \n 4 Andorra         2021  NA    56500      77500 and   europe       europe_west  \n 5 United Arab E…  2021  74.3  65200   10100000 are   asia         asia_west    \n 6 Argentina       2021  77    22100   46000000 arg   americas     america_south\n 7 Armenia         2021  76.1  13600    2970000 arm   europe       europe_east  \n 8 Antigua and B…  2021  76.7  18600      99500 atg   americas     america_north\n 9 Australia       2021  83.3  51900   26100000 aus   asia         east_asia_pa…\n10 Austria         2021  82.6  55000    9070000 aut   europe       europe_west  \n# ℹ 185 more rows\n# ℹ 9 more variables: six_regions &lt;chr&gt;, members_oecd_g77 &lt;chr&gt;,\n#   Latitude &lt;dbl&gt;, Longitude &lt;dbl&gt;, `UN member since` &lt;chr&gt;,\n#   `World bank region` &lt;chr&gt;, `World bank, 4 income groups 2017` &lt;chr&gt;,\n#   `World bank, 3 income groups 2017` &lt;chr&gt;, UNHCR &lt;chr&gt;\n\n\nThis is fine for people who are used to looking at R, but not great for public-facing work."
  },
  {
    "objectID": "slides/22/slides22.html#dt-datatables",
    "href": "slides/22/slides22.html#dt-datatables",
    "title": "Intro to Interactivity in R",
    "section": "{DT}: DataTables",
    "text": "{DT}: DataTables\nThe R package {DT} provides an R interface to the JavaScript library DataTables. R data objects (matrices or data frames) can be displayed as tables on HTML pages, and DataTables provides filtering, pagination, sorting, and many other features in the tables."
  },
  {
    "objectID": "slides/22/slides22.html#dt-example",
    "href": "slides/22/slides22.html#dt-example",
    "title": "Intro to Interactivity in R",
    "section": "{DT} Example",
    "text": "{DT} Example\n\nlibrary(DT)\ndatatable(gapminder2021)"
  },
  {
    "objectID": "slides/22/slides22.html#remove-rownames",
    "href": "slides/22/slides22.html#remove-rownames",
    "title": "Intro to Interactivity in R",
    "section": "Remove rownames",
    "text": "Remove rownames\n\ndatatable(gapminder2021,\n          rownames = FALSE)"
  },
  {
    "objectID": "slides/22/slides22.html#add-option-to-filter",
    "href": "slides/22/slides22.html#add-option-to-filter",
    "title": "Intro to Interactivity in R",
    "section": "Add option to filter",
    "text": "Add option to filter\n\ndatatable(gapminder2021,\n          rownames = FALSE,\n          filter = \"top\")"
  },
  {
    "objectID": "slides/22/slides22.html#change-font-size-of-text-within-the-table",
    "href": "slides/22/slides22.html#change-font-size-of-text-within-the-table",
    "title": "Intro to Interactivity in R",
    "section": "Change font size of text within the table\n",
    "text": "Change font size of text within the table\n\nOtherwise, font options are passed from your html document settings\n\ndatatable(gapminder2021,\n          rownames = FALSE,\n          filter = \"top\") %&gt;%\n  formatStyle(columns = colnames(gapminder), fontSize = '12pt')"
  },
  {
    "objectID": "slides/22/slides22.html#your-turn-3",
    "href": "slides/22/slides22.html#your-turn-3",
    "title": "Intro to Interactivity in R",
    "section": "Your turn",
    "text": "Your turn\n\n\nCreate a {DT} table of the penguins dataset\nAdd the option to filter, and make the font size 14pt\n\n\n\n\n\n\n−&plus;\n\n02:00"
  },
  {
    "objectID": "slides/22/slides22.html#putting-it-all-together",
    "href": "slides/22/slides22.html#putting-it-all-together",
    "title": "Intro to Interactivity in R",
    "section": "Putting it all together",
    "text": "Putting it all together\n\nLet’s improve the flexdashboard-example.Rmd Penguins data explorer:\n\nMake all graphs plotly’s with appropriate tooltips\nReplace the data output with your {DT} datatable\nInclude your leaflet map on a new page\n\nAdd value boxes on the same page as your map that show the number of penguins that live on each island\nChange the theme of the dashboard"
  },
  {
    "objectID": "slides/13/slides13.html#today",
    "href": "slides/13/slides13.html#today",
    "title": "Working with Strings",
    "section": "Today",
    "text": "Today\n\nIt’s FEBRUARY!\nLab Quiz 2 Info\nLocal versions of R/RStudio/GitHub\nNew stuff"
  },
  {
    "objectID": "slides/13/slides13.html#january",
    "href": "slides/13/slides13.html#january",
    "title": "Working with Strings",
    "section": "January:",
    "text": "January:"
  },
  {
    "objectID": "slides/13/slides13.html#february",
    "href": "slides/13/slides13.html#february",
    "title": "Working with Strings",
    "section": "February:",
    "text": "February:"
  },
  {
    "objectID": "slides/13/slides13.html#strings-in-r",
    "href": "slides/13/slides13.html#strings-in-r",
    "title": "Working with Strings",
    "section": "Strings in R",
    "text": "Strings in R\nAnything surrounded by quotes(\") or single quotes(').\n\n\"Carleton College\"\n\"2025\"\n'\"Hello World\"'"
  },
  {
    "objectID": "slides/13/slides13.html#section",
    "href": "slides/13/slides13.html#section",
    "title": "Working with Strings",
    "section": "",
    "text": "The “escape” backslash  is used to escape the special use of certain characters\n\nstr_view(\"\\\"\")\n\n[1] │ \"\n\nstr_view(\"\\\\\")\n\n[1] │ \\\n\nstr_view(\"Math\\\\Stats\")\n\n[1] │ Math\\Stats"
  },
  {
    "objectID": "slides/13/slides13.html#section-1",
    "href": "slides/13/slides13.html#section-1",
    "title": "Working with Strings",
    "section": "",
    "text": "Simple, consistent functions for working with strings.\nPart of the tidyverse\n\n\n# loaded with tidyverse\nlibrary(stringr)"
  },
  {
    "objectID": "slides/13/slides13.html#string-length",
    "href": "slides/13/slides13.html#string-length",
    "title": "Working with Strings",
    "section": "String length",
    "text": "String length\nstr_length() determines the length of a string.\n\ncc &lt;- \"Carleton College\"\nstr_length(cc)\n\n[1] 16"
  },
  {
    "objectID": "slides/13/slides13.html#combine-strings",
    "href": "slides/13/slides13.html#combine-strings",
    "title": "Working with Strings",
    "section": "Combine strings",
    "text": "Combine strings\nstr_c() allows us to easily create strings from variables/vectors.\n\nbuilding &lt;- \"CMC\"\nroom &lt;- \"102\"\nbegin_time &lt;- \"9:50 a.m.\"\nend_time &lt;- \"11:000 a.m.\"\ndays &lt;- \"MWF\"\nclass &lt;- \"STAT 220\"\nstr_c(class, \"meets from\", begin_time, \"to\", end_time, \n      days, \"in\", building, room, sep=\" \")\n\n\n\n[1] \"STAT 220 meets from 9:50 a.m. to 11:000 a.m. MWF in CMC 102\""
  },
  {
    "objectID": "slides/13/slides13.html#concatenate-strings",
    "href": "slides/13/slides13.html#concatenate-strings",
    "title": "Working with Strings",
    "section": "Concatenate Strings",
    "text": "Concatenate Strings\nstr_c() works with vectors\n\nletters\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n\n\n\nstr_c(letters, 1:26)\n\n [1] \"a1\"  \"b2\"  \"c3\"  \"d4\"  \"e5\"  \"f6\"  \"g7\"  \"h8\"  \"i9\"  \"j10\" \"k11\" \"l12\"\n[13] \"m13\" \"n14\" \"o15\" \"p16\" \"q17\" \"r18\" \"s19\" \"t20\" \"u21\" \"v22\" \"w23\" \"x24\"\n[25] \"y25\" \"z26\"\n\n\n\n\n\nstr_c(letters, 1:26, sep = \"\")\n\n [1] \"a1\"  \"b2\"  \"c3\"  \"d4\"  \"e5\"  \"f6\"  \"g7\"  \"h8\"  \"i9\"  \"j10\" \"k11\" \"l12\"\n[13] \"m13\" \"n14\" \"o15\" \"p16\" \"q17\" \"r18\" \"s19\" \"t20\" \"u21\" \"v22\" \"w23\" \"x24\"\n[25] \"y25\" \"z26\"\n\n\n\n\n\nstr_c(letters, 1:26, sep = \"-\")\n\n [1] \"a-1\"  \"b-2\"  \"c-3\"  \"d-4\"  \"e-5\"  \"f-6\"  \"g-7\"  \"h-8\"  \"i-9\"  \"j-10\"\n[11] \"k-11\" \"l-12\" \"m-13\" \"n-14\" \"o-15\" \"p-16\" \"q-17\" \"r-18\" \"s-19\" \"t-20\"\n[21] \"u-21\" \"v-22\" \"w-23\" \"x-24\" \"y-25\" \"z-26\""
  },
  {
    "objectID": "slides/13/slides13.html#case-conversion",
    "href": "slides/13/slides13.html#case-conversion",
    "title": "Working with Strings",
    "section": "Case conversion",
    "text": "Case conversion\nstr_to_lower() and str_to_upper() can help “fix” the case\n\ntext &lt;- \"NoRthFieLd, mN\"\nstr_to_lower(text)\n\n[1] \"northfield, mn\"\n\n\n\n\nstr_to_upper(text)\n\n[1] \"NORTHFIELD, MN\""
  },
  {
    "objectID": "slides/13/slides13.html#babynames",
    "href": "slides/13/slides13.html#babynames",
    "title": "Working with Strings",
    "section": "Babynames",
    "text": "Babynames\n\n\n\nlibrary(babynames)\nbabynames\n\n# A tibble: 1,924,665 × 5\n    year sex   name          n   prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;\n 1  1880 F     Mary       7065 0.0724\n 2  1880 F     Anna       2604 0.0267\n 3  1880 F     Emma       2003 0.0205\n 4  1880 F     Elizabeth  1939 0.0199\n 5  1880 F     Minnie     1746 0.0179\n 6  1880 F     Margaret   1578 0.0162\n 7  1880 F     Ida        1472 0.0151\n 8  1880 F     Alice      1414 0.0145\n 9  1880 F     Bertha     1320 0.0135\n10  1880 F     Sarah      1288 0.0132\n# ℹ 1,924,655 more rows\n\n\n\nExample questions:\n\nHow many names end in a vowel?\nHow many names contain the pattern “stat”\nHow many names contain 3 A’s?"
  },
  {
    "objectID": "slides/13/slides13.html#extract-substrings",
    "href": "slides/13/slides13.html#extract-substrings",
    "title": "Working with Strings",
    "section": "Extract substrings",
    "text": "Extract substrings\n\nstr_sub(string, start = 1, end = -1)\n\n\n\nstring = character vector\n\nstart / end = position of the first and last characters"
  },
  {
    "objectID": "slides/13/slides13.html#extract-substrings-1",
    "href": "slides/13/slides13.html#extract-substrings-1",
    "title": "Working with Strings",
    "section": "Extract substrings",
    "text": "Extract substrings\nWe can pull apart strings from the start…\n\ncc &lt;- \"Carleton College\"\nstr_sub(cc, 10)  # end defaults to last character\n\n[1] \"College\"\n\n\n\n\nstr_sub(cc, 1, 8)\n\n[1] \"Carleton\"\n\n\n\n\n\n# match the elements of each vector for positions\nstr_sub(cc, c(1, 10), c(8, 16))\n\n[1] \"Carleton\" \"College\""
  },
  {
    "objectID": "slides/13/slides13.html#extract-substrings-2",
    "href": "slides/13/slides13.html#extract-substrings-2",
    "title": "Working with Strings",
    "section": "Extract substrings",
    "text": "Extract substrings\n… or the end\n\ncc &lt;- \"Carleton College\"\nstr_sub(cc, -3)\n\n[1] \"ege\"\n\n\n\n\nstr_sub(cc, -8, -3)\n\n[1] \" Colle\""
  },
  {
    "objectID": "slides/13/slides13.html#your-turn",
    "href": "slides/13/slides13.html#your-turn",
    "title": "Working with Strings",
    "section": "Your turn:",
    "text": "Your turn:\n\nWhat will the following commands return?\n\n\nstr_sub(\"Amanda Luby\", 1, 4)\nstr_sub(\"Amanda Luby\", 4)\nstr_sub(\"Amanda Luby\", -5)\n\n\n\n\n\n−&plus;\n\n02:00"
  },
  {
    "objectID": "slides/13/slides13.html#your-turn-again",
    "href": "slides/13/slides13.html#your-turn-again",
    "title": "Working with Strings",
    "section": "Your turn (again):",
    "text": "Your turn (again):\n\nConfer with folks around you. Fill in the blanks of the .Rmd file to…\n\nIsolate the last letter of every name\nCreate a logical variable that displays whether the last letter is one of “a”, “e”, “i”, “o”, “u”, or “y”.\nUse a weighted mean to calculate the proportion of children whose name ends in a vowel by year (see ?weighted.mean)\nand then display the results as a line plot.\n\n\n\n\n\n\n−&plus;\n\n06:00"
  },
  {
    "objectID": "slides/13/slides13.html#extract-substrings-3",
    "href": "slides/13/slides13.html#extract-substrings-3",
    "title": "Working with Strings",
    "section": "Extract substrings",
    "text": "Extract substrings\nWhat about a vector of strings?\n\nfruits &lt;- c(\"apple\", \"pineapple\", \"Pear\", \"orange\", \"peach\", \"banana\")\nstr_sub(fruits, 2, 4)\n\n[1] \"ppl\" \"ine\" \"ear\" \"ran\" \"eac\" \"ana\"\n\n\n\n\nstr_sub(fruits, 2, 2)\n\n[1] \"p\" \"i\" \"e\" \"r\" \"e\" \"a\"\n\n\n\n\n\nstr_sub(fruits, 4, 4)\n\n[1] \"l\" \"e\" \"r\" \"n\" \"c\" \"a\"\n\n\n\n\n\nstr_sub(fruits, c(2, 4, 2, 4, 2, 4), c(2, 4, 2, 4, 2, 4))\n\n[1] \"p\" \"e\" \"e\" \"n\" \"e\" \"a\""
  },
  {
    "objectID": "slides/13/slides13.html#pad-strings",
    "href": "slides/13/slides13.html#pad-strings",
    "title": "Working with Strings",
    "section": "Pad strings",
    "text": "Pad strings\nWe can add character(s) to the beginning or end of a string\n\nnums &lt;- 1:10\nas.character(nums)\n\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\"\n\n\n\n\nstr_pad(nums, 2, pad =\"0\")\n\n [1] \"01\" \"02\" \"03\" \"04\" \"05\" \"06\" \"07\" \"08\" \"09\" \"10\"\n\n\n\n\n\nstr_pad(nums, 3, pad =\"0\")\n\n [1] \"001\" \"002\" \"003\" \"004\" \"005\" \"006\" \"007\" \"008\" \"009\" \"010\"\n\n\n\n\n\nstr_pad(nums, 3, pad =\"0\", side = \"right\")\n\n [1] \"100\" \"200\" \"300\" \"400\" \"500\" \"600\" \"700\" \"800\" \"900\" \"100\"\n\n\n\n\n\nstr_pad(nums, 3, pad =\"0\", side = \"both\")\n\n [1] \"010\" \"020\" \"030\" \"040\" \"050\" \"060\" \"070\" \"080\" \"090\" \"100\""
  },
  {
    "objectID": "slides/13/slides13.html#section-2",
    "href": "slides/13/slides13.html#section-2",
    "title": "Working with Strings",
    "section": "",
    "text": "Use the courses dataset in the .rmd file to answer the following:\n\nHow many of the course numbers end in .00? Use str_detect() or str_count() to help you answer this question.\nThe section number appears after the decimal point. Use mutate() and str_sub() to create a section column containing this number.\nHow many courses contain the word Introduction? Does case matter here?\nWhat is the longest course name (in terms of characters)? What is the shortest course name? Use str_length() to help you answer this question.\nWhich course name is comprised of the most words? To do this, create a new column containing the words in each title using mutate() and str_split(). Then, create another column calculating the length() of the values in column you just created.\nUse str_subset() to return the course names that contain exclamation points (!).\n\n\n\ncountdown::countdown(10)\n\n\n\n−&plus;\n\n10:00"
  },
  {
    "objectID": "slides/13/slides13.html#regular-expressions-1",
    "href": "slides/13/slides13.html#regular-expressions-1",
    "title": "Working with Strings",
    "section": "Regular expressions",
    "text": "Regular expressions\n\n\nSometimes the patterns we wish to detect, extract, etc. too complex for exact matching\n\nExtract all time stamps of the form HH:MM:SS\n\nExtract the string that comes after the dash (e.g. hw01-aluby)\n\n\nRegular expressions (regexps) are a very terse language that allow you to describe patterns in strings\nConfusing at first, but extremely useful"
  },
  {
    "objectID": "slides/13/slides13.html#example",
    "href": "slides/13/slides13.html#example",
    "title": "Working with Strings",
    "section": "Example",
    "text": "Example\nSuppose we wish to anonymize phone numbers in survey results\n\na1 &lt;- \"Home: 507-645-5489\"\na2 &lt;- \"Cell: 219.917.9871\"\na3 &lt;- \"My work phone is 507-202-2332\"\na4 &lt;- \"I don't have a phone\"\ninfo &lt;- c(a1, a2, a3, a4)\n\n\n\n[1] \"Home: 507-645-5489\"            \"Cell: 219.917.9871\"           \n[3] \"My work phone is 507-202-2332\" \"I don't have a phone\""
  },
  {
    "objectID": "slides/13/slides13.html#visualizing-matches",
    "href": "slides/13/slides13.html#visualizing-matches",
    "title": "Working with Strings",
    "section": "Visualizing matches",
    "text": "Visualizing matches\nThe helper function str_view() finds regex matches\n\nstr_view(a1, \"5\")\n\n[1] │ Home: &lt;5&gt;07-64&lt;5&gt;-&lt;5&gt;489"
  },
  {
    "objectID": "slides/13/slides13.html#match-any-character",
    "href": "slides/13/slides13.html#match-any-character",
    "title": "Working with Strings",
    "section": "\n. match any character",
    "text": ". match any character\nFind a “-” and any (.) character that follows\n\nstr_view(a1, \"-.\")\n\n[1] │ Home: 507&lt;-6&gt;45&lt;-5&gt;489"
  },
  {
    "objectID": "slides/13/slides13.html#match-any-occurence",
    "href": "slides/13/slides13.html#match-any-occurence",
    "title": "Working with Strings",
    "section": "\n[] match any occurence",
    "text": "[] match any occurence\nFind any numbers between 0 and 9\n\nstr_view(a1, \"[0123456789]\")\n\n[1] │ Home: &lt;5&gt;&lt;0&gt;&lt;7&gt;-&lt;6&gt;&lt;4&gt;&lt;5&gt;-&lt;5&gt;&lt;4&gt;&lt;8&gt;&lt;9&gt;"
  },
  {
    "objectID": "slides/13/slides13.html#match-any-occurence-1",
    "href": "slides/13/slides13.html#match-any-occurence-1",
    "title": "Working with Strings",
    "section": "\n[] match any occurence",
    "text": "[] match any occurence\nFind any numbers between 2 and 7\n\nstr_view(a1, \"[2-7]\")\n\n[1] │ Home: &lt;5&gt;0&lt;7&gt;-&lt;6&gt;&lt;4&gt;&lt;5&gt;-&lt;5&gt;&lt;4&gt;89"
  },
  {
    "objectID": "slides/13/slides13.html#your-turn-1",
    "href": "slides/13/slides13.html#your-turn-1",
    "title": "Working with Strings",
    "section": "Your turn:",
    "text": "Your turn:\n\nDetect either “.” or “-” in the info vector.\n\n\na1 &lt;- \"Home: 507-645-5489\"\na2 &lt;- \"Cell: 219.917.9871\"\na3 &lt;- \"My work phone is 507-202-2332\"\na4 &lt;- \"I don't have a phone\"\ninfo &lt;- c(a1, a2, a3, a4)\n\n\n\n\n\n−&plus;\n\n02:00"
  },
  {
    "objectID": "slides/13/slides13.html#special-patterns",
    "href": "slides/13/slides13.html#special-patterns",
    "title": "Working with Strings",
    "section": "Special patterns",
    "text": "Special patterns\nThere are a number of special patterns that match more than one character\n\n\n\n\\\\d - digit\n\n\\\\s - white space\n\n\\\\w - word\n\n\\\\t - tab\n\n\\\\n - newline\n\n\n\n\nstr_view(a1, \"\\\\d\")\n\n[1] │ Home: &lt;5&gt;&lt;0&gt;&lt;7&gt;-&lt;6&gt;&lt;4&gt;&lt;5&gt;-&lt;5&gt;&lt;4&gt;&lt;8&gt;&lt;9&gt;\n\n\n\n\n\nOutside of R, these would be single back slashes."
  },
  {
    "objectID": "slides/13/slides13.html#caution",
    "href": "slides/13/slides13.html#caution",
    "title": "Working with Strings",
    "section": "Caution!",
    "text": "Caution!\n\nstr_view(a1, \"\\\\w\")\n\n[1] │ &lt;H&gt;&lt;o&gt;&lt;m&gt;&lt;e&gt;: &lt;5&gt;&lt;0&gt;&lt;7&gt;-&lt;6&gt;&lt;4&gt;&lt;5&gt;-&lt;5&gt;&lt;4&gt;&lt;8&gt;&lt;9&gt;"
  },
  {
    "objectID": "slides/13/slides13.html#match-any-occurence-except",
    "href": "slides/13/slides13.html#match-any-occurence-except",
    "title": "Working with Strings",
    "section": "\n[^] match any occurence except",
    "text": "[^] match any occurence except\nANYTHING BUT numbers between 2 and 7\n\nstr_view(a1, \"[^2-7]\")\n\n[1] │ &lt;H&gt;&lt;o&gt;&lt;m&gt;&lt;e&gt;&lt;:&gt;&lt; &gt;5&lt;0&gt;7&lt;-&gt;645&lt;-&gt;54&lt;8&gt;&lt;9&gt;\n\n\n\n\nCommon pitfall: forgetting the brackets"
  },
  {
    "objectID": "slides/13/slides13.html#anchors",
    "href": "slides/13/slides13.html#anchors",
    "title": "Working with Strings",
    "section": "Anchors",
    "text": "Anchors\nAnchors look for matches at the start ^ or end $\n\n\n[1] │ Home: 507-645-5489\n[2] │ Cell: 219.917.9871\n[3] │ My work phone is 507-202-2332\n[4] │ I don't have a phone\n\n\n\n\nEntries that start with a digit\nEntries that end with a digit\n\n\n\n\nstr_view(info, \"^\\\\d\")\n\n\n\n\nstr_view(info, \"\\\\d$\")\n\n[1] │ Home: 507-645-548&lt;9&gt;\n[2] │ Cell: 219.917.987&lt;1&gt;\n[3] │ My work phone is 507-202-233&lt;2&gt;"
  },
  {
    "objectID": "slides/13/slides13.html#use-regex-in-str_detect-str_sub-etc",
    "href": "slides/13/slides13.html#use-regex-in-str_detect-str_sub-etc",
    "title": "Working with Strings",
    "section": "Use regex in str_detect, str_sub, etc:",
    "text": "Use regex in str_detect, str_sub, etc:\n\nstr_view(info)\n\n[1] │ Home: 507-645-5489\n[2] │ Cell: 219.917.9871\n[3] │ My work phone is 507-202-2332\n[4] │ I don't have a phone\n\n\n\nstr_detect(info, \"\\\\d\")\n\n[1]  TRUE  TRUE  TRUE FALSE\n\n\n\nstr_replace_all(info, \"\\\\d\", \"X\")\n\n[1] \"Home: XXX-XXX-XXXX\"            \"Cell: XXX.XXX.XXXX\"           \n[3] \"My work phone is XXX-XXX-XXXX\" \"I don't have a phone\""
  },
  {
    "objectID": "slides/13/slides13.html#your-turn-2",
    "href": "slides/13/slides13.html#your-turn-2",
    "title": "Working with Strings",
    "section": "Your turn",
    "text": "Your turn\n\nFill in the code to determine how many baby names in 2015 ended with a vowel.\nUse a regular expression to specify the pattern.\n\n\nbabynames %&gt;% \n  ___(___ == ___) %&gt;%                       # extract year 2015\n  ___(ends_with_vowel = ___(___, ___)) %&gt;%  # create logical column\n  count(ends_with_vowel)                    # create a frequency table\n\n\n\n\n\n−&plus;\n\n03:00"
  },
  {
    "objectID": "slides/15/slides15.html#today",
    "href": "slides/15/slides15.html#today",
    "title": "Sentiment Analysis",
    "section": "Today",
    "text": "Today\n\nSentiment analysis\nLab Quiz 2!"
  },
  {
    "objectID": "slides/15/slides15.html#data-for-today",
    "href": "slides/15/slides15.html#data-for-today",
    "title": "Sentiment Analysis",
    "section": "Data for today",
    "text": "Data for today\nRandom (?) sample of 26,882 reviews of coursera courses\n\nen_coursera_reviews &lt;- read_csv(\"https://stat220-w25.github.io/data/en_coursera_sample.csv\")\nen_coursera_reviews\n\n# A tibble: 26,882 × 5\n   CourseId                    Review                      Label cld2  review_id\n   &lt;chr&gt;                       &lt;chr&gt;                       &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 nurture-market-strategies   It would be better if the …     1 en            1\n 2 nand2tetris2                Superb course. Great prese…     5 en            2\n 3 schedule-projects           Excellent course!               5 en            3\n 4 teaching-english-capstone-2 I'd recommend this course …     5 en            4\n 5 machine-learning            This course was so effecti…     5 en            5\n 6 python-network-data         Words cannot describe how …     5 en            6\n 7 clinical-trials             Great course!                   5 en            7\n 8 python-genomics             I didn't know anything abo…     3 en            8\n 9 strategic-management        Loved everything about thi…     5 en            9\n10 script-writing              No significant instruction…     1 en           10\n# ℹ 26,872 more rows\n\n\n\n\nSource: Kaggle"
  },
  {
    "objectID": "slides/15/slides15.html#are-these-positive-or-negative-reviews",
    "href": "slides/15/slides15.html#are-these-positive-or-negative-reviews",
    "title": "Sentiment Analysis",
    "section": "Are these positive or negative reviews?",
    "text": "Are these positive or negative reviews?\n“thank you so much it was great course”\n“Too reliant on materials directly collected by professor, too little context of larger artistic community.”\n“Excellent! easy to follow and engaging!”\n“Slow and redundant. Would have preferred a faster-paced and more substantive course.”\n“Way too shallow and way too english :(”"
  },
  {
    "objectID": "slides/15/slides15.html#sentiment-analysis",
    "href": "slides/15/slides15.html#sentiment-analysis",
    "title": "Sentiment Analysis",
    "section": "Sentiment analysis",
    "text": "Sentiment analysis\nOne way to analyze the sentiment is to consider the text as a combination of the individual words. It’s computationally convenient because we’re able to use the tidy tools that we’ve been building up:\n\n\ntokenize the text\n\njoin the sentiment values to each token\n\ngroup the words in the document to summarize the overall sentiment"
  },
  {
    "objectID": "slides/15/slides15.html#sentiment-datasets-bing",
    "href": "slides/15/slides15.html#sentiment-datasets-bing",
    "title": "Sentiment Analysis",
    "section": "Sentiment datasets: bing\n",
    "text": "Sentiment datasets: bing\n\n\n\nlibrary(tidytext)\nget_sentiments(\"bing\") %&gt;%\n  slice_sample(n = 20)\n\n\n# A tibble: 20 × 2\n   word          sentiment\n   &lt;chr&gt;         &lt;chr&gt;    \n 1 undercutting  negative \n 2 unexpectedly  negative \n 3 slack         negative \n 4 fabrication   negative \n 5 majesty       positive \n 6 perilously    negative \n 7 cave          negative \n 8 partisan      negative \n 9 prik          negative \n10 miserableness negative \n11 flourish      positive \n12 acridness     negative \n13 darling       positive \n14 undisputed    positive \n15 crabby        negative \n16 inexperience  negative \n17 boastful      negative \n18 unequivocally positive \n19 greatness     positive \n20 gratify       positive"
  },
  {
    "objectID": "slides/15/slides15.html#sentiment-datasets-afinn",
    "href": "slides/15/slides15.html#sentiment-datasets-afinn",
    "title": "Sentiment Analysis",
    "section": "Sentiment datasets: afinn\n",
    "text": "Sentiment datasets: afinn\n\n\n\nlibrary(textdata)\nget_sentiments(\"afinn\") %&gt;%\n  slice_sample(n = 20)\n\n\n# A tibble: 20 × 2\n   word           value\n   &lt;chr&gt;          &lt;dbl&gt;\n 1 postponed         -1\n 2 beautifully        3\n 3 chagrin           -2\n 4 appreciation       2\n 5 spark              1\n 6 mope              -1\n 7 empathetic         2\n 8 oversimplified    -2\n 9 stimulating        2\n10 exaggerates       -2\n11 disconsolation    -2\n12 sophisticated      2\n13 fearing           -2\n14 bereaving         -2\n15 dejected          -2\n16 stopped           -1\n17 strikers          -2\n18 scary             -2\n19 worse             -3\n20 protesters        -2"
  },
  {
    "objectID": "slides/15/slides15.html#section-1",
    "href": "slides/15/slides15.html#section-1",
    "title": "Sentiment Analysis",
    "section": "",
    "text": "en_coursera_reviews \n\n# A tibble: 26,882 × 5\n   CourseId                    Review                      Label cld2  review_id\n   &lt;chr&gt;                       &lt;chr&gt;                       &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 nurture-market-strategies   It would be better if the …     1 en            1\n 2 nand2tetris2                Superb course. Great prese…     5 en            2\n 3 schedule-projects           Excellent course!               5 en            3\n 4 teaching-english-capstone-2 I'd recommend this course …     5 en            4\n 5 machine-learning            This course was so effecti…     5 en            5\n 6 python-network-data         Words cannot describe how …     5 en            6\n 7 clinical-trials             Great course!                   5 en            7\n 8 python-genomics             I didn't know anything abo…     3 en            8\n 9 strategic-management        Loved everything about thi…     5 en            9\n10 script-writing              No significant instruction…     1 en           10\n# ℹ 26,872 more rows"
  },
  {
    "objectID": "slides/15/slides15.html#inner_join",
    "href": "slides/15/slides15.html#inner_join",
    "title": "Sentiment Analysis",
    "section": "inner_join",
    "text": "inner_join"
  },
  {
    "objectID": "slides/15/slides15.html#joining-the-sentiment-data",
    "href": "slides/15/slides15.html#joining-the-sentiment-data",
    "title": "Sentiment Analysis",
    "section": "\njoining the sentiment data",
    "text": "joining the sentiment data\n\n\nbing_sentiments = get_sentiments(\"bing\")\nen_coursera_reviews %&gt;%\n  unnest_tokens(word, Review) %&gt;% \n  inner_join(bing_sentiments, by = \"word\") %&gt;%\n  select(-c(CourseId, cld2))\n\n\n# A tibble: 69,052 × 4\n   Label review_id word        sentiment\n   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;    \n 1     1         1 better      positive \n 2     5         2 superb      positive \n 3     5         2 great       positive \n 4     5         2 challenging negative \n 5     5         2 fun         positive \n 6     5         2 recommend   positive \n 7     5         3 excellent   positive \n 8     5         4 recommend   positive \n 9     5         4 enjoyed     positive \n10     5         4 great       positive \n# ℹ 69,042 more rows"
  },
  {
    "objectID": "slides/15/slides15.html#group_by-review-id-summarize-overall-sentiment",
    "href": "slides/15/slides15.html#group_by-review-id-summarize-overall-sentiment",
    "title": "Sentiment Analysis",
    "section": "\ngroup_by review ID, summarize overall sentiment",
    "text": "group_by review ID, summarize overall sentiment\n\n\nbing_review_scores &lt;- en_coursera_reviews %&gt;%\n  unnest_tokens(word, Review) %&gt;% \n  inner_join(bing_sentiments, by = \"word\") %&gt;%\n  group_by(review_id) %&gt;%\n  summarize(\n    sum = (sum(sentiment == \"positive\") - sum(sentiment == \"negative\"))\n  )\n\nbing_review_scores\n\n\n# A tibble: 25,384 × 2\n   review_id   sum\n       &lt;dbl&gt; &lt;int&gt;\n 1         1     1\n 2         2     3\n 3         3     1\n 4         4     3\n 5         5     5\n 6         6     1\n 7         7     1\n 8         8     2\n 9         9     5\n10        10     0\n# ℹ 25,374 more rows"
  },
  {
    "objectID": "slides/15/slides15.html#most-positive-review-by-sum",
    "href": "slides/15/slides15.html#most-positive-review-by-sum",
    "title": "Sentiment Analysis",
    "section": "Most positive review (by sum):",
    "text": "Most positive review (by sum):\n\n\nen_coursera_reviews %&gt;%\n  left_join(bing_review_scores, by = \"review_id\") %&gt;%\n  slice_max(sum) %&gt;%\n  pull(Review)\n\n\n[1] \"This course is awesome on so many levels. This is the best inferential statistics course I've come across. Here's why:*** The slides are beautiful and visually appealing, making following the rigorous content easier to digest.*** Instructors are captivating and articulate, the explanations are clear and concise.*** The assignments are very very tough, making the course incredibly challenging, but worth it. Honestly, I don't get why people give 1 star because the course is tough. This should be a huge plus.It was a real challenge getting 100% for everything. For every quiz, I attempted 2 - 3 times to get 100%. The challenge is worth it. I couldn't thank you enough for this course. You explain tough statistical concepts like the difference between prediction intervals and confidence intervals really well. Also, I think this course has the best teaching for Analysis of Variance (I have taken a few other statistics moocs). Also, your course helped me appreciate the meaning of R-squared, standard errors, confidence intervals in a very intuitive fashion. There are many other new things I've learnt from your course, some of them I thought I knew, but you helped me to either \\\"Aha\\\" or understand them more deeply.Before this course, most of the time statistics to me is like plug-and-play using procedures and and softwares. But now, I can understand the concepts and what the calculations really mean.Thank you for creating quizzes that make us really do step-by-step calculations and not just plug data into equations to get results like so many other statistics moocs do.The pedagogy is really great. Sometimes quizzes can be frustrating because I need to read very carefully into the meaning of the questions and all the options. However, the learning experience is really worth it.Again, thank you for an amazing course! This is rare stuff!It is without a doubt, a lot of passion and effort has been put into this course and this series.\""
  },
  {
    "objectID": "slides/15/slides15.html#most-negative-reviews-by-sum",
    "href": "slides/15/slides15.html#most-negative-reviews-by-sum",
    "title": "Sentiment Analysis",
    "section": "Most negative reviews (by sum):",
    "text": "Most negative reviews (by sum):\n\n\nen_coursera_reviews %&gt;%\n  left_join(bing_review_scores, by = \"review_id\") %&gt;%\n  slice_min(sum) %&gt;%\n  pull(Review) %&gt;%\n  pluck(1)\n\n\n[1] \"Complex concepts (e.g., regression), which cannot be taught in such a short course format (I know from extensive prior training), are taught here in an arcane way. I don't know how students without prior knowledge on these topics (e.g., regression, ROC curve analysis) could possibly understand this when taught this way.Course is also in an 'early draft' mode, with plenty of mistakes in the videos/slides. The course (and specialization) really tarnishes - instead of enhancing - this institution's outside image and reputation.Really a deception; sorry I took this class and specialization, a complete waste of my time and money. The initial presentation was misleading (and I have found online many people sharing the same feeling).\""
  },
  {
    "objectID": "slides/01/slides01.html#about-me",
    "href": "slides/01/slides01.html#about-me",
    "title": "Welcome to Stat 220",
    "section": "About me",
    "text": "About me\n\n\n\nFirst year at Carleton!\nTaught at Swarthmore for 5 years before moving here this fall\nPhD in Statistics & Data Science from Carnegie Mellon University\nGrew up in Minnesota, went to St Ben’s as an undergrad"
  },
  {
    "objectID": "slides/01/slides01.html#what-is-data-science",
    "href": "slides/01/slides01.html#what-is-data-science",
    "title": "Welcome to Stat 220",
    "section": "What is “data science”?",
    "text": "What is “data science”?"
  },
  {
    "objectID": "slides/01/slides01.html#what-is-this-class-about",
    "href": "slides/01/slides01.html#what-is-this-class-about",
    "title": "Welcome to Stat 220",
    "section": "What is this class about?",
    "text": "What is this class about?\n\nDevelop research questions that can be answered with data\nAcquire data from multiple sources\nWrangle common types of data\nVisualize data to provide insight\nCommunicate your findings\nDocument your code and collaborate on coding projects"
  },
  {
    "objectID": "slides/01/slides01.html#section",
    "href": "slides/01/slides01.html#section",
    "title": "Welcome to Stat 220",
    "section": "",
    "text": "What skills do you need?\n\nprogramming with data\nstatistical modeling\ndomain knowledge\ncommunication"
  },
  {
    "objectID": "slides/01/slides01.html#what-is-this-class-all-about",
    "href": "slides/01/slides01.html#what-is-this-class-all-about",
    "title": "Welcome to Stat 220",
    "section": "What is this class all about?",
    "text": "What is this class all about?\n\n\n\nImage by Adam Loy  adapted from work of Joe Blitzstein, Hanspeter Pfister, and Hadley Wickham"
  },
  {
    "objectID": "slides/01/slides01.html#why-r",
    "href": "slides/01/slides01.html#why-r",
    "title": "Welcome to Stat 220",
    "section": "Why R?",
    "text": "Why R?\n\nAnd the second reason, which is both a huge strength of R and a bit of a weakness, is that R is not just a programming language. It was designed from day 1 to be an environment that can do data analysis. So, compared to the other options like Python, you can get up and running in R doing data science, learning much, much less about programming to get started. And that generally makes it like easier to get up and running if you don’t have formal training in computer science or software engineering.\n\n\n-Hadley Wickham, Advice to Young (and Old) Programmers: A Conversation with Hadley Wickham"
  },
  {
    "objectID": "slides/01/slides01.html#advice",
    "href": "slides/01/slides01.html#advice",
    "title": "Welcome to Stat 220",
    "section": "Advice",
    "text": "Advice\n\n\n\n\n\n\n\n\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n\n\n\nHadley Wickham, Advice to Young (and Old) Programmers: A Conversation with Hadley Wickham; Artwork by Allison Horst"
  },
  {
    "objectID": "slides/01/slides01.html#on-your-own",
    "href": "slides/01/slides01.html#on-your-own",
    "title": "Welcome to Stat 220",
    "section": "On your own:",
    "text": "On your own:\n\n\nLog into the maize server: maize.mathcs.carleton.edu\nFollow the directions at stat220-w25.github.io/computing/rstudio-stat220 to create a “content” folder\nLoad the .Rmd file with: download.file(     \"https://math.carleton.edu/aluby/stat220/01-example-unvotes.rmd\",      destfile = \"01-example-unvotes.rmd\")\nSkim the file without running any code:\n\nWhere is the code?\nWhere is the narrative?\n\nRun each code chunk in order. What does this analysis do?\n\n\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "slides/01/slides01.html#what-steps-went-into-this-analysis",
    "href": "slides/01/slides01.html#what-steps-went-into-this-analysis",
    "title": "Welcome to Stat 220",
    "section": "What steps went into this analysis?",
    "text": "What steps went into this analysis?\n\nRecording the original data\nAccessing data via an R package\nCombining multiple datasets into one\nData cleaning: filtering, creating new columns, grouping, summarizing\nMaking a graph\nFitting a smooth line model"
  },
  {
    "objectID": "slides/01/slides01.html#your-turn",
    "href": "slides/01/slides01.html#your-turn",
    "title": "Welcome to Stat 220",
    "section": "Your turn:",
    "text": "Your turn:\n\nWith your neighbor(s):\nChoose two countries to compare to the U.S. voting record in the U.N. over the years.\nWhat did you learn?\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/01/slides01.html#course-github",
    "href": "slides/01/slides01.html#course-github",
    "title": "Welcome to Stat 220",
    "section": "Course github",
    "text": "Course github\n\nhttps://github.com/stat220-w25/\n\n\naka “the one link to rule them all”\n\n\naccess slides\nsee schedule\naccess repositories for homework and projects"
  },
  {
    "objectID": "slides/01/slides01.html#office-hours-tentative",
    "href": "slides/01/slides01.html#office-hours-tentative",
    "title": "Welcome to Stat 220",
    "section": "Office hours (tentative)",
    "text": "Office hours (tentative)\n\n\n\nDay\nTime\nType\nLocation\n\n\n\n\nMonday\n11-12\nDrop-in\nCMC 307\n\n\nTuesday\n2-3\nDrop-in\nCMC 307\n\n\nWednesday\n4-5\nDrop-in\nCMC 307\n\n\nFriday\n11-12\nBy appt\nCMC 223"
  },
  {
    "objectID": "slides/01/slides01.html#where-is-amanda-in-january",
    "href": "slides/01/slides01.html#where-is-amanda-in-january",
    "title": "Welcome to Stat 220",
    "section": "Where is Amanda in January?",
    "text": "Where is Amanda in January?"
  },
  {
    "objectID": "slides/01/slides01.html#what-will-you-do-in-this-course",
    "href": "slides/01/slides01.html#what-will-you-do-in-this-course",
    "title": "Welcome to Stat 220",
    "section": "What will you do in this course?",
    "text": "What will you do in this course?\n\n\nGraded work:\n\nHomework\nLab Quizzes\nPortfolio Projects\nFinal Project\n\n\nUngraded work:\n\nDaily prep for class: read/watch/review/try\nIn-class exercises and group work\nEngagement in small and large group discussions"
  },
  {
    "objectID": "slides/01/slides01.html#what-will-a-typical-dayweek-look-like",
    "href": "slides/01/slides01.html#what-will-a-typical-dayweek-look-like",
    "title": "Welcome to Stat 220",
    "section": "What will a typical day/week look like?",
    "text": "What will a typical day/week look like?\n\n\nBefore class:\n\nWatch a video or read a chapter\nCome with questions\nBe prepared to try what was covered\n\n\nIn class:\n\nMini lecture\n\nSometimes review\nSometimes new\n\nHands-on coding in R\n\n\nAfter class:\n\nFinish any in-class exercises\nWork on homework and portfolio projects"
  },
  {
    "objectID": "slides/01/slides01.html#grading-system",
    "href": "slides/01/slides01.html#grading-system",
    "title": "Welcome to Stat 220",
    "section": "Grading system",
    "text": "Grading system\nHomework and lab quiz problems will be graded as successful or not successful. Projects will be graded as excellent, successful, or retry. You will have the opportunity to resubmit the lab quizzes outside of class.\nTo earn a course grade, you must meet all of the requirements in a given row:\n\n\n\n\n\n\n\n\n\n\n\nHomework Problems\nLab Quiz Problems\nPortfolio Projects (4 total)\nFinal Project\n\n\n\n\nA\n85%\n90%\n2 Excellent\nExcellent\n\n\nB\n75%\n80%\n4 Successful\nSuccessful\n\n\nC\n65%\n70%\n3 Successful\nSuccessful\n\n\nD\n55%\n50%\n2 Successful\nSuccessful\n\n\n\n“+” and “-” grades are determined by partially meeting the requirements in a given row."
  },
  {
    "objectID": "slides/01/slides01.html#benefits",
    "href": "slides/01/slides01.html#benefits",
    "title": "Welcome to Stat 220",
    "section": "Benefits",
    "text": "Benefits\n\nYou decide what grade you’re aiming for, and what you have to do to earn it\nClear guidelines for “successful” and “excellent” marks\nOpportunity to revise and resubmit"
  },
  {
    "objectID": "slides/01/slides01.html#possible-drawbacks",
    "href": "slides/01/slides01.html#possible-drawbacks",
    "title": "Welcome to Stat 220",
    "section": "Possible drawbacks",
    "text": "Possible drawbacks\n\nNo partial credit!\nRevisions take time\nCategories don’t “average out”"
  },
  {
    "objectID": "slides/01/slides01.html#tokens",
    "href": "slides/01/slides01.html#tokens",
    "title": "Welcome to Stat 220",
    "section": "Tokens",
    "text": "Tokens\nYou can use a token to:\n\nRevise a portfolio project that did not earn a “successful”\n72-hour extension on a homework assignment (the request must be submitted before the deadline)\n72-hour extension on lab quiz resubmissions (the request must be submitted before the deadline)\nBy passing the syllabus quiz, you’ll activate your 5 tokens for the term. I will track token balances in the moodle gradebook (updated weekly)"
  },
  {
    "objectID": "slides/01/slides01.html#collaboration-policy",
    "href": "slides/01/slides01.html#collaboration-policy",
    "title": "Welcome to Stat 220",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\n\n\n\n\n\n\n\nCollaboration Allowed\n\n\n\n\nHomework Problems\nYou are allowed and encouraged to collaborate on homework. You may also use outside resources, but your submitted work must be your own and reflect your own understanding .\n\n\nLab Quiz Problems\nNo collaboration is allowed at all . You may use your own notes for resubmissions, but should not use outside resources.\n\n\nPortfolio Projects\nYou are expected to collaborate with your group, but cannot rely on external sources other than to help motivate the questions or provide other background information. Getting answers on significant parts of solutions from outside resources is not allowed.\n\n\nFinal Project\nYou are expected to collaborate with your group, but cannot rely on external sources other than to help motivate the questions or provide other background information. Any outside resources should be properly cited."
  },
  {
    "objectID": "slides/01/slides01.html#use-of-generative-artificial-intelligence-ai",
    "href": "slides/01/slides01.html#use-of-generative-artificial-intelligence-ai",
    "title": "Welcome to Stat 220",
    "section": "Use of generative artificial intelligence (AI)",
    "text": "Use of generative artificial intelligence (AI)\n\nTreat generative AI, such as ChatGPT or Gemini, the same as other online resources.\nGuiding principles:\n\n(1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. AI should facilitate—rather than hinder—learning.\n(2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n❌ AI tools for writing code: You may not use generative AI to take a “first pass” at a coding task. Do not type coursework prompts directly into AI tools.\n✅ AI tools for debugging code: You may make use of the technology to get help with error messages or trying to fix issues\n❌ AI tools for narrative: Unless instructed otherwise, you may not use generative AI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you.\n\n\n\nAdapted from Mine Çetinkaya-Rundel"
  },
  {
    "objectID": "slides/01/slides01.html#tools",
    "href": "slides/01/slides01.html#tools",
    "title": "Welcome to Stat 220",
    "section": "Tools",
    "text": "Tools\n\nhttps://maize.mathcs.carleton.edu\n\n\nBrowser based RStudio instance(s) provided by Carleton\nRequires internet connection to access\nProvides consistency in hardware and software environments\nLocal R installations are also fine! But it may be harder for me to provide support"
  },
  {
    "objectID": "slides/01/slides01.html#github",
    "href": "slides/01/slides01.html#github",
    "title": "Welcome to Stat 220",
    "section": "GitHub",
    "text": "GitHub\n\nhttps://github.com/stat220-w25\n\n\nGitHub organization for the course\nAll of your work and your membership (enrollment) in the organization is private\nEach assignment is a private repo on GitHub, I distribute the assignments on GitHub.\nYou will work on your assignment, then “knit 🧶 commit ✅ push ⤴️”\nYou’ll then be able to submit your PDF via gradescope\n\n\n\nFill out the Welcome Survey for collection of your account names, later this week you will be invited to the course organization."
  },
  {
    "objectID": "slides/01/slides01.html#username-advice",
    "href": "slides/01/slides01.html#username-advice",
    "title": "Welcome to Stat 220",
    "section": "Username advice",
    "text": "Username advice\n\nin case you don’t yet have a GitHub account…\n\nSome brief advice about selecting your account names (particularly for GitHub),\n\nIncorporate your actual name! People like to know who they’re dealing with and makes your username easier for people to guess or remember\nReuse your username from other contexts, e.g., Twitter or Slack\nPick a username you will be comfortable revealing to your future boss\nShorter is better than longer, but be as unique as possible\nMake it timeless. Avoid highlighting your current university, employer, or place of residence"
  },
  {
    "objectID": "slides/01/slides01.html#your-tasks-before-next-class",
    "href": "slides/01/slides01.html#your-tasks-before-next-class",
    "title": "Welcome to Stat 220",
    "section": "Your tasks before next class",
    "text": "Your tasks before next class\n\nCreate a GitHub account if you don’t have one\nComplete the welcome survey if you haven’t already\nRead the syllabus and pass syllabus quiz\nMake sure you can login in to the maize server or update your local R/RStudio versions\nComplete the readings for next class"
  },
  {
    "objectID": "slides/09/slides09.html#bakeoff-ratings",
    "href": "slides/09/slides09.html#bakeoff-ratings",
    "title": "Data Wrangling: Tidy Data",
    "section": "Bakeoff ratings",
    "text": "Bakeoff ratings\n\nRatings data for each episodes in series 1-8\n\n\n\n\n# A tibble: 8 × 11\n  series    e1    e2    e3    e4    e5    e6    e7    e8    e9   e10\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      1  2.24  3     3     2.6   3.03  2.75 NA    NA    NA    NA   \n2      2  3.1   3.53  3.82  3.6   3.83  4.25  4.42  5.06 NA    NA   \n3      3  3.85  4.6   4.53  4.71  4.61  4.82  5.1   5.35  5.7   6.74\n4      4  6.6   6.65  7.17  6.82  6.95  7.32  7.76  7.41  7.41  9.45\n5      5  8.51  8.79  9.28 10.2   9.95 10.1  10.3   9.02 10.7  13.5 \n6      6 11.6  11.6  12.0  12.4  12.4  12    12.4  11.1  12.6  15.0 \n7      7 13.6  13.4  13.0  13.3  13.1  13.1  13.4  13.3  13.4  15.9 \n8      8  9.46  9.23  8.68  8.55  8.61  8.61  9.01  8.95  9.03 10.0 \n\n\n\n\n\nSource: bakeoff R package"
  },
  {
    "objectID": "slides/09/slides09.html#warm-up",
    "href": "slides/09/slides09.html#warm-up",
    "title": "Data Wrangling: Tidy Data",
    "section": "Warm up",
    "text": "Warm up\n\nIs this dataset in tidy format? Why or why not?\nIf not, what would a tidy data set look like? Sketch out the first few rows of this data set in tidy format\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/09/slides09.html#section-3",
    "href": "slides/09/slides09.html#section-3",
    "title": "Data Wrangling: Tidy Data",
    "section": "",
    "text": "Reshape the layout of tabular data\nPart of the tidyverse"
  },
  {
    "objectID": "slides/09/slides09.html#goal",
    "href": "slides/09/slides09.html#goal",
    "title": "Data Wrangling: Tidy Data",
    "section": "Goal",
    "text": "Goal\nWant to reshape the data to be in tidy format:\n\nCurrentTarget\n\n\n\n\n# A tibble: 8 × 11\n  series    e1    e2    e3    e4    e5    e6    e7    e8    e9   e10\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      1  2.24  3     3     2.6   3.03  2.75 NA    NA    NA    NA   \n2      2  3.1   3.53  3.82  3.6   3.83  4.25  4.42  5.06 NA    NA   \n3      3  3.85  4.6   4.53  4.71  4.61  4.82  5.1   5.35  5.7   6.74\n4      4  6.6   6.65  7.17  6.82  6.95  7.32  7.76  7.41  7.41  9.45\n5      5  8.51  8.79  9.28 10.2   9.95 10.1  10.3   9.02 10.7  13.5 \n6      6 11.6  11.6  12.0  12.4  12.4  12    12.4  11.1  12.6  15.0 \n7      7 13.6  13.4  13.0  13.3  13.1  13.1  13.4  13.3  13.4  15.9 \n8      8  9.46  9.23  8.68  8.55  8.61  8.61  9.01  8.95  9.03 10.0 \n\n\n\n\n\n\n# A tibble: 80 × 3\n   series epsiode rating\n    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1      1 e1        2.24\n 2      1 e2        3   \n 3      1 e3        3   \n 4      1 e4        2.6 \n 5      1 e5        3.03\n 6      1 e6        2.75\n 7      1 e7       NA   \n 8      1 e8       NA   \n 9      1 e9       NA   \n10      1 e10      NA   \n# ℹ 70 more rows"
  },
  {
    "objectID": "slides/09/slides09.html#pivot_longer",
    "href": "slides/09/slides09.html#pivot_longer",
    "title": "Data Wrangling: Tidy Data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\n\n\ndata (as usual)\n\n\n\npivot_longer(\n  data, \n  cols, \n  names_to = \"name\", \n  values_to = \"value\"\n  )"
  },
  {
    "objectID": "slides/09/slides09.html#pivot_longer-1",
    "href": "slides/09/slides09.html#pivot_longer-1",
    "title": "Data Wrangling: Tidy Data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\n\n\ndata (as usual)\ncols: columns to pivot into longer format\n\n\n\npivot_longer(\n  data, \n  cols, \n  names_to = \"name\", \n  values_to = \"value\"\n  )"
  },
  {
    "objectID": "slides/09/slides09.html#pivot_longer-2",
    "href": "slides/09/slides09.html#pivot_longer-2",
    "title": "Data Wrangling: Tidy Data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\n\n\ndata (as usual)\ncols: columns to pivot into longer format\nnames_to: name of the column where column names of pivoted variables go (character string)\n\n\n\npivot_longer(\n  data, \n  cols, \n  names_to = \"name\", \n  values_to = \"value\"\n  )"
  },
  {
    "objectID": "slides/09/slides09.html#pivot_longer-3",
    "href": "slides/09/slides09.html#pivot_longer-3",
    "title": "Data Wrangling: Tidy Data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\n\n\ndata (as usual)\ncols: columns to pivot into longer format\nnames_to: name of the column where column names of pivoted variables go (character string)\nvalues_to: name of the column where data in pivoted variables go (character string)\n\n\n\npivot_longer(\n  data, \n  cols, \n  names_to = \"name\", \n  values_to = \"value\"\n  )"
  },
  {
    "objectID": "slides/09/slides09.html#wider-rightarrow-longer-ratings",
    "href": "slides/09/slides09.html#wider-rightarrow-longer-ratings",
    "title": "Data Wrangling: Tidy Data",
    "section": "wider \\(\\rightarrow\\) longer ratings",
    "text": "wider \\(\\rightarrow\\) longer ratings\n\n\nlonger_ratings &lt;- bakeoff_ratings %&gt;%\n  pivot_longer( \n    cols = e1:e10, \n    names_to = \"episode\", \n    values_to = \"rating\" \n  )\nlonger_ratings\n\n\n# A tibble: 80 × 3\n   series episode rating\n    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1      1 e1        2.24\n 2      1 e2        3   \n 3      1 e3        3   \n 4      1 e4        2.6 \n 5      1 e5        3.03\n 6      1 e6        2.75\n 7      1 e7       NA   \n 8      1 e8       NA   \n 9      1 e9       NA   \n10      1 e10      NA   \n# ℹ 70 more rows"
  },
  {
    "objectID": "slides/09/slides09.html#parse_number",
    "href": "slides/09/slides09.html#parse_number",
    "title": "Data Wrangling: Tidy Data",
    "section": "parse_number()",
    "text": "parse_number()\n\n\nratings &lt;- longer_ratings %&gt;%\n  mutate(\n    episode = parse_number(episode) \n  )\nratings\n\n\n# A tibble: 80 × 3\n   series episode rating\n    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1      1       1   2.24\n 2      1       2   3   \n 3      1       3   3   \n 4      1       4   2.6 \n 5      1       5   3.03\n 6      1       6   2.75\n 7      1       7  NA   \n 8      1       8  NA   \n 9      1       9  NA   \n10      1      10  NA   \n# ℹ 70 more rows"
  },
  {
    "objectID": "slides/09/slides09.html#other-parsing-functions",
    "href": "slides/09/slides09.html#other-parsing-functions",
    "title": "Data Wrangling: Tidy Data",
    "section": "Other parsing functions",
    "text": "Other parsing functions\n\n\nparse_character\nparse_date\nparse_double\nparse_double\nparse_factor\n\nparse_integer\nparse_logical\nparse_number\nparse_time\n\n\n\nThe parse_* functions are from readr"
  },
  {
    "objectID": "slides/09/slides09.html#try-it-messy_ratings",
    "href": "slides/09/slides09.html#try-it-messy_ratings",
    "title": "Data Wrangling: Tidy Data",
    "section": "Try it: messy_ratings",
    "text": "Try it: messy_ratings\nTidy this data set by\n\nSelecting the series and e*_7day columns\nPivoting the data to add a column for episode and a column for rating (we’ll clean up the episode column later)\n\n\n\n# A tibble: 8 × 21\n  series e1_7day e1_28day e2_7day e2_28day e3_7day e3_28day e4_7day e4_28day\n   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1      1    2.24    NA       3       NA       3       NA       2.6     NA   \n2      2    3.1     NA       3.53    NA       3.82    NA       3.6     NA   \n3      3    3.85    NA       4.6     NA       4.53    NA       4.71    NA   \n4      4    6.6     NA       6.65    NA       7.17    NA       6.82    NA   \n5      5    8.51    NA       8.79    NA       9.28    NA      10.2     NA   \n6      6   11.6     11.7    11.6     11.8    12.0     NA      12.4     12.7 \n7      7   13.6     13.9    13.4     13.7    13.0     13.4    13.3     13.9 \n8      8    9.46     9.72    9.23     9.53    8.68     9.06    8.55     8.87\n# ℹ 12 more variables: e5_7day &lt;dbl&gt;, e5_28day &lt;dbl&gt;, e6_7day &lt;dbl&gt;,\n#   e6_28day &lt;dbl&gt;, e7_7day &lt;dbl&gt;, e7_28day &lt;dbl&gt;, e8_7day &lt;dbl&gt;,\n#   e8_28day &lt;dbl&gt;, e9_7day &lt;dbl&gt;, e9_28day &lt;dbl&gt;, e10_7day &lt;dbl&gt;,\n#   e10_28day &lt;dbl&gt;\n\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/09/slides09.html#cleaning-episode",
    "href": "slides/09/slides09.html#cleaning-episode",
    "title": "Data Wrangling: Tidy Data",
    "section": "Cleaning episode",
    "text": "Cleaning episode\n\n\nratings2 &lt;- messy_ratings2 %&gt;%\n  select(series, contains(\"7day\")) %&gt;%\n  pivot_longer(contains(\"7day\"), \n               names_to = \"episode\", \n               values_to = \"rating\")\nratings2\n\n\n# A tibble: 80 × 3\n   series episode  rating\n    &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1      1 e1_7day    2.24\n 2      1 e2_7day    3   \n 3      1 e3_7day    3   \n 4      1 e4_7day    2.6 \n 5      1 e5_7day    3.03\n 6      1 e6_7day    2.75\n 7      1 e7_7day   NA   \n 8      1 e8_7day   NA   \n 9      1 e9_7day   NA   \n10      1 e10_7day  NA   \n# ℹ 70 more rows"
  },
  {
    "objectID": "slides/09/slides09.html#separate",
    "href": "slides/09/slides09.html#separate",
    "title": "Data Wrangling: Tidy Data",
    "section": "separate()",
    "text": "separate()\n\n\n\ndata (as usual)\n\n\n\nseparate(\n  data, \n  col, \n  into = c(\"col1\", \"col2\"),\n  sep \n  )"
  },
  {
    "objectID": "slides/09/slides09.html#separate-1",
    "href": "slides/09/slides09.html#separate-1",
    "title": "Data Wrangling: Tidy Data",
    "section": "separate()",
    "text": "separate()\n\n\n\ndata (as usual)\ncol: column to separate\n\n\n\nseparate(\n  data, \n  col, \n  into = c(\"col1\", \"col2\"),\n  sep \n  )"
  },
  {
    "objectID": "slides/09/slides09.html#separate-2",
    "href": "slides/09/slides09.html#separate-2",
    "title": "Data Wrangling: Tidy Data",
    "section": "separate()",
    "text": "separate()\n\n\n\ndata (as usual)\ncol: column to separate\ninto: names of new columns to create\n\n\n\nseparate(\n  data, \n  col, \n  into = c(\"col1\", \"col2\"),\n  sep \n  )"
  },
  {
    "objectID": "slides/09/slides09.html#separate-3",
    "href": "slides/09/slides09.html#separate-3",
    "title": "Data Wrangling: Tidy Data",
    "section": "separate()",
    "text": "separate()\n\n\n\ndata (as usual)\ncol: column to separate\ninto: names of new columns to create\nsep: separator between columns\n\n\n\nseparate(\n  data, \n  col, \n  into = c(\"col1\", \"col2\"),\n  sep \n  )"
  },
  {
    "objectID": "slides/09/slides09.html#cleaning-episode-1",
    "href": "slides/09/slides09.html#cleaning-episode-1",
    "title": "Data Wrangling: Tidy Data",
    "section": "Cleaning episode",
    "text": "Cleaning episode\n\n\nratings2 %&gt;%\n  separate( \n    col = episode, \n    into = c(\"episode\", \"period\") \n  )\n\n\n# A tibble: 80 × 4\n   series episode period rating\n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n 1      1 e1      7day     2.24\n 2      1 e2      7day     3   \n 3      1 e3      7day     3   \n 4      1 e4      7day     2.6 \n 5      1 e5      7day     3.03\n 6      1 e6      7day     2.75\n 7      1 e7      7day    NA   \n 8      1 e8      7day    NA   \n 9      1 e9      7day    NA   \n10      1 e10     7day    NA   \n# ℹ 70 more rows"
  },
  {
    "objectID": "slides/09/slides09.html#wrap-it-up",
    "href": "slides/09/slides09.html#wrap-it-up",
    "title": "Data Wrangling: Tidy Data",
    "section": "Wrap it up",
    "text": "Wrap it up\n\n\nClean the episode and period column\nMake a line plot with episode on the x-axis, rating on the y-axis, colored by series. (You will also need to map the group aesthetic to series)"
  },
  {
    "objectID": "slides/21/slides21.html#read-html-into-r",
    "href": "slides/21/slides21.html#read-html-into-r",
    "title": "Web Scraping II",
    "section": "Read HTML into R",
    "text": "Read HTML into R\n\npage &lt;- read_html(\"https://www.boxofficemojo.com/year/2024/\")\npage\n\n{html_document}\n&lt;html class=\"a-no-js\" data-19ax5a9jf=\"dingo\"&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body id=\"body\" class=\"mojo-page-id-yld a-m-us a-aui_72554-c a-aui_a11y_6 ...\n\nstr(page)\n\nList of 2\n $ node:&lt;externalptr&gt; \n $ doc :&lt;externalptr&gt; \n - attr(*, \"class\")= chr [1:2] \"xml_document\" \"xml_node\""
  },
  {
    "objectID": "slides/21/slides21.html#extract-tables",
    "href": "slides/21/slides21.html#extract-tables",
    "title": "Web Scraping II",
    "section": "Extract tables",
    "text": "Extract tables\nUse html_element() or html_elements() to extract pieces out of HTML documents\n\ntables &lt;- page %&gt;% html_elements(\"table\")\nstr(tables)\n\nList of 1\n $ :List of 2\n  ..$ node:&lt;externalptr&gt; \n  ..$ doc :&lt;externalptr&gt; \n  ..- attr(*, \"class\")= chr \"xml_node\"\n - attr(*, \"class\")= chr \"xml_nodeset\""
  },
  {
    "objectID": "slides/21/slides21.html#parse-a-table-into-a-data-frametibble",
    "href": "slides/21/slides21.html#parse-a-table-into-a-data-frametibble",
    "title": "Web Scraping II",
    "section": "Parse a table into a data frame/tibble",
    "text": "Parse a table into a data frame/tibble\n\ntop2024 &lt;- html_table(tables[[1]])\nglimpse(top2024)\n\nRows: 200\nColumns: 11\n$ Rank           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ Release        &lt;chr&gt; \"Inside Out 2\", \"Deadpool & Wolverine\", \"Wicked\", \"Moan…\n$ Genre          &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ Budget         &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Running Time` &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ Gross          &lt;chr&gt; \"$652,980,194\", \"$636,745,858\", \"$432,943,285\", \"$404,0…\n$ Theaters       &lt;chr&gt; \"4,440\", \"4,330\", \"3,888\", \"4,200\", \"4,449\", \"4,575\", \"…\n$ `Total Gross`  &lt;chr&gt; \"$652,980,194\", \"$636,745,858\", \"$471,274,200\", \"$454,5…\n$ `Release Date` &lt;chr&gt; \"Jun 14\", \"Jul 26\", \"Nov 22\", \"Nov 27\", \"Jul 3\", \"Sep 6…\n$ Distributor    &lt;chr&gt; \"Walt Disney Studios Motion Pictures\", \"Walt Disney Stu…\n$ Estimated      &lt;chr&gt; \"false\", \"false\", \"false\", \"false\", \"false\", \"false\", \"…"
  },
  {
    "objectID": "slides/21/slides21.html#scrape-then-wrangle",
    "href": "slides/21/slides21.html#scrape-then-wrangle",
    "title": "Web Scraping II",
    "section": "Scrape then wrangle",
    "text": "Scrape then wrangle\n\ntop2024 &lt;- top2024 %&gt;%\n  mutate(\n    Gross = parse_number(Gross),\n    Theaters = parse_number(Theaters),\n    `Total Gross` = parse_number(`Total Gross`)\n  ) %&gt;%\n  separate(`Release Date`, into = c(\"Month\", \"Day\"))\n\nglimpse(top2024)\n\nRows: 200\nColumns: 12\n$ Rank           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ Release        &lt;chr&gt; \"Inside Out 2\", \"Deadpool & Wolverine\", \"Wicked\", \"Moan…\n$ Genre          &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ Budget         &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Running Time` &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ Gross          &lt;dbl&gt; 652980194, 636745858, 432943285, 404017489, 361004205, …\n$ Theaters       &lt;dbl&gt; 4440, 4330, 3888, 4200, 4449, 4575, 4074, 4170, 3948, 4…\n$ `Total Gross`  &lt;dbl&gt; 652980194, 636745858, 471274200, 454574310, 361004205, …\n$ Month          &lt;chr&gt; \"Jun\", \"Jul\", \"Nov\", \"Nov\", \"Jul\", \"Sep\", \"Mar\", \"Jul\",…\n$ Day            &lt;chr&gt; \"14\", \"26\", \"22\", \"27\", \"3\", \"6\", \"1\", \"19\", \"29\", \"8\",…\n$ Distributor    &lt;chr&gt; \"Walt Disney Studios Motion Pictures\", \"Walt Disney Stu…\n$ Estimated      &lt;chr&gt; \"false\", \"false\", \"false\", \"false\", \"false\", \"false\", \"…"
  },
  {
    "objectID": "slides/21/slides21.html#data-arent-always-stored-as-tables",
    "href": "slides/21/slides21.html#data-arent-always-stored-as-tables",
    "title": "Web Scraping II",
    "section": "Data aren’t always stored as tables",
    "text": "Data aren’t always stored as tables\nhttps://www.carleton.edu/catalog/current/search/?subject=STAT&term=25WI"
  },
  {
    "objectID": "slides/21/slides21.html#where-is-the-data-stored",
    "href": "slides/21/slides21.html#where-is-the-data-stored",
    "title": "Web Scraping II",
    "section": "Where is the data stored?",
    "text": "Where is the data stored?\n\nView the page source to try to find the html elements where this data is located (e.g. ‘h1’, ‘p’, ‘table’)\n\nCourse number\nCourse title\nCourse description\nCourse meetings\nFaculty\nCourse meetings\n\n\n\n\n\n\n−&plus;\n\n03:00"
  },
  {
    "objectID": "slides/21/slides21.html#section",
    "href": "slides/21/slides21.html#section",
    "title": "Web Scraping II",
    "section": "",
    "text": "listings = read_html(\"https://www.carleton.edu/catalog/current/search/?subject=STAT&term=25WI\")\n\n\nlistings |&gt;\n  html_elements(\"h3\")\n\n{xml_nodeset (22)}\n [1] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;STAT ...\n [2] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;STAT ...\n [3] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;STAT ...\n [4] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;STAT ...\n [5] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;STAT ...\n [6] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;STAT ...\n [7] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;STAT ...\n [8] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;STAT ...\n [9] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;STAT ...\n[10] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;STAT ...\n[11] &lt;h3 class=\"courseSearchResultsHeading relatedCourses\" id=\"relatedCourses ...\n[12] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;CS 1 ...\n[13] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;CS 3 ...\n[14] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;MATH ...\n[15] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;MATH ...\n[16] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;MATH ...\n[17] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;MATH ...\n[18] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;MATH ...\n[19] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;MATH ...\n[20] &lt;h3 class=\"courseTitleBar\"&gt;\\n            &lt;span class=\"courseNumber\"&gt;MATH ...\n..."
  },
  {
    "objectID": "slides/21/slides21.html#section-1",
    "href": "slides/21/slides21.html#section-1",
    "title": "Web Scraping II",
    "section": "",
    "text": "listings |&gt;\n  html_elements(\"h3\") |&gt;\n  html_text()\n\n [1] \"\\n            STAT 120\\n            Introduction to Statistics\\n            \\n                            6 credits\\n                        \\n        \"                                   \n [2] \"\\n            STAT 220\\n            Introduction to Data Science\\n            \\n                            6 credits\\n                        \\n        \"                                 \n [3] \"\\n            STAT 230\\n            Applied Regression Analysis\\n            \\n                            6 credits\\n                        \\n        \"                                  \n [4] \"\\n            STAT 250\\n            Introduction to Statistical Inference\\n            \\n                            6 credits\\n                        \\n        \"                        \n [5] \"\\n            STAT 285\\n            Statistical Consulting\\n            \\n                            2 credits\\n                        \\n        \"                                       \n [6] \"\\n            STAT 297\\n            Assessment and Communication of External Statistical Activity\\n            \\n                            1 credits\\n                        \\n        \"\n [7] \"\\n            STAT 330\\n            Advanced Statistical Modeling\\n            \\n                            6 credits\\n                        \\n        \"                                \n [8] \"\\n            STAT 394\\n            Directed Research in Statistics\\n            \\n                            1 – 6 credits\\n                        \\n        \"                          \n [9] \"\\n            STAT 399\\n            Senior Seminar\\n            \\n                            6 credits\\n                        \\n        \"                                               \n[10] \"\\n            STAT 400\\n            Integrative Exercise\\n            \\n                            3 – 6 credits\\n                        \\n        \"                                     \n[11] \"Related Courses\"                                                                                                                                                                           \n[12] \"\\n            CS 111\\n            Introduction to Computer Science\\n            \\n                            6 credits\\n                        \\n        \"                               \n[13] \"\\n            CS 314\\n            Data Visualization\\n            \\n                            6 credits\\n                        \\n        \"                                             \n[14] \"\\n            MATH 101\\n            Calculus with Problem Solving\\n            \\n                            6 credits\\n                        \\n        \"                                \n[15] \"\\n            MATH 111\\n            Introduction to Calculus\\n            \\n                            6 credits\\n                        \\n        \"                                     \n[16] \"\\n            MATH 120\\n            Calculus 2\\n            \\n                            6 credits\\n                        \\n        \"                                                   \n[17] \"\\n            MATH 210\\n            Calculus 3\\n            \\n                            6 credits\\n                        \\n        \"                                                   \n[18] \"\\n            MATH 211\\n            Introduction to Multivariable Calculus\\n            \\n                            6 credits\\n                        \\n        \"                       \n[19] \"\\n            MATH 232\\n            Linear Algebra\\n            \\n                            6 credits\\n                        \\n        \"                                               \n[20] \"\\n            MATH 240\\n            Probability\\n            \\n                            6 credits\\n                        \\n        \"                                                  \n[21] \"Liberal Arts Requirements\"                                                                                                                                                                 \n[22] \"Other Course Tags\""
  },
  {
    "objectID": "slides/21/slides21.html#section-2",
    "href": "slides/21/slides21.html#section-2",
    "title": "Web Scraping II",
    "section": "",
    "text": "listings |&gt;\n  html_elements(\"h3\") |&gt;\n  html_text() |&gt; \n  str_squish()\n\n [1] \"STAT 120 Introduction to Statistics 6 credits\"                                   \n [2] \"STAT 220 Introduction to Data Science 6 credits\"                                 \n [3] \"STAT 230 Applied Regression Analysis 6 credits\"                                  \n [4] \"STAT 250 Introduction to Statistical Inference 6 credits\"                        \n [5] \"STAT 285 Statistical Consulting 2 credits\"                                       \n [6] \"STAT 297 Assessment and Communication of External Statistical Activity 1 credits\"\n [7] \"STAT 330 Advanced Statistical Modeling 6 credits\"                                \n [8] \"STAT 394 Directed Research in Statistics 1 – 6 credits\"                          \n [9] \"STAT 399 Senior Seminar 6 credits\"                                               \n[10] \"STAT 400 Integrative Exercise 3 – 6 credits\"                                     \n[11] \"Related Courses\"                                                                 \n[12] \"CS 111 Introduction to Computer Science 6 credits\"                               \n[13] \"CS 314 Data Visualization 6 credits\"                                             \n[14] \"MATH 101 Calculus with Problem Solving 6 credits\"                                \n[15] \"MATH 111 Introduction to Calculus 6 credits\"                                     \n[16] \"MATH 120 Calculus 2 6 credits\"                                                   \n[17] \"MATH 210 Calculus 3 6 credits\"                                                   \n[18] \"MATH 211 Introduction to Multivariable Calculus 6 credits\"                       \n[19] \"MATH 232 Linear Algebra 6 credits\"                                               \n[20] \"MATH 240 Probability 6 credits\"                                                  \n[21] \"Liberal Arts Requirements\"                                                       \n[22] \"Other Course Tags\""
  },
  {
    "objectID": "slides/21/slides21.html#selecting-coursenumber-class",
    "href": "slides/21/slides21.html#selecting-coursenumber-class",
    "title": "Web Scraping II",
    "section": "Selecting courseNumber class",
    "text": "Selecting courseNumber class\nCourse numbers are between &lt;span class=\"courseNumber\"&gt; ... &lt;/span&gt; tags\nThese tags can be selected using . followed by the name of the class\n\nlistings %&gt;% \n  html_elements(\".courseNumber\")\n\n{xml_nodeset (19)}\n [1] &lt;span class=\"courseNumber\"&gt;STAT 120&lt;/span&gt;\n [2] &lt;span class=\"courseNumber\"&gt;STAT 220&lt;/span&gt;\n [3] &lt;span class=\"courseNumber\"&gt;STAT 230&lt;/span&gt;\n [4] &lt;span class=\"courseNumber\"&gt;STAT 250&lt;/span&gt;\n [5] &lt;span class=\"courseNumber\"&gt;STAT 285&lt;/span&gt;\n [6] &lt;span class=\"courseNumber\"&gt;STAT 297&lt;/span&gt;\n [7] &lt;span class=\"courseNumber\"&gt;STAT 330&lt;/span&gt;\n [8] &lt;span class=\"courseNumber\"&gt;STAT 394&lt;/span&gt;\n [9] &lt;span class=\"courseNumber\"&gt;STAT 399&lt;/span&gt;\n[10] &lt;span class=\"courseNumber\"&gt;STAT 400&lt;/span&gt;\n[11] &lt;span class=\"courseNumber\"&gt;CS 111&lt;/span&gt;\n[12] &lt;span class=\"courseNumber\"&gt;CS 314&lt;/span&gt;\n[13] &lt;span class=\"courseNumber\"&gt;MATH 101&lt;/span&gt;\n[14] &lt;span class=\"courseNumber\"&gt;MATH 111&lt;/span&gt;\n[15] &lt;span class=\"courseNumber\"&gt;MATH 120&lt;/span&gt;\n[16] &lt;span class=\"courseNumber\"&gt;MATH 210&lt;/span&gt;\n[17] &lt;span class=\"courseNumber\"&gt;MATH 211&lt;/span&gt;\n[18] &lt;span class=\"courseNumber\"&gt;MATH 232&lt;/span&gt;\n[19] &lt;span class=\"courseNumber\"&gt;MATH 240&lt;/span&gt;"
  },
  {
    "objectID": "slides/21/slides21.html#scraping-coursenumbers",
    "href": "slides/21/slides21.html#scraping-coursenumbers",
    "title": "Web Scraping II",
    "section": "Scraping courseNumbers",
    "text": "Scraping courseNumbers\n\nlistings %&gt;% \n  html_elements(\".courseNumber\") %&gt;%\n  html_text()\n\n [1] \"STAT 120\" \"STAT 220\" \"STAT 230\" \"STAT 250\" \"STAT 285\" \"STAT 297\"\n [7] \"STAT 330\" \"STAT 394\" \"STAT 399\" \"STAT 400\" \"CS 111\"   \"CS 314\"  \n[13] \"MATH 101\" \"MATH 111\" \"MATH 120\" \"MATH 210\" \"MATH 211\" \"MATH 232\"\n[19] \"MATH 240\""
  },
  {
    "objectID": "slides/21/slides21.html#scraping-credits",
    "href": "slides/21/slides21.html#scraping-credits",
    "title": "Web Scraping II",
    "section": "Scraping credits",
    "text": "Scraping credits\n\nlistings %&gt;% \n  html_elements(\".credits\") %&gt;%\n  html_text()\n\n [1] \"\\n                            6 credits\\n                        \"    \n [2] \"\\n                            6 credits\\n                        \"    \n [3] \"\\n                            6 credits\\n                        \"    \n [4] \"\\n                            6 credits\\n                        \"    \n [5] \"\\n                            2 credits\\n                        \"    \n [6] \"\\n                            1 credits\\n                        \"    \n [7] \"\\n                            6 credits\\n                        \"    \n [8] \"\\n                            1 – 6 credits\\n                        \"\n [9] \"\\n                            6 credits\\n                        \"    \n[10] \"\\n                            3 – 6 credits\\n                        \"\n[11] \"\\n                            6 credits\\n                        \"    \n[12] \"\\n                            6 credits\\n                        \"    \n[13] \"\\n                            6 credits\\n                        \"    \n[14] \"\\n                            6 credits\\n                        \"    \n[15] \"\\n                            6 credits\\n                        \"    \n[16] \"\\n                            6 credits\\n                        \"    \n[17] \"\\n                            6 credits\\n                        \"    \n[18] \"\\n                            6 credits\\n                        \"    \n[19] \"\\n                            6 credits\\n                        \""
  },
  {
    "objectID": "slides/21/slides21.html#scraping-credits-1",
    "href": "slides/21/slides21.html#scraping-credits-1",
    "title": "Web Scraping II",
    "section": "Scraping credits",
    "text": "Scraping credits\n\nlistings %&gt;% \n  html_elements(\".credits\") %&gt;%\n  html_text() %&gt;%\n  str_squish()\n\n [1] \"6 credits\"     \"6 credits\"     \"6 credits\"     \"6 credits\"    \n [5] \"2 credits\"     \"1 credits\"     \"6 credits\"     \"1 – 6 credits\"\n [9] \"6 credits\"     \"3 – 6 credits\" \"6 credits\"     \"6 credits\"    \n[13] \"6 credits\"     \"6 credits\"     \"6 credits\"     \"6 credits\"    \n[17] \"6 credits\"     \"6 credits\"     \"6 credits\""
  },
  {
    "objectID": "slides/21/slides21.html#section-3",
    "href": "slides/21/slides21.html#section-3",
    "title": "Web Scraping II",
    "section": "",
    "text": "stat_winter2025 &lt;- tibble(\n  course = listings %&gt;% html_elements(\".courseNumber\") %&gt;% html_text(),\n  title = listings %&gt;% html_elements(\".courseTitle\") %&gt;% html_text(),\n  credits = listings %&gt;% html_elements(\".credits\") %&gt;% html_text() %&gt;% str_squish(),\n  description = listings %&gt;% html_elements(\".courseDetailWrapper\") %&gt;% html_text() %&gt;% str_squish()\n)\n\nstat_winter2025\n\n# A tibble: 19 × 4\n   course   title                                            credits description\n   &lt;chr&gt;    &lt;chr&gt;                                            &lt;chr&gt;   &lt;chr&gt;      \n 1 STAT 120 Introduction to Statistics                       6 cred… Introducti…\n 2 STAT 220 Introduction to Data Science                     6 cred… This cours…\n 3 STAT 230 Applied Regression Analysis                      6 cred… A second c…\n 4 STAT 250 Introduction to Statistical Inference            6 cred… Introducti…\n 5 STAT 285 Statistical Consulting                           2 cred… Students w…\n 6 STAT 297 Assessment and Communication of External Statis… 1 cred… An indepen…\n 7 STAT 330 Advanced Statistical Modeling                    6 cred… Topics inc…\n 8 STAT 394 Directed Research in Statistics                  1 – 6 … Students w…\n 9 STAT 399 Senior Seminar                                   6 cred… As part of…\n10 STAT 400 Integrative Exercise                             3 – 6 … Either a s…\n11 CS 111   Introduction to Computer Science                 6 cred… This cours…\n12 CS 314   Data Visualization                               6 cred… Understand…\n13 MATH 101 Calculus with Problem Solving                    6 cred… An introdu…\n14 MATH 111 Introduction to Calculus                         6 cred… An introdu…\n15 MATH 120 Calculus 2                                       6 cred… Inverse fu…\n16 MATH 210 Calculus 3                                       6 cred… Vectors, c…\n17 MATH 211 Introduction to Multivariable Calculus           6 cred… Vectors, c…\n18 MATH 232 Linear Algebra                                   6 cred… Linear alg…\n19 MATH 240 Probability                                      6 cred… Introducti…"
  },
  {
    "objectID": "slides/21/slides21.html#what-about-sections",
    "href": "slides/21/slides21.html#what-about-sections",
    "title": "Web Scraping II",
    "section": "What about sections?",
    "text": "What about sections?\n\nlistings %&gt;% \n  html_elements(\".course-section\") %&gt;%\n  html_element(\".courseSectionNumber\") %&gt;% \n  html_text() %&gt;% \n  str_squish()\n\n [1] \"STAT 120.01 Winter 2025\" \"STAT 120.02 Winter 2025\"\n [3] \"STAT 120.03 Winter 2025\" \"STAT 220.00 Winter 2025\"\n [5] \"STAT 230.00 Winter 2025\" \"STAT 250.00 Winter 2025\"\n [7] \"STAT 285.00 Winter 2025\" \"STAT 297.00 Winter 2025\"\n [9] \"STAT 330.00 Winter 2025\" \"STAT 394.11 Winter 2025\"\n[11] \"STAT 394.12 Winter 2025\" \"STAT 399.00 Winter 2025\"\n[13] \"STAT 400.01 Winter 2025\" \"STAT 400.02 Winter 2025\"\n[15] \"STAT 400.03 Winter 2025\" \"CS 111.01 Winter 2025\"  \n[17] \"CS 111.02 Winter 2025\"   \"CS 314.00 Winter 2025\"  \n[19] \"MATH 101.00 Winter 2025\" \"MATH 111.00 Winter 2025\"\n[21] \"MATH 120.01 Winter 2025\" \"MATH 120.02 Winter 2025\"\n[23] \"MATH 120.03 Winter 2025\" \"MATH 210.01 Winter 2025\"\n[25] \"MATH 210.02 Winter 2025\" \"MATH 211.00 Winter 2025\"\n[27] \"MATH 232.01 Winter 2025\" \"MATH 232.02 Winter 2025\"\n[29] \"MATH 240.00 Winter 2025\" \"MATH 240.02 Winter 2025\""
  },
  {
    "objectID": "slides/21/slides21.html#sometimes-we-cant-get-around-regex",
    "href": "slides/21/slides21.html#sometimes-we-cant-get-around-regex",
    "title": "Web Scraping II",
    "section": "Sometimes, we can’t get around regex :(",
    "text": "Sometimes, we can’t get around regex :(\n\nlistings %&gt;% \n  html_elements(\".classMeetings\") %&gt;% \n  html_text() %&gt;% \n  str_squish()\n\n [1] \"STAT 120.01 Winter 2025 Faculty:Claire Kelling 🏫 👤 Size:32 M, WCMC 102 11:10am-12:20pm FCMC 102 12:00pm-1:00pm Sophomore Priority; Not open to students who have already received credit for Psychology 200/201, Sociology/Anthropology 239 or Statistics 250 Sophomore Priority.\"\n [2] \"STAT 120.02 Winter 2025 Faculty:Spencer Wadsworth 🏫 👤 Size:32 M, WCMC 102 12:30pm-1:40pm FCMC 102 1:10pm-2:10pm\"                                                                                                                                                                  \n [3] \"STAT 120.03 Winter 2025 Faculty:Rebecca Terry 🏫 👤 Size:32 M, WCMC 102 1:50pm-3:00pm FCMC 102 2:20pm-3:20pm\"                                                                                                                                                                       \n [4] \"STAT 220.00 Winter 2025 Faculty:Amanda Luby 🏫 👤 Size:30 M, WCMC 102 9:50am-11:00am FCMC 102 9:40am-10:40am\"                                                                                                                                                                       \n [5] \"STAT 230.00 Winter 2025 Faculty:Claire Kelling 🏫 👤 Size:28 M, WCMC 306 1:50pm-3:00pm FCMC 306 2:20pm-3:20pm\"                                                                                                                                                                      \n [6] \"STAT 250.00 Winter 2025 Faculty:Adam Loy 🏫 👤 Size:28 M, WCMC 301 1:50pm-3:00pm FCMC 301 2:20pm-3:20pm\"                                                                                                                                                                            \n [7] \"STAT 285.00 Winter 2025 Faculty:Katie St. Clair 🏫 👤 Grading:S/CR/NC TCMC 304 10:10am-11:55am\"                                                                                                                                                                                     \n [8] \"STAT 297.00 Winter 2025 Faculty:Katie St. Clair 🏫 👤 · Claire Kelling 🏫 👤 Grading:S/CR/NC\"                                                                                                                                                                                       \n [9] \"STAT 330.00 Winter 2025 Faculty:Katie St. Clair 🏫 👤 Size:20 M, WCMC 306 9:50am-11:00am FCMC 306 9:40am-10:40am\"                                                                                                                                                                   \n[10] \"STAT 394.11 Winter 2025 Faculty:Claire Kelling 🏫 👤 Grading:S/CR/NC Credits:2\"                                                                                                                                                                                                     \n[11] \"STAT 394.12 Winter 2025 Faculty:Claire Kelling 🏫 👤 Grading:S/CR/NC\"                                                                                                                                                                                                               \n[12] \"STAT 399.00 Winter 2025 Faculty:Amanda Luby 🏫 👤 Size:4 Grading:S/CR/NC THCMC 328 10:10am-11:55am\"                                                                                                                                                                                 \n[13] \"STAT 400.01 Winter 2025 Faculty:Katie St. Clair 🏫 👤 Size:10 Grading:S/NC Credits:6\"                                                                                                                                                                                               \n[14] \"STAT 400.02 Winter 2025 Faculty:Adam Loy 🏫 👤 Size:12 Grading:S/NC Credits:3 T, THCMC 304 1:15pm-3:00pm\"                                                                                                                                                                           \n[15] \"STAT 400.03 Winter 2025 Faculty:Katie St. Clair 🏫 👤 Size:8 Grading:S/NC Credits:3 TCMC 328 1:15pm-3:00pm\"                                                                                                                                                                         \n[16] \"CS 111.01 Winter 2025 Faculty:Tom Finzell 🏫 👤 Size:38 M, WOlin 310 8:30am-9:40am FOlin 310 8:30am-9:30am\"                                                                                                                                                                         \n[17] \"CS 111.02 Winter 2025 Faculty:Tom Finzell 🏫 👤 Size:38 M, WOlin 310 11:10am-12:20pm FOlin 310 12:00pm-1:00pm Sophomore Priority Sophomore Priority.\"                                                                                                                               \n[18] \"CS 314.00 Winter 2025 Faculty:Bridger Herman 🏫 👤 Size:34 M, WLeighton 304 12:30pm-1:40pm FLeighton 304 1:10pm-2:10pm\"                                                                                                                                                             \n[19] \"MATH 101.00 Winter 2025 Faculty:Deanna Haunsperger 🏫 👤 Size:30 M, WCMC 209 9:50am-11:00am FCMC 209 9:40am-10:40am\"                                                                                                                                                                \n[20] \"MATH 111.00 Winter 2025 Faculty:Rob Thompson 🏫 👤 Size:30 M, WCMC 210 11:10am-12:20pm FCMC 210 12:00pm-1:00pm\"                                                                                                                                                                     \n[21] \"MATH 120.01 Winter 2025 Faculty:Rebecca Terry 🏫 👤 Size:30 M, WCMC 301 11:10am-12:20pm FCMC 301 12:00pm-1:00pm\"                                                                                                                                                                    \n[22] \"MATH 120.02 Winter 2025 Faculty:Corey Brooke 🏫 👤 Size:30 M, WCMC 210 12:30pm-1:40pm FCMC 210 1:10pm-2:10pm\"                                                                                                                                                                       \n[23] \"MATH 120.03 Winter 2025 Faculty:Mike Adams 🏫 👤 Size:30 M, WCMC 209 1:50pm-3:00pm FCMC 209 2:20pm-3:20pm\"                                                                                                                                                                          \n[24] \"MATH 210.01 Winter 2025 Faculty:Corey Brooke 🏫 👤 Size:30 M, WCMC 210 9:50am-11:00am FCMC 210 9:40am-10:40am\"                                                                                                                                                                      \n[25] \"MATH 210.02 Winter 2025 Faculty:Caroline Turnage-Butterbaugh 🏫 👤 Size:30 M, WCMC 209 11:10am-12:20pm FCMC 209 12:00pm-1:00pm\"                                                                                                                                                     \n[26] \"MATH 211.00 Winter 2025 Faculty:Kate Meyer 🏫 👤 Size:30 M, WCMC 206 8:30am-9:40am FCMC 206 8:30am-9:30am\"                                                                                                                                                                          \n[27] \"MATH 232.01 Winter 2025 Faculty:Rafe Jones 🏫 👤 Size:30 M, WCMC 206 11:10am-12:20pm FCMC 206 12:00pm-1:00pm\"                                                                                                                                                                       \n[28] \"MATH 232.02 Winter 2025 Faculty:MurphyKate Montee 🏫 👤 Size:30 M, WCMC 209 12:30pm-1:40pm FCMC 209 1:10pm-2:10pm\"                                                                                                                                                                  \n[29] \"MATH 240.00 Winter 2025 Faculty:Adam Loy 🏫 👤 Size:30 M, WCMC 306 12:30pm-1:40pm FCMC 306 1:10pm-2:10pm\"                                                                                                                                                                           \n[30] \"MATH 240.02 Winter 2025 Faculty:Rob Thompson 🏫 👤 Size:30 M, WCMC 301 12:30pm-1:40pm FCMC 301 1:10pm-2:10pm\""
  },
  {
    "objectID": "slides/21/slides21.html#selectorgadget",
    "href": "slides/21/slides21.html#selectorgadget",
    "title": "Web Scraping II",
    "section": "selectorGadget",
    "text": "selectorGadget\n\n\n\nOpen source tool that eases CSS selector generation and discovery\nEasiest to use with the Chrome Extension\nFind out more on the SelectorGadget vignette"
  },
  {
    "objectID": "slides/21/slides21.html#selectorgadget-1",
    "href": "slides/21/slides21.html#selectorgadget-1",
    "title": "Web Scraping II",
    "section": "selectorGadget",
    "text": "selectorGadget\n\n\n\nClick on the app logo next to the search bar\nA box will open in the bottom right of the website\nClick on a page element (it will turn green), SelectorGadget will generate a minimal CSS selector for that element, and will highlight (yellow) everything that is matched by the selector\nClick on a highlighted element to remove it from the selector (red), or click on an unhighlighted element to add it to the selector"
  },
  {
    "objectID": "slides/21/slides21.html#try-it",
    "href": "slides/21/slides21.html#try-it",
    "title": "Web Scraping II",
    "section": "Try it",
    "text": "Try it\n\n\nUse the SelectorGadget to explore http://www.imdb.com/chart/top\nWhat should the columns of our target dataset be? Do they correspond to any specific css selectors?\n\n\n\n\n\n\n−&plus;\n\n03:00"
  },
  {
    "objectID": "slides/21/slides21.html#extract-title",
    "href": "slides/21/slides21.html#extract-title",
    "title": "Web Scraping II",
    "section": "Extract title",
    "text": "Extract title\n\nimdb &lt;- read_html(\"http://www.imdb.com/chart/top\")\ntitles &lt;- imdb %&gt;%\n  html_elements(\".with-margin .ipc-title__text\") %&gt;%\n  html_text()\n\nhead(titles)\n\n[1] \"1. The Shawshank Redemption\"                     \n[2] \"2. The Godfather\"                                \n[3] \"3. The Dark Knight\"                              \n[4] \"4. The Godfather Part II\"                        \n[5] \"5. 12 Angry Men\"                                 \n[6] \"6. The Lord of the Rings: The Return of the King\""
  },
  {
    "objectID": "slides/21/slides21.html#extract-year",
    "href": "slides/21/slides21.html#extract-year",
    "title": "Web Scraping II",
    "section": "Extract year",
    "text": "Extract year\n\nyears &lt;- imdb %&gt;%\n  html_elements(\".cli-title-metadata-item:nth-child(1)\") %&gt;%\n  html_text()\n\nhead(years)\n\n[1] \"1994\" \"1972\" \"2008\" \"1974\" \"1957\" \"2003\""
  },
  {
    "objectID": "slides/21/slides21.html#extract-runtime",
    "href": "slides/21/slides21.html#extract-runtime",
    "title": "Web Scraping II",
    "section": "Extract runtime",
    "text": "Extract runtime\n\nruntimes &lt;- imdb %&gt;%\n  html_elements(\".cli-title-metadata-item:nth-child(2)\") %&gt;%\n  html_text()\n\nhead(runtimes)\n\n[1] \"2h 22m\" \"2h 55m\" \"2h 32m\" \"3h 22m\" \"1h 36m\" \"3h 21m\""
  },
  {
    "objectID": "slides/21/slides21.html#extract-mpaa-rating",
    "href": "slides/21/slides21.html#extract-mpaa-rating",
    "title": "Web Scraping II",
    "section": "Extract MPAA rating",
    "text": "Extract MPAA rating\n\nmpaas &lt;- imdb %&gt;%\n  html_elements(\".cli-title-metadata-item:nth-child(3)\") %&gt;%\n  html_text()\n\nhead(mpaas)\n\n[1] \"R\"        \"R\"        \"PG-13\"    \"R\"        \"Approved\" \"PG-13\""
  },
  {
    "objectID": "slides/21/slides21.html#put-the-pieces-together",
    "href": "slides/21/slides21.html#put-the-pieces-together",
    "title": "Web Scraping II",
    "section": "Put the pieces together",
    "text": "Put the pieces together\n\nimdb_top_250 &lt;- tibble(\n  title = titles, \n  year = years, \n  runtime = runtimes,\n  mpaa = mpaas\n  )\n\nimdb_top_250\n\n# A tibble: 25 × 4\n   title                                                year  runtime mpaa    \n   &lt;chr&gt;                                                &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   \n 1 1. The Shawshank Redemption                          1994  2h 22m  R       \n 2 2. The Godfather                                     1972  2h 55m  R       \n 3 3. The Dark Knight                                   2008  2h 32m  PG-13   \n 4 4. The Godfather Part II                             1974  3h 22m  R       \n 5 5. 12 Angry Men                                      1957  1h 36m  Approved\n 6 6. The Lord of the Rings: The Return of the King     2003  3h 21m  PG-13   \n 7 7. Schindler's List                                  1993  3h 15m  R       \n 8 8. Pulp Fiction                                      1994  2h 34m  R       \n 9 9. The Lord of the Rings: The Fellowship of the Ring 2001  2h 58m  PG-13   \n10 10. The Good, the Bad and the Ugly                   1966  2h 58m  R       \n# ℹ 15 more rows"
  },
  {
    "objectID": "slides/21/slides21.html#wait-a-second.-theres-not-250-movies-here",
    "href": "slides/21/slides21.html#wait-a-second.-theres-not-250-movies-here",
    "title": "Web Scraping II",
    "section": "Wait a second…. there’s not 250 movies here",
    "text": "Wait a second…. there’s not 250 movies here\n\nimdb_top_250\n\n# A tibble: 25 × 4\n   title                                                year  runtime mpaa    \n   &lt;chr&gt;                                                &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   \n 1 1. The Shawshank Redemption                          1994  2h 22m  R       \n 2 2. The Godfather                                     1972  2h 55m  R       \n 3 3. The Dark Knight                                   2008  2h 32m  PG-13   \n 4 4. The Godfather Part II                             1974  3h 22m  R       \n 5 5. 12 Angry Men                                      1957  1h 36m  Approved\n 6 6. The Lord of the Rings: The Return of the King     2003  3h 21m  PG-13   \n 7 7. Schindler's List                                  1993  3h 15m  R       \n 8 8. Pulp Fiction                                      1994  2h 34m  R       \n 9 9. The Lord of the Rings: The Fellowship of the Ring 2001  2h 58m  PG-13   \n10 10. The Good, the Bad and the Ugly                   1966  2h 58m  R       \n# ℹ 15 more rows\n\n\n\nMost modern tables in webpages are dynamically loaded (they wait for you to scroll down to load more rows). rvest can’t scroll, so it can only see the initial data that’s loaded"
  },
  {
    "objectID": "slides/21/slides21.html#what-do-we-do",
    "href": "slides/21/slides21.html#what-do-we-do",
    "title": "Web Scraping II",
    "section": "What do we do?",
    "text": "What do we do?\n\nIs there an API available? Can I access it as a student/researcher at no/low cost?\n\nIMDb: Yes, but cost prohibitive\n\n\nIs there a different scraping tool available?\n\nYes, {RSelenium} is one that might work, but beyond the scope of this course\n\n\nCan I get the information I need from a different website?\n\n\nThe Movie Database might work\n\n\nIf I download the page, is more information available?\n\nIn this case, yes, but might not always work"
  },
  {
    "objectID": "slides/21/slides21.html#with-local-copy-of-website",
    "href": "slides/21/slides21.html#with-local-copy-of-website",
    "title": "Web Scraping II",
    "section": "With local copy of website",
    "text": "With local copy of website\n\nimdb_local &lt;- read_html(\"IMDb Top 250 Movies.html\")\ntitles &lt;- imdb_local %&gt;%\n  html_elements(\".with-margin .ipc-title__text\") %&gt;%\n  html_text()\n\n\ntitles\n\n  [1] \"1. The Shawshank Redemption\"                                             \n  [2] \"2. The Godfather\"                                                        \n  [3] \"3. The Dark Knight\"                                                      \n  [4] \"4. The Godfather Part II\"                                                \n  [5] \"5. 12 Angry Men\"                                                         \n  [6] \"6. The Lord of the Rings: The Return of the King\"                        \n  [7] \"7. Schindler's List\"                                                     \n  [8] \"8. Pulp Fiction\"                                                         \n  [9] \"9. The Lord of the Rings: The Fellowship of the Ring\"                    \n [10] \"10. The Good, the Bad and the Ugly\"                                      \n [11] \"11. Forrest Gump\"                                                        \n [12] \"12. The Lord of the Rings: The Two Towers\"                               \n [13] \"13. Fight Club\"                                                          \n [14] \"14. Inception\"                                                           \n [15] \"15. Star Wars: Episode V - The Empire Strikes Back\"                      \n [16] \"16. The Matrix\"                                                          \n [17] \"17. Goodfellas\"                                                          \n [18] \"18. One Flew Over the Cuckoo's Nest\"                                     \n [19] \"19. Interstellar\"                                                        \n [20] \"20. Se7en\"                                                               \n [21] \"21. It's a Wonderful Life\"                                               \n [22] \"22. Seven Samurai\"                                                       \n [23] \"23. The Silence of the Lambs\"                                            \n [24] \"24. Saving Private Ryan\"                                                 \n [25] \"25. City of God\"                                                         \n [26] \"26. The Green Mile\"                                                      \n [27] \"27. Life Is Beautiful\"                                                   \n [28] \"28. Terminator 2: Judgment Day\"                                          \n [29] \"29. Star Wars: Episode IV - A New Hope\"                                  \n [30] \"30. Back to the Future\"                                                  \n [31] \"31. Spirited Away\"                                                       \n [32] \"32. The Pianist\"                                                         \n [33] \"33. Gladiator\"                                                           \n [34] \"34. Parasite\"                                                            \n [35] \"35. Psycho\"                                                              \n [36] \"36. The Lion King\"                                                       \n [37] \"37. Grave of the Fireflies\"                                              \n [38] \"38. The Departed\"                                                        \n [39] \"39. Whiplash\"                                                            \n [40] \"40. Harakiri\"                                                            \n [41] \"41. American History X\"                                                  \n [42] \"42. The Prestige\"                                                        \n [43] \"43. Léon: The Professional\"                                              \n [44] \"44. Spider-Man: Across the Spider-Verse\"                                 \n [45] \"45. Casablanca\"                                                          \n [46] \"46. The Usual Suspects\"                                                  \n [47] \"47. The Intouchables\"                                                    \n [48] \"48. Cinema Paradiso\"                                                     \n [49] \"49. Modern Times\"                                                        \n [50] \"50. Alien\"                                                               \n [51] \"51. Rear Window\"                                                         \n [52] \"52. Once Upon a Time in the West\"                                        \n [53] \"53. Django Unchained\"                                                    \n [54] \"54. City Lights\"                                                         \n [55] \"55. Dune: Part Two\"                                                      \n [56] \"56. Apocalypse Now\"                                                      \n [57] \"57. Memento\"                                                             \n [58] \"58. WALL·E\"                                                              \n [59] \"59. Raiders of the Lost Ark\"                                             \n [60] \"60. The Lives of Others\"                                                 \n [61] \"61. Avengers: Infinity War\"                                              \n [62] \"62. Sunset Boulevard\"                                                    \n [63] \"63. Spider-Man: Into the Spider-Verse\"                                   \n [64] \"64. Paths of Glory\"                                                      \n [65] \"65. Witness for the Prosecution\"                                         \n [66] \"66. The Shining\"                                                         \n [67] \"67. The Great Dictator\"                                                  \n [68] \"68. 12th Fail\"                                                           \n [69] \"69. Aliens\"                                                              \n [70] \"70. Inglourious Basterds\"                                                \n [71] \"71. The Dark Knight Rises\"                                               \n [72] \"72. Coco\"                                                                \n [73] \"73. Amadeus\"                                                             \n [74] \"74. Toy Story\"                                                           \n [75] \"75. Avengers: Endgame\"                                                   \n [76] \"76. Oldboy\"                                                              \n [77] \"77. Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb\"\n [78] \"78. Good Will Hunting\"                                                   \n [79] \"79. American Beauty\"                                                     \n [80] \"80. Das Boot\"                                                            \n [81] \"81. Braveheart\"                                                          \n [82] \"82. Princess Mononoke\"                                                   \n [83] \"83. Your Name.\"                                                          \n [84] \"84. High and Low\"                                                        \n [85] \"85. 3 Idiots\"                                                            \n [86] \"86. Joker\"                                                               \n [87] \"87. Once Upon a Time in America\"                                         \n [88] \"88. Capernaum\"                                                           \n [89] \"89. Singin' in the Rain\"                                                 \n [90] \"90. Come and See\"                                                        \n [91] \"91. Requiem for a Dream\"                                                 \n [92] \"92. Toy Story 3\"                                                         \n [93] \"93. Star Wars: Episode VI - Return of the Jedi\"                          \n [94] \"94. The Hunt\"                                                            \n [95] \"95. Eternal Sunshine of the Spotless Mind\"                               \n [96] \"96. Ikiru\"                                                               \n [97] \"97. 2001: A Space Odyssey\"                                               \n [98] \"98. Reservoir Dogs\"                                                      \n [99] \"99. The Apartment\"                                                       \n[100] \"100. Lawrence of Arabia\"                                                 \n[101] \"101. Incendies\"                                                          \n[102] \"102. Scarface\"                                                           \n[103] \"103. Double Indemnity\"                                                   \n[104] \"104. North by Northwest\"                                                 \n[105] \"105. Heat\"                                                               \n[106] \"106. Citizen Kane\"                                                       \n[107] \"107. M\"                                                                  \n[108] \"108. Up\"                                                                 \n[109] \"109. Full Metal Jacket\"                                                  \n[110] \"110. Vertigo\"                                                            \n[111] \"111. Amélie\"                                                             \n[112] \"112. A Clockwork Orange\"                                                 \n[113] \"113. Oppenheimer\"                                                        \n[114] \"114. To Kill a Mockingbird\"                                              \n[115] \"115. A Separation\"                                                       \n[116] \"116. Die Hard\"                                                           \n[117] \"117. The Sting\"                                                          \n[118] \"118. Like Stars on Earth\"                                                \n[119] \"119. Indiana Jones and the Last Crusade\"                                 \n[120] \"120. Metropolis\"                                                         \n[121] \"121. I'm Still Here\"                                                     \n[122] \"122. Snatch\"                                                             \n[123] \"123. 1917\"                                                               \n[124] \"124. L.A. Confidential\"                                                  \n[125] \"125. Bicycle Thieves\"                                                    \n[126] \"126. Downfall\"                                                           \n[127] \"127. Dangal\"                                                             \n[128] \"128. Taxi Driver\"                                                        \n[129] \"129. Hamilton\"                                                           \n[130] \"130. The Wolf of Wall Street\"                                            \n[131] \"131. Batman Begins\"                                                      \n[132] \"132. Green Book\"                                                         \n[133] \"133. For a Few Dollars More\"                                             \n[134] \"134. Some Like It Hot\"                                                   \n[135] \"135. The Truman Show\"                                                    \n[136] \"136. Judgment at Nuremberg\"                                              \n[137] \"137. The Kid\"                                                            \n[138] \"138. The Father\"                                                         \n[139] \"139. Shutter Island\"                                                     \n[140] \"140. All About Eve\"                                                      \n[141] \"141. There Will Be Blood\"                                                \n[142] \"142. Jurassic Park\"                                                      \n[143] \"143. Casino\"                                                             \n[144] \"144. The Sixth Sense\"                                                    \n[145] \"145. Ran\"                                                                \n[146] \"146. Top Gun: Maverick\"                                                  \n[147] \"147. No Country for Old Men\"                                             \n[148] \"148. The Thing\"                                                          \n[149] \"149. Pan's Labyrinth\"                                                    \n[150] \"150. Unforgiven\"                                                         \n[151] \"151. A Beautiful Mind\"                                                   \n[152] \"152. Kill Bill: Vol. 1\"                                                  \n[153] \"153. The Treasure of the Sierra Madre\"                                   \n[154] \"154. Yojimbo\"                                                            \n[155] \"155. Prisoners\"                                                          \n[156] \"156. Finding Nemo\"                                                       \n[157] \"157. The Great Escape\"                                                   \n[158] \"158. Monty Python and the Holy Grail\"                                    \n[159] \"159. Howl's Moving Castle\"                                               \n[160] \"160. The Elephant Man\"                                                   \n[161] \"161. Dial M for Murder\"                                                  \n[162] \"162. Gone with the Wind\"                                                 \n[163] \"163. Rashomon\"                                                           \n[164] \"164. The Wild Robot\"                                                     \n[165] \"165. Chinatown\"                                                          \n[166] \"166. Klaus\"                                                              \n[167] \"167. The Secret in Their Eyes\"                                           \n[168] \"168. Lock, Stock and Two Smoking Barrels\"                                \n[169] \"169. V for Vendetta\"                                                     \n[170] \"170. Inside Out\"                                                         \n[171] \"171. Three Billboards Outside Ebbing, Missouri\"                          \n[172] \"172. Trainspotting\"                                                      \n[173] \"173. The Bridge on the River Kwai\"                                       \n[174] \"174. Raging Bull\"                                                        \n[175] \"175. Catch Me If You Can\"                                                \n[176] \"176. Fargo\"                                                              \n[177] \"177. Warrior\"                                                            \n[178] \"178. Harry Potter and the Deathly Hallows: Part 2\"                       \n[179] \"179. Gran Torino\"                                                        \n[180] \"180. Million Dollar Baby\"                                                \n[181] \"181. Spider-Man: No Way Home\"                                            \n[182] \"182. My Neighbor Totoro\"                                                 \n[183] \"183. Mad Max: Fury Road\"                                                 \n[184] \"184. Ben-Hur\"                                                            \n[185] \"185. Children of Heaven\"                                                 \n[186] \"186. Barry Lyndon\"                                                       \n[187] \"187. 12 Years a Slave\"                                                   \n[188] \"188. Before Sunrise\"                                                     \n[189] \"189. Blade Runner\"                                                       \n[190] \"190. The Grand Budapest Hotel\"                                           \n[191] \"191. Dead Poets Society\"                                                 \n[192] \"192. Hacksaw Ridge\"                                                      \n[193] \"193. Gone Girl\"                                                          \n[194] \"194. Memories of Murder\"                                                 \n[195] \"195. In the Name of the Father\"                                          \n[196] \"196. Monsters, Inc.\"                                                     \n[197] \"197. Ratatouille\"                                                        \n[198] \"198. The Gold Rush\"                                                      \n[199] \"199. Wild Tales\"                                                         \n[200] \"200. How to Train Your Dragon\"                                           \n[201] \"201. Sherlock Jr.\"                                                       \n[202] \"202. Jaws\"                                                               \n[203] \"203. The Deer Hunter\"                                                    \n[204] \"204. Mary and Max\"                                                       \n[205] \"205. The General\"                                                        \n[206] \"206. Ford v Ferrari\"                                                     \n[207] \"207. The Wages of Fear\"                                                  \n[208] \"208. On the Waterfront\"                                                  \n[209] \"209. Mr. Smith Goes to Washington\"                                       \n[210] \"210. Wild Strawberries\"                                                  \n[211] \"211. Maharaja\"                                                           \n[212] \"212. Logan\"                                                              \n[213] \"213. The Third Man\"                                                      \n[214] \"214. Rocky\"                                                              \n[215] \"215. Tokyo Story\"                                                        \n[216] \"216. The Big Lebowski\"                                                   \n[217] \"217. Spotlight\"                                                          \n[218] \"218. The Seventh Seal\"                                                   \n[219] \"219. The Terminator\"                                                     \n[220] \"220. Room\"                                                               \n[221] \"221. Pirates of the Caribbean: The Curse of the Black Pearl\"             \n[222] \"222. Hotel Rwanda\"                                                       \n[223] \"223. La haine\"                                                           \n[224] \"224. Platoon\"                                                            \n[225] \"225. Demon Slayer: Kimetsu no Yaiba - Tsuzumi Mansion Arc\"               \n[226] \"226. Jai Bhim\"                                                           \n[227] \"227. Before Sunset\"                                                      \n[228] \"228. The Best Years of Our Lives\"                                        \n[229] \"229. The Exorcist\"                                                       \n[230] \"230. The Passion of Joan of Arc\"                                         \n[231] \"231. The Wizard of Oz\"                                                   \n[232] \"232. The Incredibles\"                                                    \n[233] \"233. Rush\"                                                               \n[234] \"234. The Sound of Music\"                                                 \n[235] \"235. Hachi: A Dog's Tale\"                                                \n[236] \"236. Stand by Me\"                                                        \n[237] \"237. Network\"                                                            \n[238] \"238. My Father and My Son\"                                               \n[239] \"239. The Handmaiden\"                                                     \n[240] \"240. The Iron Giant\"                                                     \n[241] \"241. To Be or Not to Be\"                                                 \n[242] \"242. The Battle of Algiers\"                                              \n[243] \"243. Into the Wild\"                                                      \n[244] \"244. The Grapes of Wrath\"                                                \n[245] \"245. Groundhog Day\"                                                      \n[246] \"246. The Help\"                                                           \n[247] \"247. A Silent Voice: The Movie\"                                          \n[248] \"248. Amores Perros\"                                                      \n[249] \"249. Rebecca\"                                                            \n[250] \"250. A Man Escaped\""
  },
  {
    "objectID": "slides/21/slides21.html#section-4",
    "href": "slides/21/slides21.html#section-4",
    "title": "Web Scraping II",
    "section": "",
    "text": "Rmarkdown:\n\nIntegrate code, text, and graphs\nOutput is a “report”\nCode is run interactively (in chunks) and when knitting your final document\n\n\nR script:\n\nThink of it as a file that contains only R chunks\nNo “knitting”: all code must be run explicitly\nUseful for longer chunks of code\n\ndata-cleaning.R\nfit-models.R\nscrape-data.R"
  },
  {
    "objectID": "slides/21/slides21.html#for-scraping",
    "href": "slides/21/slides21.html#for-scraping",
    "title": "Web Scraping II",
    "section": "For scraping:",
    "text": "For scraping:\n\nWe don’t want to scrape a website more than we need to\nFor HW, it’s OK to continue to use .Rmd unless specified\nFor projects that involve intensive data-gathering:\n\nuse an R script to read in the “raw” data, clean it, and save it to a tidy csv\nRead your “clean” data to your .rmd and proceed as usual"
  },
  {
    "objectID": "slides/21/slides21.html#your-turn",
    "href": "slides/21/slides21.html#your-turn",
    "title": "Web Scraping II",
    "section": "Your turn:",
    "text": "Your turn:\n\n\n\nIn an R script:\n\nScrape the names, scores, and years of most popular TV shows on IMDB: www.imdb.com/chart/tvmeter\nCreate a data frame called tvshows with the variables: rank, title, stars, year, episodes, n_ratings\nWrangle your resulting data so that all variable types are imported correctly\nUse write_csv to save your file. If time, read it into the 21-scraping.rmd and make a graph"
  },
  {
    "objectID": "slides/21/slides21.html#section-5",
    "href": "slides/21/slides21.html#section-5",
    "title": "Web Scraping II",
    "section": "",
    "text": "Dataset includes variables like:\n\nPolitical leanings\nReligion\nDrug usage\nSexual preferences\nZodiac sign\nWith over 2,000 total variables (although not all users had all variables recorded)"
  },
  {
    "objectID": "slides/21/slides21.html#follow-up-study-and-article-correction",
    "href": "slides/21/slides21.html#follow-up-study-and-article-correction",
    "title": "Web Scraping II",
    "section": "Follow-up study (and article correction)",
    "text": "Follow-up study (and article correction)\nhttps://www.tandfonline.com/doi/abs/10.1080/10691898.2015.11889737"
  },
  {
    "objectID": "slides/10/slides10.html#today",
    "href": "slides/10/slides10.html#today",
    "title": "Data Wrangling: Combining Data",
    "section": "Today",
    "text": "Today\nMore on wrangling:\n\nCombining datasets\nMore practice with pivot_"
  },
  {
    "objectID": "slides/10/slides10.html#peer-programming",
    "href": "slides/10/slides10.html#peer-programming",
    "title": "Data Wrangling: Combining Data",
    "section": "Peer programming",
    "text": "Peer programming\n\nWork on code in a small group (2-3)\nOne person does the typing, the others observe and support\nRules of thumb:\n\nno typing until your group has discussed a possible approach\nlet the typer finish their command/line/pipeline before pointing out any typos\neverybody should contribute ideas and understand the code that is written\n\nWhoever does the typing will share the completed .Rmd so you all have it"
  },
  {
    "objectID": "slides/10/slides10.html#warm-up",
    "href": "slides/10/slides10.html#warm-up",
    "title": "Data Wrangling: Combining Data",
    "section": "Warm up",
    "text": "Warm up\n\n\nFind your groupmates, introduce yourselves:\n\nName & topic of your first portfolio project\n\nChoose someone to be the “typer”. That person should open the 10-combining.rmd activity in RStudio\n\nCan’t decide? Choose the person who had the shortest walk to class today\n\nTake a look at the first 3 pairs of data together and talk through (conceptually! in words!) how you think they should be combined\n\n\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/10/slides10.html#example-1-star-wars-characters",
    "href": "slides/10/slides10.html#example-1-star-wars-characters",
    "title": "Data Wrangling: Combining Data",
    "section": "Example 1: Star Wars Characters",
    "text": "Example 1: Star Wars Characters\nDataset 1:\n\nstarwars_characters\n\n# A tibble: 87 × 6\n   name               height  mass homeworld species first_film\n   &lt;chr&gt;               &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;     \n 1 Luke Skywalker        172    77 Tatooine  Human   A New Hope\n 2 C-3PO                 167    75 Tatooine  Droid   A New Hope\n 3 R2-D2                  96    32 Naboo     Droid   A New Hope\n 4 Darth Vader           202   136 Tatooine  Human   A New Hope\n 5 Leia Organa           150    49 Alderaan  Human   A New Hope\n 6 Owen Lars             178   120 Tatooine  Human   A New Hope\n 7 Beru Whitesun Lars    165    75 Tatooine  Human   A New Hope\n 8 R5-D4                  97    32 Tatooine  Droid   A New Hope\n 9 Biggs Darklighter     183    84 Tatooine  Human   A New Hope\n10 Obi-Wan Kenobi        182    77 Stewjon   Human   A New Hope\n# ℹ 77 more rows\n\n\nDataset 2:\n\nstarwars_lastjedi\n\n# A tibble: 2 × 6\n  name         height mass  homeworld species first_film   \n  &lt;chr&gt;        &lt;lgl&gt;  &lt;lgl&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;        \n1 Rose Tico    NA     NA    Otomok    Human   The Last Jedi\n2 Amilyn Holdo NA     NA    &lt;NA&gt;      Human   The Last Jedi"
  },
  {
    "objectID": "slides/10/slides10.html#bind_rows",
    "href": "slides/10/slides10.html#bind_rows",
    "title": "Data Wrangling: Combining Data",
    "section": "bind_rows()",
    "text": "bind_rows()\n\n\n\ndata_1: our “starting” data\ndata_2 to data_n: additional rows of data that we want to add to data_1\n\n\n\nbind_rows(\n  data_1, \n  data_2, \n  ..., \n  data_n\n  )"
  },
  {
    "objectID": "slides/10/slides10.html#section",
    "href": "slides/10/slides10.html#section",
    "title": "Data Wrangling: Combining Data",
    "section": "",
    "text": "starwars_characters %&gt;%\n  bind_rows(starwars_lastjedi) %&gt;%\n  slice_tail(n=10)\n\n\n\n# A tibble: 10 × 6\n   name            height  mass homeworld species first_film          \n   &lt;chr&gt;            &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;               \n 1 Raymus Antilles    188    79 Alderaan  Human   A New Hope          \n 2 Sly Moore          178    48 Umbara    &lt;NA&gt;    Attack of the Clones\n 3 Tion Medon         206    80 Utapau    Pau'an  Revenge of the Sith \n 4 Finn                NA    NA &lt;NA&gt;      Human   The Force Awakens   \n 5 Rey                 NA    NA &lt;NA&gt;      Human   The Force Awakens   \n 6 Poe Dameron         NA    NA &lt;NA&gt;      Human   The Force Awakens   \n 7 BB8                 NA    NA &lt;NA&gt;      Droid   The Force Awakens   \n 8 Captain Phasma      NA    NA &lt;NA&gt;      Human   The Force Awakens   \n 9 Rose Tico           NA    NA Otomok    Human   The Last Jedi       \n10 Amilyn Holdo        NA    NA &lt;NA&gt;      Human   The Last Jedi"
  },
  {
    "objectID": "slides/10/slides10.html#example-2-stats-sections",
    "href": "slides/10/slides10.html#example-2-stats-sections",
    "title": "Data Wrangling: Combining Data",
    "section": "Example 2: Stats Sections",
    "text": "Example 2: Stats Sections\nDataset 1:\n\nstats_sections_fw\n\n# A tibble: 8 × 3\n  class    fall winter\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 stat120     3      3\n2 stat220     1      1\n3 stat230     1      1\n4 stat250     0      1\n5 stat270     1      0\n6 stat285     1      1\n7 stat320     0      0\n8 stat330     0      1\n\n\nDataset 2:\n\nstats_sections_s\n\n# A tibble: 8 × 1\n  spring\n   &lt;dbl&gt;\n1      4\n2      1\n3      1\n4      1\n5      0\n6      1\n7      1\n8      0"
  },
  {
    "objectID": "slides/10/slides10.html#bind_cols",
    "href": "slides/10/slides10.html#bind_cols",
    "title": "Data Wrangling: Combining Data",
    "section": "bind_cols()",
    "text": "bind_cols()\n\n\n\ndata_1: our “starting” data\ndata_2 to data_n: additional columns of data that we want to add to data_1\n\n\n\nbind_cols(\n  data_1, \n  data_2, \n  ..., \n  data_n\n  )"
  },
  {
    "objectID": "slides/10/slides10.html#section-1",
    "href": "slides/10/slides10.html#section-1",
    "title": "Data Wrangling: Combining Data",
    "section": "",
    "text": "stats_sections_fw %&gt;%\n  bind_cols(stats_sections_s)\n\n\n\n# A tibble: 8 × 4\n  class    fall winter spring\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 stat120     3      3      4\n2 stat220     1      1      1\n3 stat230     1      1      1\n4 stat250     0      1      1\n5 stat270     1      0      0\n6 stat285     1      1      1\n7 stat320     0      0      1\n8 stat330     0      1      0"
  },
  {
    "objectID": "slides/10/slides10.html#we-got-lucky",
    "href": "slides/10/slides10.html#we-got-lucky",
    "title": "Data Wrangling: Combining Data",
    "section": "We got lucky",
    "text": "We got lucky\n\n\nOur second dataset followed this structure:\n\n\n# A tibble: 8 × 2\n  class   spring\n  &lt;chr&gt;    &lt;dbl&gt;\n1 stat120      4\n2 stat220      1\n3 stat230      1\n4 stat250      1\n5 stat270      0\n6 stat285      1\n7 stat320      1\n8 stat330      0\n\n\n\nBut it could have also had this structure:\n\n\n# A tibble: 8 × 2\n  class   spring\n  &lt;chr&gt;    &lt;dbl&gt;\n1 stat270      0\n2 stat330      0\n3 stat220      1\n4 stat230      1\n5 stat250      1\n6 stat285      1\n7 stat320      1\n8 stat120      4"
  },
  {
    "objectID": "slides/10/slides10.html#example-3-survivor-castaways",
    "href": "slides/10/slides10.html#example-3-survivor-castaways",
    "title": "Data Wrangling: Combining Data",
    "section": "Example 3: Survivor castaways",
    "text": "Example 3: Survivor castaways\nDataset 1:\n\nus_castaway_results\n\n# A tibble: 870 × 7\n   castaway_id castaway season_name      season place jury  finalist\n   &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;   \n 1 US0001      Sonja    Survivor: Borneo      1    16 FALSE FALSE   \n 2 US0002      B.B.     Survivor: Borneo      1    15 FALSE FALSE   \n 3 US0003      Stacey   Survivor: Borneo      1    14 FALSE FALSE   \n 4 US0004      Ramona   Survivor: Borneo      1    13 FALSE FALSE   \n 5 US0005      Dirk     Survivor: Borneo      1    12 FALSE FALSE   \n 6 US0006      Joel     Survivor: Borneo      1    11 FALSE FALSE   \n 7 US0007      Gretchen Survivor: Borneo      1    10 FALSE FALSE   \n 8 US0008      Greg     Survivor: Borneo      1     9 TRUE  FALSE   \n 9 US0009      Jenna    Survivor: Borneo      1     8 TRUE  FALSE   \n10 US0010      Gervase  Survivor: Borneo      1     7 TRUE  FALSE   \n# ℹ 860 more rows\n\n\nDataset 2:\n\ncast_details\n\n# A tibble: 1,118 × 6\n   castaway_id full_name        date_of_birth gender occupation personality_type\n   &lt;chr&gt;       &lt;chr&gt;            &lt;date&gt;        &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;           \n 1 US0014      Rudy Boesch      1928-01-20    Male   Retired N… ISTJ            \n 2 US0002      B.B. Andersen    1936-01-18    Male   Real Esta… ESTJ            \n 3 US0001      Sonja Christoph… 1937-01-28    Female Musician   ENFP            \n 4 US0075      Jake Billingsley 1941-08-21    Male   Land Brok… ISFJ            \n 5 US0151      Jim Lynch        1942-01-07    Male   Retired F… ISTJ            \n 6 US0474      Joseph Del Campo 1943-07-04    Male   Former FB… ISTJ            \n 7 US0304      Jimmy Johnson    1943-07-16    Male   Former NF… ESFJ            \n 8 US0047      Kim Johnson      1944-09-18    Female Retired T… ISFJ            \n 9 US0128      Scout Cloud Lee  1944-11-08    Female Rancher    INFJ            \n10 US0061      Paschal English  1945-03-05    Male   Judge      ISFJ            \n# ℹ 1,108 more rows"
  },
  {
    "objectID": "slides/10/slides10.html#desired-output",
    "href": "slides/10/slides10.html#desired-output",
    "title": "Data Wrangling: Combining Data",
    "section": "Desired output",
    "text": "Desired output\n\n\n# A tibble: 870 × 12\n   castaway_id castaway season_name      season place jury  finalist full_name  \n   &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;    &lt;chr&gt;      \n 1 US0001      Sonja    Survivor: Borneo      1    16 FALSE FALSE    Sonja Chri…\n 2 US0002      B.B.     Survivor: Borneo      1    15 FALSE FALSE    B.B. Ander…\n 3 US0003      Stacey   Survivor: Borneo      1    14 FALSE FALSE    Stacey Sti…\n 4 US0004      Ramona   Survivor: Borneo      1    13 FALSE FALSE    Ramona Gray\n 5 US0005      Dirk     Survivor: Borneo      1    12 FALSE FALSE    Dirk Been  \n 6 US0006      Joel     Survivor: Borneo      1    11 FALSE FALSE    Joel Klug  \n 7 US0007      Gretchen Survivor: Borneo      1    10 FALSE FALSE    Gretchen C…\n 8 US0008      Greg     Survivor: Borneo      1     9 TRUE  FALSE    Greg Buis  \n 9 US0009      Jenna    Survivor: Borneo      1     8 TRUE  FALSE    Jenna Lewis\n10 US0010      Gervase  Survivor: Borneo      1     7 TRUE  FALSE    Gervase Pe…\n# ℹ 860 more rows\n# ℹ 4 more variables: date_of_birth &lt;date&gt;, gender &lt;chr&gt;, occupation &lt;chr&gt;,\n#   personality_type &lt;chr&gt;"
  },
  {
    "objectID": "slides/10/slides10.html#left_join",
    "href": "slides/10/slides10.html#left_join",
    "title": "Data Wrangling: Combining Data",
    "section": "left_join()",
    "text": "left_join()\n\nus_castaway_results %&gt;%\n  left_join(cast_details, by = \"castaway_id\") %&gt;%\n  select(-season_name)\n\n\n\n# A tibble: 870 × 11\n   castaway_id castaway season place jury  finalist full_name      date_of_birth\n   &lt;chr&gt;       &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;    &lt;chr&gt;          &lt;date&gt;       \n 1 US0001      Sonja         1    16 FALSE FALSE    Sonja Christo… 1937-01-28   \n 2 US0002      B.B.          1    15 FALSE FALSE    B.B. Andersen  1936-01-18   \n 3 US0003      Stacey        1    14 FALSE FALSE    Stacey Stillm… 1972-08-11   \n 4 US0004      Ramona        1    13 FALSE FALSE    Ramona Gray    1971-01-20   \n 5 US0005      Dirk          1    12 FALSE FALSE    Dirk Been      1976-06-15   \n 6 US0006      Joel          1    11 FALSE FALSE    Joel Klug      1972-04-13   \n 7 US0007      Gretchen      1    10 FALSE FALSE    Gretchen Cordy 1962-02-07   \n 8 US0008      Greg          1     9 TRUE  FALSE    Greg Buis      1975-12-31   \n 9 US0009      Jenna         1     8 TRUE  FALSE    Jenna Lewis    1977-07-16   \n10 US0010      Gervase       1     7 TRUE  FALSE    Gervase Peter… 1969-11-02   \n# ℹ 860 more rows\n# ℹ 3 more variables: gender &lt;chr&gt;, occupation &lt;chr&gt;, personality_type &lt;chr&gt;"
  },
  {
    "objectID": "slides/10/slides10.html#left_join-keeps-duplicate-rows-in-x",
    "href": "slides/10/slides10.html#left_join-keeps-duplicate-rows-in-x",
    "title": "Data Wrangling: Combining Data",
    "section": "left_join() keeps duplicate rows in x",
    "text": "left_join() keeps duplicate rows in x\n\nus_castaway_results %&gt;%\n  left_join(cast_details, by = \"castaway_id\") %&gt;%\n  filter(castaway == \"Sandra\") %&gt;%\n  select(-season_name)\n\n\n\n# A tibble: 4 × 11\n  castaway_id castaway season place jury  finalist full_name       date_of_birth\n  &lt;chr&gt;       &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;    &lt;chr&gt;           &lt;date&gt;       \n1 US0112      Sandra        7     1 FALSE TRUE     Sandra Diaz-Tw… 1974-07-30   \n2 US0112      Sandra       20     1 FALSE TRUE     Sandra Diaz-Tw… 1974-07-30   \n3 US0112      Sandra       34    15 FALSE FALSE    Sandra Diaz-Tw… 1974-07-30   \n4 US0112      Sandra       40    15 FALSE FALSE    Sandra Diaz-Tw… 1974-07-30   \n# ℹ 3 more variables: gender &lt;chr&gt;, occupation &lt;chr&gt;, personality_type &lt;chr&gt;"
  },
  {
    "objectID": "slides/10/slides10.html#other-types-of-_joins",
    "href": "slides/10/slides10.html#other-types-of-_joins",
    "title": "Data Wrangling: Combining Data",
    "section": "Other types of _joins",
    "text": "Other types of _joins\n\nleft_join(): all rows from x\nright_join(): all rows from y\nfull_join(): all rows from both x and y\ninner_join(): all rows from x where there are matching values in y, return all combination of multiple matches in the case of multiple matches\nsemi_join(): all rows from x where there are matching values in y, keeping just columns from x\nanti_join(): return all rows from x where there are not matching values in y, never duplicate rows of x\n…"
  },
  {
    "objectID": "slides/10/slides10.html#setup",
    "href": "slides/10/slides10.html#setup",
    "title": "Data Wrangling: Combining Data",
    "section": "Setup",
    "text": "Setup\nFor the next few slides…\n\n\n\nx\n\n# A tibble: 3 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2     \n3     3 x3     \n\n\n\n\ny\n\n# A tibble: 3 × 2\n     id value_y\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 y1     \n2     2 y2     \n3     4 y4"
  },
  {
    "objectID": "slides/10/slides10.html#left_join-1",
    "href": "slides/10/slides10.html#left_join-1",
    "title": "Data Wrangling: Combining Data",
    "section": "left_join()",
    "text": "left_join()\nKeep all rows from x\n\n\n\n\n\nleft_join(x, y, by = \"id\")\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;"
  },
  {
    "objectID": "slides/10/slides10.html#full_join",
    "href": "slides/10/slides10.html#full_join",
    "title": "Data Wrangling: Combining Data",
    "section": "full_join()",
    "text": "full_join()\nKeep all rows from both x and y\n\n\n\n\n\nfull_join(x, y)\n\n# A tibble: 4 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;   \n4     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "slides/10/slides10.html#semi_join",
    "href": "slides/10/slides10.html#semi_join",
    "title": "Data Wrangling: Combining Data",
    "section": "semi_join()",
    "text": "semi_join()\nKeep all rows from x where there are matching values in y, keeping just columns from x\n\n\n\n\n\nsemi_join(x, y)\n\n# A tibble: 2 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2     \n\n\n\nSimilar to filter()"
  },
  {
    "objectID": "slides/10/slides10.html#anti_join",
    "href": "slides/10/slides10.html#anti_join",
    "title": "Data Wrangling: Combining Data",
    "section": "anti_join()",
    "text": "anti_join()\nKeep all rows from x where there are not matching values in y, never duplicate rows of x\n\n\n\n\n\nanti_join(x, y)\n\n# A tibble: 1 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     3 x3     \n\n\n\nSimilar to filter() with !"
  },
  {
    "objectID": "slides/10/slides10.html#join-functions",
    "href": "slides/10/slides10.html#join-functions",
    "title": "Data Wrangling: Combining Data",
    "section": "*_join() functions",
    "text": "*_join() functions\n\nFrom dplyr\nIncredibly useful for bringing datasets with common information (e.g., unique identifier) together\nUse by argument\nAlways check that the numbers of rows and columns of the result dataset makes sense\nRefer to two-table verbs vignette when needed"
  },
  {
    "objectID": "slides/10/slides10.html#keys",
    "href": "slides/10/slides10.html#keys",
    "title": "Data Wrangling: Combining Data",
    "section": "keys",
    "text": "keys\nIn these examples, the colored boxes represent keys\n\n\n\n\n\nkeys uniquely identify the observation of interest\nAre present in both datasets and used to match the rows\nDepend on the context (e.g. could be castaway ID, could be season ID, could be epiosde number, etc.)\nCan be multiple columns\ndplyr will try to find them automatically, but it’s better to be explicit using the by argument"
  },
  {
    "objectID": "slides/10/slides10.html#lets-try-it-bakeoff-data-again",
    "href": "slides/10/slides10.html#lets-try-it-bakeoff-data-again",
    "title": "Data Wrangling: Combining Data",
    "section": "Let’s try it: Bakeoff data (again)",
    "text": "Let’s try it: Bakeoff data (again)\nOn Friday, we tidied data containing ratings from The Great British Bakeoff.\n\nBefore:\n\n\n# A tibble: 3 × 21\n  series e1_7day e1_28day e2_7day e2_28day e3_7day e3_28day e4_7day e4_28day\n   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1      1    2.24       NA    3          NA    3          NA    2.6        NA\n2      2    3.1        NA    3.53       NA    3.82       NA    3.6        NA\n3      3    3.85       NA    4.6        NA    4.53       NA    4.71       NA\n# ℹ 12 more variables: e5_7day &lt;dbl&gt;, e5_28day &lt;dbl&gt;, e6_7day &lt;dbl&gt;,\n#   e6_28day &lt;dbl&gt;, e7_7day &lt;dbl&gt;, e7_28day &lt;dbl&gt;, e8_7day &lt;dbl&gt;,\n#   e8_28day &lt;dbl&gt;, e9_7day &lt;dbl&gt;, e9_28day &lt;dbl&gt;, e10_7day &lt;dbl&gt;,\n#   e10_28day &lt;dbl&gt;\n\n\n\n\nAfter:\n\n\n# A tibble: 5 × 4\n  series episode period viewers\n   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1      1       1      7    2.24\n2      1       2      7    3   \n3      1       3      7    3   \n4      1       4      7    2.6 \n5      1       5      7    3.03"
  },
  {
    "objectID": "slides/10/slides10.html#lets-try-it-bakeoff-data-again-1",
    "href": "slides/10/slides10.html#lets-try-it-bakeoff-data-again-1",
    "title": "Data Wrangling: Combining Data",
    "section": "Let’s try it: Bakeoff data (again)",
    "text": "Let’s try it: Bakeoff data (again)\nBut that data only had through season 8. We now have a new dataset with seasons 9-14:\n\n\n# A tibble: 6 × 21\n  series e1_7day e1_28day e2_7day e2_28day e3_7day e3_28day e4_7day e4_28day\n   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1      9    9.55     9.92    9.31     9.76    8.91     9.35    8.88     9.41\n2     10    9.62    10.0     9.38     9.8     8.94     9.42    8.96     9.49\n3     11   11.2     11.8    10.8     11.4    10.7     11.2    10.6     11.2 \n4     12    9.57    10.2     8.98     9.64    8.69     9.39    8.75     9.13\n5     13    8.3      1       7.6      1       7.35     1       7.76     1   \n6     14    7.84     1       7.54     1       7.28     1       7.12     1   \n# ℹ 12 more variables: e5_7day &lt;dbl&gt;, e5_28day &lt;dbl&gt;, e6_7day &lt;dbl&gt;,\n#   e6_28day &lt;dbl&gt;, e7_7day &lt;dbl&gt;, e7_28day &lt;dbl&gt;, e8_7day &lt;dbl&gt;,\n#   e8_28day &lt;dbl&gt;, e9_7day &lt;dbl&gt;, e9_28day &lt;dbl&gt;, e10_7day &lt;dbl&gt;,\n#   e10_28day &lt;dbl&gt;\n\n\n\n\nYour task is to join these two datasets together using (1) bind_rows(), (2) _join() and (3) bind_cols() (you’ll also get some pivot_ practice along the way)"
  },
  {
    "objectID": "slides/10/slides10.html#part-ii-the-episodes-data",
    "href": "slides/10/slides10.html#part-ii-the-episodes-data",
    "title": "Data Wrangling: Combining Data",
    "section": "Part II: the episodes data",
    "text": "Part II: the episodes data\nThe episodes data has information about each episode of GBBO.\n\n\nIn particular, it includes:\n\nbaker: each baker that competed on that episode\nsignature: the name of the dessert they made for the signature challenge\ntechnical: the place the baker earned in the technical challenge\nshowstopper: the name of the dessert they made for the showstopper challenge\nresult: whether the baker was “Safe” or “Eliminated”\n\n\n\nepisodes\n\n# A tibble: 1,007 × 7\n   series episode baker     signature               technical showstopper result\n    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                       &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt; \n 1      1       1 Annetha   Light Jamaican Black C…         2 Red, White… Safe  \n 2      1       1 David     Chocolate Orange Cake           3 Black Fore… Safe  \n 3      1       1 Edd       Caramel Cinnamon and B…         1 &lt;NA&gt;        Safe  \n 4      1       1 Jasminder Fresh Mango and Passio…        NA &lt;NA&gt;        Safe  \n 5      1       1 Jonathan  Carrot Cake with Lime …         9 Three Tier… Safe  \n 6      1       1 Lea       Cranberry and Pistachi…        10 Raspberrie… Elimi…\n 7      1       1 Louise    Carrot and Orange Cake         NA Never Fail… Safe  \n 8      1       1 Mark      Sticky Marmalade Tea L…        NA Heart-shap… Elimi…\n 9      1       1 Miranda   Triple Layered Brownie…         8 Three Tier… Safe  \n10      1       1 Ruth      Lemon Drizzle Cakewith…        NA Classic Ch… Safe  \n# ℹ 997 more rows"
  },
  {
    "objectID": "slides/10/slides10.html#lets-try-it-bakeoff-data-episodes",
    "href": "slides/10/slides10.html#lets-try-it-bakeoff-data-episodes",
    "title": "Data Wrangling: Combining Data",
    "section": "Let’s try it: Bakeoff data (episodes)",
    "text": "Let’s try it: Bakeoff data (episodes)\n\nJoin the tidy dataset (all 14 seasons) with the episodes data.\nYour task is to print the “signature” desserts that were made on the 10 episodes that had the highest 7-day viewership."
  },
  {
    "objectID": "slides/16/slides16.html#today",
    "href": "slides/16/slides16.html#today",
    "title": "Functions",
    "section": "Today",
    "text": "Today\n\nWriting Functions\nConditional Execution"
  },
  {
    "objectID": "slides/16/slides16.html#warm-up",
    "href": "slides/16/slides16.html#warm-up",
    "title": "Functions",
    "section": "Warm up",
    "text": "Warm up\n\nWhat does the mutate code below do?\n\n\ndf %&gt;% slice_head(n = 3)\n\n# A tibble: 3 × 4\n      a       b     c       d\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1  1.08 -1.46   0.243  0.239 \n2  1.02  0.0941 0.431 -0.0970\n3 -1.83  0.310  1.38  -0.841 \n\n\n\ndf |&gt; mutate(\n  a = (a - mean(a, na.rm = TRUE)) / \n    sd(a, na.rm = TRUE),\n  b = (b - mean(b, na.rm = TRUE)) / \n    sd(b, na.rm = TRUE),\n  c = (c - mean(a, na.rm = TRUE)) / \n    sd(c, na.rm = TRUE),\n  d = (d - mean(d, na.rm = TRUE)) / \n    sd(d, na.rm = TRUE)\n)\n\n\n\n\n\n−&plus;\n\n01:00"
  },
  {
    "objectID": "slides/16/slides16.html#rescaling-variables",
    "href": "slides/16/slides16.html#rescaling-variables",
    "title": "Functions",
    "section": "Rescaling variables",
    "text": "Rescaling variables\nStandardizing/rescaling/normalizing variables is often an essential first step in predictive modeling\n\nExample:\n\nSet of digitized breast cancer image features\nEach row in the data set represents an image of a tumor sample, including the diagnosis (benign or malignant) and several other measurements (nucleus texture, perimeter, area, etc.)\nDiagnosis for each image was conducted by physicians."
  },
  {
    "objectID": "slides/16/slides16.html#section",
    "href": "slides/16/slides16.html#section",
    "title": "Functions",
    "section": "",
    "text": "# A tibble: 569 × 12\n        ID Class Radius Texture Perimeter  Area Smoothness Compactness Concavity\n     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n 1  8.42e5 M       18.0    10.4     123.  1001      0.118       0.278     0.300 \n 2  8.43e5 M       20.6    17.8     133.  1326      0.0847      0.0786    0.0869\n 3  8.43e7 M       19.7    21.2     130   1203      0.110       0.160     0.197 \n 4  8.43e7 M       11.4    20.4      77.6  386.     0.142       0.284     0.241 \n 5  8.44e7 M       20.3    14.3     135.  1297      0.100       0.133     0.198 \n 6  8.44e5 M       12.4    15.7      82.6  477.     0.128       0.17      0.158 \n 7  8.44e5 M       18.2    20.0     120.  1040      0.0946      0.109     0.113 \n 8  8.45e7 M       13.7    20.8      90.2  578.     0.119       0.164     0.0937\n 9  8.45e5 M       13      21.8      87.5  520.     0.127       0.193     0.186 \n10  8.45e7 M       12.5    24.0      84.0  476.     0.119       0.240     0.227 \n11  8.46e5 M       16.0    23.2     103.   798.     0.0821      0.0667    0.0330\n12  8.46e7 M       15.8    17.9     104.   781      0.0971      0.129     0.0995\n13  8.46e5 M       19.2    24.8     132.  1123      0.0974      0.246     0.206 \n14  8.46e5 M       15.8    24.0     104.   783.     0.0840      0.100     0.0994\n15  8.47e7 M       13.7    22.6      93.6  578.     0.113       0.229     0.213 \n16  8.48e7 M       14.5    27.5      96.7  659.     0.114       0.160     0.164 \n# ℹ 553 more rows\n# ℹ 3 more variables: Concave_Points &lt;dbl&gt;, Symmetry &lt;dbl&gt;,\n#   Fractal_Dimension &lt;dbl&gt;"
  },
  {
    "objectID": "slides/16/slides16.html#standardizing-variables",
    "href": "slides/16/slides16.html#standardizing-variables",
    "title": "Functions",
    "section": "Standardizing variables",
    "text": "Standardizing variables\nGoal: standardize the 10 quantitative variables in the data set\n\nApproach: subtract sample mean, divide by sample standard deviation\n\n\n\nscaled_cancer &lt;- unscaled_cancer %&gt;%\n  mutate(\n    Radius = (Radius - mean(Radius)) / sd(Radius),\n    Texture = (Texture - mean(Texture)) / sd(Texture),\n    Perimeter = (Perimeter - mean(Perimeter)) / sd(Perimeter),\n    Area = (Area - mean(Area)) / sd(Area),\n    Smoothness = (Smoothness - mean(Smoothness)) / sd(Smoothness),\n    Compactness = (Compactness - mean(Compactness)) / sd(Compactness),\n    Concavity = (Concavity - mean(Concavity)) / sd(Concavity),\n    Concave_Points = (Concave_Points - mean(Concave_Points)) / sd(Concave_Points),\n    Symmetry = (Symmetry - mean(Symmetry)) / sd(Symmetry),\n    Fractal_Dimension = (Fractal_Dimension - mean(Fractal_Dimension)) / sd(Fractal_Dimension) \n  )"
  },
  {
    "objectID": "slides/16/slides16.html#dont-repeat-yourself-dry",
    "href": "slides/16/slides16.html#dont-repeat-yourself-dry",
    "title": "Functions",
    "section": "Don’t repeat yourself (DRY)",
    "text": "Don’t repeat yourself (DRY)\n\nWe’ve copied, pasted, and edited the same code chunk many times\nThat’s a lot of work when the only change in the code is the variable name!\n\n\n\nscaled_cancer &lt;- unscaled_cancer %&gt;%\n  mutate(\n    Radius = (Radius - mean(Radius)) / sd(Radius), \n    Texture = (Texture - mean(Texture)) / sd(Texture), \n    Perimeter = (Perimeter - mean(Perimeter)) / sd(Perimeter), \n    Area = (Area - mean(Area)) / sd(Area), \n    Smoothness = (Smoothness - mean(Smoothness)) / sd(Smoothness), \n    Compactness = (Compactness - mean(Compactness)) / sd(Compactness),\n    Concavity = (Concavity - mean(Concavity)) / sd(Concavity), \n    Concave_Points = (Concave_Points - mean(Concave_Points)) / sd(Concave_Points), \n    Symmetry = (Symmetry - mean(Symmetry)) / sd(Symmetry), \n    Fractal_Dimension = (Fractal_Dimension - mean(Fractal_Dimension)) / sd(Fractal_Dimension) \n  )"
  },
  {
    "objectID": "slides/16/slides16.html#section-1",
    "href": "slides/16/slides16.html#section-1",
    "title": "Functions",
    "section": "",
    "text": "You should consider writing a function whenever you’ve copied and pasted a  block of code more than twice\n\n\n—Hadley Wickham"
  },
  {
    "objectID": "slides/16/slides16.html#why-functions",
    "href": "slides/16/slides16.html#why-functions",
    "title": "Functions",
    "section": "Why functions?",
    "text": "Why functions?\nAutomate common tasks in a more powerful and more general way than copy-and-pasting\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\n\nDown the line — Improve your reach as a data scientist by writing functions (and packages!) that others use"
  },
  {
    "objectID": "slides/16/slides16.html#anatomy-of-a-function",
    "href": "slides/16/slides16.html#anatomy-of-a-function",
    "title": "Functions",
    "section": "Anatomy of a function",
    "text": "Anatomy of a function\n\n\n\nA short but informative name, preferably a verb\n\n\n\ncalc_this &lt;- function() { \n\n}"
  },
  {
    "objectID": "slides/16/slides16.html#anatomy-of-a-function-1",
    "href": "slides/16/slides16.html#anatomy-of-a-function-1",
    "title": "Functions",
    "section": "Anatomy of a function",
    "text": "Anatomy of a function\n\n\n\nA short but informative name, preferably a verb\n\nArguments of the function inside function()\n\n\n\n\ncalc_this &lt;- function(..arguments..) { \n\n}"
  },
  {
    "objectID": "slides/16/slides16.html#anatomy-of-a-function-2",
    "href": "slides/16/slides16.html#anatomy-of-a-function-2",
    "title": "Functions",
    "section": "Anatomy of a function",
    "text": "Anatomy of a function\n\n\n\nA short but informative name, preferably a verb\n\nArguments of the function inside function()\n\nPlace the code you have developed in body of the function, a { block that immediately follows function(...).\n\n\n\ncalc_this &lt;- function(..arguments..) { \n  # do stuff with arguments \n  # last result will be returned \n}"
  },
  {
    "objectID": "slides/16/slides16.html#building-standardize",
    "href": "slides/16/slides16.html#building-standardize",
    "title": "Functions",
    "section": "Building standardize\n",
    "text": "Building standardize\n\n\n\n\nA short but informative name, preferably a verb\n\n\n\nstandardize &lt;- function() { \n\n}"
  },
  {
    "objectID": "slides/16/slides16.html#building-standardize-1",
    "href": "slides/16/slides16.html#building-standardize-1",
    "title": "Functions",
    "section": "Building standardize\n",
    "text": "Building standardize\n\n\n\n\nA short but informative name, preferably a verb\n\nArguments of the function inside function()\n\n\n\n\nstandardize &lt;- function(x) { \n\n}"
  },
  {
    "objectID": "slides/16/slides16.html#building-standardize-2",
    "href": "slides/16/slides16.html#building-standardize-2",
    "title": "Functions",
    "section": "Building standardize\n",
    "text": "Building standardize\n\n\n\n\nA short but informative name, preferably a verb\n\nArguments of the function inside function()\n\nPlace the code you have developed in body of the function, a { block that immediately follows function(...).\n\n\n\nstandardize &lt;- function(x) { \n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}"
  },
  {
    "objectID": "slides/16/slides16.html#does-it-work",
    "href": "slides/16/slides16.html#does-it-work",
    "title": "Functions",
    "section": "Does it work?",
    "text": "Does it work?\nStandardized Compactness\n\nstd_compact &lt;- standardize(unscaled_cancer$Compactness)\nhead(std_compact)\n\n[1]  3.2806281 -0.4866435  1.0519999  3.3999174  0.5388663  1.2432416\n\n\n\nUnstandardized Compactness\n\nhead(unscaled_cancer$Compactness)\n\n[1] 0.27760 0.07864 0.15990 0.28390 0.13280 0.17000"
  },
  {
    "objectID": "slides/16/slides16.html#your-turn",
    "href": "slides/16/slides16.html#your-turn",
    "title": "Functions",
    "section": "Your turn",
    "text": "Your turn\n\nTurn the following code snippets into functions. Think about what each function does before you begin, and be sure to give each function an informative name.\n\nmean(is.na(x))\nx / sum(x, na.rm = TRUE)\nsd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)\n\n\nYou can test your functions on variables from the palmerpenguins::penguins dataset (e.g. my_func(penguins$flipper_length_mm)).\n\n\n\n\n−&plus;\n\n06:00"
  },
  {
    "objectID": "slides/16/slides16.html#return-values",
    "href": "slides/16/slides16.html#return-values",
    "title": "Functions",
    "section": "Return values",
    "text": "Return values\nThe value returned by the function is usually the last statement it evaluates\n\nstandardize &lt;- function(x) { \n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}\n\n\nYou can force a function to return early using return().\nThis is often paired with conditional execution (more later).\n\nstandardize &lt;- function(x) { \n return((x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE))\n}"
  },
  {
    "objectID": "slides/16/slides16.html#adding-arguments",
    "href": "slides/16/slides16.html#adding-arguments",
    "title": "Functions",
    "section": "Adding arguments",
    "text": "Adding arguments\nWe can include na.rm as an argument to give the user control over it\n\nstandardize &lt;- function(x, na.rm) {\n  (x - mean(x, na.rm = na.rm)) / sd(x, na.rm = na.rm)\n}\n\n\n\nstd_compact &lt;- standardize(unscaled_cancer$Compactness, na.rm = TRUE)\nhead(std_compact)\n\n[1]  3.2806281 -0.4866435  1.0519999  3.3999174  0.5388663  1.2432416"
  },
  {
    "objectID": "slides/16/slides16.html#setting-defaults",
    "href": "slides/16/slides16.html#setting-defaults",
    "title": "Functions",
    "section": "Setting defaults",
    "text": "Setting defaults\nUnless a default value is set for an argument, R will require a value to be specified in the function call\n\nstd_compact &lt;- standardize(unscaled_cancer$Compactness)\n\n Error in mean(x, na.rm = na.rm) : \n  argument \"na.rm\" is missing, with no default"
  },
  {
    "objectID": "slides/16/slides16.html#setting-defaults-1",
    "href": "slides/16/slides16.html#setting-defaults-1",
    "title": "Functions",
    "section": "Setting defaults",
    "text": "Setting defaults\nTo set a default, set the value in the function definition\n\nstandardize &lt;- function(x, na.rm = TRUE) { \n  (x - mean(x, na.rm = na.rm)) / sd(x, na.rm = na.rm)\n}\n\n\nstd_compact &lt;- standardize(unscaled_cancer$Compactness)"
  },
  {
    "objectID": "slides/16/slides16.html#your-turn-1",
    "href": "slides/16/slides16.html#your-turn-1",
    "title": "Functions",
    "section": "Your turn",
    "text": "Your turn\n\n\nWrite a function called column_mean that takes a data set and column name (as a string) as inputs and returns the column mean as output. (Hint: access the column using [[)\nYou should also include a na.rm argument and set the default to TRUE so that NAs are removed from the calculation by default.\nTest your function on the mtcars data set.\n\n\n\ncolumn_mean(mtcars, \"cyl\")\n\n[1] 6.1875\n\n\n\n\n\n\n−&plus;\n\n05:00"
  },
  {
    "objectID": "slides/16/slides16.html#plotting-functions",
    "href": "slides/16/slides16.html#plotting-functions",
    "title": "Functions",
    "section": "Plotting functions",
    "text": "Plotting functions\n\n\np1 = unscaled_cancer %&gt;%\n  ggplot(aes(x = Radius, fill = Class)) + \n  geom_histogram(col = \"white\", bins = 20, alpha = .7) \n\np2 = unscaled_cancer %&gt;%\n  ggplot(aes(x = Texture, fill = Class)) + \n  geom_histogram(col = \"white\", bins = 20, alpha = .7) \n\np3 = unscaled_cancer %&gt;%\n  ggplot(aes(x = Perimeter, fill = Class)) + \n  geom_histogram(col = \"white\", bins = 20, alpha = .7) \n\np4 = unscaled_cancer %&gt;%\n  ggplot(aes(x = Area, fill = Class)) + \n  geom_histogram(col = \"white\", bins = 20, alpha = .7) \n\n(p1 + p2)/(p3 + p4)"
  },
  {
    "objectID": "slides/16/slides16.html#custom-histogram-function",
    "href": "slides/16/slides16.html#custom-histogram-function",
    "title": "Functions",
    "section": "Custom histogram() function",
    "text": "Custom histogram() function\n\nhistogram &lt;- function(df, var, bins = 20) {\n  df %&gt;%\n    ggplot(aes(x = var, fill = Class)) + \n    geom_histogram(col = \"white\", bins = 20, alpha = .7) \n}\n\nhistogram(unscaled_cancer, Radius)\n\n\nError in `geom_histogram()`:\n! Problem while computing aesthetics.\nℹ Error occurred in the 1st layer.\nCaused by error:\n! object 'Radius' not found"
  },
  {
    "objectID": "slides/16/slides16.html#embracing",
    "href": "slides/16/slides16.html#embracing",
    "title": "Functions",
    "section": "🤗 embracing 🤗",
    "text": "🤗 embracing 🤗\nThis issue arises in {dplyr} and {ggplot} functions because they use a special kind of evaluation, which allows us to refer to our variable names directly.\n\nTo write our own functions that use these packages, we use 🤗 embracing 🤗 (wrap the variable in braces). This tells R to use the value stored inside the argument, not the argument as the literal variable name.\n\n\nOne way to remember what’s happening is to think of { } as looking down a tunnel — { var } will make a dplyr function look inside of var rather than looking for a variable called var."
  },
  {
    "objectID": "slides/16/slides16.html#histogram-function",
    "href": "slides/16/slides16.html#histogram-function",
    "title": "Functions",
    "section": "\nhistogram() function",
    "text": "histogram() function\n\n\nhistogram &lt;- function(df, var, bins = 20) {\n  df %&gt;%\n    ggplot(aes(x = {{var}}, fill = Class)) + \n    geom_histogram(col = \"white\", bins = 20, alpha = .7) \n}\n\nhistogram(unscaled_cancer, Radius)"
  },
  {
    "objectID": "slides/16/slides16.html#your-turn-2",
    "href": "slides/16/slides16.html#your-turn-2",
    "title": "Functions",
    "section": "Your turn",
    "text": "Your turn\n\nWrite a plotting function that makes a scatterplot of any two quantitative variables, coloring the points by a 3rd categorical variable.\nTest your function with the following examples:\n\n\n\n\nscatterplot(unscaled_cancer, \n            Radius, \n            Texture, \n            Class)\n\n\n\n\n\n\n\n\n\nscatterplot(penguins, \n            bill_length_mm, \n            bill_depth_mm, \n            species)\n\n\n\n\n\n\n\n\n\n\n\n\n−&plus;\n\n02:00"
  },
  {
    "objectID": "slides/16/slides16.html#functions-with-conditional-execution",
    "href": "slides/16/slides16.html#functions-with-conditional-execution",
    "title": "Functions",
    "section": "Functions with conditional execution",
    "text": "Functions with conditional execution\n\nSometimes, we want our function to do different things depending on the arguments we feed it.\nExample: a histobar function that makes a histogram if the variable is quantitative and a barchart if the variable is categorical.\n\n\n\n\n\nhistobar(unscaled_cancer, Radius)\n\n\n\n\n\n\n\n\n\n\n\nhistobar(unscaled_cancer, Class)"
  },
  {
    "objectID": "slides/16/slides16.html#conditional-execution",
    "href": "slides/16/slides16.html#conditional-execution",
    "title": "Functions",
    "section": "Conditional execution",
    "text": "Conditional execution\nThe if() statement allows us to control which statements are executed.\n\nif(condition) {\n  # commands when TRUE\n}\n\n\nif(condition) {\n  # commands when TRUE\n} else {\n  # commands when FALSE\n}"
  },
  {
    "objectID": "slides/16/slides16.html#conditional-execution-1",
    "href": "slides/16/slides16.html#conditional-execution-1",
    "title": "Functions",
    "section": "Conditional execution",
    "text": "Conditional execution\nA basic example\n\nx &lt;- 5\nif (x &gt; 5) {\n  x &lt;- x + 1\n}\nx\n\n\n\n[1] 5\n\n\n\n\nx &lt;- 6\nif (x &gt; 5) {\n  x &lt;- x + 1\n}\nx\n\n\n\n[1] 7"
  },
  {
    "objectID": "slides/16/slides16.html#conditional-execution-2",
    "href": "slides/16/slides16.html#conditional-execution-2",
    "title": "Functions",
    "section": "Conditional execution",
    "text": "Conditional execution\nAnother basic example\n\nx &lt;- 5\nif (x &gt; 5) {\n  x &lt;- x + 1\n} else {\n  x &lt;- x - 1\n}\n\nx\n\n\n\n[1] 4"
  },
  {
    "objectID": "slides/16/slides16.html#histobar",
    "href": "slides/16/slides16.html#histobar",
    "title": "Functions",
    "section": "histobar",
    "text": "histobar\n\nhistobar &lt;- function(df, var){\n  if(is.numeric(class({{var}}))){\n    ggplot(df, aes(x = {{var}})) + \n      geom_histogram(col = \"white\")\n  }\n  else {\n    ggplot(df, aes(y = {{var}})) + \n      geom_bar()\n  }\n}\n\n\n\nhistobar(unscaled_cancer, Radius)\n\n\n\nError: object 'Radius' not found"
  },
  {
    "objectID": "slides/16/slides16.html#histobar-1",
    "href": "slides/16/slides16.html#histobar-1",
    "title": "Functions",
    "section": "histobar",
    "text": "histobar\n\nhistobar &lt;- function(df, var){\n  if(is.numeric(df %&gt;% pull({{var}}))){\n    ggplot(df, aes(x = {{var}})) + \n      geom_histogram(col = \"white\")\n  }\n  else {\n    ggplot(df, aes(y = {{var}})) + \n      geom_bar()\n  }\n}"
  },
  {
    "objectID": "slides/16/slides16.html#testing-histobar",
    "href": "slides/16/slides16.html#testing-histobar",
    "title": "Functions",
    "section": "Testing histobar\n",
    "text": "Testing histobar\n\n\nhistobar(unscaled_cancer, Radius)"
  },
  {
    "objectID": "slides/16/slides16.html#testing-histobar-1",
    "href": "slides/16/slides16.html#testing-histobar-1",
    "title": "Functions",
    "section": "Testing histobar\n",
    "text": "Testing histobar\n\n\nhistobar(unscaled_cancer, Class)"
  },
  {
    "objectID": "slides/16/slides16.html#testing-histobar-2",
    "href": "slides/16/slides16.html#testing-histobar-2",
    "title": "Functions",
    "section": "Testing histobar\n",
    "text": "Testing histobar\n\n\nhistobar(palmerpenguins::penguins, species)"
  },
  {
    "objectID": "slides/16/slides16.html#testing-histobar-3",
    "href": "slides/16/slides16.html#testing-histobar-3",
    "title": "Functions",
    "section": "Testing histobar\n",
    "text": "Testing histobar\n\n\nhistobar(palmerpenguins::penguins, flipper_length_mm)"
  },
  {
    "objectID": "slides/16/slides16.html#your-turn-3",
    "href": "slides/16/slides16.html#your-turn-3",
    "title": "Functions",
    "section": "Your turn",
    "text": "Your turn\n\nEdit your scatterplot function to include an argument called draw_line. If draw_line is TRUE, your function should add a line of best fit to your scatterplot. Test your function with the following examples\n\n\n\n\nscatterplot(unscaled_cancer, \n            Radius, \n            Texture, \n            Class, \n            draw_line = FALSE)\n\n\n\n\n\n\n\n\n\nscatterplot(palmerpenguins::penguins, \n            bill_length_mm, \n            bill_depth_mm, \n            species, \n            draw_line = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n−&plus;\n\n02:00"
  },
  {
    "objectID": "slides/16/slides16.html#coding-style",
    "href": "slides/16/slides16.html#coding-style",
    "title": "Functions",
    "section": "Coding style",
    "text": "Coding style\nIt’s ok to drop the curly braces if you have a very short if statement that can fit on one line (no more than 80 characters!)\n\nif (y &lt; 20) \"Too low\" \n\n\nif (y &lt; 20) \"Too low\" else \"Too high\""
  },
  {
    "objectID": "slides/16/slides16.html#coding-style-1",
    "href": "slides/16/slides16.html#coding-style-1",
    "title": "Functions",
    "section": "Coding style",
    "text": "Coding style\n\nPart of writing reproducible and shareable code is - following good style guidelines.\nMostly, this means choosing good object names and using white space in a consistent and clear way.\nTidyverse style guide has guidelines for writing funtions and if statements"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#columns",
    "href": "slides/slides-cheat-sheet.html#columns",
    "title": "Slides Cheat Sheet",
    "section": "Columns",
    "text": "Columns\n\n\n\nFirst year at Carleton!\nTaught at Swarthmore for 5 years before moving here this fall\nPhD in Statistics & Data Science from Carnegie Mellon University\nGrew up in Minnesota, went to St Ben’s as an undergrad"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#only-graph-from-code",
    "href": "slides/slides-cheat-sheet.html#only-graph-from-code",
    "title": "Slides Cheat Sheet",
    "section": "Only graph from code",
    "text": "Only graph from code"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#background-image-half",
    "href": "slides/slides-cheat-sheet.html#background-image-half",
    "title": "Slides Cheat Sheet",
    "section": "Background Image (half)",
    "text": "Background Image (half)\n\n\nWhat skills do you need?\n\nprogramming with data\nstatistical modeling\ndomain knowledge\ncommunication"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#full-size-image",
    "href": "slides/slides-cheat-sheet.html#full-size-image",
    "title": "Slides Cheat Sheet",
    "section": "Full size image",
    "text": "Full size image\n\n\n\nImage by Adam Loy  adapted from work of Joe Blitzstein, Hanspeter Pfister, and Hadley Wickham"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#background-image-full-size",
    "href": "slides/slides-cheat-sheet.html#background-image-full-size",
    "title": "Slides Cheat Sheet",
    "section": "Background image (full size)",
    "text": "Background image (full size)"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#countdown",
    "href": "slides/slides-cheat-sheet.html#countdown",
    "title": "Slides Cheat Sheet",
    "section": "Countdown",
    "text": "Countdown\n\nWith your neighbor(s):\nChoose two countries to compare to the U.S. voting record in the U.N. over the years.\nWhat did you learn?\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#table-column-widths",
    "href": "slides/slides-cheat-sheet.html#table-column-widths",
    "title": "Slides Cheat Sheet",
    "section": "table column widths",
    "text": "table column widths\n\n\n\n\n\n\n\n\nCollaboration Allowed\n\n\n\n\nHomework Problems\nYou are allowed and encouraged to collaborate on homework. You may also use outside resources, but your submitted work must be your own and reflect your own understanding .\n\n\nLab Quiz Problems\nNo collaboration is allowed at all . You may use your own notes for resubmissions, but should not use outside resources.\n\n\nPortfolio Projects\nYou are expected to collaborate with your group, but cannot rely on external sources other than to help motivate the questions or provide other background information. Getting answers on significant parts of solutions from outside resources is not allowed.\n\n\nFinal Project\nYou are expected to collaborate with your group, but cannot rely on external sources other than to help motivate the questions or provide other background information. Any outside resources should be properly cited."
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#use-of-generative-artificial-intelligence-ai",
    "href": "slides/slides-cheat-sheet.html#use-of-generative-artificial-intelligence-ai",
    "title": "Slides Cheat Sheet",
    "section": "Use of generative artificial intelligence (AI)",
    "text": "Use of generative artificial intelligence (AI)\n\nTreat generative AI, such as ChatGPT or Gemini, the same as other online resources.\nGuiding principles:\n\n(1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. AI should facilitate—rather than hinder—learning.\n(2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n❌ AI tools for writing code: You may not use generative AI to take a “first pass” at a coding task. Do not type coursework prompts directly into AI tools.\n✅ AI tools for debugging code: You may make use of the technology to get help with error messages or trying to fix issues\n❌ AI tools for narrative: Unless instructed otherwise, you may not use generative AI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you.\n\n\n\nAdapted from Mine Çetinkaya-Rundel"
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#linktask",
    "href": "slides/slides-cheat-sheet.html#linktask",
    "title": "Slides Cheat Sheet",
    "section": "Link/task",
    "text": "Link/task\n\nhttps://github.com/stat220-w25\n\n\nFill out the Welcome Survey for collection of your account names, later this week you will be invited to the course organization."
  },
  {
    "objectID": "slides/slides-cheat-sheet.html#handwriting-font",
    "href": "slides/slides-cheat-sheet.html#handwriting-font",
    "title": "Slides Cheat Sheet",
    "section": "handwriting font",
    "text": "handwriting font\n\nin case you don’t yet have a GitHub account…"
  },
  {
    "objectID": "slides/20/slides20.html#ways-to-access-data-from-the-web",
    "href": "slides/20/slides20.html#ways-to-access-data-from-the-web",
    "title": "Intro to Web Scraping",
    "section": "Ways to access data from the web:",
    "text": "Ways to access data from the web:\n\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files.\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy)."
  },
  {
    "objectID": "slides/20/slides20.html#api-httr-request-from-last-class",
    "href": "slides/20/slides20.html#api-httr-request-from-last-class",
    "title": "Intro to Web Scraping",
    "section": "API httr request from last class",
    "text": "API httr request from last class\n\nrequest(\"https://api.census.gov/data\") %&gt;% \n    req_url_path_append(\"2019\") %&gt;% \n    req_url_path_append(\"acs\") %&gt;% \n    req_url_path_append(\"acs1\") %&gt;% \n    req_url_query(get = c(\"NAME\", \"B02015_009E\", \"B02015_009M\"), \n                  `for` = I(\"state:*\"), \n                  key = census_api_key, \n                  .multi = \"comma\")\n\n&lt;httr2_request&gt;\nGET\nhttps://api.census.gov/data/2019/acs/acs1?get=NAME,B02015_009E,B02015_009M&for=state:*&key=4a2344XXXXXXXXXXXXXXXXXXXXXXXXXXXXX\nBody: empty\nCan use your browser to go to the URL address and see what will be returned"
  },
  {
    "objectID": "slides/20/slides20.html#section",
    "href": "slides/20/slides20.html#section",
    "title": "Intro to Web Scraping",
    "section": "",
    "text": "When debugging, you can also test a single URL and build up your pipeline from there\n\nrequest(\"https://api.census.gov/data/2019/acs/acs1?get=NAME,B02015_009E,B02015_009M&for=state:*\") \n\n&lt;httr2_request&gt;\nGET\nhttps://api.census.gov/data/2019/acs/acs1?get=NAME,B02015_009E,B02015_009M&for=state:*\nBody: empty"
  },
  {
    "objectID": "slides/20/slides20.html#api-vs-screen-scraping",
    "href": "slides/20/slides20.html#api-vs-screen-scraping",
    "title": "Intro to Web Scraping",
    "section": "API vs Screen Scraping",
    "text": "API vs Screen Scraping\n\n\nAPI:\n\nDesigned to be accessed by computers\nOften need to sign up for a key\nStructured set of requests, need to dig in to documentation to figure out how to access the data you need\nOften more natural structure for tidying\n\n\nScreen scraping:\n\nDesigned to be read by humans\nCan be restricted or rate-limited in terms of service\nNeed to dig in to source code of the web page to figure out how to access the data that you need"
  },
  {
    "objectID": "slides/20/slides20.html#check-the-terms-of-useservice-first",
    "href": "slides/20/slides20.html#check-the-terms-of-useservice-first",
    "title": "Intro to Web Scraping",
    "section": "Check the terms of use/service first!",
    "text": "Check the terms of use/service first!\n\nCan you query this webpage?\nAre there restrictions on the use of the data?\nHow many requests can you make per minute?\n…and more…"
  },
  {
    "objectID": "slides/20/slides20.html#checking-for-permission-to-scrape",
    "href": "slides/20/slides20.html#checking-for-permission-to-scrape",
    "title": "Intro to Web Scraping",
    "section": "Checking for permission to scrape",
    "text": "Checking for permission to scrape\nUse robotstxt::paths_allowed() to see if you can scrape the web page.\n\nYou can scrape Zillow\n\nlibrary(robotstxt)\npaths_allowed(\"http://www.zillow.com\")\n\n[1] TRUE\n\n\n\n\nBut not Facebook\n\npaths_allowed(\"http://www.facebook.com\")\n\n[1] FALSE\n\n\n\n\n\nWhat websites have data about you? Think of 1-2 and see if scraping is allowed on those sites."
  },
  {
    "objectID": "slides/20/slides20.html#hypertext-markup-language",
    "href": "slides/20/slides20.html#hypertext-markup-language",
    "title": "Intro to Web Scraping",
    "section": "Hypertext Markup Language",
    "text": "Hypertext Markup Language\n\n\nLots of data on the web is still available as HTML\nIt is structured (hierarchical / tree based), but it’s often not available in a form useful for analysis (flat / tidy).\n\n\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is a title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\n  &lt;/body&gt;\n&lt;/html&gt;"
  },
  {
    "objectID": "slides/20/slides20.html#html-tags",
    "href": "slides/20/slides20.html#html-tags",
    "title": "Intro to Web Scraping",
    "section": "HTML tags",
    "text": "HTML tags\nHTML uses tags to describe different aspects of document content\n\n\n\n\n\n\nTag\nExample\n\n\n\nheading\n&lt;h1&gt;My Title&lt;/h1&gt;\n\n\nparagraph\n&lt;p&gt;A paragraph of content...&lt;/p&gt;\n\n\ntable\n&lt;table&gt; ... &lt;/table&gt;\n\n\nanchor (with attribute)\n&lt;a href=\"http://www.mysite.net\"&gt;click here for link&lt;/a&gt;"
  },
  {
    "objectID": "slides/20/slides20.html#rvest",
    "href": "slides/20/slides20.html#rvest",
    "title": "Intro to Web Scraping",
    "section": "{rvest}",
    "text": "{rvest}\n\n\n\n\n\nPronounced like “harvest”\nProcessing and manipulation of HTML data\nInstalled with the {tidyverse} but not loaded automatically\n\n\nlibrary(rvest)"
  },
  {
    "objectID": "slides/20/slides20.html#core-rvest-functions",
    "href": "slides/20/slides20.html#core-rvest-functions",
    "title": "Intro to Web Scraping",
    "section": "Core rvest functions",
    "text": "Core rvest functions\n\n\nFunction\nDescription\n\n\n\nread_html\nRead HTML data from a url or character string\n\n\nhtml_element\nSelect a specified element from HTML document\n\n\nhtml_elements\nSelect specified elements from HTML document\n\n\nhtml_table\nParse an HTML table into a data frame\n\n\nhtml_text\nExtract tag pairs’ content\n\n\nhtml_name\nExtract tags’ names\n\n\nhtml_attrs\nExtract all of each tag’s attributes\n\n\nhtml_attr\nExtract tags’ attribute value by name"
  },
  {
    "objectID": "slides/20/slides20.html#example-box-office-mojo",
    "href": "slides/20/slides20.html#example-box-office-mojo",
    "title": "Intro to Web Scraping",
    "section": "Example: box office mojo",
    "text": "Example: box office mojo\nhttps://www.boxofficemojo.com/year/2024/\n\n\n\n\nTake a look at the web page and the html source code\nChrome or Firefox: right click -&gt; View page source\n\nLook for the \"table\" div ID or tag"
  },
  {
    "objectID": "slides/20/slides20.html#read-html-into-r",
    "href": "slides/20/slides20.html#read-html-into-r",
    "title": "Intro to Web Scraping",
    "section": "Read HTML into R",
    "text": "Read HTML into R\n\npage &lt;- read_html(\"https://www.boxofficemojo.com/year/2024/\")\npage\n\n{html_document}\n&lt;html class=\"a-no-js\" data-19ax5a9jf=\"dingo\"&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body id=\"body\" class=\"mojo-page-id-yld a-m-us a-aui_72554-c a-aui_a11y_6 ...\n\nstr(page)\n\nList of 2\n $ node:&lt;externalptr&gt; \n $ doc :&lt;externalptr&gt; \n - attr(*, \"class\")= chr [1:2] \"xml_document\" \"xml_node\""
  },
  {
    "objectID": "slides/20/slides20.html#html-elements",
    "href": "slides/20/slides20.html#html-elements",
    "title": "Intro to Web Scraping",
    "section": "HTML elements",
    "text": "HTML elements\nThere are over 100 HTML elements:\n\nEvery HTML page must be in an &lt;html&gt; element, and it must have two children: &lt;head&gt; and &lt;body&gt;\n\nBlock tags like &lt;h1&gt;, &lt;p&gt;, &lt;ol&gt; form the structure of the page\nInline tags like &lt;b&gt;, &lt;i&gt;, and &lt;a&gt; format text inside block tags\n\n\nWe’ll often work with tables. HTML tables are composed of four main elements &lt;table&gt;, &lt;tr&gt; (table row), &lt;th&gt; (table heading), and &lt;td&gt; (table data).\n\n\n\nIf you run into one that you need to figure out, I recommend the MDN Web Docs for explanations and examples"
  },
  {
    "objectID": "slides/20/slides20.html#extract-tables",
    "href": "slides/20/slides20.html#extract-tables",
    "title": "Intro to Web Scraping",
    "section": "Extract tables",
    "text": "Extract tables\nUse html_element() or html_elements() to extract pieces out of HTML documents\n\ntables &lt;- page %&gt;% html_elements(\"table\")\nstr(tables)\n\nList of 1\n $ :List of 2\n  ..$ node:&lt;externalptr&gt; \n  ..$ doc :&lt;externalptr&gt; \n  ..- attr(*, \"class\")= chr \"xml_node\"\n - attr(*, \"class\")= chr \"xml_nodeset\""
  },
  {
    "objectID": "slides/20/slides20.html#html_element-vs-html_elements",
    "href": "slides/20/slides20.html#html_element-vs-html_elements",
    "title": "Intro to Web Scraping",
    "section": "\nhtml_element() vs html_elements()\n",
    "text": "html_element() vs html_elements()\n\n\nhtml_elements() returns all matching elements beneath any of the inputs, flattening results into a new node set\nhtml_element() always returns a vector the same length as the input, using a “missing” element where needed.\n\n\nTypically, we’ll use html_elements to get the overall structure for our data, followed by something else (sometimes html_element, sometimes html_table) to access what we need"
  },
  {
    "objectID": "slides/20/slides20.html#check-that-its-the-right-table",
    "href": "slides/20/slides20.html#check-that-its-the-right-table",
    "title": "Intro to Web Scraping",
    "section": "Check that it’s the right table",
    "text": "Check that it’s the right table\nIt looks promising!\n\ntables\n\n{xml_nodeset (1)}\n[1] &lt;table class=\"a-bordered a-horizontal-stripes a-size-base a-span12 mojo-b ...\n\n\n\nBut we don’t have a data frame yet…\n\ntables[[1]]\n\n{html_node}\n&lt;table class=\"a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated mojo-body-table-compact\"&gt;\n [1] &lt;tr&gt;\\n&lt;th class=\"a-text-right mojo-field-type-rank mojo-sort-column mojo ...\n [2] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n [3] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n [4] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n [5] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n [6] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n [7] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n [8] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n [9] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n[10] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n[11] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n[12] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n[13] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n[14] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n[15] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n[16] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n[17] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n[18] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n[19] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n[20] &lt;tr&gt;\\n&lt;td class=\"a-text-right mojo-header-column mojo-truncate mojo-fiel ...\n..."
  },
  {
    "objectID": "slides/20/slides20.html#parse-a-table-into-a-data-frame",
    "href": "slides/20/slides20.html#parse-a-table-into-a-data-frame",
    "title": "Intro to Web Scraping",
    "section": "Parse a table into a data frame",
    "text": "Parse a table into a data frame\n\ntop2024 &lt;- html_table(tables[[1]])\nglimpse(top2024)\n\nRows: 200\nColumns: 11\n$ Rank           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ Release        &lt;chr&gt; \"Inside Out 2\", \"Deadpool & Wolverine\", \"Wicked\", \"Moan…\n$ Genre          &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ Budget         &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Running Time` &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ Gross          &lt;chr&gt; \"$652,980,194\", \"$636,745,858\", \"$432,943,285\", \"$404,0…\n$ Theaters       &lt;chr&gt; \"4,440\", \"4,330\", \"3,888\", \"4,200\", \"4,449\", \"4,575\", \"…\n$ `Total Gross`  &lt;chr&gt; \"$652,980,194\", \"$636,745,858\", \"$471,274,200\", \"$458,7…\n$ `Release Date` &lt;chr&gt; \"Jun 14\", \"Jul 26\", \"Nov 22\", \"Nov 27\", \"Jul 3\", \"Sep 6…\n$ Distributor    &lt;chr&gt; \"Walt Disney Studios Motion Pictures\", \"Walt Disney Stu…\n$ Estimated      &lt;chr&gt; \"false\", \"false\", \"false\", \"false\", \"false\", \"false\", \"…"
  },
  {
    "objectID": "slides/20/slides20.html#parse-tables-into-data-frames",
    "href": "slides/20/slides20.html#parse-tables-into-data-frames",
    "title": "Intro to Web Scraping",
    "section": "Parse tables into data frames",
    "text": "Parse tables into data frames\nIf there had been multiple tables on the webpage, then we could parse them all at once using html_table()\nIt returns a list of data frames\n\ntable_list &lt;- html_table(tables)\nstr(table_list)\n\nList of 1\n $ : tibble [200 × 11] (S3: tbl_df/tbl/data.frame)\n  ..$ Rank        : int [1:200] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ Release     : chr [1:200] \"Inside Out 2\" \"Deadpool & Wolverine\" \"Wicked\" \"Moana 2\" ...\n  ..$ Genre       : chr [1:200] \"-\" \"-\" \"-\" \"-\" ...\n  ..$ Budget      : chr [1:200] \"-\" \"-\" \"-\" \"-\" ...\n  ..$ Running Time: chr [1:200] \"-\" \"-\" \"-\" \"-\" ...\n  ..$ Gross       : chr [1:200] \"$652,980,194\" \"$636,745,858\" \"$432,943,285\" \"$404,017,489\" ...\n  ..$ Theaters    : chr [1:200] \"4,440\" \"4,330\" \"3,888\" \"4,200\" ...\n  ..$ Total Gross : chr [1:200] \"$652,980,194\" \"$636,745,858\" \"$471,274,200\" \"$458,766,891\" ...\n  ..$ Release Date: chr [1:200] \"Jun 14\" \"Jul 26\" \"Nov 22\" \"Nov 27\" ...\n  ..$ Distributor : chr [1:200] \"Walt Disney Studios Motion Pictures\" \"Walt Disney Studios Motion Pictures\" \"Universal Pictures\" \"Walt Disney Studios Motion Pictures\" ...\n  ..$ Estimated   : chr [1:200] \"false\" \"false\" \"false\" \"false\" ..."
  },
  {
    "objectID": "slides/20/slides20.html#scrape-then-wrangle",
    "href": "slides/20/slides20.html#scrape-then-wrangle",
    "title": "Intro to Web Scraping",
    "section": "Scrape then wrangle",
    "text": "Scrape then wrangle\nData aren’t ready for analysis, too many character columns!\n\n\nRows: 200\nColumns: 11\n$ Rank           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ Release        &lt;chr&gt; \"Inside Out 2\", \"Deadpool & Wolverine\", \"Wicked\", \"Moan…\n$ Genre          &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ Budget         &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Running Time` &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ Gross          &lt;chr&gt; \"$652,980,194\", \"$636,745,858\", \"$432,943,285\", \"$404,0…\n$ Theaters       &lt;chr&gt; \"4,440\", \"4,330\", \"3,888\", \"4,200\", \"4,449\", \"4,575\", \"…\n$ `Total Gross`  &lt;chr&gt; \"$652,980,194\", \"$636,745,858\", \"$471,274,200\", \"$458,7…\n$ `Release Date` &lt;chr&gt; \"Jun 14\", \"Jul 26\", \"Nov 22\", \"Nov 27\", \"Jul 3\", \"Sep 6…\n$ Distributor    &lt;chr&gt; \"Walt Disney Studios Motion Pictures\", \"Walt Disney Stu…\n$ Estimated      &lt;chr&gt; \"false\", \"false\", \"false\", \"false\", \"false\", \"false\", \"…"
  },
  {
    "objectID": "slides/20/slides20.html#scrape-then-wrangle-1",
    "href": "slides/20/slides20.html#scrape-then-wrangle-1",
    "title": "Intro to Web Scraping",
    "section": "Scrape then wrangle",
    "text": "Scrape then wrangle\n\ntop2024 &lt;- top2024 %&gt;%\n  mutate(\n    Gross = parse_number(Gross),\n    Theaters = parse_number(Theaters),\n    `Total Gross` = parse_number(`Total Gross`)\n  ) %&gt;%\n  separate(`Release Date`, into = c(\"Month\", \"Day\"))\n\nglimpse(top2024)\n\nRows: 200\nColumns: 12\n$ Rank           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ Release        &lt;chr&gt; \"Inside Out 2\", \"Deadpool & Wolverine\", \"Wicked\", \"Moan…\n$ Genre          &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ Budget         &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Running Time` &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ Gross          &lt;dbl&gt; 652980194, 636745858, 432943285, 404017489, 361004205, …\n$ Theaters       &lt;dbl&gt; 4440, 4330, 3888, 4200, 4449, 4575, 4074, 4170, 3948, 4…\n$ `Total Gross`  &lt;dbl&gt; 652980194, 636745858, 471274200, 458766891, 361004205, …\n$ Month          &lt;chr&gt; \"Jun\", \"Jul\", \"Nov\", \"Nov\", \"Jul\", \"Sep\", \"Mar\", \"Jul\",…\n$ Day            &lt;chr&gt; \"14\", \"26\", \"22\", \"27\", \"3\", \"6\", \"1\", \"19\", \"29\", \"8\",…\n$ Distributor    &lt;chr&gt; \"Walt Disney Studios Motion Pictures\", \"Walt Disney Stu…\n$ Estimated      &lt;chr&gt; \"false\", \"false\", \"false\", \"false\", \"false\", \"false\", \"…"
  },
  {
    "objectID": "slides/20/slides20.html#scraped-data-will-almost-always-need-wranglingcleaning",
    "href": "slides/20/slides20.html#scraped-data-will-almost-always-need-wranglingcleaning",
    "title": "Intro to Web Scraping",
    "section": "Scraped data will almost always need wrangling/cleaning",
    "text": "Scraped data will almost always need wrangling/cleaning\n\nAre numeric columns numeric?\nAre date columns dates?\nAre factor and string columns treated correctly?"
  },
  {
    "objectID": "slides/20/slides20.html#section-1",
    "href": "slides/20/slides20.html#section-1",
    "title": "Intro to Web Scraping",
    "section": "",
    "text": ":::\nSource: Playing the Whole Game, Kim & Hardin\n:::"
  },
  {
    "objectID": "slides/20/slides20.html#what-next",
    "href": "slides/20/slides20.html#what-next",
    "title": "Intro to Web Scraping",
    "section": "What next?",
    "text": "What next?\n\n\nData we want to access isn’t always stored in tables\n\nExample: Carleton course search\n\n\n\nMore next class!"
  },
  {
    "objectID": "slides/05/slides05.html#today",
    "href": "slides/05/slides05.html#today",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Today",
    "text": "Today\n\ngit/GitHub\nIntro to Spatial Data\nMaking Maps in ggplot2"
  },
  {
    "objectID": "slides/05/slides05.html#section",
    "href": "slides/05/slides05.html#section",
    "title": "Intro to Maps  and Spatial Data",
    "section": "",
    "text": "Think of the state on GitHub as “worst case scenario”\nIf you screw things up, copy your important files (eg. hw.Rmd) to a safe place.\n\nUsually your files are JUST FINE. But it is easy to goof up the Git infrastructure when you’re new at this. And it can be hard to get that straightened out on your own.\n\nRename the existing local repo as a temporary measure, i.e. before you do something radical, like delete it.\nClone the original repo from GitHub to RStudio (follow the directions to create a new project). You are back to a happy state.\nCopy all relevant files back over from your safe space. The ones whose updated state you need to commit.\nKnit, commit, push\nCarry on with your life.\n\n\n\n\n\n\nBurn It All Down from Happy Git with R"
  },
  {
    "objectID": "slides/05/slides05.html#cholera",
    "href": "slides/05/slides05.html#cholera",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Cholera",
    "text": "Cholera\nIn 1854, a Cholera outbreak killed 127 people in 3 days in a London neighborhood, resulting in a mass exodus of local residents. At the time, people thought that Cholera w as an airborne disease. John Snow was a physician who was critical of the airborne theory, and set out to investigate.\n\nWhat might this data look like?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndate\nlast_name\nfirst_name\naddress\nage\ncause_of_death\n\n\n\n\nAug 31, 1854\nJones\nThomas\n26 Broad St.\n37\ncholera\n\n\nAug 31, 1854\nJones\nMary\n26 Broad St.\n11\ncholera\n\n\nSept 1, 1854\nWarwick\nMartin\n14 Broad St.\n23\ncholera\n\n\n\n\n\n\n\n\nSource: MDSR Ch17.1"
  },
  {
    "objectID": "slides/05/slides05.html#section-2",
    "href": "slides/05/slides05.html#section-2",
    "title": "Intro to Maps  and Spatial Data",
    "section": "",
    "text": "What makes “address” a useful variable is that it is linked to a specific location in the physical world. If we plot these addresses, we get something like the following:\n\n\n\n\n\n\n\n\n\n\n\nSource: MDSR Ch17.1"
  },
  {
    "objectID": "slides/05/slides05.html#section-3",
    "href": "slides/05/slides05.html#section-3",
    "title": "Intro to Maps  and Spatial Data",
    "section": "",
    "text": "While we can see patterns in the last plot, the underlying map of the London streets provides helpful context that makes it more intelligble:\n\n\n\n\n\n\n\nSource: MDSR Ch17.1"
  },
  {
    "objectID": "slides/05/slides05.html#section-4",
    "href": "slides/05/slides05.html#section-4",
    "title": "Intro to Maps  and Spatial Data",
    "section": "",
    "text": "Snow’s insight was driven by another set of data—the locations of the street-side water pumps (it’s kind of hard to see, but they are labelled on the map). Nearly all of the cases were clustered around a single pump on the center of Broad Street.\nJohn Snow’s map (and water pump) are now “famous” among epidemiologists and statisticians.\n\n\n\n\nJohn Snow’s water pump (and pub) from a 2019 visit\n\n\n\n\n\nSource: MDSR Ch17.1"
  },
  {
    "objectID": "slides/05/slides05.html#a-successful-data-science-episode",
    "href": "slides/05/slides05.html#a-successful-data-science-episode",
    "title": "Intro to Maps  and Spatial Data",
    "section": "A successful data science episode:",
    "text": "A successful data science episode:\n\nCombine three sources of data (Cholera deaths, water pump locations, and street map)\nWhile a model might have come to the same conclusion, simply plotting the data is much simpler (and more convincing to lots of people)\nThe problem was resolved when the data-based evidence was combined with a plausible model that explained the physical phenomenon.\n\n\n\nSource: MDSR Ch17.1"
  },
  {
    "objectID": "slides/05/slides05.html#what-is-a-map",
    "href": "slides/05/slides05.html#what-is-a-map",
    "title": "Intro to Maps  and Spatial Data",
    "section": "What is a map?",
    "text": "What is a map?\nA bunch of latitude longitude points…"
  },
  {
    "objectID": "slides/05/slides05.html#what-is-a-map-1",
    "href": "slides/05/slides05.html#what-is-a-map-1",
    "title": "Intro to Maps  and Spatial Data",
    "section": "What is a map?",
    "text": "What is a map?\n… that are connected with lines in a very specific order."
  },
  {
    "objectID": "slides/05/slides05.html#necessary-map-data",
    "href": "slides/05/slides05.html#necessary-map-data",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Necessary map data",
    "text": "Necessary map data\n\nlatitude/longitude points for all map boundaries\nwhich boundary group all lat/long points belong\nthe order to connect points within each group"
  },
  {
    "objectID": "slides/05/slides05.html#state-map-data",
    "href": "slides/05/slides05.html#state-map-data",
    "title": "Intro to Maps  and Spatial Data",
    "section": "State map data",
    "text": "State map data\nggplot2::map_data() provides the necessary information\n\nstates &lt;- map_data(\"state\")\nglimpse(states)\n\nRows: 15,537\nColumns: 6\n$ long      &lt;dbl&gt; -87.46201, -87.48493, -87.52503, -87.53076, -87.57087, -87.5…\n$ lat       &lt;dbl&gt; 30.38968, 30.37249, 30.37249, 30.33239, 30.32665, 30.32665, …\n$ group     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ order     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ region    &lt;chr&gt; \"alabama\", \"alabama\", \"alabama\", \"alabama\", \"alabama\", \"alab…\n$ subregion &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …"
  },
  {
    "objectID": "slides/05/slides05.html#using-geom_polygon",
    "href": "slides/05/slides05.html#using-geom_polygon",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Using geom_polygon()",
    "text": "Using geom_polygon()\nUsing geom_polygon() will treat states as solid shapes, making it easier to add color\n\n\nggplot(states, aes(x=long, y=lat, group=group)) + \n    geom_polygon(color=\"gold2\", fill=\"navyblue\")"
  },
  {
    "objectID": "slides/05/slides05.html#using-coord_fixed",
    "href": "slides/05/slides05.html#using-coord_fixed",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Using coord_fixed()",
    "text": "Using coord_fixed()\nUsing coord_fixed() forces x and y units to be equal\n\n\nggplot(states, aes(x=long, y=lat, group=group)) + \n    geom_polygon(color=\"gold2\", fill=\"navyblue\") +\n  coord_fixed()"
  },
  {
    "objectID": "slides/05/slides05.html#your-turn",
    "href": "slides/05/slides05.html#your-turn",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Your turn",
    "text": "Your turn\n\nggplot(states, aes(x=long, y=lat, group=group)) + \n    geom_polygon(color=\"gold2\", fill=\"navyblue\") +\n    coord_fixed()\n\n\n\nEdit this code so that each shape is colored in with a different color.\nYou only need the 3 variables used: long, lat, and group\n05-maps.Rmd file available in the activities repo\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/05/slides05.html#coordinate-systems-and-projections",
    "href": "slides/05/slides05.html#coordinate-systems-and-projections",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Coordinate Systems and Projections",
    "text": "Coordinate Systems and Projections"
  },
  {
    "objectID": "slides/05/slides05.html#section-5",
    "href": "slides/05/slides05.html#section-5",
    "title": "Intro to Maps  and Spatial Data",
    "section": "",
    "text": "Geospatial data exists on the globe and is generally described with a latitude and longitude. Any projection from the globe to euclidean space (X-Y plane) is going to cause some distortion."
  },
  {
    "objectID": "slides/05/slides05.html#section-6",
    "href": "slides/05/slides05.html#section-6",
    "title": "Intro to Maps  and Spatial Data",
    "section": "",
    "text": "From The West Wing Season 2 Episode 16"
  },
  {
    "objectID": "slides/05/slides05.html#changing-the-coordinate-system",
    "href": "slides/05/slides05.html#changing-the-coordinate-system",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Changing the coordinate system",
    "text": "Changing the coordinate system\ncoord_map function provides a Mercator projection (mapproj package has more options)\n\n\nggplot(states, aes(x=long, y=lat, group=group)) + \n  geom_polygon(color=\"gold2\", fill=\"navyblue\") + \n  coord_map() + \n  theme_map()"
  },
  {
    "objectID": "slides/05/slides05.html#changing-the-coordinate-system-1",
    "href": "slides/05/slides05.html#changing-the-coordinate-system-1",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Changing the coordinate system",
    "text": "Changing the coordinate system\ncoord_map function provides a Mercator projection (mapproj package has more options)\n\n\nggplot(states, aes(x=long, y=lat, group=group)) + \n  geom_polygon(color=\"gold2\", fill=\"navyblue\") + \n  coord_map(projection = \"sinusoidal\") + \n  theme_map()"
  },
  {
    "objectID": "slides/05/slides05.html#mercator-vs-sinusoidal-projection-world-map",
    "href": "slides/05/slides05.html#mercator-vs-sinusoidal-projection-world-map",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Mercator vs Sinusoidal projection (world map)",
    "text": "Mercator vs Sinusoidal projection (world map)\n\nworld &lt;- map_data(\"world\")\n\nggplot(world, aes(x=long, y=lat, group=group)) + \n  geom_polygon(color=\"gold2\", fill=\"navyblue\") + \n  coord_map(projection = \"mercator\", xlim = c(-180, 180)) + \n  theme_map()"
  },
  {
    "objectID": "slides/05/slides05.html#common-types-of-maps",
    "href": "slides/05/slides05.html#common-types-of-maps",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Common Types of Maps",
    "text": "Common Types of Maps\n\nChloropleth\nProportional Symbol\nCartograms/Geofacets"
  },
  {
    "objectID": "slides/05/slides05.html#chloropleth",
    "href": "slides/05/slides05.html#chloropleth",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Chloropleth",
    "text": "Chloropleth\nFill in regions with variable values\n\n\nNeed two data sources:\n\nmap data with lat, long, region\ndata with measurements for each region\n\nyou don’t need to join them!\n\n\n\n\n\nFundamentals of Data Visualization"
  },
  {
    "objectID": "slides/05/slides05.html#proportional-symbol",
    "href": "slides/05/slides05.html#proportional-symbol",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Proportional Symbol",
    "text": "Proportional Symbol\nOverlay symbols on an existing map, where the size of the shape is proportional to the variable\n\n\n\nMade with {ggmap} and {nycflights23}"
  },
  {
    "objectID": "slides/05/slides05.html#cartogram",
    "href": "slides/05/slides05.html#cartogram",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Cartogram",
    "text": "Cartogram\nUse approximate geographical position to encode information, but not lat/long directly\n\n\n\nFundamentals of Data Visualization"
  },
  {
    "objectID": "slides/05/slides05.html#your-task",
    "href": "slides/05/slides05.html#your-task",
    "title": "Intro to Maps  and Spatial Data",
    "section": "Your task",
    "text": "Your task\nYour task is to use the American Community Survey data to make a chloropleth map of the US\n\nYou should:\n\nUse the starter code provided in 05-maps.rmd\nChoose a different variable\nChange the color scale\nUpdate the title, axis labels, and legend"
  },
  {
    "objectID": "slides/03/slides03.html#plan-for-today",
    "href": "slides/03/slides03.html#plan-for-today",
    "title": "ggplot2",
    "section": "Plan for today:",
    "text": "Plan for today:\n\nSuper quick grammar of graphics recap\nSpeed Groupwork\nIntro to portfolio project 1"
  },
  {
    "objectID": "slides/03/slides03.html#what-are-the-essential-elements-of-this-scatterplot",
    "href": "slides/03/slides03.html#what-are-the-essential-elements-of-this-scatterplot",
    "title": "ggplot2",
    "section": "What are the essential elements of this scatterplot?",
    "text": "What are the essential elements of this scatterplot?"
  },
  {
    "objectID": "slides/03/slides03.html#data",
    "href": "slides/03/slides03.html#data",
    "title": "ggplot2",
    "section": "Data",
    "text": "Data\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007\n\n\nAdelie\nTorgersen\n38.9\n17.8\n181\n3625\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.2\n19.6\n195\n4675\nmale\n2007\n\n\nAdelie\nTorgersen\n34.1\n18.1\n193\n3475\nNA\n2007\n\n\nAdelie\nTorgersen\n42.0\n20.2\n190\n4250\nNA\n2007\n\n\nAdelie\nTorgersen\n37.8\n17.1\n186\n3300\nNA\n2007\n\n\nAdelie\nTorgersen\n37.8\n17.3\n180\n3700\nNA\n2007\n\n\nAdelie\nTorgersen\n41.1\n17.6\n182\n3200\nfemale\n2007\n\n\nAdelie\nTorgersen\n38.6\n21.2\n191\n3800\nmale\n2007\n\n\nAdelie\nTorgersen\n34.6\n21.1\n198\n4400\nmale\n2007\n\n\nAdelie\nTorgersen\n36.6\n17.8\n185\n3700\nfemale\n2007\n\n\nAdelie\nTorgersen\n38.7\n19.0\n195\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n42.5\n20.7\n197\n4500\nmale\n2007\n\n\nAdelie\nTorgersen\n34.4\n18.4\n184\n3325\nfemale\n2007\n\n\nAdelie\nTorgersen\n46.0\n21.5\n194\n4200\nmale\n2007\n\n\nAdelie\nBiscoe\n37.8\n18.3\n174\n3400\nfemale\n2007\n\n\nAdelie\nBiscoe\n37.7\n18.7\n180\n3600\nmale\n2007\n\n\nAdelie\nBiscoe\n35.9\n19.2\n189\n3800\nfemale\n2007\n\n\nAdelie\nBiscoe\n38.2\n18.1\n185\n3950\nmale\n2007\n\n\nAdelie\nBiscoe\n38.8\n17.2\n180\n3800\nmale\n2007\n\n\nAdelie\nBiscoe\n35.3\n18.9\n187\n3800\nfemale\n2007\n\n\nAdelie\nBiscoe\n40.6\n18.6\n183\n3550\nmale\n2007\n\n\nAdelie\nBiscoe\n40.5\n17.9\n187\n3200\nfemale\n2007\n\n\nAdelie\nBiscoe\n37.9\n18.6\n172\n3150\nfemale\n2007\n\n\nAdelie\nBiscoe\n40.5\n18.9\n180\n3950\nmale\n2007\n\n\nAdelie\nDream\n39.5\n16.7\n178\n3250\nfemale\n2007\n\n\nAdelie\nDream\n37.2\n18.1\n178\n3900\nmale\n2007\n\n\nAdelie\nDream\n39.5\n17.8\n188\n3300\nfemale\n2007\n\n\nAdelie\nDream\n40.9\n18.9\n184\n3900\nmale\n2007\n\n\nAdelie\nDream\n36.4\n17.0\n195\n3325\nfemale\n2007\n\n\nAdelie\nDream\n39.2\n21.1\n196\n4150\nmale\n2007\n\n\nAdelie\nDream\n38.8\n20.0\n190\n3950\nmale\n2007\n\n\nAdelie\nDream\n42.2\n18.5\n180\n3550\nfemale\n2007\n\n\nAdelie\nDream\n37.6\n19.3\n181\n3300\nfemale\n2007\n\n\nAdelie\nDream\n39.8\n19.1\n184\n4650\nmale\n2007\n\n\nAdelie\nDream\n36.5\n18.0\n182\n3150\nfemale\n2007\n\n\nAdelie\nDream\n40.8\n18.4\n195\n3900\nmale\n2007\n\n\nAdelie\nDream\n36.0\n18.5\n186\n3100\nfemale\n2007\n\n\nAdelie\nDream\n44.1\n19.7\n196\n4400\nmale\n2007\n\n\nAdelie\nDream\n37.0\n16.9\n185\n3000\nfemale\n2007\n\n\nAdelie\nDream\n39.6\n18.8\n190\n4600\nmale\n2007\n\n\nAdelie\nDream\n41.1\n19.0\n182\n3425\nmale\n2007\n\n\nAdelie\nDream\n37.5\n18.9\n179\n2975\nNA\n2007\n\n\nAdelie\nDream\n36.0\n17.9\n190\n3450\nfemale\n2007\n\n\nAdelie\nDream\n42.3\n21.2\n191\n4150\nmale\n2007\n\n\nAdelie\nBiscoe\n39.6\n17.7\n186\n3500\nfemale\n2008\n\n\nAdelie\nBiscoe\n40.1\n18.9\n188\n4300\nmale\n2008\n\n\nAdelie\nBiscoe\n35.0\n17.9\n190\n3450\nfemale\n2008\n\n\nAdelie\nBiscoe\n42.0\n19.5\n200\n4050\nmale\n2008\n\n\nAdelie\nBiscoe\n34.5\n18.1\n187\n2900\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.4\n18.6\n191\n3700\nmale\n2008\n\n\nAdelie\nBiscoe\n39.0\n17.5\n186\n3550\nfemale\n2008\n\n\nAdelie\nBiscoe\n40.6\n18.8\n193\n3800\nmale\n2008\n\n\nAdelie\nBiscoe\n36.5\n16.6\n181\n2850\nfemale\n2008\n\n\nAdelie\nBiscoe\n37.6\n19.1\n194\n3750\nmale\n2008\n\n\nAdelie\nBiscoe\n35.7\n16.9\n185\n3150\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.3\n21.1\n195\n4400\nmale\n2008\n\n\nAdelie\nBiscoe\n37.6\n17.0\n185\n3600\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.1\n18.2\n192\n4050\nmale\n2008\n\n\nAdelie\nBiscoe\n36.4\n17.1\n184\n2850\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.6\n18.0\n192\n3950\nmale\n2008\n\n\nAdelie\nBiscoe\n35.5\n16.2\n195\n3350\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.1\n19.1\n188\n4100\nmale\n2008\n\n\nAdelie\nTorgersen\n35.9\n16.6\n190\n3050\nfemale\n2008\n\n\nAdelie\nTorgersen\n41.8\n19.4\n198\n4450\nmale\n2008\n\n\nAdelie\nTorgersen\n33.5\n19.0\n190\n3600\nfemale\n2008\n\n\nAdelie\nTorgersen\n39.7\n18.4\n190\n3900\nmale\n2008\n\n\nAdelie\nTorgersen\n39.6\n17.2\n196\n3550\nfemale\n2008\n\n\nAdelie\nTorgersen\n45.8\n18.9\n197\n4150\nmale\n2008\n\n\nAdelie\nTorgersen\n35.5\n17.5\n190\n3700\nfemale\n2008\n\n\nAdelie\nTorgersen\n42.8\n18.5\n195\n4250\nmale\n2008\n\n\nAdelie\nTorgersen\n40.9\n16.8\n191\n3700\nfemale\n2008\n\n\nAdelie\nTorgersen\n37.2\n19.4\n184\n3900\nmale\n2008\n\n\nAdelie\nTorgersen\n36.2\n16.1\n187\n3550\nfemale\n2008\n\n\nAdelie\nTorgersen\n42.1\n19.1\n195\n4000\nmale\n2008\n\n\nAdelie\nTorgersen\n34.6\n17.2\n189\n3200\nfemale\n2008\n\n\nAdelie\nTorgersen\n42.9\n17.6\n196\n4700\nmale\n2008\n\n\nAdelie\nTorgersen\n36.7\n18.8\n187\n3800\nfemale\n2008\n\n\nAdelie\nTorgersen\n35.1\n19.4\n193\n4200\nmale\n2008\n\n\nAdelie\nDream\n37.3\n17.8\n191\n3350\nfemale\n2008\n\n\nAdelie\nDream\n41.3\n20.3\n194\n3550\nmale\n2008\n\n\nAdelie\nDream\n36.3\n19.5\n190\n3800\nmale\n2008\n\n\nAdelie\nDream\n36.9\n18.6\n189\n3500\nfemale\n2008\n\n\nAdelie\nDream\n38.3\n19.2\n189\n3950\nmale\n2008\n\n\nAdelie\nDream\n38.9\n18.8\n190\n3600\nfemale\n2008\n\n\nAdelie\nDream\n35.7\n18.0\n202\n3550\nfemale\n2008\n\n\nAdelie\nDream\n41.1\n18.1\n205\n4300\nmale\n2008\n\n\nAdelie\nDream\n34.0\n17.1\n185\n3400\nfemale\n2008\n\n\nAdelie\nDream\n39.6\n18.1\n186\n4450\nmale\n2008\n\n\nAdelie\nDream\n36.2\n17.3\n187\n3300\nfemale\n2008\n\n\nAdelie\nDream\n40.8\n18.9\n208\n4300\nmale\n2008\n\n\nAdelie\nDream\n38.1\n18.6\n190\n3700\nfemale\n2008\n\n\nAdelie\nDream\n40.3\n18.5\n196\n4350\nmale\n2008\n\n\nAdelie\nDream\n33.1\n16.1\n178\n2900\nfemale\n2008\n\n\nAdelie\nDream\n43.2\n18.5\n192\n4100\nmale\n2008\n\n\nAdelie\nBiscoe\n35.0\n17.9\n192\n3725\nfemale\n2009\n\n\nAdelie\nBiscoe\n41.0\n20.0\n203\n4725\nmale\n2009\n\n\nAdelie\nBiscoe\n37.7\n16.0\n183\n3075\nfemale\n2009\n\n\nAdelie\nBiscoe\n37.8\n20.0\n190\n4250\nmale\n2009\n\n\nAdelie\nBiscoe\n37.9\n18.6\n193\n2925\nfemale\n2009\n\n\nAdelie\nBiscoe\n39.7\n18.9\n184\n3550\nmale\n2009\n\n\nAdelie\nBiscoe\n38.6\n17.2\n199\n3750\nfemale\n2009\n\n\nAdelie\nBiscoe\n38.2\n20.0\n190\n3900\nmale\n2009\n\n\nAdelie\nBiscoe\n38.1\n17.0\n181\n3175\nfemale\n2009\n\n\nAdelie\nBiscoe\n43.2\n19.0\n197\n4775\nmale\n2009\n\n\nAdelie\nBiscoe\n38.1\n16.5\n198\n3825\nfemale\n2009\n\n\nAdelie\nBiscoe\n45.6\n20.3\n191\n4600\nmale\n2009\n\n\nAdelie\nBiscoe\n39.7\n17.7\n193\n3200\nfemale\n2009\n\n\nAdelie\nBiscoe\n42.2\n19.5\n197\n4275\nmale\n2009\n\n\nAdelie\nBiscoe\n39.6\n20.7\n191\n3900\nfemale\n2009\n\n\nAdelie\nBiscoe\n42.7\n18.3\n196\n4075\nmale\n2009\n\n\nAdelie\nTorgersen\n38.6\n17.0\n188\n2900\nfemale\n2009\n\n\nAdelie\nTorgersen\n37.3\n20.5\n199\n3775\nmale\n2009\n\n\nAdelie\nTorgersen\n35.7\n17.0\n189\n3350\nfemale\n2009\n\n\nAdelie\nTorgersen\n41.1\n18.6\n189\n3325\nmale\n2009\n\n\nAdelie\nTorgersen\n36.2\n17.2\n187\n3150\nfemale\n2009\n\n\nAdelie\nTorgersen\n37.7\n19.8\n198\n3500\nmale\n2009\n\n\nAdelie\nTorgersen\n40.2\n17.0\n176\n3450\nfemale\n2009\n\n\nAdelie\nTorgersen\n41.4\n18.5\n202\n3875\nmale\n2009\n\n\nAdelie\nTorgersen\n35.2\n15.9\n186\n3050\nfemale\n2009\n\n\nAdelie\nTorgersen\n40.6\n19.0\n199\n4000\nmale\n2009\n\n\nAdelie\nTorgersen\n38.8\n17.6\n191\n3275\nfemale\n2009\n\n\nAdelie\nTorgersen\n41.5\n18.3\n195\n4300\nmale\n2009\n\n\nAdelie\nTorgersen\n39.0\n17.1\n191\n3050\nfemale\n2009\n\n\nAdelie\nTorgersen\n44.1\n18.0\n210\n4000\nmale\n2009\n\n\nAdelie\nTorgersen\n38.5\n17.9\n190\n3325\nfemale\n2009\n\n\nAdelie\nTorgersen\n43.1\n19.2\n197\n3500\nmale\n2009\n\n\nAdelie\nDream\n36.8\n18.5\n193\n3500\nfemale\n2009\n\n\nAdelie\nDream\n37.5\n18.5\n199\n4475\nmale\n2009\n\n\nAdelie\nDream\n38.1\n17.6\n187\n3425\nfemale\n2009\n\n\nAdelie\nDream\n41.1\n17.5\n190\n3900\nmale\n2009\n\n\nAdelie\nDream\n35.6\n17.5\n191\n3175\nfemale\n2009\n\n\nAdelie\nDream\n40.2\n20.1\n200\n3975\nmale\n2009\n\n\nAdelie\nDream\n37.0\n16.5\n185\n3400\nfemale\n2009\n\n\nAdelie\nDream\n39.7\n17.9\n193\n4250\nmale\n2009\n\n\nAdelie\nDream\n40.2\n17.1\n193\n3400\nfemale\n2009\n\n\nAdelie\nDream\n40.6\n17.2\n187\n3475\nmale\n2009\n\n\nAdelie\nDream\n32.1\n15.5\n188\n3050\nfemale\n2009\n\n\nAdelie\nDream\n40.7\n17.0\n190\n3725\nmale\n2009\n\n\nAdelie\nDream\n37.3\n16.8\n192\n3000\nfemale\n2009\n\n\nAdelie\nDream\n39.0\n18.7\n185\n3650\nmale\n2009\n\n\nAdelie\nDream\n39.2\n18.6\n190\n4250\nmale\n2009\n\n\nAdelie\nDream\n36.6\n18.4\n184\n3475\nfemale\n2009\n\n\nAdelie\nDream\n36.0\n17.8\n195\n3450\nfemale\n2009\n\n\nAdelie\nDream\n37.8\n18.1\n193\n3750\nmale\n2009\n\n\nAdelie\nDream\n36.0\n17.1\n187\n3700\nfemale\n2009\n\n\nAdelie\nDream\n41.5\n18.5\n201\n4000\nmale\n2009\n\n\nGentoo\nBiscoe\n46.1\n13.2\n211\n4500\nfemale\n2007\n\n\nGentoo\nBiscoe\n50.0\n16.3\n230\n5700\nmale\n2007\n\n\nGentoo\nBiscoe\n48.7\n14.1\n210\n4450\nfemale\n2007\n\n\nGentoo\nBiscoe\n50.0\n15.2\n218\n5700\nmale\n2007\n\n\nGentoo\nBiscoe\n47.6\n14.5\n215\n5400\nmale\n2007\n\n\nGentoo\nBiscoe\n46.5\n13.5\n210\n4550\nfemale\n2007\n\n\nGentoo\nBiscoe\n45.4\n14.6\n211\n4800\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.7\n15.3\n219\n5200\nmale\n2007\n\n\nGentoo\nBiscoe\n43.3\n13.4\n209\n4400\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.8\n15.4\n215\n5150\nmale\n2007\n\n\nGentoo\nBiscoe\n40.9\n13.7\n214\n4650\nfemale\n2007\n\n\nGentoo\nBiscoe\n49.0\n16.1\n216\n5550\nmale\n2007\n\n\nGentoo\nBiscoe\n45.5\n13.7\n214\n4650\nfemale\n2007\n\n\nGentoo\nBiscoe\n48.4\n14.6\n213\n5850\nmale\n2007\n\n\nGentoo\nBiscoe\n45.8\n14.6\n210\n4200\nfemale\n2007\n\n\nGentoo\nBiscoe\n49.3\n15.7\n217\n5850\nmale\n2007\n\n\nGentoo\nBiscoe\n42.0\n13.5\n210\n4150\nfemale\n2007\n\n\nGentoo\nBiscoe\n49.2\n15.2\n221\n6300\nmale\n2007\n\n\nGentoo\nBiscoe\n46.2\n14.5\n209\n4800\nfemale\n2007\n\n\nGentoo\nBiscoe\n48.7\n15.1\n222\n5350\nmale\n2007\n\n\nGentoo\nBiscoe\n50.2\n14.3\n218\n5700\nmale\n2007\n\n\nGentoo\nBiscoe\n45.1\n14.5\n215\n5000\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.5\n14.5\n213\n4400\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.3\n15.8\n215\n5050\nmale\n2007\n\n\nGentoo\nBiscoe\n42.9\n13.1\n215\n5000\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.1\n15.1\n215\n5100\nmale\n2007\n\n\nGentoo\nBiscoe\n44.5\n14.3\n216\n4100\nNA\n2007\n\n\nGentoo\nBiscoe\n47.8\n15.0\n215\n5650\nmale\n2007\n\n\nGentoo\nBiscoe\n48.2\n14.3\n210\n4600\nfemale\n2007\n\n\nGentoo\nBiscoe\n50.0\n15.3\n220\n5550\nmale\n2007\n\n\nGentoo\nBiscoe\n47.3\n15.3\n222\n5250\nmale\n2007\n\n\nGentoo\nBiscoe\n42.8\n14.2\n209\n4700\nfemale\n2007\n\n\nGentoo\nBiscoe\n45.1\n14.5\n207\n5050\nfemale\n2007\n\n\nGentoo\nBiscoe\n59.6\n17.0\n230\n6050\nmale\n2007\n\n\nGentoo\nBiscoe\n49.1\n14.8\n220\n5150\nfemale\n2008\n\n\nGentoo\nBiscoe\n48.4\n16.3\n220\n5400\nmale\n2008\n\n\nGentoo\nBiscoe\n42.6\n13.7\n213\n4950\nfemale\n2008\n\n\nGentoo\nBiscoe\n44.4\n17.3\n219\n5250\nmale\n2008\n\n\nGentoo\nBiscoe\n44.0\n13.6\n208\n4350\nfemale\n2008\n\n\nGentoo\nBiscoe\n48.7\n15.7\n208\n5350\nmale\n2008\n\n\nGentoo\nBiscoe\n42.7\n13.7\n208\n3950\nfemale\n2008\n\n\nGentoo\nBiscoe\n49.6\n16.0\n225\n5700\nmale\n2008\n\n\nGentoo\nBiscoe\n45.3\n13.7\n210\n4300\nfemale\n2008\n\n\nGentoo\nBiscoe\n49.6\n15.0\n216\n4750\nmale\n2008\n\n\nGentoo\nBiscoe\n50.5\n15.9\n222\n5550\nmale\n2008\n\n\nGentoo\nBiscoe\n43.6\n13.9\n217\n4900\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.5\n13.9\n210\n4200\nfemale\n2008\n\n\nGentoo\nBiscoe\n50.5\n15.9\n225\n5400\nmale\n2008\n\n\nGentoo\nBiscoe\n44.9\n13.3\n213\n5100\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.2\n15.8\n215\n5300\nmale\n2008\n\n\nGentoo\nBiscoe\n46.6\n14.2\n210\n4850\nfemale\n2008\n\n\nGentoo\nBiscoe\n48.5\n14.1\n220\n5300\nmale\n2008\n\n\nGentoo\nBiscoe\n45.1\n14.4\n210\n4400\nfemale\n2008\n\n\nGentoo\nBiscoe\n50.1\n15.0\n225\n5000\nmale\n2008\n\n\nGentoo\nBiscoe\n46.5\n14.4\n217\n4900\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.0\n15.4\n220\n5050\nmale\n2008\n\n\nGentoo\nBiscoe\n43.8\n13.9\n208\n4300\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.5\n15.0\n220\n5000\nmale\n2008\n\n\nGentoo\nBiscoe\n43.2\n14.5\n208\n4450\nfemale\n2008\n\n\nGentoo\nBiscoe\n50.4\n15.3\n224\n5550\nmale\n2008\n\n\nGentoo\nBiscoe\n45.3\n13.8\n208\n4200\nfemale\n2008\n\n\nGentoo\nBiscoe\n46.2\n14.9\n221\n5300\nmale\n2008\n\n\nGentoo\nBiscoe\n45.7\n13.9\n214\n4400\nfemale\n2008\n\n\nGentoo\nBiscoe\n54.3\n15.7\n231\n5650\nmale\n2008\n\n\nGentoo\nBiscoe\n45.8\n14.2\n219\n4700\nfemale\n2008\n\n\nGentoo\nBiscoe\n49.8\n16.8\n230\n5700\nmale\n2008\n\n\nGentoo\nBiscoe\n46.2\n14.4\n214\n4650\nNA\n2008\n\n\nGentoo\nBiscoe\n49.5\n16.2\n229\n5800\nmale\n2008\n\n\nGentoo\nBiscoe\n43.5\n14.2\n220\n4700\nfemale\n2008\n\n\nGentoo\nBiscoe\n50.7\n15.0\n223\n5550\nmale\n2008\n\n\nGentoo\nBiscoe\n47.7\n15.0\n216\n4750\nfemale\n2008\n\n\nGentoo\nBiscoe\n46.4\n15.6\n221\n5000\nmale\n2008\n\n\nGentoo\nBiscoe\n48.2\n15.6\n221\n5100\nmale\n2008\n\n\nGentoo\nBiscoe\n46.5\n14.8\n217\n5200\nfemale\n2008\n\n\nGentoo\nBiscoe\n46.4\n15.0\n216\n4700\nfemale\n2008\n\n\nGentoo\nBiscoe\n48.6\n16.0\n230\n5800\nmale\n2008\n\n\nGentoo\nBiscoe\n47.5\n14.2\n209\n4600\nfemale\n2008\n\n\nGentoo\nBiscoe\n51.1\n16.3\n220\n6000\nmale\n2008\n\n\nGentoo\nBiscoe\n45.2\n13.8\n215\n4750\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.2\n16.4\n223\n5950\nmale\n2008\n\n\nGentoo\nBiscoe\n49.1\n14.5\n212\n4625\nfemale\n2009\n\n\nGentoo\nBiscoe\n52.5\n15.6\n221\n5450\nmale\n2009\n\n\nGentoo\nBiscoe\n47.4\n14.6\n212\n4725\nfemale\n2009\n\n\nGentoo\nBiscoe\n50.0\n15.9\n224\n5350\nmale\n2009\n\n\nGentoo\nBiscoe\n44.9\n13.8\n212\n4750\nfemale\n2009\n\n\nGentoo\nBiscoe\n50.8\n17.3\n228\n5600\nmale\n2009\n\n\nGentoo\nBiscoe\n43.4\n14.4\n218\n4600\nfemale\n2009\n\n\nGentoo\nBiscoe\n51.3\n14.2\n218\n5300\nmale\n2009\n\n\nGentoo\nBiscoe\n47.5\n14.0\n212\n4875\nfemale\n2009\n\n\nGentoo\nBiscoe\n52.1\n17.0\n230\n5550\nmale\n2009\n\n\nGentoo\nBiscoe\n47.5\n15.0\n218\n4950\nfemale\n2009\n\n\nGentoo\nBiscoe\n52.2\n17.1\n228\n5400\nmale\n2009\n\n\nGentoo\nBiscoe\n45.5\n14.5\n212\n4750\nfemale\n2009\n\n\nGentoo\nBiscoe\n49.5\n16.1\n224\n5650\nmale\n2009\n\n\nGentoo\nBiscoe\n44.5\n14.7\n214\n4850\nfemale\n2009\n\n\nGentoo\nBiscoe\n50.8\n15.7\n226\n5200\nmale\n2009\n\n\nGentoo\nBiscoe\n49.4\n15.8\n216\n4925\nmale\n2009\n\n\nGentoo\nBiscoe\n46.9\n14.6\n222\n4875\nfemale\n2009\n\n\nGentoo\nBiscoe\n48.4\n14.4\n203\n4625\nfemale\n2009\n\n\nGentoo\nBiscoe\n51.1\n16.5\n225\n5250\nmale\n2009\n\n\nGentoo\nBiscoe\n48.5\n15.0\n219\n4850\nfemale\n2009\n\n\nGentoo\nBiscoe\n55.9\n17.0\n228\n5600\nmale\n2009\n\n\nGentoo\nBiscoe\n47.2\n15.5\n215\n4975\nfemale\n2009\n\n\nGentoo\nBiscoe\n49.1\n15.0\n228\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n47.3\n13.8\n216\n4725\nNA\n2009\n\n\nGentoo\nBiscoe\n46.8\n16.1\n215\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n41.7\n14.7\n210\n4700\nfemale\n2009\n\n\nGentoo\nBiscoe\n53.4\n15.8\n219\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n43.3\n14.0\n208\n4575\nfemale\n2009\n\n\nGentoo\nBiscoe\n48.1\n15.1\n209\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n50.5\n15.2\n216\n5000\nfemale\n2009\n\n\nGentoo\nBiscoe\n49.8\n15.9\n229\n5950\nmale\n2009\n\n\nGentoo\nBiscoe\n43.5\n15.2\n213\n4650\nfemale\n2009\n\n\nGentoo\nBiscoe\n51.5\n16.3\n230\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n46.2\n14.1\n217\n4375\nfemale\n2009\n\n\nGentoo\nBiscoe\n55.1\n16.0\n230\n5850\nmale\n2009\n\n\nGentoo\nBiscoe\n44.5\n15.7\n217\n4875\nNA\n2009\n\n\nGentoo\nBiscoe\n48.8\n16.2\n222\n6000\nmale\n2009\n\n\nGentoo\nBiscoe\n47.2\n13.7\n214\n4925\nfemale\n2009\n\n\nGentoo\nBiscoe\nNA\nNA\nNA\nNA\nNA\n2009\n\n\nGentoo\nBiscoe\n46.8\n14.3\n215\n4850\nfemale\n2009\n\n\nGentoo\nBiscoe\n50.4\n15.7\n222\n5750\nmale\n2009\n\n\nGentoo\nBiscoe\n45.2\n14.8\n212\n5200\nfemale\n2009\n\n\nGentoo\nBiscoe\n49.9\n16.1\n213\n5400\nmale\n2009\n\n\nChinstrap\nDream\n46.5\n17.9\n192\n3500\nfemale\n2007\n\n\nChinstrap\nDream\n50.0\n19.5\n196\n3900\nmale\n2007\n\n\nChinstrap\nDream\n51.3\n19.2\n193\n3650\nmale\n2007\n\n\nChinstrap\nDream\n45.4\n18.7\n188\n3525\nfemale\n2007\n\n\nChinstrap\nDream\n52.7\n19.8\n197\n3725\nmale\n2007\n\n\nChinstrap\nDream\n45.2\n17.8\n198\n3950\nfemale\n2007\n\n\nChinstrap\nDream\n46.1\n18.2\n178\n3250\nfemale\n2007\n\n\nChinstrap\nDream\n51.3\n18.2\n197\n3750\nmale\n2007\n\n\nChinstrap\nDream\n46.0\n18.9\n195\n4150\nfemale\n2007\n\n\nChinstrap\nDream\n51.3\n19.9\n198\n3700\nmale\n2007\n\n\nChinstrap\nDream\n46.6\n17.8\n193\n3800\nfemale\n2007\n\n\nChinstrap\nDream\n51.7\n20.3\n194\n3775\nmale\n2007\n\n\nChinstrap\nDream\n47.0\n17.3\n185\n3700\nfemale\n2007\n\n\nChinstrap\nDream\n52.0\n18.1\n201\n4050\nmale\n2007\n\n\nChinstrap\nDream\n45.9\n17.1\n190\n3575\nfemale\n2007\n\n\nChinstrap\nDream\n50.5\n19.6\n201\n4050\nmale\n2007\n\n\nChinstrap\nDream\n50.3\n20.0\n197\n3300\nmale\n2007\n\n\nChinstrap\nDream\n58.0\n17.8\n181\n3700\nfemale\n2007\n\n\nChinstrap\nDream\n46.4\n18.6\n190\n3450\nfemale\n2007\n\n\nChinstrap\nDream\n49.2\n18.2\n195\n4400\nmale\n2007\n\n\nChinstrap\nDream\n42.4\n17.3\n181\n3600\nfemale\n2007\n\n\nChinstrap\nDream\n48.5\n17.5\n191\n3400\nmale\n2007\n\n\nChinstrap\nDream\n43.2\n16.6\n187\n2900\nfemale\n2007\n\n\nChinstrap\nDream\n50.6\n19.4\n193\n3800\nmale\n2007\n\n\nChinstrap\nDream\n46.7\n17.9\n195\n3300\nfemale\n2007\n\n\nChinstrap\nDream\n52.0\n19.0\n197\n4150\nmale\n2007\n\n\nChinstrap\nDream\n50.5\n18.4\n200\n3400\nfemale\n2008\n\n\nChinstrap\nDream\n49.5\n19.0\n200\n3800\nmale\n2008\n\n\nChinstrap\nDream\n46.4\n17.8\n191\n3700\nfemale\n2008\n\n\nChinstrap\nDream\n52.8\n20.0\n205\n4550\nmale\n2008\n\n\nChinstrap\nDream\n40.9\n16.6\n187\n3200\nfemale\n2008\n\n\nChinstrap\nDream\n54.2\n20.8\n201\n4300\nmale\n2008\n\n\nChinstrap\nDream\n42.5\n16.7\n187\n3350\nfemale\n2008\n\n\nChinstrap\nDream\n51.0\n18.8\n203\n4100\nmale\n2008\n\n\nChinstrap\nDream\n49.7\n18.6\n195\n3600\nmale\n2008\n\n\nChinstrap\nDream\n47.5\n16.8\n199\n3900\nfemale\n2008\n\n\nChinstrap\nDream\n47.6\n18.3\n195\n3850\nfemale\n2008\n\n\nChinstrap\nDream\n52.0\n20.7\n210\n4800\nmale\n2008\n\n\nChinstrap\nDream\n46.9\n16.6\n192\n2700\nfemale\n2008\n\n\nChinstrap\nDream\n53.5\n19.9\n205\n4500\nmale\n2008\n\n\nChinstrap\nDream\n49.0\n19.5\n210\n3950\nmale\n2008\n\n\nChinstrap\nDream\n46.2\n17.5\n187\n3650\nfemale\n2008\n\n\nChinstrap\nDream\n50.9\n19.1\n196\n3550\nmale\n2008\n\n\nChinstrap\nDream\n45.5\n17.0\n196\n3500\nfemale\n2008\n\n\nChinstrap\nDream\n50.9\n17.9\n196\n3675\nfemale\n2009\n\n\nChinstrap\nDream\n50.8\n18.5\n201\n4450\nmale\n2009\n\n\nChinstrap\nDream\n50.1\n17.9\n190\n3400\nfemale\n2009\n\n\nChinstrap\nDream\n49.0\n19.6\n212\n4300\nmale\n2009\n\n\nChinstrap\nDream\n51.5\n18.7\n187\n3250\nmale\n2009\n\n\nChinstrap\nDream\n49.8\n17.3\n198\n3675\nfemale\n2009\n\n\nChinstrap\nDream\n48.1\n16.4\n199\n3325\nfemale\n2009\n\n\nChinstrap\nDream\n51.4\n19.0\n201\n3950\nmale\n2009\n\n\nChinstrap\nDream\n45.7\n17.3\n193\n3600\nfemale\n2009\n\n\nChinstrap\nDream\n50.7\n19.7\n203\n4050\nmale\n2009\n\n\nChinstrap\nDream\n42.5\n17.3\n187\n3350\nfemale\n2009\n\n\nChinstrap\nDream\n52.2\n18.8\n197\n3450\nmale\n2009\n\n\nChinstrap\nDream\n45.2\n16.6\n191\n3250\nfemale\n2009\n\n\nChinstrap\nDream\n49.3\n19.9\n203\n4050\nmale\n2009\n\n\nChinstrap\nDream\n50.2\n18.8\n202\n3800\nmale\n2009\n\n\nChinstrap\nDream\n45.6\n19.4\n194\n3525\nfemale\n2009\n\n\nChinstrap\nDream\n51.9\n19.5\n206\n3950\nmale\n2009\n\n\nChinstrap\nDream\n46.8\n16.5\n189\n3650\nfemale\n2009\n\n\nChinstrap\nDream\n45.7\n17.0\n195\n3650\nfemale\n2009\n\n\nChinstrap\nDream\n55.8\n19.8\n207\n4000\nmale\n2009\n\n\nChinstrap\nDream\n43.5\n18.1\n202\n3400\nfemale\n2009\n\n\nChinstrap\nDream\n49.6\n18.2\n193\n3775\nmale\n2009\n\n\nChinstrap\nDream\n50.8\n19.0\n210\n4100\nmale\n2009\n\n\nChinstrap\nDream\n50.2\n18.7\n198\n3775\nfemale\n2009"
  },
  {
    "objectID": "slides/03/slides03.html#aesthetic",
    "href": "slides/03/slides03.html#aesthetic",
    "title": "ggplot2",
    "section": "Aesthetic",
    "text": "Aesthetic\n\n\nA visual property of the objects in the plot\n\nx → body mass\ny → flipper length\ncolor → species"
  },
  {
    "objectID": "slides/03/slides03.html#geometric-object",
    "href": "slides/03/slides03.html#geometric-object",
    "title": "ggplot2",
    "section": "Geometric Object",
    "text": "Geometric Object\n\n\nHow the data are represented\n\npoints!"
  },
  {
    "objectID": "slides/03/slides03.html#the-basic-ggplot-template",
    "href": "slides/03/slides03.html#the-basic-ggplot-template",
    "title": "ggplot2",
    "section": "The basic ggplot template:",
    "text": "The basic ggplot template:\n\nggplot(data = &lt;dataset_name&gt;) + \n  &lt;geom_function&gt;(mapping = aes(&lt;mappings&gt;))"
  },
  {
    "objectID": "slides/03/slides03.html#facets",
    "href": "slides/03/slides03.html#facets",
    "title": "ggplot2",
    "section": "Facets",
    "text": "Facets\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, col = species)) + \n  geom_point() + \n  facet_wrap(vars(species)) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/03/slides03.html#statistical-transformations",
    "href": "slides/03/slides03.html#statistical-transformations",
    "title": "ggplot2",
    "section": "Statistical Transformations",
    "text": "Statistical Transformations"
  },
  {
    "objectID": "slides/03/slides03.html#coordinates",
    "href": "slides/03/slides03.html#coordinates",
    "title": "ggplot2",
    "section": "Coordinates",
    "text": "Coordinates\n\n\nSource: Nathan Yau, Data Points"
  },
  {
    "objectID": "slides/03/slides03.html#scalesguides",
    "href": "slides/03/slides03.html#scalesguides",
    "title": "ggplot2",
    "section": "Scales/guides",
    "text": "Scales/guides\n\n\nSource: Nathan Yau, Data Points"
  },
  {
    "objectID": "slides/03/slides03.html#themes",
    "href": "slides/03/slides03.html#themes",
    "title": "ggplot2",
    "section": "Themes",
    "text": "Themes\nAll non-data ink (e.g. background color, appearance of grid lines)"
  },
  {
    "objectID": "slides/03/slides03.html#how-it-works",
    "href": "slides/03/slides03.html#how-it-works",
    "title": "ggplot2",
    "section": "How it works",
    "text": "How it works\n\nDraw a card\nFind your number’s location\nIntroduce yourselves\nGet to work!"
  },
  {
    "objectID": "slides/03/slides03.html#round-1-view-the-data-pipes",
    "href": "slides/03/slides03.html#round-1-view-the-data-pipes",
    "title": "ggplot2",
    "section": "Round 1: View the data + pipes",
    "text": "Round 1: View the data + pipes\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/03/slides03.html#round-2-scatterplots",
    "href": "slides/03/slides03.html#round-2-scatterplots",
    "title": "ggplot2",
    "section": "Round 2: Scatterplots",
    "text": "Round 2: Scatterplots\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/03/slides03.html#round-3-additional-aesthetics",
    "href": "slides/03/slides03.html#round-3-additional-aesthetics",
    "title": "ggplot2",
    "section": "Round 3: Additional Aesthetics",
    "text": "Round 3: Additional Aesthetics\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/03/slides03.html#round-4-visualizing-distributions",
    "href": "slides/03/slides03.html#round-4-visualizing-distributions",
    "title": "ggplot2",
    "section": "Round 4: Visualizing Distributions",
    "text": "Round 4: Visualizing Distributions\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/03/slides03.html#round-5-bar-and-column-charts-labeling",
    "href": "slides/03/slides03.html#round-5-bar-and-column-charts-labeling",
    "title": "ggplot2",
    "section": "Round 5: Bar and column charts + Labeling",
    "text": "Round 5: Bar and column charts + Labeling\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio Server\n🔗 Carleton’s Maize Server\n\n\nCourse GitHub organization\n🔗 GitHub\n\n\nGradebook\n🔗 on Moodle\n\n\nSpend a Token\n🔗 Spend a token\n\n\nTextbooks\n🔗 Modern Data Science with R (MDS)\n🔗 R for Data Science (R4DS)\n🔗 Fundamentals of Data Visualization\n\n\nPackage documentation\n🔗 ggplot2: ggplot2.tidyverse.org\n🔗 dplyr: dplyr.tidyverse.org\n🔗 tidyr: tidyr.tidyverse.org\n🔗 forcats: forcats.tidyverse.org\n🔗 stringr: stringr.tidyverse.org\n🔗 lubridate: lubridate.tidyverse.org\n🔗 readr: readr.tidyverse.org",
    "crumbs": [
      "Course information",
      "Useful links"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stat 220: Intro to Data Science",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the term. Note that this schedule will be updated as the term progresses and the timeline of topics and assignments might be updated. Any major changes to due dates will be announced in class and indicated in bold here.\n\n\n\n\n\n\nWEEK\nDOW\nDATE\nPREPARE\nTOPIC\nMATERIALS\nDUE\n\n\n\n1\nM\nMon, Jan 6\n📝complete welcome survey\n\nWelcome + data, R review\n\nslides01 01-example-unvotes\n\n\n\n\n1\nW\nWed, Jan 8\n📚 R basics  📚 R4DS 1e 27.1-27.4  📺 git and GitHub for poets  📝 Read syllabus and pass syllabus quiz to activate tokens\nGithub + reproducible reports\n\nslides02 02-reproducible-reports 02-lego-report\n\n\n\n\n1\nF\nFri, Jan 10\n📝 10 minute activity on markdown  📚 R4DS Ch1  📺 intro to ggplot\n\nggplot\n\nslides03 03-ggplot-intro and .rmd\n\nHW 1 (on moodle)\n\n\n2\nM\nMon, Jan 13\n📚 DataViz 17-21 \n\nTheming + Design\n\nslides04  04-customizing-plots .rmd\n\n\n\n\n2\nW\nWed, Jan 15\n📚 DataViz 15 \n\nMaps/spatial data\n\nslides05  05-maps .rmd\n\nHW 2\n\n\n2\nF\nFri, Jan 17\n📺 first 15 minutes of Accessible Data Science Beyond Visual Models  📚 Skim Writing Alt Text to Communicate the Meaning in Data Visualizations\n\nAccesibility for data viz\nslides06\n\n\n\n3\nM\nMon, Jan 20\n📚 R4DS 3.1-3.4 \n\nVerbs\n\nslides07 07-verbs\n\nPortfolio 1\n\n\n3\nW\nWed, Jan 22\n📚 R4DS 3.5  📚 R4DS 4 \n\nGroups and summarizing Code style\n\nslides08 08-dplyr2\n\nHW 3\n\n\n3\nF\nFri, Jan 24\n📚 R4DS 5.1-5.4 \n\nTidy data\n\nslides09 09-tidyr\n\nLab Quiz 1\n\n\n4\nM\nMon, Jan 27\n📚 R4DS 19.1-19.3\n\nCombining datasets\n\nslides10 10-combining\n\n\n\n\n4\nW\nWed, Jan 29\n📚 R4DS 7.1-7.4  📚 R4DS 17.1-17.3 \n\nImport data and dates/times\n\nslides11 11-import\n\nHW 4\n\n\n4\nF\nFri, Jan 31\n📚 R4DS 16 \n\nWorking with factors\n\nslides12 12-factors\n\n\n\n\n5\nM\nMon, Feb 3\n📚 R4DS 14  📚 R4DS 15.1-15.5\n\nWorking with strings and Regex\n\nslides13 13-strings-regex\n\n\n\n\n5\nW\nWed, Feb 5\n📚 MDSR 19.2  🌎 Google ngram viewer\n\nIntro to Text Analysis\n\nslides14 14-text-case-study\n\nHW 5, Portfolio 2\n\n\n\n5\nF\nFri, Feb 7\n📚 The Trouble with Sentiment Analysis\n\nSentiment Analysis\n\nslides15 15-sentiment\n\nLab Quiz 2\n\n\n6\nM\nMon, Feb 10\n\n❌ Midterm Break; no class\n\n\n\n\n6\nW\nWed, Feb 12\n📚 R4DS 25\n\nFunctions\n\nslides16 16-functions\n\n\n\n\n6\nF\nFri, Feb 14\n📚 MDSR 7.1-7.3\n\nIteration\n\nslides17 17-iteration\n\nHW6\n\n\n7\nM\nMon, Feb 17\n\nIteration II\n\nslides18 18-iteration-2\n\n\n\n\n7\nW\nWed, Feb 19\n📚What is an API? 📚R4DS 23 (skip case studies) 📝 sign up for a census API key\n\nAPIs\n\nslides19 19-apis\n\nHW7 \n\n\n\n7\nF\nFri, Feb 21\n\nIntro to Scraping\nslides20\n\nLab Quiz 3, Final Project Idea Form\n\n\n\n8\nM\nMon, Feb 24\n📚 R4DS 24.2;24.5  📝 install and test selectorGadget\n\nScraping/Data Privacy\n\nslides21 21-scraping\n\nFinal Project Ranking Form\n\n\n8\nW\nWed, Feb 26\nExplore htmlWidgets gallery + source code  Explore NZ Earthquakes and source code\n\nRMarkdown Formats/Intro to Interactivity\n\nslides22 22-interactivity\n\nHW8, Portfolio 3\n\n\n\n8\nF\nFri, Feb 28\nPick one:  📺 Shiny basics playlist  📚Ch 1-2 of Mastering Shiny\n\nShiny 1\n\n\n\n\n9\nM\nMon, Mar 3\nPick one:  📺 Reactivity in shiny playlist  📚Ch 3 of Mastering Shiny\n\nShiny 2\n\n\n\n\n9\nW\nWed, Mar 5\n📚MDSR 15.1-15.4\n\nSQL\n\nFinal Project sketch\n\n\n9\nF\nFri, Mar 7\n\nSQL\n\nPortfolio 4\n\n\n10\nM\nMon, Mar 10\n\nProject Demos\n\n\n\n\n10\nW\nWed, Mar 12\n\nProject Demos\n\nHW9",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "slides/04/slides04.html#today",
    "href": "slides/04/slides04.html#today",
    "title": "Plot design",
    "section": "Today",
    "text": "Today\n\nggplot2 review\ncustomizations in ggplot2\nSome guidelines for plot design"
  },
  {
    "objectID": "slides/04/slides04.html#what-we-know",
    "href": "slides/04/slides04.html#what-we-know",
    "title": "Plot design",
    "section": "What we know:",
    "text": "What we know:\n\n\n\nA basic set of geometries\n\n\ngeom_point()\ngeom_histogram()\ngeom_boxplot()\ngeom_violin()\ngeom_bar()\n\n\n\nHow to map variables to aesthetics\n\n\nx and y axis\ncolor\nshape\nalpha\nsize\n\n\n\nHow to change axis labels and titles\n\n\nlabs()"
  },
  {
    "objectID": "slides/04/slides04.html#what-next",
    "href": "slides/04/slides04.html#what-next",
    "title": "Plot design",
    "section": "What next?",
    "text": "What next?\n\nSetting aesthetics\nUsing facets\nChanging scales\nChanging coordinates\nChanging themes\nAdding annotations"
  },
  {
    "objectID": "slides/04/slides04.html#warm-up",
    "href": "slides/04/slides04.html#warm-up",
    "title": "Plot design",
    "section": "Warm Up",
    "text": "Warm Up\n\n\n\n\nLog into maize\n\nIf you have to type your PAT in everytime you push to GitHub, follow the directions at Getting Set up with Git and GitHub #4 to tell RStudio to save your credentials\n\nFind the .rmd template for today at the course website\nChoose your favorite way to open it up in maize/Rstudio\nWork with a neighbor to recreate this graph –&gt; (use 15 bins)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/04/slides04.html#polishing-plots",
    "href": "slides/04/slides04.html#polishing-plots",
    "title": "Plot design",
    "section": "Polishing plots",
    "text": "Polishing plots\n\n\n\n\n\n\n\n\n\n\n\n\nWe’re not quite satisfied….\n\nI want the bars to have a border that stands out\nLet’s try a facetted graph\nI don’t like the default color scheme\nI don’t like the gray background"
  },
  {
    "objectID": "slides/04/slides04.html#setting-aesthetics",
    "href": "slides/04/slides04.html#setting-aesthetics",
    "title": "Plot design",
    "section": "Setting aesthetics",
    "text": "Setting aesthetics\nSetting = choosing a certain value for an aesthetic\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    )"
  },
  {
    "objectID": "slides/04/slides04.html#facets",
    "href": "slides/04/slides04.html#facets",
    "title": "Plot design",
    "section": "Facets",
    "text": "Facets\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) +\n  facet_wrap(vars(day_of_week))"
  },
  {
    "objectID": "slides/04/slides04.html#changing-scales",
    "href": "slides/04/slides04.html#changing-scales",
    "title": "Plot design",
    "section": "Changing scales",
    "text": "Changing scales\n\nscale_&lt;aes&gt;_&lt;method&gt;()\n\n\n\nExamples:\n\nscale_fill_manual()\nscale_fill_brewer()\nscale_color_viridis()\nscale_shape_manual()\n\n\nRecommended reading:\n\nUsing colors in R\nTaking control of qualitative colors in ggplot2"
  },
  {
    "objectID": "slides/04/slides04.html#example-built-in-scale",
    "href": "slides/04/slides04.html#example-built-in-scale",
    "title": "Plot design",
    "section": "Example (built-in scale)",
    "text": "Example (built-in scale)\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_brewer(palette = \"Greens\")"
  },
  {
    "objectID": "slides/04/slides04.html#example-built-in-scale-1",
    "href": "slides/04/slides04.html#example-built-in-scale-1",
    "title": "Plot design",
    "section": "Example (built-in scale)",
    "text": "Example (built-in scale)\n\nRColorBrewer::display.brewer.all()"
  },
  {
    "objectID": "slides/04/slides04.html#example-built-in-scale-2",
    "href": "slides/04/slides04.html#example-built-in-scale-2",
    "title": "Plot design",
    "section": "Example (built-in scale)",
    "text": "Example (built-in scale)\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_viridis_d(option = \"mako\")\n\n\n\n\n\n\n\n\n\n\n\nTo see all the options built into R (or add-on packages): Color Palette Finder"
  },
  {
    "objectID": "slides/04/slides04.html#example-manual-color-palette",
    "href": "slides/04/slides04.html#example-manual-color-palette",
    "title": "Plot design",
    "section": "Example (manual color palette)",
    "text": "Example (manual color palette)\nLet’s make Wednesdays navyblue and Thursdays gold2\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\"))"
  },
  {
    "objectID": "slides/04/slides04.html#can-also-change-non-color-scales",
    "href": "slides/04/slides04.html#can-also-change-non-color-scales",
    "title": "Plot design",
    "section": "Can also change non-color scales",
    "text": "Can also change non-color scales\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  scale_x_continuous(limits = c(1,10))"
  },
  {
    "objectID": "slides/04/slides04.html#can-also-change-non-color-scales-1",
    "href": "slides/04/slides04.html#can-also-change-non-color-scales-1",
    "title": "Plot design",
    "section": "Can also change non-color scales",
    "text": "Can also change non-color scales\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  scale_x_log10(limits = c(1,10))"
  },
  {
    "objectID": "slides/04/slides04.html#can-also-change-non-color-scales-2",
    "href": "slides/04/slides04.html#can-also-change-non-color-scales-2",
    "title": "Plot design",
    "section": "Can also change non-color scales",
    "text": "Can also change non-color scales\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  scale_x_reverse()"
  },
  {
    "objectID": "slides/04/slides04.html#changing-themes",
    "href": "slides/04/slides04.html#changing-themes",
    "title": "Plot design",
    "section": "Changing Themes",
    "text": "Changing Themes\nTheme: The non-data ink on your plots\n\n\n\nbackground\ntick marks\ngrid lines\nfont\nlegend position\nlegend appearance"
  },
  {
    "objectID": "slides/04/slides04.html#prepackaged-themes",
    "href": "slides/04/slides04.html#prepackaged-themes",
    "title": "Plot design",
    "section": "Prepackaged themes",
    "text": "Prepackaged themes\n\n\nggplot2 themes\n\ntheme_grey()\ntheme_bw()\ntheme_linedraw()\ntheme_light()\ntheme_dark()\ntheme_minimal()\ntheme_classic()\ntheme_void()\ntheme_test()\n\n\nggthemes themes\n\ntheme_clean()\ntheme_economist()\ntheme_excel()\ntheme_fivethirtyeight()\ntheme_gdocs()\ntheme_solarized()\ntheme_stata()\ntheme_tufte()\ntheme_wsj()\nAnd more!"
  },
  {
    "objectID": "slides/04/slides04.html#using-a-prepackaged-theme",
    "href": "slides/04/slides04.html#using-a-prepackaged-theme",
    "title": "Plot design",
    "section": "Using a prepackaged theme",
    "text": "Using a prepackaged theme\n\nggplot(data = &lt;DATA&gt;) + \n  &lt;GEOM_FUNCTION&gt;(\n     mapping = aes(&lt;MAPPINGS&gt;)\n  ) +\n  &lt;FACET_FUNCTION&gt; +\n  theme_&lt;name&gt;()"
  },
  {
    "objectID": "slides/04/slides04.html#try-it",
    "href": "slides/04/slides04.html#try-it",
    "title": "Plot design",
    "section": "Try it",
    "text": "Try it\nApply theme_light() to the histogram\n\n\n\n\n\n\n\n\n\n\n\n\n−+\n00:30"
  },
  {
    "objectID": "slides/04/slides04.html#even-more-customizations",
    "href": "slides/04/slides04.html#even-more-customizations",
    "title": "Plot design",
    "section": "Even more customizations",
    "text": "Even more customizations\n\nMove legend\nClean up labels and title\nGet rid of .5’s in x-axis\nAnnotations"
  },
  {
    "objectID": "slides/04/slides04.html#theme",
    "href": "slides/04/slides04.html#theme",
    "title": "Plot design",
    "section": "?theme",
    "text": "?theme\n\ntheme(line, rect, text, title, aspect.ratio, axis.title, axis.title.x,\n  axis.title.x.top, axis.title.x.bottom, axis.title.y, axis.title.y.left,\n  axis.title.y.right, axis.text, axis.text.x, axis.text.x.top,\n  axis.text.x.bottom, axis.text.y, axis.text.y.left, axis.text.y.right,\n  axis.ticks, axis.ticks.x, axis.ticks.x.top, axis.ticks.x.bottom,\n  axis.ticks.y, axis.ticks.y.left, axis.ticks.y.right, axis.ticks.length,\n  axis.line, axis.line.x, axis.line.x.top, axis.line.x.bottom, axis.line.y,\n  axis.line.y.left, axis.line.y.right, legend.background, legend.margin,\n  legend.spacing, legend.spacing.x, legend.spacing.y, legend.key,\n  legend.key.size, legend.key.height, legend.key.width, legend.text,\n  legend.text.align, legend.title, legend.title.align, legend.position,\n  legend.direction, legend.justification, legend.box, legend.box.just,\n  legend.box.margin, legend.box.background, legend.box.spacing,\n  panel.background, panel.border, panel.spacing, panel.spacing.x,\n  panel.spacing.y, panel.grid, panel.grid.major, panel.grid.minor,\n  panel.grid.major.x, panel.grid.major.y, panel.grid.minor.x,\n  panel.grid.minor.y, panel.ontop, plot.background, plot.title,\n  plot.subtitle, plot.caption, plot.tag, plot.tag.position, plot.margin,\n  strip.background, strip.background.x, strip.background.y,\n  strip.placement, strip.text, strip.text.x, strip.text.y,\n  strip.switch.pad.grid, strip.switch.pad.wrap, ..., complete = FALSE,\n  validate = TRUE)\n\n\n\nTo see examples in action, see “Theme Elements” of the ggplot2 book"
  },
  {
    "objectID": "slides/04/slides04.html#move-legend-and-make-the-background-transparent",
    "href": "slides/04/slides04.html#move-legend-and-make-the-background-transparent",
    "title": "Plot design",
    "section": "Move legend and make the background transparent",
    "text": "Move legend and make the background transparent\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  theme_minimal() + \n  theme(\n    legend.position = c(.15, .85),\n    legend.background = element_blank()\n  )"
  },
  {
    "objectID": "slides/04/slides04.html#clean-up-labels-and-title",
    "href": "slides/04/slides04.html#clean-up-labels-and-title",
    "title": "Plot design",
    "section": "Clean up labels and title",
    "text": "Clean up labels and title\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  theme_minimal() + \n  theme(\n    legend.position = c(.15, .85),\n    legend.background = element_blank()\n  ) + \n  labs(\n    x = \"Season Average IMDB Rating\",\n    y = \"\",\n    fill = \"\",\n    title = \"Survivor is better on Thursdays\"\n  )"
  },
  {
    "objectID": "slides/04/slides04.html#remove-minor-gridlines",
    "href": "slides/04/slides04.html#remove-minor-gridlines",
    "title": "Plot design",
    "section": "Remove minor gridlines",
    "text": "Remove minor gridlines\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  theme_minimal() + \n  theme(\n    legend.position = c(.15, .85),\n    legend.background = element_blank(),\n    panel.grid.minor = element_blank()\n  ) + \n  labs(\n    x = \"Season Average IMDB Rating\",\n    y = \"\",\n    fill = \"\",\n    title = \"Survivor is better on Thursdays\"\n  )"
  },
  {
    "objectID": "slides/04/slides04.html#get-rid-of-.5s",
    "href": "slides/04/slides04.html#get-rid-of-.5s",
    "title": "Plot design",
    "section": "Get rid of .5’s",
    "text": "Get rid of .5’s\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  scale_x_continuous(breaks = c(6, 7, 8, 9)) +\n  theme_minimal() + \n  theme(\n    legend.position = c(.15, .85),\n    legend.background = element_blank(),\n    panel.grid.minor = element_blank()\n  ) + \n  labs(\n    x = \"Season Average IMDB Rating\",\n    y = \"\",\n    fill = \"\",\n    title = \"Survivor is better on Thursdays\"\n  )"
  },
  {
    "objectID": "slides/04/slides04.html#add-an-annotation",
    "href": "slides/04/slides04.html#add-an-annotation",
    "title": "Plot design",
    "section": "Add an annotation",
    "text": "Add an annotation\n\n\nggplot(season_summary) + \n  geom_histogram(\n    aes(x = imdb_mean, fill = day_of_week), \n    bins = 15,\n    color = \"white\"\n    ) + \n  scale_fill_manual(values = c(\"gold2\", \"navyblue\")) + \n  scale_x_continuous(breaks = c(6, 7, 8, 9)) +\n  theme_minimal() + \n  theme(\n    legend.position = c(.15, .85),\n    legend.background = element_blank(),\n    panel.grid.minor = element_blank()\n  ) + \n  labs(\n    x = \"Season Average IMDB Rating\",\n    y = \"\",\n    fill = \"\",\n    title = \"Survivor is better on Thursdays\"\n  ) +\n  annotate(\"text\", \n           x = 6, \n           y = 3, \n           label = \"Lowest ratings \\n occur on \\n Wednesdays\",\n           col = \"navyblue\")"
  },
  {
    "objectID": "slides/04/slides04.html#which-do-you-prefer",
    "href": "slides/04/slides04.html#which-do-you-prefer",
    "title": "Plot design",
    "section": "Which do you prefer?",
    "text": "Which do you prefer?\nPlot A:"
  },
  {
    "objectID": "slides/04/slides04.html#which-do-you-prefer-1",
    "href": "slides/04/slides04.html#which-do-you-prefer-1",
    "title": "Plot design",
    "section": "Which do you prefer?",
    "text": "Which do you prefer?\nPlot B:"
  },
  {
    "objectID": "slides/04/slides04.html#general-guidelines",
    "href": "slides/04/slides04.html#general-guidelines",
    "title": "Plot design",
    "section": "General guidelines",
    "text": "General guidelines\n\nShow the data, don’t distort it\nChoose the right plot\nUse color meaningfully and with restraint\nTell a story\nLeave out non-story details"
  },
  {
    "objectID": "slides/04/slides04.html#show-the-data-dont-distort-it",
    "href": "slides/04/slides04.html#show-the-data-dont-distort-it",
    "title": "Plot design",
    "section": "Show the data, don’t distort it",
    "text": "Show the data, don’t distort it"
  },
  {
    "objectID": "slides/04/slides04.html#show-the-data-dont-distort-it-1",
    "href": "slides/04/slides04.html#show-the-data-dont-distort-it-1",
    "title": "Plot design",
    "section": "Show the data, don’t distort it",
    "text": "Show the data, don’t distort it\n\n\nWhat a huge effect! \n\nBut it isn’t the whole story"
  },
  {
    "objectID": "slides/04/slides04.html#choose-the-right-plot",
    "href": "slides/04/slides04.html#choose-the-right-plot",
    "title": "Plot design",
    "section": "Choose the right plot",
    "text": "Choose the right plot\n\n\n\nWilke has good suggestions in chapters 5-16\nAlways stop and think about how easy it is to see the story\nTry a few different options"
  },
  {
    "objectID": "slides/04/slides04.html#example-which-slice-is-the-biggestsmallest",
    "href": "slides/04/slides04.html#example-which-slice-is-the-biggestsmallest",
    "title": "Plot design",
    "section": "Example: Which slice is the biggest/smallest?",
    "text": "Example: Which slice is the biggest/smallest?\n\n\n\n\n\n\n\n\n−+\n00:30\n\n\n\n\n\n\n\n\n\n\n\n\nThe issue with pie chart by Data to Viz"
  },
  {
    "objectID": "slides/04/slides04.html#use-color-meaningfully-and-with-restraint",
    "href": "slides/04/slides04.html#use-color-meaningfully-and-with-restraint",
    "title": "Plot design",
    "section": "Use color meaningfully and with restraint",
    "text": "Use color meaningfully and with restraint"
  },
  {
    "objectID": "slides/04/slides04.html#use-color-meaningfully-and-with-restraint-1",
    "href": "slides/04/slides04.html#use-color-meaningfully-and-with-restraint-1",
    "title": "Plot design",
    "section": "Use color meaningfully and with restraint",
    "text": "Use color meaningfully and with restraint"
  },
  {
    "objectID": "slides/04/slides04.html#tell-a-story",
    "href": "slides/04/slides04.html#tell-a-story",
    "title": "Plot design",
    "section": "Tell a story",
    "text": "Tell a story\nOne way to do this is by highlighting the important parts"
  },
  {
    "objectID": "slides/04/slides04.html#leave-out-non-story-details",
    "href": "slides/04/slides04.html#leave-out-non-story-details",
    "title": "Plot design",
    "section": "Leave out non-story details",
    "text": "Leave out non-story details\nIs this train schedule easy to read?"
  },
  {
    "objectID": "slides/04/slides04.html#avoid-distractions",
    "href": "slides/04/slides04.html#avoid-distractions",
    "title": "Plot design",
    "section": "Avoid distractions",
    "text": "Avoid distractions\nDoes removing gridlines make it somewhat easier?"
  },
  {
    "objectID": "slides/04/slides04.html#data-visualizations-have-an-aura-of-objectivity",
    "href": "slides/04/slides04.html#data-visualizations-have-an-aura-of-objectivity",
    "title": "Plot design",
    "section": "Data visualizations have an aura of objectivity",
    "text": "Data visualizations have an aura of objectivity\n\n\n\n“We focus on four conventions which imbue visualisations with a sense of objectivity, transparency and facticity. These include: a) two-dimensional viewpoints; b) clean layouts; c) geometric shapes and lines; d) the inclusion of data sources.”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Kennedy, Hill, Aiello & Allen. (2016) The work that visualisation conventions do. Information, Communication and Society, 19 (6). pp. 715-735. ISSN 1369-118X"
  },
  {
    "objectID": "slides/04/slides04.html#good-graphs-can-also-break-these-guidelines",
    "href": "slides/04/slides04.html#good-graphs-can-also-break-these-guidelines",
    "title": "Plot design",
    "section": "Good graphs can also break these guidelines",
    "text": "Good graphs can also break these guidelines\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mona Chalabi @monachalabi"
  },
  {
    "objectID": "slides/04/slides04.html#good-graphs-can-also-break-these-guidelines-1",
    "href": "slides/04/slides04.html#good-graphs-can-also-break-these-guidelines-1",
    "title": "Plot design",
    "section": "Good graphs can also break these guidelines",
    "text": "Good graphs can also break these guidelines\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mona Chalabi @monachalabi"
  },
  {
    "objectID": "slides/04/slides04.html#your-turn",
    "href": "slides/04/slides04.html#your-turn",
    "title": "Plot design",
    "section": "Your turn",
    "text": "Your turn\nNow that we have the toolkit to make customizations to our plots, and some “rules” for good graphs, let’s break them!\n\n\nChoose a graph (the one from class today, one from last class, one from homework, etc.)\nMake it ugly\n\n\nChange the color scale\nChoose a complete theme\nMake at least 3 custom tweaks to the theme options\n\n\nExplain why it’s ugly (what “rules” are you breaking? what makes it an ineffective graph?)\nPost to our slack #social channel when you’re done (you don’t have to post your explanation)"
  },
  {
    "objectID": "slides/02/slides02.html#plan-for-today",
    "href": "slides/02/slides02.html#plan-for-today",
    "title": "Github +  Reproducible  Reporting",
    "section": "Plan for today:",
    "text": "Plan for today:\n\nQuestions from syllabus quiz\nGithub\n\nAccessing your private repos\nknit 🧶 commit ✅ push ⤴️\n\nReproducible Reporting"
  },
  {
    "objectID": "slides/02/slides02.html#questions-from-syllabus-quiz",
    "href": "slides/02/slides02.html#questions-from-syllabus-quiz",
    "title": "Github +  Reproducible  Reporting",
    "section": "Questions from syllabus quiz",
    "text": "Questions from syllabus quiz\n\nWill the course build off of Stat120 concepts?\nClarification of what gets submitted to gradescope and what to GitHub\nRMarkdown versus Quarto?\nExamples of previous final projects?\nInfo about portfolio projects?"
  },
  {
    "objectID": "slides/02/slides02.html#git-github",
    "href": "slides/02/slides02.html#git-github",
    "title": "Github +  Reproducible  Reporting",
    "section": "Git + GitHub",
    "text": "Git + GitHub\n\n\n\nGit is a version control system - like “Track Changes”, on steroids\nIt’s not the only version control system, but it’s a very popular one\n\n\n\nGitHub is the home for your Git-based projects on the internet—like DropBox but much, much better\nWe will use GitHub as a platform for web hosting and collaboration"
  },
  {
    "objectID": "slides/02/slides02.html#why-do-we-need-it",
    "href": "slides/02/slides02.html#why-do-we-need-it",
    "title": "Github +  Reproducible  Reporting",
    "section": "Why do we need it?",
    "text": "Why do we need it?"
  },
  {
    "objectID": "slides/02/slides02.html#versioning",
    "href": "slides/02/slides02.html#versioning",
    "title": "Github +  Reproducible  Reporting",
    "section": "Versioning",
    "text": "Versioning"
  },
  {
    "objectID": "slides/02/slides02.html#versioning-with-human-readable-messages",
    "href": "slides/02/slides02.html#versioning-with-human-readable-messages",
    "title": "Github +  Reproducible  Reporting",
    "section": "Versioning (with human-readable messages)",
    "text": "Versioning (with human-readable messages)"
  },
  {
    "objectID": "slides/02/slides02.html#how-does-it-work-for-stat220",
    "href": "slides/02/slides02.html#how-does-it-work-for-stat220",
    "title": "Github +  Reproducible  Reporting",
    "section": "How does it work for Stat220?",
    "text": "How does it work for Stat220?"
  },
  {
    "objectID": "slides/02/slides02.html#how-does-it-work-for-stat220-1",
    "href": "slides/02/slides02.html#how-does-it-work-for-stat220-1",
    "title": "Github +  Reproducible  Reporting",
    "section": "How does it work for Stat220?",
    "text": "How does it work for Stat220?"
  },
  {
    "objectID": "slides/02/slides02.html#how-does-it-work-for-stat220-2",
    "href": "slides/02/slides02.html#how-does-it-work-for-stat220-2",
    "title": "Github +  Reproducible  Reporting",
    "section": "How does it work for Stat220?",
    "text": "How does it work for Stat220?"
  },
  {
    "objectID": "slides/02/slides02.html#how-does-it-work-for-stat220-3",
    "href": "slides/02/slides02.html#how-does-it-work-for-stat220-3",
    "title": "Github +  Reproducible  Reporting",
    "section": "How does it work for Stat220?",
    "text": "How does it work for Stat220?"
  },
  {
    "objectID": "slides/02/slides02.html#lets-try-it",
    "href": "slides/02/slides02.html#lets-try-it",
    "title": "Github +  Reproducible  Reporting",
    "section": "Let’s try it!",
    "text": "Let’s try it!\n\n\n\nFollow the “Individual Assignment” directions at https://stat220-w25.github.io/computing/git-stat220.html to access your day02 repo and create an R project\nEdit the .Rmd file:\n\nChange “author” to your name\nUse # to add descriptive section headers for each code chunk\nAdd a sentence or two describing the summary statistics of the dataset\n\nknit 🧶 commit ✅ push ⤴️\nView on github.com/stat220-w25/day02yourusername and confirm you can see your changes\n\n\n\n\n\n\n−+\n15:00"
  },
  {
    "objectID": "slides/02/slides02.html#why-do-we-need-it-1",
    "href": "slides/02/slides02.html#why-do-we-need-it-1",
    "title": "Github +  Reproducible  Reporting",
    "section": "Why do we need it?",
    "text": "Why do we need it?\nOops! I gave you the wrong set of data."
  },
  {
    "objectID": "slides/02/slides02.html#why-do-we-need-it-2",
    "href": "slides/02/slides02.html#why-do-we-need-it-2",
    "title": "Github +  Reproducible  Reporting",
    "section": "Why do we need it?",
    "text": "Why do we need it?\n\nKarl – this is very interesting , however you used an old version of the data (n=143 rather than n=226). I’m really sorry you did all that work on the incomplete dataset.\nBruce\n\n\n\nAdapted from Karl Broman"
  },
  {
    "objectID": "slides/02/slides02.html#other-examples",
    "href": "slides/02/slides02.html#other-examples",
    "title": "Github +  Reproducible  Reporting",
    "section": "Other examples:",
    "text": "Other examples:\n\nThe results in Table 1 don’t seem to correspond to those in Figure 2.\nIn what order do I run these scripts?\nWhere did we get this data file?\nWhy did I omit those samples?\nHow did I make that figure?\n“Your script is now giving an error.”\n“The attached is similar to the code we used.”\n\n\n\nAdapted from Karl Broman"
  },
  {
    "objectID": "slides/02/slides02.html#reproducible-data-science",
    "href": "slides/02/slides02.html#reproducible-data-science",
    "title": "Github +  Reproducible  Reporting",
    "section": "Reproducible data science",
    "text": "Reproducible data science\n\n\nShort Term Impact\n\nAre the tables and figures reproducible from the code and data?\nDoes the code actually do what you think it does?\nIn addition to what was done, is it clear why it was done? (e.g., how were parameter settings chosen?)\n\n\nLong Term Impact\n\nCan the code be used for other data?\nCan you extend the code to other things?"
  },
  {
    "objectID": "slides/02/slides02.html#the-toolkit",
    "href": "slides/02/slides02.html#the-toolkit",
    "title": "Github +  Reproducible  Reporting",
    "section": "The toolkit",
    "text": "The toolkit\n\n\n\n\n\n\n\n\n\n\nScriptability \\(\\rightarrow\\) R\nCode environment \\(\\rightarrow\\) RStudio\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) R Markdown\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/02/slides02.html#what-is-r-markdown",
    "href": "slides/02/slides02.html#what-is-r-markdown",
    "title": "Github +  Reproducible  Reporting",
    "section": "What is R Markdown?",
    "text": "What is R Markdown?\n\nAn authoring framework for data science.\nA document format (.Rmd).\nAn R package named rmarkdown.\nA file format for making dynamic documents with R.\nA tool for integrating prose, code, and results.\nA computational document."
  },
  {
    "objectID": "slides/02/slides02.html#what-about-quarto",
    "href": "slides/02/slides02.html#what-about-quarto",
    "title": "Github +  Reproducible  Reporting",
    "section": "What about quarto?",
    "text": "What about quarto?\n\n“Next Gen” RMarkdown\nMore compatibility with other languages (python, observable.js, etc.)\nnot an R package/separate software\nI’m going to distribute HW, etc. via RMarkdown, but you are welcome to use either!"
  },
  {
    "objectID": "slides/02/slides02.html#the-setup-chunk",
    "href": "slides/02/slides02.html#the-setup-chunk",
    "title": "Github +  Reproducible  Reporting",
    "section": "The setup chunk",
    "text": "The setup chunk\n\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,   \n  comment = \"#&gt;\", \n  out.width = \"100%\" \n)\n```\n\n\nA special chunk label: setup\nTypically #1\nAll following chunks will use these options (i.e., sets global chunk options)\nTip: set include=FALSE\nYou can (and should) use individual chunk options too"
  },
  {
    "objectID": "slides/02/slides02.html#parameters",
    "href": "slides/02/slides02.html#parameters",
    "title": "Github +  Reproducible  Reporting",
    "section": "Parameters",
    "text": "Parameters\n\n\n---\ntitle: Survivor\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    theme: flatly\nparams:\n  season: '20'\n---"
  },
  {
    "objectID": "slides/02/slides02.html#your-task",
    "href": "slides/02/slides02.html#your-task",
    "title": "Github +  Reproducible  Reporting",
    "section": "Your Task",
    "text": "Your Task\n\n\nThere’s an example HTML report on the schedule\nYour task is to reproduce it in 02-example-lego.rmd (or .qmd, if you prefer).\nTo be as reproducible as possible, you’ll need to use:\n\nYAML metadata\nYAML parameters\nCode chunks with appropriate options\nInline R code"
  },
  {
    "objectID": "slides/02/slides02.html#hints",
    "href": "slides/02/slides02.html#hints",
    "title": "Github +  Reproducible  Reporting",
    "section": "Hints",
    "text": "Hints\n\n\nTo begin, use inline R code to replace “hard coding” the quantities that are highlighted below.\n\n\nFor example, instead of typing 19798 you would include nrow(sets) as an inline code chunk. Make sure the report knits and you get the right values.\n\nNext, add a parameter to your YAML header that stores the location of the data set. Make sure the report knits.\nChange the code chunk where you load the data set to use the data parameter you just defined rather than the hard-coded URL. Make sure the report knits.\nNow, let’s make a parameter for the source of the data set so you don’t have to search where every mention of it in the report, it will be with the other metadata (where it belongs). To do this, add a parameter that gives the source of your data (call it data_source) and set it equal to “the 2022-09-09 repository on Tidy Tuesday.” Make sure the report knits.\nAt this point it looks like everything is working—awesome job! To put it to the test, let’s update the parameters of your report and knit it to see if everything changes as we would expect. Here are the new parameter values:\n\ndata: \"http://math.carleton.edu/aluby/stat220/lego_subset.csv\"\ndata_source: \"Amanda's website\"\n\n(optional) If you have time, or would like to try outside of class, I’ve created a practice gradescope assignment space. First, add .pdf output to your document and knit to PDF. Commit the PDF and push to github. Then, log into gradescope (you may have to go through the link on moodle the first time) and link your github repo. You should then be able to submit your .pdf\n\noutput: \n  html_document:\n    default\n  pdf_document:\n    default"
  },
  {
    "objectID": "slides/18/slides18.html#bakeoff-data-season-14-only",
    "href": "slides/18/slides18.html#bakeoff-data-season-14-only",
    "title": "Iteration II",
    "section": "Bakeoff data (season 14 only)",
    "text": "Bakeoff data (season 14 only)\n\nbakeoff = read_csv(\"https://stat220-w25.github.io/data/bakeoff-episodes.csv\") |&gt;\n  filter(series == 14)\n\nbakeoff\n\n# A tibble: 76 × 7\n   series episode baker  signature                  technical showstopper result\n    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;                          &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt; \n 1     14       1 Abbi   Foraged Poppy Seed, Lemon…         3 'Herbert t… Safe  \n 2     14       1 Amos   Blood Orange & Dark Choco…         2 'Orca on a… Elimi…\n 3     14       1 Cristy 'Lemon Meringue' Vertical…         6 'Raspberry… Safe  \n 4     14       1 Dan    Rhubarb & Custard Vertica…         1 'Bruno' Ca… Star …\n 5     14       1 Dana   'Salted Caramel Latte' Ve…        12 'My Amazin… Safe  \n 6     14       1 Josh   'Tropical' Vertical Layer…         8 'Mum's Hig… Safe  \n 7     14       1 Keith  'Dad's Chocolate Orange' …         4 'Maisie' C… Safe  \n 8     14       1 Matty  'Tiramisu' Vertical Layer…         7 'Marty the… Safe  \n 9     14       1 Nicky  'St. Clements' Vertical L…        10 'Always Be… Safe  \n10     14       1 Rowan  Chocolate & Raspberry Ver…         9 'Cosmopoli… Safe  \n# ℹ 66 more rows"
  },
  {
    "objectID": "slides/18/slides18.html#warm-up",
    "href": "slides/18/slides18.html#warm-up",
    "title": "Iteration II",
    "section": "Warm up",
    "text": "Warm up\n\nWhat does this chunk of code do? What will results look like?\n\n\nresults = character(10)\n\nfor(k in 1:10){\n  eliminated = bakeoff |&gt;\n    filter(episode == k, str_detect(result, \"Eliminated\")) \n  \n  if(nrow(eliminated) == 1){\n    results[k] = eliminated$showstopper\n  } else if(nrow(eliminated) &gt; 1){\n    results[k] = str_flatten(eliminated$showstopper, collapse = \", \")\n  } else{\n    results[k] = \"none\"\n  }\n}\n\n\n\n\n\n−&plus;\n\n02:00"
  },
  {
    "objectID": "slides/18/slides18.html#warm-up-1",
    "href": "slides/18/slides18.html#warm-up-1",
    "title": "Iteration II",
    "section": "Warm up",
    "text": "Warm up\n\nresults\n\n [1] \"'Orca on a Wave' Cake\"                                                   \n [2] \"'Seaside Meal Deal' Illusion Biscuits\"                                   \n [3] \"'My Favourite Tree' Plaited Centrepiece\"                                 \n [4] \"none\"                                                                    \n [5] \"'Gran's Garden Trio' Decorative Pies, 'Lattice Fabulous' Decorative Pies\"\n [6] \"'Stop and Smell the Rosé' Floral Dessert\"                                \n [7] \"'Flowers for my Bee' Meringue Bombe\"                                     \n [8] \"'Marvellous Sweet Factory' Buffet\"                                       \n [9] \"'Mango Mojito' Millefoglie\"                                              \n[10] \"none\""
  },
  {
    "objectID": "slides/18/slides18.html#warm-up-2",
    "href": "slides/18/slides18.html#warm-up-2",
    "title": "Iteration II",
    "section": "Warm up",
    "text": "Warm up\n\nresults = character(9)\n\nfor(k in 1:10){\n  eliminated = bakeoff |&gt;\n    filter(episode == k, str_detect(result, \"Eliminated\")) \n  \n  if(nrow(eliminated) == 1){\n    results[k] = eliminated$showstopper\n  } else if(nrow(eliminated) &gt; 1){\n    results[k] = str_flatten(eliminated$showstopper, collapse = \", \")\n  } else{\n    results[k] = \"none\"\n  }\n}"
  },
  {
    "objectID": "slides/18/slides18.html#recap-from-last-class",
    "href": "slides/18/slides18.html#recap-from-last-class",
    "title": "Iteration II",
    "section": "Recap from last class",
    "text": "Recap from last class\n\n\nfor loops for iteration\n\nPre-allocating storage\nCreating an index vector\n\n\nUsing across() to iterate over columns"
  },
  {
    "objectID": "slides/18/slides18.html#example",
    "href": "slides/18/slides18.html#example",
    "title": "Iteration II",
    "section": "Example",
    "text": "Example\nWe want to find the range of any quantitative variables, and the number of levels of any factor variables in the penguins dataset.\n\n\n\nfor loop\nacross\n\n\n\n\noutput = numeric(8)\n\nfor(k in seq_along(penguins)){\n  if(is.numeric(penguins[[k]])){\n    output[k] = max(penguins[[k]], na.rm = TRUE) - min(penguins[[k]], na.rm = TRUE)\n  }\n  if(is.factor(penguins[[k]])){\n    output[k] = length(levels(penguins[[k]]))\n  }\n}\noutput\n\n[1]    3.0    3.0   27.5    8.4   59.0 3600.0    2.0    2.0\n\n\n\n\n\npenguins |&gt;\n  summarize(\n    across(where(is.numeric), \\(x) max(x, na.rm = TRUE) - min(x, na.rm = TRUE)),\n    across(where(is.factor), \\(x) length(levels(x)))\n  )\n\n# A tibble: 1 × 8\n  bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year species\n           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt; &lt;int&gt;   &lt;int&gt;\n1           27.5           8.4                59        3600     2       3\n# ℹ 2 more variables: island &lt;int&gt;, sex &lt;int&gt;"
  },
  {
    "objectID": "slides/18/slides18.html#section",
    "href": "slides/18/slides18.html#section",
    "title": "Iteration II",
    "section": "",
    "text": "The good news: we can use across to do lots of for-loop-type tasks in our {dplyr} pipelines.\n\nThe bad news: across() only works with {dplyr} functions like mutate or summarize\n\n\nThe good news: there’s a more general-purpose solution in the {tidyverse}"
  },
  {
    "objectID": "slides/18/slides18.html#section-1",
    "href": "slides/18/slides18.html#section-1",
    "title": "Iteration II",
    "section": "",
    "text": "Enhances the functional programming toolkit of R\nMain function is map, which allows you to replace many for loops\nLoaded with library(tidyverse)"
  },
  {
    "objectID": "slides/18/slides18.html#map",
    "href": "slides/18/slides18.html#map",
    "title": "Iteration II",
    "section": "map()",
    "text": "map()\n\n\n\n\n.x what to iterate over\n\n.f function to apply\n\n\n\nmap(.x, \n    .f,\n    ...)"
  },
  {
    "objectID": "slides/18/slides18.html#how-does-mapping-work",
    "href": "slides/18/slides18.html#how-does-mapping-work",
    "title": "Iteration II",
    "section": "How does mapping work?",
    "text": "How does mapping work?\nSuppose we have quiz 1 and quiz 2 scores of 4 students stored in a list…\n\nquiz_scores &lt;- list(\n  quiz1 &lt;- c(80, 90, 70, 50),\n  quiz2 &lt;- c(85, 83, 45, 60)\n)\n\n\n…and we find the mean score in each quiz\n\nmap(quiz_scores, mean)\n\n[[1]]\n[1] 72.5\n\n[[2]]\n[1] 68.25"
  },
  {
    "objectID": "slides/18/slides18.html#section-2",
    "href": "slides/18/slides18.html#section-2",
    "title": "Iteration II",
    "section": "",
    "text": "…and suppose we want the results as a numeric (double) vector\n\nmap_dbl(quiz_scores, mean)\n\n[1] 72.50 68.25\n\n\n\n…or as a character string\n\nmap_chr(quiz_scores, mean)\n\n[1] \"72.500000\" \"68.250000\""
  },
  {
    "objectID": "slides/18/slides18.html#map_something",
    "href": "slides/18/slides18.html#map_something",
    "title": "Iteration II",
    "section": "map_something",
    "text": "map_something\nFunctions for looping over an object and returning a value (of a specific type):\n\n\n\nmap() - returns a list\n\nmap_lgl() - returns a logical vector\n\nmap_int() - returns a integer vector\n\nmap_dbl() - returns a double vector\n\nmap_chr() - returns a character vector\n\nmap_df() / map_dfr() - returns a data frame by row binding …"
  },
  {
    "objectID": "slides/18/slides18.html#try-it-map",
    "href": "slides/18/slides18.html#try-it-map",
    "title": "Iteration II",
    "section": "Try it: map\n",
    "text": "Try it: map\n\n\n\nEdit the code chunk below so it returns a numeric vector\nEdit the code chunk so it only maps to the numeric columns (3-12) of unscaled cancer\n\n\n\n\nmap(unscaled_cancer, mean)\n\n\n\n\nmap the summary function to all columns in the {palmerpenguins} penguins data\n\n\n\n\n\n\n−&plus;\n\n03:00"
  },
  {
    "objectID": "slides/18/slides18.html#example-bakeoff-data",
    "href": "slides/18/slides18.html#example-bakeoff-data",
    "title": "Iteration II",
    "section": "Example: bakeoff data",
    "text": "Example: bakeoff data\n\n\nFor loop\nFor loop + function\nMap + function\n\n\n\n\nresults = character(10)\n\nfor(k in 1:10){\n  eliminated = bakeoff |&gt;\n    filter(episode == k, str_detect(result, \"Eliminated\")) \n  \n  if(nrow(eliminated) == 1){\n    results[k] = eliminated$showstopper\n  } else if(nrow(eliminated) &gt; 1){\n    results[k] = str_flatten(eliminated$showstopper, collapse = \", \")\n  } else{\n    results[k] = \"none\"\n  }\n}\n\n\n\n\neliminated_showstopper = function(ep_number){\n   bakeoff |&gt;\n    filter(episode == ep_number, str_detect(result, \"Eliminated\")) |&gt;\n    summarize(\n      n = n(),\n      showstopper = if_else(n &gt; 0, \n                            str_flatten(showstopper, collapse = \",\"), \"none\")) |&gt;\n    pull(showstopper)\n}\n\nresults = character(10)\n\nfor(k in 1:10){\n  results[k] = eliminated_showstopper(k)\n}\n\n\n\n\nmap_chr(1:10, eliminated_showstopper)\n\n [1] \"'Orca on a Wave' Cake\"                                                  \n [2] \"'Seaside Meal Deal' Illusion Biscuits\"                                  \n [3] \"'My Favourite Tree' Plaited Centrepiece\"                                \n [4] \"none\"                                                                   \n [5] \"'Gran's Garden Trio' Decorative Pies,'Lattice Fabulous' Decorative Pies\"\n [6] \"'Stop and Smell the Rosé' Floral Dessert\"                               \n [7] \"'Flowers for my Bee' Meringue Bombe\"                                    \n [8] \"'Marvellous Sweet Factory' Buffet\"                                      \n [9] \"'Mango Mojito' Millefoglie\"                                             \n[10] \"none\""
  },
  {
    "objectID": "slides/18/slides18.html#map-vs-for-loop",
    "href": "slides/18/slides18.html#map-vs-for-loop",
    "title": "Iteration II",
    "section": "\nmap vs for loop",
    "text": "map vs for loop\n\n\nPros\n\nDon’t have to pre-allocate storage\nDon’t have to define an index\nLess error-prone\nTakes advantage of functional programming\n\n\nCons\n\nHard to get used to if you’ve previously learned for-loops\nOften need to define a function\nLess fine-grained control\n\n\n\nFor this class, we’ll learn the basics of both and get practice on homework. For projects, you can use whichever approach makes more sense to you."
  },
  {
    "objectID": "slides/18/slides18.html#your-turn-map-with-penguins",
    "href": "slides/18/slides18.html#your-turn-map-with-penguins",
    "title": "Iteration II",
    "section": "Your turn: map with penguins\n",
    "text": "Your turn: map with penguins\n\n\nUsing the penguins data, use map to calculate the range of a numeric variable and the table of a factor variable. (It may be helpful to first write a custom function for this output)\nYour result should be a list (it will have length 8).\n\n\n\n\n\n−&plus;\n\n04:00"
  },
  {
    "objectID": "slides/18/slides18.html#more-practice-survivor-data",
    "href": "slides/18/slides18.html#more-practice-survivor-data",
    "title": "Iteration II",
    "section": "More practice: survivor data",
    "text": "More practice: survivor data\n\nus_castaway_results \n\n# A tibble: 870 × 7\n   castaway_id castaway season_name      season place jury  finalist\n   &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;   \n 1 US0001      Sonja    Survivor: Borneo      1    16 FALSE FALSE   \n 2 US0002      B.B.     Survivor: Borneo      1    15 FALSE FALSE   \n 3 US0003      Stacey   Survivor: Borneo      1    14 FALSE FALSE   \n 4 US0004      Ramona   Survivor: Borneo      1    13 FALSE FALSE   \n 5 US0005      Dirk     Survivor: Borneo      1    12 FALSE FALSE   \n 6 US0006      Joel     Survivor: Borneo      1    11 FALSE FALSE   \n 7 US0007      Gretchen Survivor: Borneo      1    10 FALSE FALSE   \n 8 US0008      Greg     Survivor: Borneo      1     9 TRUE  FALSE   \n 9 US0009      Jenna    Survivor: Borneo      1     8 TRUE  FALSE   \n10 US0010      Gervase  Survivor: Borneo      1     7 TRUE  FALSE   \n# ℹ 860 more rows\n\n\n\n\n\nWrite a function called finalists that takes the input of a survivor season (as a numeric) and outputs a string of the finalists’ names for that season. The finalists’ names should be separated with a comma.\nUse map_chr to return a character vector of finalists for seasons 31-40.\n\n\n\n\n\n\n−&plus;\n\n05:00"
  },
  {
    "objectID": "slides/18/slides18.html#simulation-1",
    "href": "slides/18/slides18.html#simulation-1",
    "title": "Iteration II",
    "section": "Simulation",
    "text": "Simulation\n\nIteration is especially useful for simulation\n\nIn statistics, we often work with a random sample to try to learn something about a population.\nWe care about the uncertainty of our results: did we find a true trend, or could it be due to sampling variability?"
  },
  {
    "objectID": "slides/18/slides18.html#example-survivor-data",
    "href": "slides/18/slides18.html#example-survivor-data",
    "title": "Iteration II",
    "section": "Example: survivor data",
    "text": "Example: survivor data\nIf we randomly choose 20 previous survivor players to play on a new season, how likely are we to get zero finalists?\n\nus_castaway_results %&gt;%\n  slice_sample(n = 20) %&gt;%\n  filter(finalist) %&gt;%\n  count()\n\n\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1     2"
  },
  {
    "objectID": "slides/18/slides18.html#the-plan",
    "href": "slides/18/slides18.html#the-plan",
    "title": "Iteration II",
    "section": "The plan",
    "text": "The plan\n\nWrite a function that runs our “experiment”\nSet up an iteration procedure to run our experiment a bunch of times\nAnalyze the results"
  },
  {
    "objectID": "slides/18/slides18.html#section-3",
    "href": "slides/18/slides18.html#section-3",
    "title": "Iteration II",
    "section": "",
    "text": "Write a function that runs our “experiment”\n\nsample_finalists = function(n){\n    us_castaway_results %&gt;%\n    slice_sample(n = n) %&gt;%\n    filter(finalist) %&gt;%\n    count() %&gt;%\n    pull(n)\n}\n\nn_finalists = integer(1000)\n\nfor(k in 1:1000){\n  n_finalists[k] = sample_finalists(20)\n}\n\ntable(n_finalists)/1000"
  },
  {
    "objectID": "slides/18/slides18.html#section-4",
    "href": "slides/18/slides18.html#section-4",
    "title": "Iteration II",
    "section": "",
    "text": "Set up a for loop to run our experiment a bunch of times\n\nsample_finalists = function(n){\n    us_castaway_results %&gt;%\n    slice_sample(n = n) %&gt;%\n    filter(finalist) %&gt;%\n    count() %&gt;%\n    pull(n)\n}\n\nn_finalists = integer(1000)\n\nfor(k in 1:1000){\n  n_finalists[k] = sample_finalists(20)\n}\n\ntable(n_finalists)/1000"
  },
  {
    "objectID": "slides/18/slides18.html#section-5",
    "href": "slides/18/slides18.html#section-5",
    "title": "Iteration II",
    "section": "",
    "text": "Analyze the results\n\nsample_finalists = function(n){\n    us_castaway_results %&gt;%\n    slice_sample(n = n) %&gt;%\n    filter(finalist) %&gt;%\n    count() %&gt;%\n    pull(n)\n}\n\nn_finalists = integer(1000)\n\nfor(k in 1:1000){\n  n_finalists[k] = sample_finalists(20)\n}\n\ntable(n_finalists)/1000\n\n\n\nn_finalists\n    0     1     2     3     4     5     6     7     8 \n0.031 0.139 0.248 0.261 0.165 0.099 0.043 0.010 0.004"
  },
  {
    "objectID": "slides/18/slides18.html#same-approach-using-map",
    "href": "slides/18/slides18.html#same-approach-using-map",
    "title": "Iteration II",
    "section": "Same approach using map\n",
    "text": "Same approach using map\n\n\n\nDefine something to map over\nApply sample_finalists function to “something”\nAnalyze results"
  },
  {
    "objectID": "slides/18/slides18.html#same-approach-using-map-1",
    "href": "slides/18/slides18.html#same-approach-using-map-1",
    "title": "Iteration II",
    "section": "Same approach using map\n",
    "text": "Same approach using map\n\nDefine something to map over:\n\nrep(20,5)\n\n[1] 20 20 20 20 20\n\n\n\nApply sample_finalists function and analyze results\n\nrep(20, 1000) |&gt;\n  map_dbl(sample_finalists) |&gt;\n  table()\n\n\n\n\n  0   1   2   3   4   5   6   7   8 \n 41 144 244 243 175  95  41  15   2"
  },
  {
    "objectID": "slides/18/slides18.html#your-turn",
    "href": "slides/18/slides18.html#your-turn",
    "title": "Iteration II",
    "section": "Your turn",
    "text": "Your turn\n\nSome survivor seasons only had 16 players, while others had 22. This could result in some seasons being slightly under/overrepresented in our sample. Let’s account for this.\nEdit this experiment to instead randomly sample one player from each season (this results in 47 players) and then sample 20 players from the 47 random ones.\n(Hint: look at the by argument in slice_sample)\n\n\n\n\n\n−&plus;\n\n04:00"
  },
  {
    "objectID": "slides/18/slides18.html#unscaled_cancer",
    "href": "slides/18/slides18.html#unscaled_cancer",
    "title": "Iteration II",
    "section": "unscaled_cancer",
    "text": "unscaled_cancer\nRecall the unscaled_cancer dataset from last week:\n\nunscaled_cancer\n\n# A tibble: 569 × 12\n        ID Class Radius Texture Perimeter  Area Smoothness Compactness Concavity\n     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n 1  8.42e5 M       18.0    10.4     123.  1001      0.118       0.278     0.300 \n 2  8.43e5 M       20.6    17.8     133.  1326      0.0847      0.0786    0.0869\n 3  8.43e7 M       19.7    21.2     130   1203      0.110       0.160     0.197 \n 4  8.43e7 M       11.4    20.4      77.6  386.     0.142       0.284     0.241 \n 5  8.44e7 M       20.3    14.3     135.  1297      0.100       0.133     0.198 \n 6  8.44e5 M       12.4    15.7      82.6  477.     0.128       0.17      0.158 \n 7  8.44e5 M       18.2    20.0     120.  1040      0.0946      0.109     0.113 \n 8  8.45e7 M       13.7    20.8      90.2  578.     0.119       0.164     0.0937\n 9  8.45e5 M       13      21.8      87.5  520.     0.127       0.193     0.186 \n10  8.45e7 M       12.5    24.0      84.0  476.     0.119       0.240     0.227 \n# ℹ 559 more rows\n# ℹ 3 more variables: Concave_Points &lt;dbl&gt;, Symmetry &lt;dbl&gt;,\n#   Fractal_Dimension &lt;dbl&gt;"
  },
  {
    "objectID": "slides/18/slides18.html#differences-in-groups",
    "href": "slides/18/slides18.html#differences-in-groups",
    "title": "Iteration II",
    "section": "Differences in groups",
    "text": "Differences in groups\nOne question we might be interested in is “Is the radius of malignant tumors noticeably different than the radius of benign tumors?”\n\nunscaled_cancer %&gt;%\n  group_by(Class) %&gt;%\n  summarize(\n    mean = mean(Radius)\n  )\n\n# A tibble: 2 × 2\n  Class  mean\n  &lt;chr&gt; &lt;dbl&gt;\n1 B      12.1\n2 M      17.5\n\n\n\nThis tells us the average difference within this sample, but we don’t know if this difference is “surprising” or not."
  },
  {
    "objectID": "slides/18/slides18.html#permutation-test",
    "href": "slides/18/slides18.html#permutation-test",
    "title": "Iteration II",
    "section": "Permutation test",
    "text": "Permutation test\nIn a previous statistics class, you may have seen a permutation test for a difference in means.\nBasic idea:\n\nAssume there is no difference in the groups\nShuffle the group labels (benign/malignant) at random\nCompute the difference in means for the two groups\nRepeat the experiment a bunch of times\nCompare the observed difference to the distribution of simulated differences\n\n\nIf the observed difference is much bigger than the simulated differences, we have evidence of a statistically significant result"
  },
  {
    "objectID": "slides/18/slides18.html#your-turn-permutation-test",
    "href": "slides/18/slides18.html#your-turn-permutation-test",
    "title": "Iteration II",
    "section": "Your turn: Permutation test",
    "text": "Your turn: Permutation test\n\n\nDefine a function to run the experiment\n\nCreate a new column of unscaled_cancer called class_shuffled, which is a permutation of the original Class variable (Hint: see sample function)\nGroup by class_shuffled and compute the group means\nFind the difference in the means\n\n\nRepeat the experiment 1000 times, making sure to save the difference in means\nMake a histogram of the simulated differences. How (un)likely is the difference we observed?"
  },
  {
    "objectID": "slides/11/slides11.html#today",
    "href": "slides/11/slides11.html#today",
    "title": "Data Import & Dates/Times",
    "section": "Today",
    "text": "Today\n\nProject 1 grading/questions\nIntro to Project 2\nHW 4 due tonight\nHW 5 + check-in survey\nNew stuff!"
  },
  {
    "objectID": "slides/11/slides11.html#readr-functions",
    "href": "slides/11/slides11.html#readr-functions",
    "title": "Data Import & Dates/Times",
    "section": "readr functions",
    "text": "readr functions\n\n\n\nfunction\nreads\n\n\n\n\nread_csv()\nComma separated values\n\n\nread_csv2()\nSemi-colon separated values\n\n\nread_delim()\nGeneral delimited files\n\n\nread_fwf()\nFixed width files\n\n\nread_log()\nApache log files\n\n\nread_table()\nSpace separated\n\n\nread_tsv()\nTab delimited values"
  },
  {
    "objectID": "slides/11/slides11.html#basic-syntax",
    "href": "slides/11/slides11.html#basic-syntax",
    "title": "Data Import & Dates/Times",
    "section": "Basic syntax",
    "text": "Basic syntax\nAll readr functions share a common syntax\n\ndf &lt;- read_csv(file = \"path/to/file.csv\", ...)"
  },
  {
    "objectID": "slides/11/slides11.html#whats-the-big-deal",
    "href": "slides/11/slides11.html#whats-the-big-deal",
    "title": "Data Import & Dates/Times",
    "section": "What’s the big deal?",
    "text": "What’s the big deal?\nCompared to read.table and its derivatives, readr functions are:\n\n~ 10 times faster\nReturn tibbles\nHave more intuitive defaults. No row names, no strings as factors."
  },
  {
    "objectID": "slides/11/slides11.html#tibbles-enhance-data-frames",
    "href": "slides/11/slides11.html#tibbles-enhance-data-frames",
    "title": "Data Import & Dates/Times",
    "section": "tibbles enhance data frames",
    "text": "tibbles enhance data frames\n\n\n\n\nSubsetting - [ always returns a new tibble, [[ and $ always return a new vector\nNo partial matching - You must use full column names when subsetting\nDisplay - When you print a tibble, R provides a concise view of the data that fits on one screen"
  },
  {
    "objectID": "slides/11/slides11.html#concise-printing",
    "href": "slides/11/slides11.html#concise-printing",
    "title": "Data Import & Dates/Times",
    "section": "Concise printing",
    "text": "Concise printing"
  },
  {
    "objectID": "slides/11/slides11.html#conversion",
    "href": "slides/11/slides11.html#conversion",
    "title": "Data Import & Dates/Times",
    "section": "Conversion",
    "text": "Conversion\n\nas_tibble() - convert a data frame to a tibble\nas.data.frame() - convert a tibble to a data frame"
  },
  {
    "objectID": "slides/11/slides11.html#desserts-data",
    "href": "slides/11/slides11.html#desserts-data",
    "title": "Data Import & Dates/Times",
    "section": "desserts data",
    "text": "desserts data\n\n\nContains results from series 1-8 of The Great British Bake Off\nCase defined by series, episode and baker\n\n\n\n\nSource: Allison Hill and the bakeoff package; compiled by Adam Loy"
  },
  {
    "objectID": "slides/11/slides11.html#warm-up",
    "href": "slides/11/slides11.html#warm-up",
    "title": "Data Import & Dates/Times",
    "section": "Warm up",
    "text": "Warm up\n\nUse read_csv() to import the desserts data set from  https://stat220-w25.github.io/data/desserts.csv\nStore the data in the desserts object\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/11/slides11.html#did-it-work-as-expected",
    "href": "slides/11/slides11.html#did-it-work-as-expected",
    "title": "Data Import & Dates/Times",
    "section": "Did it work as expected?",
    "text": "Did it work as expected?\n\ndesserts &lt;- read_csv(\"https://stat220-w25.github.io/data/desserts.csv\")\n\n\n\n\n\nRows: 549\nColumns: 16\n$ series                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ episode               &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, …\n$ baker                 &lt;chr&gt; \"Annetha\", \"David\", \"Edd\", \"Jasminder\", \"Jonatha…\n$ technical             &lt;chr&gt; \"2nd\", \"3rd\", \"1st\", \"N/A\", \"9th\", \"N/A\", \"8th\",…\n$ result                &lt;chr&gt; \"IN\", \"IN\", \"IN\", \"IN\", \"IN\", \"IN\", \"IN\", \"IN\", …\n$ uk_airdate            &lt;chr&gt; \"17 August 2010\", \"17 August 2010\", \"17 August 2…\n$ us_season             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ us_airdate            &lt;date&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ showstopper_chocolate &lt;chr&gt; \"chocolate\", \"chocolate\", \"no chocolate\", \"no ch…\n$ showstopper_dessert   &lt;chr&gt; \"other\", \"other\", \"other\", \"other\", \"other\", \"ca…\n$ showstopper_fruit     &lt;chr&gt; \"no fruit\", \"no fruit\", \"no fruit\", \"no fruit\", …\n$ showstopper_nut       &lt;chr&gt; \"no nut\", \"no nut\", \"no nut\", \"no nut\", \"almond\"…\n$ signature_chocolate   &lt;chr&gt; \"no chocolate\", \"chocolate\", \"no chocolate\", \"no…\n$ signature_dessert     &lt;chr&gt; \"cake\", \"cake\", \"cake\", \"cake\", \"cake\", \"cake\", …\n$ signature_fruit       &lt;chr&gt; \"no fruit\", \"fruit\", \"fruit\", \"fruit\", \"fruit\", …\n$ signature_nut         &lt;chr&gt; \"no nut\", \"no nut\", \"no nut\", \"no nut\", \"no nut\"…\n\n\n\nA couple issues…\n\ntechnical is character, not numeric\nuk_airdate is character, not date"
  },
  {
    "objectID": "slides/11/slides11.html#the-col_types-argument",
    "href": "slides/11/slides11.html#the-col_types-argument",
    "title": "Data Import & Dates/Times",
    "section": "The col_types argument",
    "text": "The col_types argument\nBy default, looks at first 1000 rows to guess variable data types (guess_max), but we can also tell R how to read column types\n\n\ndesserts &lt;- read_csv(\n  \"https://stat220-w25.github.io/data/desserts.csv\",\n  col_types = list( \n    technical = col_number(), \n    uk_airdate = col_date()   \n  ) \n)"
  },
  {
    "objectID": "slides/11/slides11.html#looking-for-problems",
    "href": "slides/11/slides11.html#looking-for-problems",
    "title": "Data Import & Dates/Times",
    "section": "Looking for problems",
    "text": "Looking for problems\nList of potential problems parsing the file\n\nproblems(desserts)\n\n# A tibble: 556 × 5\n     row   col expected        actual         file \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;\n 1     2     6 date in ISO8601 17 August 2010 \"\"   \n 2     3     6 date in ISO8601 17 August 2010 \"\"   \n 3     4     6 date in ISO8601 17 August 2010 \"\"   \n 4     5     4 a number        N/A            \"\"   \n 5     5     6 date in ISO8601 17 August 2010 \"\"   \n 6     6     6 date in ISO8601 17 August 2010 \"\"   \n 7     7     4 a number        N/A            \"\"   \n 8     7     6 date in ISO8601 17 August 2010 \"\"   \n 9     8     6 date in ISO8601 17 August 2010 \"\"   \n10     9     4 a number        N/A            \"\"   \n# ℹ 546 more rows"
  },
  {
    "objectID": "slides/11/slides11.html#date-formatting-woes",
    "href": "slides/11/slides11.html#date-formatting-woes",
    "title": "Data Import & Dates/Times",
    "section": "Date formatting woes",
    "text": "Date formatting woes\n\nprint(problems(desserts), n=5)\n\n# A tibble: 556 × 5\n    row   col expected        actual         file \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;\n1     2     6 date in ISO8601 17 August 2010 \"\"   \n2     3     6 date in ISO8601 17 August 2010 \"\"   \n3     4     6 date in ISO8601 17 August 2010 \"\"   \n4     5     4 a number        N/A            \"\"   \n5     5     6 date in ISO8601 17 August 2010 \"\"   \n# ℹ 551 more rows\n\n\nISO8601 format: 2010-08-17\nWhat we have: 17 August 2010"
  },
  {
    "objectID": "slides/11/slides11.html#section-1",
    "href": "slides/11/slides11.html#section-1",
    "title": "Data Import & Dates/Times",
    "section": "",
    "text": "Counting Stuff blog by Randy Au"
  },
  {
    "objectID": "slides/11/slides11.html#adding-format-instructions",
    "href": "slides/11/slides11.html#adding-format-instructions",
    "title": "Data Import & Dates/Times",
    "section": "Adding format instructions",
    "text": "Adding format instructions\n\ndesserts &lt;- read_csv(\n  \"https://stat220-w25.github.io/data/desserts.csv\",\n  col_types = list(\n    technical = col_number(), \n    uk_airdate = col_date(format = \"%d %B %Y\")  \n  ) \n)\n\n\nYear: \"%Y\" (4 digits). \"%y\" (2 digits)\nMonth: \"%m\" (2 digits), \"%b\" (abbreviated name in current locale), \"%B\" (full name in current locale).\nDay: \"%d\" (2 digits), \"%e\" (optional leading space)"
  },
  {
    "objectID": "slides/11/slides11.html#looking-for-problems-1",
    "href": "slides/11/slides11.html#looking-for-problems-1",
    "title": "Data Import & Dates/Times",
    "section": "Looking for problems",
    "text": "Looking for problems\nList of potential problems parsing the file\n\nproblems(desserts)\n\n# A tibble: 7 × 5\n    row   col expected actual file \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;\n1     5     4 a number N/A    \"\"   \n2     7     4 a number N/A    \"\"   \n3     9     4 a number N/A    \"\"   \n4    11     4 a number N/A    \"\"   \n5    35     4 a number N/A    \"\"   \n6    36     4 a number N/A    \"\"   \n7    37     4 a number N/A    \"\""
  },
  {
    "objectID": "slides/11/slides11.html#addressing-missing-values",
    "href": "slides/11/slides11.html#addressing-missing-values",
    "title": "Data Import & Dates/Times",
    "section": "Addressing missing values",
    "text": "Addressing missing values\nBy default na = c(\"\", \"NA\") are the recognized missing values\n\ndesserts &lt;- read_csv(\n  \"https://stat220-w25.github.io/data/desserts.csv\",\n  col_types = list(\n    technical = col_number(), \n    uk_airdate = col_date(format = \"%d %B %Y\")\n  ),\n  na = c(\"\", \"NA\", \"N/A\") \n)"
  },
  {
    "objectID": "slides/11/slides11.html#looking-for-problems-2",
    "href": "slides/11/slides11.html#looking-for-problems-2",
    "title": "Data Import & Dates/Times",
    "section": "Looking for problems",
    "text": "Looking for problems\nList of potential problems parsing the file\n\n\n# A tibble: 0 × 5\n# ℹ 5 variables: row &lt;int&gt;, col &lt;int&gt;, expected &lt;chr&gt;, actual &lt;chr&gt;, file &lt;chr&gt;"
  },
  {
    "objectID": "slides/11/slides11.html#section-2",
    "href": "slides/11/slides11.html#section-2",
    "title": "Data Import & Dates/Times",
    "section": "",
    "text": "desserts\n\n# A tibble: 549 × 16\n   series episode baker     technical result uk_airdate us_season us_airdate\n    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;  &lt;date&gt;         &lt;dbl&gt; &lt;date&gt;    \n 1      1       1 Annetha           2 IN     2010-08-17        NA NA        \n 2      1       1 David             3 IN     2010-08-17        NA NA        \n 3      1       1 Edd               1 IN     2010-08-17        NA NA        \n 4      1       1 Jasminder        NA IN     2010-08-17        NA NA        \n 5      1       1 Jonathan          9 IN     2010-08-17        NA NA        \n 6      1       1 Louise           NA IN     2010-08-17        NA NA        \n 7      1       1 Miranda           8 IN     2010-08-17        NA NA        \n 8      1       1 Ruth             NA IN     2010-08-17        NA NA        \n 9      1       1 Lea              10 OUT    2010-08-17        NA NA        \n10      1       1 Mark             NA OUT    2010-08-17        NA NA        \n# ℹ 539 more rows\n# ℹ 8 more variables: showstopper_chocolate &lt;chr&gt;, showstopper_dessert &lt;chr&gt;,\n#   showstopper_fruit &lt;chr&gt;, showstopper_nut &lt;chr&gt;, signature_chocolate &lt;chr&gt;,\n#   signature_dessert &lt;chr&gt;, signature_fruit &lt;chr&gt;, signature_nut &lt;chr&gt;"
  },
  {
    "objectID": "slides/11/slides11.html#column-casting-functions",
    "href": "slides/11/slides11.html#column-casting-functions",
    "title": "Data Import & Dates/Times",
    "section": "Column casting functions",
    "text": "Column casting functions\n\n\n\nType\ndplyr::glimpse()\nreadr::col_*()\n\n\n\n\nlogical\n&lt;lgl&gt;\ncol_logical\n\n\nnumeric\n&lt;int&gt; or &lt;dbl&gt;\ncol_number\n\n\ncharacter\n&lt;chr&gt;\ncol_character\n\n\nfactor\n&lt;fct&gt;\ncol_factor\n\n\ndate\n&lt;date&gt;\ncol_date"
  },
  {
    "objectID": "slides/11/slides11.html#read_csv",
    "href": "slides/11/slides11.html#read_csv",
    "title": "Data Import & Dates/Times",
    "section": "?read_csv",
    "text": "?read_csv\n\nread_csv(file, \n         col_names = TRUE,\n         col_types = NULL,\n         locale = default_locale(),\n         na = c(\"\", \"NA\"), \n         quoted_na = TRUE,\n         quote = \"\\\"\", \n         comment = \"\",\n         trim_ws = TRUE,\n         skip = 0,\n         n_max = Inf,\n         guess_max = min(1000, n_max),\n         progress = show_progress())"
  },
  {
    "objectID": "slides/11/slides11.html#your-turn",
    "href": "slides/11/slides11.html#your-turn",
    "title": "Data Import & Dates/Times",
    "section": "Your turn",
    "text": "Your turn\n\nUse the appropriate read_&lt;type&gt;() function to import the following data sets:\n\ndata-4.csv\ntricky-1.csv\ntricky2.csv\n\nThe full URLs are in the 11-import.Rmd activity\nIf you hit any errors/problems, be sure to explore them and identify the issue, even if you can’t “fix” it."
  },
  {
    "objectID": "slides/11/slides11.html#section-3",
    "href": "slides/11/slides11.html#section-3",
    "title": "Data Import & Dates/Times",
    "section": "",
    "text": "Help!\n\nI already imported data and now I have dates/times as character strings or numeric vectors!"
  },
  {
    "objectID": "slides/11/slides11.html#nycflights13-revisited",
    "href": "slides/11/slides11.html#nycflights13-revisited",
    "title": "Data Import & Dates/Times",
    "section": "nycflights13 revisited",
    "text": "nycflights13 revisited\nRecall that the departure and arrival times were in integer format\n\n\nflights %&gt;% select(contains(\"_time\"), hour, minute)\n\n\n# A tibble: 435,352 × 7\n   dep_time sched_dep_time arr_time sched_arr_time air_time  hour minute\n      &lt;int&gt;          &lt;int&gt;    &lt;int&gt;          &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1        1           2038      328              3      367    20     38\n 2       18           2300      228            135      108    23      0\n 3       31           2344      500            426      190    23     44\n 4       33           2140      238           2352      108    21     40\n 5       36           2048      223           2252       80    20     48\n 6      503            500      808            815      154     5      0\n 7      520            510      948            949      192     5     10\n 8      524            530      645            710      119     5     30\n 9      537            520      926            818      258     5     20\n10      547            545      845            852      157     5     45\n# ℹ 435,342 more rows"
  },
  {
    "objectID": "slides/11/slides11.html#section-4",
    "href": "slides/11/slides11.html#section-4",
    "title": "Data Import & Dates/Times",
    "section": "",
    "text": "A class for representing clock times\nPart of the tidyverse\nNeed to load separately"
  },
  {
    "objectID": "slides/11/slides11.html#creating-times-with-hms",
    "href": "slides/11/slides11.html#creating-times-with-hms",
    "title": "Data Import & Dates/Times",
    "section": "Creating times with hms()",
    "text": "Creating times with hms()\nWe can use the hour and minute column to create a clock time\n\n\nlibrary(hms)\nsched_dep_times &lt;- flights %&gt;% \n  mutate(sched_dep_time_hms = hms(hours = hour, minutes = minute)) %&gt;% \n  pull()\nhead(sched_dep_times)\n\n\n20:38:00\n23:00:00\n23:44:00\n21:40:00\n20:48:00\n05:00:00"
  },
  {
    "objectID": "slides/11/slides11.html#hms-creates-a-special-type-of-object",
    "href": "slides/11/slides11.html#hms-creates-a-special-type-of-object",
    "title": "Data Import & Dates/Times",
    "section": "hms() creates a special type of object",
    "text": "hms() creates a special type of object\n\n\nclass(sched_dep_times)\n\n\n[1] \"hms\"      \"difftime\""
  },
  {
    "objectID": "slides/11/slides11.html#creating-times-with-hms-1",
    "href": "slides/11/slides11.html#creating-times-with-hms-1",
    "title": "Data Import & Dates/Times",
    "section": "Creating times with hms()",
    "text": "Creating times with hms()\nIf we don’t already have hours, minutes, seconds separately, we’ll need to parse out that information\n\nInteger timeParse + hms()\n\n\n\n\ndep_time &lt;- flights %&gt;% pull(dep_time)\nhead(dep_time)\n\n\n[1]   1  18  31  33  36 503\n\n\n\n\n\n\ndep_time_hms &lt;- hms(hours = dep_time %/% 100, minutes = dep_time %% 100)\nhead(dep_time_hms)\n\n\n00:01:00\n00:18:00\n00:31:00\n00:33:00\n00:36:00\n05:03:00\n\n\n%/% divides first number by second number, returns the whole number (integer division)\n%% divides first number by second number, returns the remainder (modulo)"
  },
  {
    "objectID": "slides/11/slides11.html#ultramarathon-results",
    "href": "slides/11/slides11.html#ultramarathon-results",
    "title": "Data Import & Dates/Times",
    "section": "Ultramarathon results",
    "text": "Ultramarathon results\n\nUltra marathon = anything longer than 26.2 miles\nThe dates and times imported as character strings!\n\n\n\n## Rows: 392\n## Columns: 11\n## $ state            &lt;chr&gt; \"Minnesota\", \"Minnesota\", \"Minnesota\", \"Minnesota\", \"…\n## $ Event            &lt;chr&gt; \"Zumbro\", \"Zumbro\", \"Zumbro\", \"Zumbro\", \"Zumbro\", \"Zu…\n## $ City             &lt;chr&gt; \"Theilman\", \"Theilman\", \"Theilman\", \"Theilman\", \"Thei…\n## $ race_url         &lt;chr&gt; \"https://calendar.ultrarunning.com/event/zumbro\", \"ht…\n## $ date             &lt;chr&gt; \"04/08/21\", \"04/11/20\", \"04/13/19\", \"04/13/18\", \"04/0…\n## $ Finishers        &lt;chr&gt; \"121\", \"Race Cancelled\", \"Race Cancelled\", \"49\", \"149…\n## $ top_result_m     &lt;chr&gt; \"5:23:55\", \"Race Cancelled\", \"Race Cancelled\", \"9:13:…\n## $ top_result_f     &lt;chr&gt; \"6:30:42\", \"Race Cancelled\", \"Race Cancelled\", \"10:15…\n## $ distance         &lt;chr&gt; \"34 Miles\", \"50 Miles\", \"50 Miles\", \"50 Miles\", \"50 M…\n## $ elevation_rating &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…\n## $ surface_rating   &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…"
  },
  {
    "objectID": "slides/11/slides11.html#section-5",
    "href": "slides/11/slides11.html#section-5",
    "title": "Data Import & Dates/Times",
    "section": "",
    "text": "Functions for working with dates and time spans\nPart of the tidyverse\nNeed to load separately"
  },
  {
    "objectID": "slides/11/slides11.html#parsing-dates",
    "href": "slides/11/slides11.html#parsing-dates",
    "title": "Data Import & Dates/Times",
    "section": "Parsing dates",
    "text": "Parsing dates\n{lubridate} functions are intuitively named\n\nlibrary(lubridate)\nmdy(\"01/29/25\")\n\n[1] \"2025-01-29\"\n\n\n\ndmy(\"29-01-2025\")\n\n[1] \"2025-01-29\"\n\n\n\nymd(\"2025-01-29\")\n\n[1] \"2025-01-29\"\n\n\n\nymd_hm(\"2025-01-29 09:55\")\n\n[1] \"2025-01-29 09:55:00 UTC\""
  },
  {
    "objectID": "slides/11/slides11.html#ultramarathon-example",
    "href": "slides/11/slides11.html#ultramarathon-example",
    "title": "Data Import & Dates/Times",
    "section": "Ultramarathon example",
    "text": "Ultramarathon example\nDates are in the form 04/08/21, so use mdy() to parse\n\nmn_ultras &lt;- mn_ultras %&gt;% mutate(date = mdy(date))\nglimpse(mn_ultras)\n\nRows: 392\nColumns: 11\n$ state            &lt;chr&gt; \"Minnesota\", \"Minnesota\", \"Minnesota\", \"Minnesota\", \"…\n$ Event            &lt;chr&gt; \"Zumbro\", \"Zumbro\", \"Zumbro\", \"Zumbro\", \"Zumbro\", \"Zu…\n$ City             &lt;chr&gt; \"Theilman\", \"Theilman\", \"Theilman\", \"Theilman\", \"Thei…\n$ race_url         &lt;chr&gt; \"https://calendar.ultrarunning.com/event/zumbro\", \"ht…\n$ date             &lt;date&gt; 2021-04-08, 2020-04-11, 2019-04-13, 2018-04-13, 2017…\n$ Finishers        &lt;chr&gt; \"121\", \"Race Cancelled\", \"Race Cancelled\", \"49\", \"149…\n$ top_result_m     &lt;chr&gt; \"5:23:55\", \"Race Cancelled\", \"Race Cancelled\", \"9:13:…\n$ top_result_f     &lt;chr&gt; \"6:30:42\", \"Race Cancelled\", \"Race Cancelled\", \"10:15…\n$ distance         &lt;chr&gt; \"34 Miles\", \"50 Miles\", \"50 Miles\", \"50 Miles\", \"50 M…\n$ elevation_rating &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…\n$ surface_rating   &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…"
  },
  {
    "objectID": "slides/11/slides11.html#extract-info-from-a-datetime",
    "href": "slides/11/slides11.html#extract-info-from-a-datetime",
    "title": "Data Import & Dates/Times",
    "section": "Extract info from a date/time",
    "text": "Extract info from a date/time\n{lubridate} functions are intuitively named\n\n\n\n\n\n\n\nfunction\naction\n\n\n\n\nyear(), month()\nextract year/month\n\n\nweek()\nextract week of the year\n\n\nday(), wday()\nextract day of month/day of week\n\n\nhour(), minute(), second()\nextract hour/minute/second\n\n\n\nAdding label = TRUE creates an ordered factor (for month or wday)"
  },
  {
    "objectID": "slides/11/slides11.html#extract-info-from-a-datetime-1",
    "href": "slides/11/slides11.html#extract-info-from-a-datetime-1",
    "title": "Data Import & Dates/Times",
    "section": "Extract info from a date/time",
    "text": "Extract info from a date/time\nThe most recent race in the data set was on 2022-01-31\n\nmonth()day()wday()\n\n\nWhat month was that in?\n\nmonth(\"2022-01-31\", label = TRUE)\n\n[1] Jan\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\n\n\n\nWhat day of the month was it on?\n\nday(\"2022-01-31\")\n\n[1] 31\n\n\n\n\nWhat day of the week was it on?\n\nwday(\"2022-01-31\", label = TRUE)\n\n[1] Mon\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat"
  },
  {
    "objectID": "slides/11/slides11.html#measuring-time",
    "href": "slides/11/slides11.html#measuring-time",
    "title": "Data Import & Dates/Times",
    "section": "Measuring time",
    "text": "Measuring time\nHow long ago was the last race?\n\nrace &lt;- ymd(\"2022-01-31\")\ntoday() - race\n\nTime difference of 1095 days\n\n\n\nDifferences in date/time objects are difftime objects\ndifftimes use inconsistent units (sometimes weeks, days, hours, minutes, or seconds)"
  },
  {
    "objectID": "slides/11/slides11.html#measuring-time-durations",
    "href": "slides/11/slides11.html#measuring-time-durations",
    "title": "Data Import & Dates/Times",
    "section": "Measuring time: durations",
    "text": "Measuring time: durations\nA time span that is always measured in seconds\n\nas.duration(today() - race)\n\n[1] \"94608000s (~3 years)\"\n\n\nPlus, a better display"
  },
  {
    "objectID": "slides/11/slides11.html#measuring-time-periods",
    "href": "slides/11/slides11.html#measuring-time-periods",
    "title": "Data Import & Dates/Times",
    "section": "Measuring time: periods",
    "text": "Measuring time: periods\nTo do math with dates add and subtract periods\n\nymd_hms(\"2025-01-29 09:55:00\", tz = \"America/Chicago\") + days(1)\n\n[1] \"2025-01-30 09:55:00 CST\"\n\n\n\nymd_hms(\"2023-02-28 09:55:00\", tz = \"America/Chicago\") + days(1)\n\n[1] \"2023-03-01 09:55:00 CST\"\n\n\nPeriods are measured in clock units"
  },
  {
    "objectID": "slides/11/slides11.html#try-it",
    "href": "slides/11/slides11.html#try-it",
    "title": "Data Import & Dates/Times",
    "section": "Try it",
    "text": "Try it\n\nYour task is create a 1-columnn tibble containing all dates that our class meets this term using lubridate functions. You should only specify the first day of class (1/6/2025)\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/11/slides11.html#try-it-2",
    "href": "slides/11/slides11.html#try-it-2",
    "title": "Data Import & Dates/Times",
    "section": "Try it 2",
    "text": "Try it 2\n\nNow, create a second column where the dates have been formatted. (Hint: see ?stamp)\nYour dates should have the form “Wednesday: Jan 29 2025”\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/17/slides17.html#recap-from-last-class-standardizing-a-vector",
    "href": "slides/17/slides17.html#recap-from-last-class-standardizing-a-vector",
    "title": "Iteration",
    "section": "Recap from last class: Standardizing a vector",
    "text": "Recap from last class: Standardizing a vector\nHere’s a short function that standardizes an input vector\n\nstandardize &lt;- function(x, na.rm = TRUE) {\n  (x - mean(x, na.rm = na.rm)) / sd(x, na.rm = na.rm)\n}\n\nNow we can easily standardize all of our variables, right?"
  },
  {
    "objectID": "slides/17/slides17.html#cancer-data",
    "href": "slides/17/slides17.html#cancer-data",
    "title": "Iteration",
    "section": "Cancer data",
    "text": "Cancer data\n\nSet of digitized breast cancer image features\nRow = an image of a tumor sample\nVariables include the diagnosis (benign or malignant) and measurements\n\n\n\nRows: 569\nColumns: 12\n$ ID                &lt;dbl&gt; 842302, 842517, 84300903, 84348301, 84358402, 843786…\n$ Class             &lt;chr&gt; \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M…\n$ Radius            &lt;dbl&gt; 17.990, 20.570, 19.690, 11.420, 20.290, 12.450, 18.2…\n$ Texture           &lt;dbl&gt; 10.38, 17.77, 21.25, 20.38, 14.34, 15.70, 19.98, 20.…\n$ Perimeter         &lt;dbl&gt; 122.80, 132.90, 130.00, 77.58, 135.10, 82.57, 119.60…\n$ Area              &lt;dbl&gt; 1001.0, 1326.0, 1203.0, 386.1, 1297.0, 477.1, 1040.0…\n$ Smoothness        &lt;dbl&gt; 0.11840, 0.08474, 0.10960, 0.14250, 0.10030, 0.12780…\n$ Compactness       &lt;dbl&gt; 0.27760, 0.07864, 0.15990, 0.28390, 0.13280, 0.17000…\n$ Concavity         &lt;dbl&gt; 0.30010, 0.08690, 0.19740, 0.24140, 0.19800, 0.15780…\n$ Concave_Points    &lt;dbl&gt; 0.14710, 0.07017, 0.12790, 0.10520, 0.10430, 0.08089…\n$ Symmetry          &lt;dbl&gt; 0.2419, 0.1812, 0.2069, 0.2597, 0.1809, 0.2087, 0.17…\n$ Fractal_Dimension &lt;dbl&gt; 0.07871, 0.05667, 0.05999, 0.09744, 0.05883, 0.07613…"
  },
  {
    "objectID": "slides/17/slides17.html#standardizing-cancer-data",
    "href": "slides/17/slides17.html#standardizing-cancer-data",
    "title": "Iteration",
    "section": "Standardizing cancer data",
    "text": "Standardizing cancer data\n\nscaled_cancer &lt;- unscaled_cancer %&gt;%\n  mutate(\n    Radius = standardize(Radius),\n    Texture = standardize(Texture),\n    Perimeter = standardize(Perimeter),\n    Area = standardize(Area),\n    Smoothness = standardize(Smoothness),\n    Compactness = standardize(Compactness),\n    Concavity = standardize(Concavity),\n    Concave_points = standardize(Concave_Points),\n    Symmetry = standardize(Symmetry),\n    Fractal_dimension = standardize(Fractal_Dimension)\n  )"
  },
  {
    "objectID": "slides/17/slides17.html#section",
    "href": "slides/17/slides17.html#section",
    "title": "Iteration",
    "section": "",
    "text": "You should consider writing a function iterating whenever you’ve copied and pasted a  block of code more than twice\n\n\n—Hadley Wickham  -Amanda Luby"
  },
  {
    "objectID": "slides/17/slides17.html#iteration",
    "href": "slides/17/slides17.html#iteration",
    "title": "Iteration",
    "section": "Iteration",
    "text": "Iteration\n\nProgrammatically repeat the code\n\nWe have two options for doing this:\n\nusing a for loop, or similar (imperative programming)\nmapping with functional programming"
  },
  {
    "objectID": "slides/17/slides17.html#for-loops",
    "href": "slides/17/slides17.html#for-loops",
    "title": "Iteration",
    "section": "for loops",
    "text": "for loops\n\nfor loops are the simplest and most common type of loop in R\nGiven a vector iterate through the elements and evaluate the code block for each\n\n\nGoal: Standardize all of the numeric columns via for loops."
  },
  {
    "objectID": "slides/17/slides17.html#for-loops-1",
    "href": "slides/17/slides17.html#for-loops-1",
    "title": "Iteration",
    "section": "for loops",
    "text": "for loops\n(1) Set up a object to store results\n\nscaled_cancer &lt;- unscaled_cancer %&gt;%\n  mutate(\n    Radius = NA,\n    Texture = NA,\n    Perimeter = NA,\n    Area = NA,\n    Smoothness = NA,\n    Compactness = NA,\n    Concavity = NA,\n    Concave_Points = NA,\n    Symmetry = NA,\n    Fractal_dimension = NA\n  )\n\nscaled_cancer\n\n# A tibble: 569 × 13\n        ID Class Radius Texture Perimeter Area  Smoothness Compactness Concavity\n     &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt;  &lt;lgl&gt;   &lt;lgl&gt;     &lt;lgl&gt; &lt;lgl&gt;      &lt;lgl&gt;       &lt;lgl&gt;    \n 1  8.42e5 M     NA     NA      NA        NA    NA         NA          NA       \n 2  8.43e5 M     NA     NA      NA        NA    NA         NA          NA       \n 3  8.43e7 M     NA     NA      NA        NA    NA         NA          NA       \n 4  8.43e7 M     NA     NA      NA        NA    NA         NA          NA       \n 5  8.44e7 M     NA     NA      NA        NA    NA         NA          NA       \n 6  8.44e5 M     NA     NA      NA        NA    NA         NA          NA       \n 7  8.44e5 M     NA     NA      NA        NA    NA         NA          NA       \n 8  8.45e7 M     NA     NA      NA        NA    NA         NA          NA       \n 9  8.45e5 M     NA     NA      NA        NA    NA         NA          NA       \n10  8.45e7 M     NA     NA      NA        NA    NA         NA          NA       \n# ℹ 559 more rows\n# ℹ 4 more variables: Concave_Points &lt;lgl&gt;, Symmetry &lt;lgl&gt;,\n#   Fractal_Dimension &lt;dbl&gt;, Fractal_dimension &lt;lgl&gt;"
  },
  {
    "objectID": "slides/17/slides17.html#for-loops-2",
    "href": "slides/17/slides17.html#for-loops-2",
    "title": "Iteration",
    "section": "for loops",
    "text": "for loops\n(2) Determine an index over which to iterate\nColumns 3 to 12 are numeric, our index is 3:12\n\n\n# A tibble: 569 × 13\n        ID Class Radius Texture Perimeter Area  Smoothness Compactness Concavity\n     &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt;  &lt;lgl&gt;   &lt;lgl&gt;     &lt;lgl&gt; &lt;lgl&gt;      &lt;lgl&gt;       &lt;lgl&gt;    \n 1  8.42e5 M     NA     NA      NA        NA    NA         NA          NA       \n 2  8.43e5 M     NA     NA      NA        NA    NA         NA          NA       \n 3  8.43e7 M     NA     NA      NA        NA    NA         NA          NA       \n 4  8.43e7 M     NA     NA      NA        NA    NA         NA          NA       \n 5  8.44e7 M     NA     NA      NA        NA    NA         NA          NA       \n 6  8.44e5 M     NA     NA      NA        NA    NA         NA          NA       \n 7  8.44e5 M     NA     NA      NA        NA    NA         NA          NA       \n 8  8.45e7 M     NA     NA      NA        NA    NA         NA          NA       \n 9  8.45e5 M     NA     NA      NA        NA    NA         NA          NA       \n10  8.45e7 M     NA     NA      NA        NA    NA         NA          NA       \n# ℹ 559 more rows\n# ℹ 4 more variables: Concave_Points &lt;lgl&gt;, Symmetry &lt;lgl&gt;,\n#   Fractal_Dimension &lt;dbl&gt;, Fractal_dimension &lt;lgl&gt;"
  },
  {
    "objectID": "slides/17/slides17.html#for-loops-3",
    "href": "slides/17/slides17.html#for-loops-3",
    "title": "Iteration",
    "section": "for loops",
    "text": "for loops\n(3) Iterate through the index, standardize and save results i &lt;- 3\n\n\nfor (i in 3:12){\n  scaled_cancer[, i] &lt;- standardize(unscaled_cancer[[i]])\n}\n\n\n\n# A tibble: 569 × 13\n        ID Class Radius Texture Perimeter Area  Smoothness Compactness Concavity\n     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt;   &lt;lgl&gt;     &lt;lgl&gt; &lt;lgl&gt;      &lt;lgl&gt;       &lt;lgl&gt;    \n1   842302 M      1.10  NA      NA        NA    NA         NA          NA       \n2   842517 M      1.83  NA      NA        NA    NA         NA          NA       \n3 84300903 M      1.58  NA      NA        NA    NA         NA          NA       \n4 84348301 M     -0.768 NA      NA        NA    NA         NA          NA       \n5 84358402 M      1.75  NA      NA        NA    NA         NA          NA       \n# ℹ 564 more rows\n# ℹ 4 more variables: Concave_Points &lt;lgl&gt;, Symmetry &lt;lgl&gt;,\n#   Fractal_Dimension &lt;dbl&gt;, Fractal_dimension &lt;lgl&gt;"
  },
  {
    "objectID": "slides/17/slides17.html#for-loops-4",
    "href": "slides/17/slides17.html#for-loops-4",
    "title": "Iteration",
    "section": "for loops",
    "text": "for loops\n(3) Iterate through the index, standardize and save results i &lt;- 4\n\n\nfor (i in 3:12){\n  scaled_cancer[, i] &lt;- standardize(unscaled_cancer[[i]])\n}\n\n\n\n# A tibble: 569 × 13\n        ID Class Radius Texture Perimeter Area  Smoothness Compactness Concavity\n     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;lgl&gt;     &lt;lgl&gt; &lt;lgl&gt;      &lt;lgl&gt;       &lt;lgl&gt;    \n1   842302 M      1.10   -2.07  NA        NA    NA         NA          NA       \n2   842517 M      1.83   -0.353 NA        NA    NA         NA          NA       \n3 84300903 M      1.58    0.456 NA        NA    NA         NA          NA       \n4 84348301 M     -0.768   0.254 NA        NA    NA         NA          NA       \n5 84358402 M      1.75   -1.15  NA        NA    NA         NA          NA       \n# ℹ 564 more rows\n# ℹ 4 more variables: Concave_Points &lt;lgl&gt;, Symmetry &lt;lgl&gt;,\n#   Fractal_Dimension &lt;dbl&gt;, Fractal_dimension &lt;lgl&gt;"
  },
  {
    "objectID": "slides/17/slides17.html#for-loops-5",
    "href": "slides/17/slides17.html#for-loops-5",
    "title": "Iteration",
    "section": "for loops",
    "text": "for loops\n(3) Iterate through the index, standardize and save results i &lt;- 5\n\n\nfor (i in 3:12){\n  scaled_cancer[, i] &lt;- standardize(unscaled_cancer[[i]])\n}\n\n\n\n# A tibble: 569 × 13\n        ID Class Radius Texture Perimeter Area  Smoothness Compactness Concavity\n     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;      &lt;lgl&gt;       &lt;lgl&gt;    \n1   842302 M      1.10   -2.07      1.27  NA    NA         NA          NA       \n2   842517 M      1.83   -0.353     1.68  NA    NA         NA          NA       \n3 84300903 M      1.58    0.456     1.57  NA    NA         NA          NA       \n4 84348301 M     -0.768   0.254    -0.592 NA    NA         NA          NA       \n5 84358402 M      1.75   -1.15      1.78  NA    NA         NA          NA       \n# ℹ 564 more rows\n# ℹ 4 more variables: Concave_Points &lt;lgl&gt;, Symmetry &lt;lgl&gt;,\n#   Fractal_Dimension &lt;dbl&gt;, Fractal_dimension &lt;lgl&gt;"
  },
  {
    "objectID": "slides/17/slides17.html#for-loops-6",
    "href": "slides/17/slides17.html#for-loops-6",
    "title": "Iteration",
    "section": "for loops",
    "text": "for loops\n(3) Iterate through the index, standardize and save results i &lt;- 6\n\n\nfor (i in 3:12){\n  scaled_cancer[, i] &lt;- standardize(unscaled_cancer[[i]])\n}\n\n\n\n# A tibble: 569 × 13\n       ID Class Radius Texture Perimeter   Area Smoothness Compactness Concavity\n    &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt;      &lt;lgl&gt;       &lt;lgl&gt;    \n1  8.42e5 M      1.10   -2.07      1.27   0.984 NA         NA          NA       \n2  8.43e5 M      1.83   -0.353     1.68   1.91  NA         NA          NA       \n3  8.43e7 M      1.58    0.456     1.57   1.56  NA         NA          NA       \n4  8.43e7 M     -0.768   0.254    -0.592 -0.764 NA         NA          NA       \n5  8.44e7 M      1.75   -1.15      1.78   1.82  NA         NA          NA       \n# ℹ 564 more rows\n# ℹ 4 more variables: Concave_Points &lt;lgl&gt;, Symmetry &lt;lgl&gt;,\n#   Fractal_Dimension &lt;dbl&gt;, Fractal_dimension &lt;lgl&gt;"
  },
  {
    "objectID": "slides/17/slides17.html#putting-it-all-together",
    "href": "slides/17/slides17.html#putting-it-all-together",
    "title": "Iteration",
    "section": "Putting it all together:",
    "text": "Putting it all together:\n\n# Preallocate storage\nscaled_cancer &lt;- unscaled_cancer %&gt;%\n  mutate(\n    Radius = NA,\n    Texture = NA,\n    Perimeter = NA,\n    Area = NA,\n    Smoothness = NA,\n    Compactness = NA,\n    Concavity = NA,\n    Concave_Points = NA,\n    Symmetry = NA,\n    Fractal_dimension = NA\n  )\n\n# Iterate over numeric columns and save\nfor (i in 3:12){\n  scaled_cancer[, i] &lt;- standardize(unscaled_cancer[[i]])\n}\n\nscaled_cancer\n\n# A tibble: 569 × 13\n       ID Class Radius Texture Perimeter   Area Smoothness Compactness Concavity\n    &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n 1 8.42e5 M      1.10   -2.07     1.27    0.984      1.57       3.28      2.65  \n 2 8.43e5 M      1.83   -0.353    1.68    1.91      -0.826     -0.487    -0.0238\n 3 8.43e7 M      1.58    0.456    1.57    1.56       0.941      1.05      1.36  \n 4 8.43e7 M     -0.768   0.254   -0.592  -0.764      3.28       3.40      1.91  \n 5 8.44e7 M      1.75   -1.15     1.78    1.82       0.280      0.539     1.37  \n 6 8.44e5 M     -0.476  -0.835   -0.387  -0.505      2.24       1.24      0.866 \n 7 8.44e5 M      1.17    0.161    1.14    1.09      -0.123      0.0882    0.300 \n 8 8.45e7 M     -0.118   0.358   -0.0728 -0.219      1.60       1.14      0.0610\n 9 8.45e5 M     -0.320   0.588   -0.184  -0.384      2.20       1.68      1.22  \n10 8.45e7 M     -0.473   1.10    -0.329  -0.509      1.58       2.56      1.74  \n# ℹ 559 more rows\n# ℹ 4 more variables: Concave_Points &lt;dbl&gt;, Symmetry &lt;dbl&gt;,\n#   Fractal_Dimension &lt;dbl&gt;, Fractal_dimension &lt;lgl&gt;"
  },
  {
    "objectID": "slides/17/slides17.html#your-turn",
    "href": "slides/17/slides17.html#your-turn",
    "title": "Iteration",
    "section": "Your turn",
    "text": "Your turn\n\nLoad the palmerpenguins package.\nWrite a for loop that calculates the mean of the numeric variables in the penguins data set and stores the means in a named vector.\n\n\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\n\n\n\n\n−&plus;\n\n03:00"
  },
  {
    "objectID": "slides/17/slides17.html#preallocate-storage-to-increase-speed",
    "href": "slides/17/slides17.html#preallocate-storage-to-increase-speed",
    "title": "Iteration",
    "section": "Preallocate storage to increase speed",
    "text": "Preallocate storage to increase speed\n\n\n\nadd_to_vector &lt;- function(n) {\n  output &lt;- NULL \n  for (i in 1:n) {\n    output &lt;- c(output, i)\n  }\n  output\n}\n\nadd_to_vector(10000)\n\n\n\n0.113 sec elapsed\n\n\n\n\nadd_to_vector2 &lt;- function(n) {\n  output &lt;- vector(\"integer\", n)  \n  for (i in 1:n) {\n   output[i] &lt;- i\n  }\n  output\n}\n\nadd_to_vector2(10000)\n\n\n\n0.05 sec elapsed"
  },
  {
    "objectID": "slides/17/slides17.html#the-difference-is-noticable-for-larger-n",
    "href": "slides/17/slides17.html#the-difference-is-noticable-for-larger-n",
    "title": "Iteration",
    "section": "The difference is noticable for larger n",
    "text": "The difference is noticable for larger n\n\n\n\nadd_to_vector &lt;- function(n) {\n  output &lt;- NULL \n  for (i in 1:n) {\n    output &lt;- c(output, i)\n  }\n  output\n}\n\nadd_to_vector(100000)\n\n6.38 sec elapsed\n\n\nadd_to_vector2 &lt;- function(n) {\n  output &lt;- vector(\"integer\", n)  \n  for (i in 1:n) {\n   output[i] &lt;- i\n  }\n  output\n}\n\nadd_to_vector2(100000)\n\n0.438 sec elapsed"
  },
  {
    "objectID": "slides/17/slides17.html#preallocating-output",
    "href": "slides/17/slides17.html#preallocating-output",
    "title": "Iteration",
    "section": "Preallocating output",
    "text": "Preallocating output\nHere are a few useful ways to preallocate storage for a vector of length n:\n\noutput &lt;- double(n)    # numeric vector\noutput &lt;- integer(n)   # integer vector\noutput &lt;- character(n) # character vector\noutput &lt;- rep(NA, n)   # vector of NAs\n\n\nYou can make tibbles of NAs by combining vectors via tibble()\n\noutput_tbl &lt;- tibble(\n  a = double(n),\n  b = integer(n),\n  c = character(n),\n  d = rep(NA, n)\n)"
  },
  {
    "objectID": "slides/17/slides17.html#create-index-vector",
    "href": "slides/17/slides17.html#create-index-vector",
    "title": "Iteration",
    "section": "Create index vector",
    "text": "Create index vector\nUseful ways to create index vector to iterate over:\n\n1:n - manual creation if you already have n stored\n\nseq_along(df) - construct an index “along” the columns of your data frame/tibble\ne.g. seq_along(unscaled_cancer)  ⚠️ Use this instead of 1:nrow(df)or 1:length(x)\n\n\nx - pass in a vector, there’s no reason it needs to be an “index”\ne.g. colnames(unscaled_cancer)"
  },
  {
    "objectID": "slides/17/slides17.html#your-turn-1",
    "href": "slides/17/slides17.html#your-turn-1",
    "title": "Iteration",
    "section": "Your turn:",
    "text": "Your turn:\n\nRevisit the {palmerpenguins} penguins data.\nWrite a for loop that calculates the summary() of a numeric variable and the table() of a factor variable.\nStore the results in a list (it will have length 8).\n\n\n\n\n\n−&plus;\n\n03:00"
  },
  {
    "objectID": "slides/17/slides17.html#r-has-lots-of-alternatives-to-for-loops",
    "href": "slides/17/slides17.html#r-has-lots-of-alternatives-to-for-loops",
    "title": "Iteration",
    "section": "R has lots of alternatives to for loops",
    "text": "R has lots of alternatives to for loops\n\nThe basic data type in R is a vector\nIn R, an “integer” is the same as a vector of integers of length 1\nIn more general-purpose programming languages, single items are stored differently than arrays of those items\nThis means that R is highly optimized for vectorized operations"
  },
  {
    "objectID": "slides/17/slides17.html#across-1",
    "href": "slides/17/slides17.html#across-1",
    "title": "Iteration",
    "section": "across()",
    "text": "across()\n\n\n\n\n.cols: columns to apply function to\n\n.fns function to apply\n\n\n\nacross(.cols, \n       .fns)"
  },
  {
    "objectID": "slides/17/slides17.html#across-on-unscaled-cancer-data",
    "href": "slides/17/slides17.html#across-on-unscaled-cancer-data",
    "title": "Iteration",
    "section": "\nacross() on unscaled cancer data",
    "text": "across() on unscaled cancer data\n\n\nOne Function\nMultiple Functions\nMutate\n\n\n\n\nunscaled_cancer |&gt;\n  summarize(across(Radius:Fractal_Dimension, mean))\n\n# A tibble: 1 × 10\n  Radius Texture Perimeter  Area Smoothness Compactness Concavity Concave_Points\n   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;\n1   14.1    19.3      92.0  655.     0.0964       0.104    0.0888         0.0489\n# ℹ 2 more variables: Symmetry &lt;dbl&gt;, Fractal_Dimension &lt;dbl&gt;\n\n\n\n\n\nunscaled_cancer |&gt;\n  summarize(across(Radius:Fractal_Dimension, list(mean = mean, \n                                                  sd = sd)))\n\n# A tibble: 1 × 20\n  Radius_mean Radius_sd Texture_mean Texture_sd Perimeter_mean Perimeter_sd\n        &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n1        14.1      3.52         19.3       4.30           92.0         24.3\n# ℹ 14 more variables: Area_mean &lt;dbl&gt;, Area_sd &lt;dbl&gt;, Smoothness_mean &lt;dbl&gt;,\n#   Smoothness_sd &lt;dbl&gt;, Compactness_mean &lt;dbl&gt;, Compactness_sd &lt;dbl&gt;,\n#   Concavity_mean &lt;dbl&gt;, Concavity_sd &lt;dbl&gt;, Concave_Points_mean &lt;dbl&gt;,\n#   Concave_Points_sd &lt;dbl&gt;, Symmetry_mean &lt;dbl&gt;, Symmetry_sd &lt;dbl&gt;,\n#   Fractal_Dimension_mean &lt;dbl&gt;, Fractal_Dimension_sd &lt;dbl&gt;\n\n\n\n\n\nunscaled_cancer |&gt;\n  mutate(across(Radius:Fractal_Dimension, standardize))\n\n# A tibble: 569 × 12\n       ID Class Radius Texture Perimeter   Area Smoothness Compactness Concavity\n    &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n 1 8.42e5 M      1.10   -2.07     1.27    0.984      1.57       3.28      2.65  \n 2 8.43e5 M      1.83   -0.353    1.68    1.91      -0.826     -0.487    -0.0238\n 3 8.43e7 M      1.58    0.456    1.57    1.56       0.941      1.05      1.36  \n 4 8.43e7 M     -0.768   0.254   -0.592  -0.764      3.28       3.40      1.91  \n 5 8.44e7 M      1.75   -1.15     1.78    1.82       0.280      0.539     1.37  \n 6 8.44e5 M     -0.476  -0.835   -0.387  -0.505      2.24       1.24      0.866 \n 7 8.44e5 M      1.17    0.161    1.14    1.09      -0.123      0.0882    0.300 \n 8 8.45e7 M     -0.118   0.358   -0.0728 -0.219      1.60       1.14      0.0610\n 9 8.45e5 M     -0.320   0.588   -0.184  -0.384      2.20       1.68      1.22  \n10 8.45e7 M     -0.473   1.10    -0.329  -0.509      1.58       2.56      1.74  \n# ℹ 559 more rows\n# ℹ 3 more variables: Concave_Points &lt;dbl&gt;, Symmetry &lt;dbl&gt;,\n#   Fractal_Dimension &lt;dbl&gt;"
  },
  {
    "objectID": "slides/17/slides17.html#helper-functions-for-across",
    "href": "slides/17/slides17.html#helper-functions-for-across",
    "title": "Iteration",
    "section": "Helper functions for across()\n",
    "text": "Helper functions for across()\n\n\n\n\nwhere(is.numeric) selects all numeric columns.\n\nwhere(is.character) selects all string columns.\n\nwhere(is.Date) selects all date columns.\n\nwhere(is.logical) selects all logical columns."
  },
  {
    "objectID": "slides/17/slides17.html#across-on-unscaled-cancer-data-1",
    "href": "slides/17/slides17.html#across-on-unscaled-cancer-data-1",
    "title": "Iteration",
    "section": "\nacross() on unscaled cancer data",
    "text": "across() on unscaled cancer data\n\nunscaled_cancer %&gt;%\n  mutate(across(where(is.numeric), standardize))\n\n# A tibble: 569 × 12\n       ID Class Radius Texture Perimeter   Area Smoothness Compactness Concavity\n    &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n 1 -0.236 M      1.10   -2.07     1.27    0.984      1.57       3.28      2.65  \n 2 -0.236 M      1.83   -0.353    1.68    1.91      -0.826     -0.487    -0.0238\n 3  0.431 M      1.58    0.456    1.57    1.56       0.941      1.05      1.36  \n 4  0.432 M     -0.768   0.254   -0.592  -0.764      3.28       3.40      1.91  \n 5  0.432 M      1.75   -1.15     1.78    1.82       0.280      0.539     1.37  \n 6 -0.236 M     -0.476  -0.835   -0.387  -0.505      2.24       1.24      0.866 \n 7 -0.236 M      1.17    0.161    1.14    1.09      -0.123      0.0882    0.300 \n 8  0.433 M     -0.118   0.358   -0.0728 -0.219      1.60       1.14      0.0610\n 9 -0.236 M     -0.320   0.588   -0.184  -0.384      2.20       1.68      1.22  \n10  0.433 M     -0.473   1.10    -0.329  -0.509      1.58       2.56      1.74  \n# ℹ 559 more rows\n# ℹ 3 more variables: Concave_Points &lt;dbl&gt;, Symmetry &lt;dbl&gt;,\n#   Fractal_Dimension &lt;dbl&gt;"
  },
  {
    "objectID": "slides/17/slides17.html#across-with-a-new-function",
    "href": "slides/17/slides17.html#across-with-a-new-function",
    "title": "Iteration",
    "section": "\nacross() with a new function",
    "text": "across() with a new function\nLet’s say we want the range of each quantitative variable (max(x) - min(x)). We could name a new function, or we could do it directly in across()\n\n\nunscaled_cancer %&gt;%\n  summarize(across(where(is.numeric), function(x) max(x) - min(x)))\n\n\n\n# A tibble: 1 × 11\n         ID Radius Texture Perimeter  Area Smoothness Compactness Concavity\n      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1 911311832   21.1    29.6      145. 2358.      0.111       0.326     0.427\n# ℹ 3 more variables: Concave_Points &lt;dbl&gt;, Symmetry &lt;dbl&gt;,\n#   Fractal_Dimension &lt;dbl&gt;\n\n\n\n\nOr we can use an anonymous function\n\nunscaled_cancer %&gt;%\n  summarize(across(where(is.numeric), \\(x) max(x) - min(x)))\n\n# A tibble: 1 × 11\n         ID Radius Texture Perimeter  Area Smoothness Compactness Concavity\n      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1 911311832   21.1    29.6      145. 2358.      0.111       0.326     0.427\n# ℹ 3 more variables: Concave_Points &lt;dbl&gt;, Symmetry &lt;dbl&gt;,\n#   Fractal_Dimension &lt;dbl&gt;"
  },
  {
    "objectID": "slides/17/slides17.html#your-turn-2",
    "href": "slides/17/slides17.html#your-turn-2",
    "title": "Iteration",
    "section": "Your turn",
    "text": "Your turn\n\nUse summarize and across to find the range of any quantitative variables, and the number of levels of any factor variables in the penguins dataset.\n\n\ncountdown(4)\n\n\n\n−&plus;\n\n04:00"
  },
  {
    "objectID": "slides/17/slides17.html#section-1",
    "href": "slides/17/slides17.html#section-1",
    "title": "Iteration",
    "section": "",
    "text": "The good news: we can use across to do lots of for-loop-type tasks in our {dplyr} pipelines.\n\nThe bad news: across() only works with {dplyr} functions like mutate or summarize\n\n\nThe good news: there’s a more general-purpose solution in the {tidyverse}"
  },
  {
    "objectID": "slides/17/slides17.html#section-2",
    "href": "slides/17/slides17.html#section-2",
    "title": "Iteration",
    "section": "",
    "text": "Enhances the functional programming toolkit of R\nMain function is map, which allows you to replace many for loops\nLoaded with library(tidyverse)"
  },
  {
    "objectID": "slides/17/slides17.html#map",
    "href": "slides/17/slides17.html#map",
    "title": "Iteration",
    "section": "map()",
    "text": "map()\n\n\n\n\n.x what to iterate over\n\n.f function to apply\n\n\n\nmap(.x, \n    .f,\n    ...)"
  },
  {
    "objectID": "slides/17/slides17.html#how-does-mapping-work",
    "href": "slides/17/slides17.html#how-does-mapping-work",
    "title": "Iteration",
    "section": "How does mapping work?",
    "text": "How does mapping work?\nSuppose we have quiz 1 and quiz 2 scores of 4 students stored in a list…\n\nquiz_scores &lt;- list(\n  quiz1 &lt;- c(80, 90, 70, 50),\n  quiz2 &lt;- c(85, 83, 45, 60)\n)\n\n\n…and we find the mean score in each quiz\n\nmap(quiz_scores, mean)\n\n[[1]]\n[1] 72.5\n\n[[2]]\n[1] 68.25"
  },
  {
    "objectID": "slides/17/slides17.html#section-3",
    "href": "slides/17/slides17.html#section-3",
    "title": "Iteration",
    "section": "",
    "text": "…and suppose we want the results as a numeric (double) vector\n\nmap_dbl(quiz_scores, mean)\n\n[1] 72.50 68.25\n\n\n\n…or as a character string\n\nmap_chr(quiz_scores, mean)\n\n[1] \"72.500000\" \"68.250000\""
  },
  {
    "objectID": "slides/17/slides17.html#map_something",
    "href": "slides/17/slides17.html#map_something",
    "title": "Iteration",
    "section": "map_something",
    "text": "map_something\nFunctions for looping over an object and returning a value (of a specific type):\n\n\n\nmap() - returns a list\n\nmap_lgl() - returns a logical vector\n\nmap_int() - returns a integer vector\n\nmap_dbl() - returns a double vector\n\nmap_chr() - returns a character vector\n\nmap_df() / map_dfr() - returns a data frame by row binding\n\nmap_dfc() - returns a data frame by column binding\n…"
  },
  {
    "objectID": "slides/17/slides17.html#your-turn-3",
    "href": "slides/17/slides17.html#your-turn-3",
    "title": "Iteration",
    "section": "Your turn:",
    "text": "Your turn:\n\nUsing the penguins data, use map to calculate the summary() of a numeric variable and the table() of a factor variable. (It may be helpful to first write a custom function for this output)\nYour result should be a list (it will have length 8).\n\n\n\n\n\n−&plus;\n\n04:00"
  },
  {
    "objectID": "slides/17/slides17.html#more-practice-survivor-data",
    "href": "slides/17/slides17.html#more-practice-survivor-data",
    "title": "Iteration",
    "section": "More practice: survivor data",
    "text": "More practice: survivor data\n\n\nWrite a function called finalists that takes the input of a survivor season (as a numeric) and outputs a vector of the finalists’ names for that season.\nUse map to return a list of finalists for seasons 31-40.\nNow, return a character vector instead of a list (you may need to edit your function). For each season, the finalists’ names should be separated with a comma.\n\n\n\nload(url(\"https://stat220-w25.github.io/data/combining-data-examples.Rda\"))\nus_castaway_results\n\n# A tibble: 870 × 7\n   castaway_id castaway season_name      season place jury  finalist\n   &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;   \n 1 US0001      Sonja    Survivor: Borneo      1    16 FALSE FALSE   \n 2 US0002      B.B.     Survivor: Borneo      1    15 FALSE FALSE   \n 3 US0003      Stacey   Survivor: Borneo      1    14 FALSE FALSE   \n 4 US0004      Ramona   Survivor: Borneo      1    13 FALSE FALSE   \n 5 US0005      Dirk     Survivor: Borneo      1    12 FALSE FALSE   \n 6 US0006      Joel     Survivor: Borneo      1    11 FALSE FALSE   \n 7 US0007      Gretchen Survivor: Borneo      1    10 FALSE FALSE   \n 8 US0008      Greg     Survivor: Borneo      1     9 TRUE  FALSE   \n 9 US0009      Jenna    Survivor: Borneo      1     8 TRUE  FALSE   \n10 US0010      Gervase  Survivor: Borneo      1     7 TRUE  FALSE   \n# ℹ 860 more rows"
  },
  {
    "objectID": "slides/17/slides17.html#more-practice",
    "href": "slides/17/slides17.html#more-practice",
    "title": "Iteration",
    "section": "More practice",
    "text": "More practice\n\nExplain what each step of the pipeline in this function does. (Try things out to confirm!)\n\n\nshow_missing &lt;- function(df, group_vars, summary_vars = everything()) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) sum(is.na(x))),\n      .groups = \"drop\"\n    ) |&gt;\n    select(where(\\(x) any(x &gt; 0)))\n}\n\nnycflights23::flights |&gt; show_missing(c(year, month, day))\n\n# A tibble: 365 × 9\n    year month   day dep_time dep_delay arr_time arr_delay tailnum air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;     &lt;int&gt;    &lt;int&gt;     &lt;int&gt;   &lt;int&gt;    &lt;int&gt;\n 1  2023     1     1        5         5        6         9       2        9\n 2  2023     1     2       28        28       30        37       8       37\n 3  2023     1     3       16        16       16        19       1       19\n 4  2023     1     4       16        16       18        21       2       21\n 5  2023     1     5       10        10       10        13       0       13\n 6  2023     1     6        1         1        1         3       0        3\n 7  2023     1     7        1         1        1         3       0        3\n 8  2023     1     8        0         0        0         1       0        1\n 9  2023     1     9       15        15       15        16       1       16\n10  2023     1    10        4         4        4         4       1        4\n# ℹ 355 more rows"
  },
  {
    "objectID": "slides/19/slides19.html#what-is-an-api",
    "href": "slides/19/slides19.html#what-is-an-api",
    "title": "APIs",
    "section": "What is an API?",
    "text": "What is an API?\n“API stands for Application Programming Interface. It is a set of rules and protocols that lets different software applications communicate with each other.\nIn this class, we’ll use APIs to allow R to communicate with websites. These APIs focus on transmitting raw data, rather than images, fonts, etc. that humans interact with when they visit the page."
  },
  {
    "objectID": "slides/19/slides19.html#how-do-we-use-them",
    "href": "slides/19/slides19.html#how-do-we-use-them",
    "title": "APIs",
    "section": "How do we use them?",
    "text": "How do we use them?\nIn this class, we’re going to cover two ways to access API’s:\n\nwith a wrapper R package\ndirectly with httr requests"
  },
  {
    "objectID": "slides/19/slides19.html#api-wrapper-packages",
    "href": "slides/19/slides19.html#api-wrapper-packages",
    "title": "APIs",
    "section": "API wrapper packages",
    "text": "API wrapper packages\n\nTo find a wrapper package search for “R package”, plus the name of the website, plus “data”\n\n“R package nytimes data”\n“R package reddit data”\n“R package weather.com data”"
  },
  {
    "objectID": "slides/19/slides19.html#example-nytimes-data",
    "href": "slides/19/slides19.html#example-nytimes-data",
    "title": "APIs",
    "section": "Example: nytimes data",
    "text": "Example: nytimes data\n\n\n\n\n\nR functions for accessing New York Times’ APIs\nFunctionality for “article search”, “most popular”, and “Times newswire” APIs.\n\n\nremotes::install_github(\"mkearney/nytimes\")\nlibrary(nytimes)"
  },
  {
    "objectID": "slides/19/slides19.html#nyt_search",
    "href": "slides/19/slides19.html#nyt_search",
    "title": "APIs",
    "section": "nyt_search",
    "text": "nyt_search\nAllows R to interact with the NY Times\n\n\n\nmn_search &lt;- nyt_search(q = \"minnesota\", \n                        n = 50, \n                        end_date = \"20240101\")\n\n\n\n\nq: search term\n\nn: number of articles to return\n\nend_date: which date to start searching backwards from"
  },
  {
    "objectID": "slides/19/slides19.html#output-is-designed-for-computers-to-read",
    "href": "slides/19/slides19.html#output-is-designed-for-computers-to-read",
    "title": "APIs",
    "section": "Output is designed for computers to read",
    "text": "Output is designed for computers to read\n\nstr(mn_search)\n\nList of 5\n $ :List of 10\n  ..$ url        : chr \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=minnesota&sort=newest&end_date=20240101&api-key=5pk1D\"| __truncated__\n  ..$ status_code: int 200\n  ..$ headers    :List of 14\n  .. ..$ date                         : chr \"Wed, 19 Feb 2025 02:24:56 GMT\"\n  .. ..$ content-type                 : chr \"application/json\"\n  .. ..$ content-length               : chr \"227759\"\n  .. ..$ connection                   : chr \"keep-alive\"\n  .. ..$ server                       : chr \"nginx\"\n  .. ..$ vary                         : chr \"Origin\"\n  .. ..$ vary                         : chr \"Access-Control-Request-Method\"\n  .. ..$ vary                         : chr \"Access-Control-Request-Headers\"\n  .. ..$ via                          : chr \"1.1 google\"\n  .. ..$ alt-svc                      : chr \"h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000\"\n  .. ..$ access-control-allow-headers : chr \"Accept, Content-Type, Origin, X-Forwarded-For, X-Prototype-Version, X-Requested-With\"\n  .. ..$ access-control-allow-methods : chr \"GET, OPTIONS\"\n  .. ..$ access-control-allow-origin  : chr \"*\"\n  .. ..$ access-control-expose-headers: chr \"Content-Length, X-JSON\"\n  .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n  ..$ all_headers:List of 1\n  .. ..$ :List of 3\n  .. .. ..$ status : int 200\n  .. .. ..$ version: chr \"HTTP/1.1\"\n  .. .. ..$ headers:List of 14\n  .. .. .. ..$ date                         : chr \"Wed, 19 Feb 2025 02:24:56 GMT\"\n  .. .. .. ..$ content-type                 : chr \"application/json\"\n  .. .. .. ..$ content-length               : chr \"227759\"\n  .. .. .. ..$ connection                   : chr \"keep-alive\"\n  .. .. .. ..$ server                       : chr \"nginx\"\n  .. .. .. ..$ vary                         : chr \"Origin\"\n  .. .. .. ..$ vary                         : chr \"Access-Control-Request-Method\"\n  .. .. .. ..$ vary                         : chr \"Access-Control-Request-Headers\"\n  .. .. .. ..$ via                          : chr \"1.1 google\"\n  .. .. .. ..$ alt-svc                      : chr \"h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000\"\n  .. .. .. ..$ access-control-allow-headers : chr \"Accept, Content-Type, Origin, X-Forwarded-For, X-Prototype-Version, X-Requested-With\"\n  .. .. .. ..$ access-control-allow-methods : chr \"GET, OPTIONS\"\n  .. .. .. ..$ access-control-allow-origin  : chr \"*\"\n  .. .. .. ..$ access-control-expose-headers: chr \"Content-Length, X-JSON\"\n  .. .. .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n  ..$ cookies    :'data.frame': 0 obs. of  7 variables:\n  .. ..$ domain    : logi(0) \n  .. ..$ flag      : logi(0) \n  .. ..$ path      : logi(0) \n  .. ..$ secure    : logi(0) \n  .. ..$ expiration: 'POSIXct' num(0) \n  .. ..$ name      : logi(0) \n  .. ..$ value     : logi(0) \n  ..$ content    : raw [1:227759] 7b 22 73 74 ...\n  ..$ date       : POSIXct[1:1], format: \"2025-02-19 02:24:56\"\n  ..$ times      : Named num [1:6] 0 0.0263 0.0735 0.0735 0.7194 ...\n  .. ..- attr(*, \"names\")= chr [1:6] \"redirect\" \"namelookup\" \"connect\" \"pretransfer\" ...\n  ..$ request    :List of 7\n  .. ..$ method    : chr \"GET\"\n  .. ..$ url       : chr \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=minnesota&sort=newest&end_date=20240101&api-key=5pk1D\"| __truncated__\n  .. ..$ headers   : Named chr \"application/json, text/xml, application/xml, */*\"\n  .. .. ..- attr(*, \"names\")= chr \"Accept\"\n  .. ..$ fields    : NULL\n  .. ..$ options   :List of 2\n  .. .. ..$ useragent: chr \"libcurl/8.11.1 r-curl/6.2.0 httr/1.4.7\"\n  .. .. ..$ httpget  : logi TRUE\n  .. ..$ auth_token: NULL\n  .. ..$ output    : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"write_memory\" \"write_function\"\n  .. ..- attr(*, \"class\")= chr \"request\"\n  ..$ handle     :Class 'curl_handle' &lt;externalptr&gt; \n  ..- attr(*, \"class\")= chr \"response\"\n $ :List of 10\n  ..$ url        : chr \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=minnesota&page=1&sort=newest&end_date=20240101&api-ke\"| __truncated__\n  ..$ status_code: int 200\n  ..$ headers    :List of 14\n  .. ..$ date                         : chr \"Wed, 19 Feb 2025 02:24:57 GMT\"\n  .. ..$ content-type                 : chr \"application/json\"\n  .. ..$ content-length               : chr \"221487\"\n  .. ..$ connection                   : chr \"keep-alive\"\n  .. ..$ server                       : chr \"nginx\"\n  .. ..$ vary                         : chr \"Origin\"\n  .. ..$ vary                         : chr \"Access-Control-Request-Method\"\n  .. ..$ vary                         : chr \"Access-Control-Request-Headers\"\n  .. ..$ via                          : chr \"1.1 google\"\n  .. ..$ alt-svc                      : chr \"h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000\"\n  .. ..$ access-control-allow-headers : chr \"Accept, Content-Type, Origin, X-Forwarded-For, X-Prototype-Version, X-Requested-With\"\n  .. ..$ access-control-allow-methods : chr \"GET, OPTIONS\"\n  .. ..$ access-control-allow-origin  : chr \"*\"\n  .. ..$ access-control-expose-headers: chr \"Content-Length, X-JSON\"\n  .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n  ..$ all_headers:List of 1\n  .. ..$ :List of 3\n  .. .. ..$ status : int 200\n  .. .. ..$ version: chr \"HTTP/1.1\"\n  .. .. ..$ headers:List of 14\n  .. .. .. ..$ date                         : chr \"Wed, 19 Feb 2025 02:24:57 GMT\"\n  .. .. .. ..$ content-type                 : chr \"application/json\"\n  .. .. .. ..$ content-length               : chr \"221487\"\n  .. .. .. ..$ connection                   : chr \"keep-alive\"\n  .. .. .. ..$ server                       : chr \"nginx\"\n  .. .. .. ..$ vary                         : chr \"Origin\"\n  .. .. .. ..$ vary                         : chr \"Access-Control-Request-Method\"\n  .. .. .. ..$ vary                         : chr \"Access-Control-Request-Headers\"\n  .. .. .. ..$ via                          : chr \"1.1 google\"\n  .. .. .. ..$ alt-svc                      : chr \"h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000\"\n  .. .. .. ..$ access-control-allow-headers : chr \"Accept, Content-Type, Origin, X-Forwarded-For, X-Prototype-Version, X-Requested-With\"\n  .. .. .. ..$ access-control-allow-methods : chr \"GET, OPTIONS\"\n  .. .. .. ..$ access-control-allow-origin  : chr \"*\"\n  .. .. .. ..$ access-control-expose-headers: chr \"Content-Length, X-JSON\"\n  .. .. .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n  ..$ cookies    :'data.frame': 0 obs. of  7 variables:\n  .. ..$ domain    : logi(0) \n  .. ..$ flag      : logi(0) \n  .. ..$ path      : logi(0) \n  .. ..$ secure    : logi(0) \n  .. ..$ expiration: 'POSIXct' num(0) \n  .. ..$ name      : logi(0) \n  .. ..$ value     : logi(0) \n  ..$ content    : raw [1:221487] 7b 22 73 74 ...\n  ..$ date       : POSIXct[1:1], format: \"2025-02-19 02:24:57\"\n  ..$ times      : Named num [1:6] 0 0.000179 0 0.00039 0.303562 ...\n  .. ..- attr(*, \"names\")= chr [1:6] \"redirect\" \"namelookup\" \"connect\" \"pretransfer\" ...\n  ..$ request    :List of 7\n  .. ..$ method    : chr \"GET\"\n  .. ..$ url       : chr \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=minnesota&page=1&sort=newest&end_date=20240101&api-ke\"| __truncated__\n  .. ..$ headers   : Named chr \"application/json, text/xml, application/xml, */*\"\n  .. .. ..- attr(*, \"names\")= chr \"Accept\"\n  .. ..$ fields    : NULL\n  .. ..$ options   :List of 2\n  .. .. ..$ useragent: chr \"libcurl/8.11.1 r-curl/6.2.0 httr/1.4.7\"\n  .. .. ..$ httpget  : logi TRUE\n  .. ..$ auth_token: NULL\n  .. ..$ output    : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"write_memory\" \"write_function\"\n  .. ..- attr(*, \"class\")= chr \"request\"\n  ..$ handle     :Class 'curl_handle' &lt;externalptr&gt; \n  ..- attr(*, \"class\")= chr \"response\"\n $ :List of 10\n  ..$ url        : chr \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=minnesota&page=2&sort=newest&end_date=20240101&api-ke\"| __truncated__\n  ..$ status_code: int 200\n  ..$ headers    :List of 14\n  .. ..$ date                         : chr \"Wed, 19 Feb 2025 02:24:59 GMT\"\n  .. ..$ content-type                 : chr \"application/json\"\n  .. ..$ content-length               : chr \"215044\"\n  .. ..$ connection                   : chr \"keep-alive\"\n  .. ..$ server                       : chr \"nginx\"\n  .. ..$ vary                         : chr \"Origin\"\n  .. ..$ vary                         : chr \"Access-Control-Request-Method\"\n  .. ..$ vary                         : chr \"Access-Control-Request-Headers\"\n  .. ..$ via                          : chr \"1.1 google\"\n  .. ..$ alt-svc                      : chr \"h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000\"\n  .. ..$ access-control-allow-headers : chr \"Accept, Content-Type, Origin, X-Forwarded-For, X-Prototype-Version, X-Requested-With\"\n  .. ..$ access-control-allow-methods : chr \"GET, OPTIONS\"\n  .. ..$ access-control-allow-origin  : chr \"*\"\n  .. ..$ access-control-expose-headers: chr \"Content-Length, X-JSON\"\n  .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n  ..$ all_headers:List of 1\n  .. ..$ :List of 3\n  .. .. ..$ status : int 200\n  .. .. ..$ version: chr \"HTTP/1.1\"\n  .. .. ..$ headers:List of 14\n  .. .. .. ..$ date                         : chr \"Wed, 19 Feb 2025 02:24:59 GMT\"\n  .. .. .. ..$ content-type                 : chr \"application/json\"\n  .. .. .. ..$ content-length               : chr \"215044\"\n  .. .. .. ..$ connection                   : chr \"keep-alive\"\n  .. .. .. ..$ server                       : chr \"nginx\"\n  .. .. .. ..$ vary                         : chr \"Origin\"\n  .. .. .. ..$ vary                         : chr \"Access-Control-Request-Method\"\n  .. .. .. ..$ vary                         : chr \"Access-Control-Request-Headers\"\n  .. .. .. ..$ via                          : chr \"1.1 google\"\n  .. .. .. ..$ alt-svc                      : chr \"h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000\"\n  .. .. .. ..$ access-control-allow-headers : chr \"Accept, Content-Type, Origin, X-Forwarded-For, X-Prototype-Version, X-Requested-With\"\n  .. .. .. ..$ access-control-allow-methods : chr \"GET, OPTIONS\"\n  .. .. .. ..$ access-control-allow-origin  : chr \"*\"\n  .. .. .. ..$ access-control-expose-headers: chr \"Content-Length, X-JSON\"\n  .. .. .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n  ..$ cookies    :'data.frame': 0 obs. of  7 variables:\n  .. ..$ domain    : logi(0) \n  .. ..$ flag      : logi(0) \n  .. ..$ path      : logi(0) \n  .. ..$ secure    : logi(0) \n  .. ..$ expiration: 'POSIXct' num(0) \n  .. ..$ name      : logi(0) \n  .. ..$ value     : logi(0) \n  ..$ content    : raw [1:215044] 7b 22 73 74 ...\n  ..$ date       : POSIXct[1:1], format: \"2025-02-19 02:24:59\"\n  ..$ times      : Named num [1:6] 0 0.000098 0 0.000211 0.336513 ...\n  .. ..- attr(*, \"names\")= chr [1:6] \"redirect\" \"namelookup\" \"connect\" \"pretransfer\" ...\n  ..$ request    :List of 7\n  .. ..$ method    : chr \"GET\"\n  .. ..$ url       : chr \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=minnesota&page=2&sort=newest&end_date=20240101&api-ke\"| __truncated__\n  .. ..$ headers   : Named chr \"application/json, text/xml, application/xml, */*\"\n  .. .. ..- attr(*, \"names\")= chr \"Accept\"\n  .. ..$ fields    : NULL\n  .. ..$ options   :List of 2\n  .. .. ..$ useragent: chr \"libcurl/8.11.1 r-curl/6.2.0 httr/1.4.7\"\n  .. .. ..$ httpget  : logi TRUE\n  .. ..$ auth_token: NULL\n  .. ..$ output    : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"write_memory\" \"write_function\"\n  .. ..- attr(*, \"class\")= chr \"request\"\n  ..$ handle     :Class 'curl_handle' &lt;externalptr&gt; \n  ..- attr(*, \"class\")= chr \"response\"\n $ :List of 10\n  ..$ url        : chr \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=minnesota&page=3&sort=newest&end_date=20240101&api-ke\"| __truncated__\n  ..$ status_code: int 200\n  ..$ headers    :List of 14\n  .. ..$ date                         : chr \"Wed, 19 Feb 2025 02:25:00 GMT\"\n  .. ..$ content-type                 : chr \"application/json\"\n  .. ..$ content-length               : chr \"219733\"\n  .. ..$ connection                   : chr \"keep-alive\"\n  .. ..$ server                       : chr \"nginx\"\n  .. ..$ vary                         : chr \"Origin\"\n  .. ..$ vary                         : chr \"Access-Control-Request-Method\"\n  .. ..$ vary                         : chr \"Access-Control-Request-Headers\"\n  .. ..$ via                          : chr \"1.1 google\"\n  .. ..$ alt-svc                      : chr \"h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000\"\n  .. ..$ access-control-allow-headers : chr \"Accept, Content-Type, Origin, X-Forwarded-For, X-Prototype-Version, X-Requested-With\"\n  .. ..$ access-control-allow-methods : chr \"GET, OPTIONS\"\n  .. ..$ access-control-allow-origin  : chr \"*\"\n  .. ..$ access-control-expose-headers: chr \"Content-Length, X-JSON\"\n  .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n  ..$ all_headers:List of 1\n  .. ..$ :List of 3\n  .. .. ..$ status : int 200\n  .. .. ..$ version: chr \"HTTP/1.1\"\n  .. .. ..$ headers:List of 14\n  .. .. .. ..$ date                         : chr \"Wed, 19 Feb 2025 02:25:00 GMT\"\n  .. .. .. ..$ content-type                 : chr \"application/json\"\n  .. .. .. ..$ content-length               : chr \"219733\"\n  .. .. .. ..$ connection                   : chr \"keep-alive\"\n  .. .. .. ..$ server                       : chr \"nginx\"\n  .. .. .. ..$ vary                         : chr \"Origin\"\n  .. .. .. ..$ vary                         : chr \"Access-Control-Request-Method\"\n  .. .. .. ..$ vary                         : chr \"Access-Control-Request-Headers\"\n  .. .. .. ..$ via                          : chr \"1.1 google\"\n  .. .. .. ..$ alt-svc                      : chr \"h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000\"\n  .. .. .. ..$ access-control-allow-headers : chr \"Accept, Content-Type, Origin, X-Forwarded-For, X-Prototype-Version, X-Requested-With\"\n  .. .. .. ..$ access-control-allow-methods : chr \"GET, OPTIONS\"\n  .. .. .. ..$ access-control-allow-origin  : chr \"*\"\n  .. .. .. ..$ access-control-expose-headers: chr \"Content-Length, X-JSON\"\n  .. .. .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n  ..$ cookies    :'data.frame': 0 obs. of  7 variables:\n  .. ..$ domain    : logi(0) \n  .. ..$ flag      : logi(0) \n  .. ..$ path      : logi(0) \n  .. ..$ secure    : logi(0) \n  .. ..$ expiration: 'POSIXct' num(0) \n  .. ..$ name      : logi(0) \n  .. ..$ value     : logi(0) \n  ..$ content    : raw [1:219733] 7b 22 73 74 ...\n  ..$ date       : POSIXct[1:1], format: \"2025-02-19 02:25:00\"\n  ..$ times      : Named num [1:6] 0 0.000084 0 0.000296 0.370724 ...\n  .. ..- attr(*, \"names\")= chr [1:6] \"redirect\" \"namelookup\" \"connect\" \"pretransfer\" ...\n  ..$ request    :List of 7\n  .. ..$ method    : chr \"GET\"\n  .. ..$ url       : chr \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=minnesota&page=3&sort=newest&end_date=20240101&api-ke\"| __truncated__\n  .. ..$ headers   : Named chr \"application/json, text/xml, application/xml, */*\"\n  .. .. ..- attr(*, \"names\")= chr \"Accept\"\n  .. ..$ fields    : NULL\n  .. ..$ options   :List of 2\n  .. .. ..$ useragent: chr \"libcurl/8.11.1 r-curl/6.2.0 httr/1.4.7\"\n  .. .. ..$ httpget  : logi TRUE\n  .. ..$ auth_token: NULL\n  .. ..$ output    : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"write_memory\" \"write_function\"\n  .. ..- attr(*, \"class\")= chr \"request\"\n  ..$ handle     :Class 'curl_handle' &lt;externalptr&gt; \n  ..- attr(*, \"class\")= chr \"response\"\n $ :List of 10\n  ..$ url        : chr \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=minnesota&page=4&sort=newest&end_date=20240101&api-ke\"| __truncated__\n  ..$ status_code: int 200\n  ..$ headers    :List of 14\n  .. ..$ date                         : chr \"Wed, 19 Feb 2025 02:25:01 GMT\"\n  .. ..$ content-type                 : chr \"application/json\"\n  .. ..$ content-length               : chr \"226154\"\n  .. ..$ connection                   : chr \"keep-alive\"\n  .. ..$ server                       : chr \"nginx\"\n  .. ..$ vary                         : chr \"Origin\"\n  .. ..$ vary                         : chr \"Access-Control-Request-Method\"\n  .. ..$ vary                         : chr \"Access-Control-Request-Headers\"\n  .. ..$ via                          : chr \"1.1 google\"\n  .. ..$ alt-svc                      : chr \"h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000\"\n  .. ..$ access-control-allow-headers : chr \"Accept, Content-Type, Origin, X-Forwarded-For, X-Prototype-Version, X-Requested-With\"\n  .. ..$ access-control-allow-methods : chr \"GET, OPTIONS\"\n  .. ..$ access-control-allow-origin  : chr \"*\"\n  .. ..$ access-control-expose-headers: chr \"Content-Length, X-JSON\"\n  .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n  ..$ all_headers:List of 1\n  .. ..$ :List of 3\n  .. .. ..$ status : int 200\n  .. .. ..$ version: chr \"HTTP/1.1\"\n  .. .. ..$ headers:List of 14\n  .. .. .. ..$ date                         : chr \"Wed, 19 Feb 2025 02:25:01 GMT\"\n  .. .. .. ..$ content-type                 : chr \"application/json\"\n  .. .. .. ..$ content-length               : chr \"226154\"\n  .. .. .. ..$ connection                   : chr \"keep-alive\"\n  .. .. .. ..$ server                       : chr \"nginx\"\n  .. .. .. ..$ vary                         : chr \"Origin\"\n  .. .. .. ..$ vary                         : chr \"Access-Control-Request-Method\"\n  .. .. .. ..$ vary                         : chr \"Access-Control-Request-Headers\"\n  .. .. .. ..$ via                          : chr \"1.1 google\"\n  .. .. .. ..$ alt-svc                      : chr \"h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000\"\n  .. .. .. ..$ access-control-allow-headers : chr \"Accept, Content-Type, Origin, X-Forwarded-For, X-Prototype-Version, X-Requested-With\"\n  .. .. .. ..$ access-control-allow-methods : chr \"GET, OPTIONS\"\n  .. .. .. ..$ access-control-allow-origin  : chr \"*\"\n  .. .. .. ..$ access-control-expose-headers: chr \"Content-Length, X-JSON\"\n  .. .. .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n  ..$ cookies    :'data.frame': 0 obs. of  7 variables:\n  .. ..$ domain    : logi(0) \n  .. ..$ flag      : logi(0) \n  .. ..$ path      : logi(0) \n  .. ..$ secure    : logi(0) \n  .. ..$ expiration: 'POSIXct' num(0) \n  .. ..$ name      : logi(0) \n  .. ..$ value     : logi(0) \n  ..$ content    : raw [1:226154] 7b 22 73 74 ...\n  ..$ date       : POSIXct[1:1], format: \"2025-02-19 02:25:01\"\n  ..$ times      : Named num [1:6] 0 0.000096 0 0.000301 0.321168 ...\n  .. ..- attr(*, \"names\")= chr [1:6] \"redirect\" \"namelookup\" \"connect\" \"pretransfer\" ...\n  ..$ request    :List of 7\n  .. ..$ method    : chr \"GET\"\n  .. ..$ url       : chr \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=minnesota&page=4&sort=newest&end_date=20240101&api-ke\"| __truncated__\n  .. ..$ headers   : Named chr \"application/json, text/xml, application/xml, */*\"\n  .. .. ..- attr(*, \"names\")= chr \"Accept\"\n  .. ..$ fields    : NULL\n  .. ..$ options   :List of 2\n  .. .. ..$ useragent: chr \"libcurl/8.11.1 r-curl/6.2.0 httr/1.4.7\"\n  .. .. ..$ httpget  : logi TRUE\n  .. ..$ auth_token: NULL\n  .. ..$ output    : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"write_memory\" \"write_function\"\n  .. ..- attr(*, \"class\")= chr \"request\"\n  ..$ handle     :Class 'curl_handle' &lt;externalptr&gt; \n  ..- attr(*, \"class\")= chr \"response\"\n - attr(*, \"class\")= chr \"search\""
  },
  {
    "objectID": "slides/19/slides19.html#convert-response-to-tibble",
    "href": "slides/19/slides19.html#convert-response-to-tibble",
    "title": "APIs",
    "section": "Convert response to tibble",
    "text": "Convert response to tibble\n\nmn_tbl &lt;- as_tibble(mn_search)\nmn_tbl\n\n# A tibble: 50 × 19\n   id             abstract byline document_type headline keywords lead_paragraph\n   &lt;chr&gt;          &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;         \n 1 nyt://article… This ye… By Ja… article       A New Y… New Yea… It’s the firs…\n 2 nyt://article… Many st… By Ad… article       New Sta… States … A spate of ne…\n 3 nyt://article… In Chil… By Ja… article       Cats Fi… Prisons… Some say they…\n 4 nyt://interac… Detaile… By Jo… multimedia    Week 17… Footbal… Detailed tabl…\n 5 nyt://article… Maine f… By Je… article       Maine J… Preside… Maine on Thur…\n 6 nyt://article… The Uni… By Ni… article       Univers… College… The chancello…\n 7 nyt://interac… Data sh… By El… multimedia    Where M… Immigra… Data shows wh…\n 8 nyt://article… Private… By Ha… article       They’re… Child L… One morning i…\n 9 nyt://article… The his… By Jo… article       The Vir… English… My partner an…\n10 nyt://article… Gator t… By Sc… article       ‘Fargo’… Televis… After eight e…\n# ℹ 40 more rows\n# ℹ 12 more variables: multimedia &lt;chr&gt;, news_desk &lt;chr&gt;, print_page &lt;chr&gt;,\n#   print_section &lt;chr&gt;, pub_date &lt;dttm&gt;, section_name &lt;chr&gt;, snippet &lt;chr&gt;,\n#   source &lt;chr&gt;, type_of_material &lt;chr&gt;, uri &lt;chr&gt;, web_url &lt;chr&gt;,\n#   word_count &lt;int&gt;"
  },
  {
    "objectID": "slides/19/slides19.html#lets-take-a-peek-at-a-couple-of-columns",
    "href": "slides/19/slides19.html#lets-take-a-peek-at-a-couple-of-columns",
    "title": "APIs",
    "section": "Let’s take a peek at a couple of columns:",
    "text": "Let’s take a peek at a couple of columns:\n\nmn_tbl %&gt;%\n  select(pub_date, headline, document_type, keywords)\n\n# A tibble: 50 × 4\n   pub_date            headline                           document_type keywords\n   &lt;dttm&gt;              &lt;chr&gt;                              &lt;chr&gt;         &lt;chr&gt;   \n 1 2024-01-01 10:57:10 A New Year’s Energy Boost          article       New Yea…\n 2 2024-01-01 08:00:30 New State Laws on Hot-Button Issu… article       States …\n 3 2023-12-31 10:02:32 Cats Filled the Prison. Then the … article       Prisons…\n 4 2023-12-30 05:08:59 Week 17 N.F.L. Playoff Picture: A… multimedia    Footbal…\n 5 2023-12-29 00:01:11 Maine Joins Colorado in Finding T… article       Preside…\n 6 2023-12-28 23:46:06 University Chancellor Fired After… article       College…\n 7 2023-12-28 10:03:05 Where Migrant Children Are Living… multimedia    Immigra…\n 8 2023-12-28 10:02:51 They’re Paid Billions to Root Out… article       Child L…\n 9 2023-12-27 20:00:02 The Virtues of Inauthenticity      article       English…\n10 2023-12-27 04:00:07 ‘Fargo’ Season 5, Episode 7: Not … article       Televis…\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/19/slides19.html#pros-of-using-an-api",
    "href": "slides/19/slides19.html#pros-of-using-an-api",
    "title": "APIs",
    "section": "Pros of using an API:",
    "text": "Pros of using an API:\n\nProvenance: we’ve accessed our data directly from the source and didn’t have to save it in a file format or open it in a different program\nReproducibility: accessing data via code allows others to reproduce our work\nCustomizability: we can generate as specific (or broad) of a dataset as we would like"
  },
  {
    "objectID": "slides/19/slides19.html#but-ive-hidden-some-steps-from-you",
    "href": "slides/19/slides19.html#but-ive-hidden-some-steps-from-you",
    "title": "APIs",
    "section": "But, I’ve hidden some steps from you",
    "text": "But, I’ve hidden some steps from you\n\nMost APIs require you to sign up for an API key\n\nThis allows the website to track who is accessing their data, how many requests they are making, how often they are making them, etc.\nMost APIs (especially if they’re free) are rate limited\n\nThe NYTimes API limits you to 500 requests per day and 5 requests per minute\nThis seems like a lot, but you can burn through them quickly when you’re not sure what you’re doing!\n\n\nIn addition to signing up for a key, we need to make sure R knows how to find it"
  },
  {
    "objectID": "slides/19/slides19.html#census-data",
    "href": "slides/19/slides19.html#census-data",
    "title": "APIs",
    "section": "Census data",
    "text": "Census data\n\nEvery ten years, the US Census Bureau runs a census of the US population. The goal is to survey everybody in the country.\nThey also run the American Community Survey, which tracks demographic indicators among a random sample of people every 1, 3, or 5 years\nThey also collect a variety of other data:\n\nPSEO\nHousehold pulse survey\nHealth insurance, poverty statistics, business owners, etc.\n\n\n\n\nImportantly, the data is paid for by the public (via taxes) and is available for use by the public"
  },
  {
    "objectID": "slides/19/slides19.html#section",
    "href": "slides/19/slides19.html#section",
    "title": "APIs",
    "section": "",
    "text": "R functions for accessing some census data\nIncludes geospatial information for mapping\nDesigned to work within the tidyverse ecosystem\n\n\ninstall.packages(\"tidycensus\")\nlibrary(tidycensus)"
  },
  {
    "objectID": "slides/19/slides19.html#example-call",
    "href": "slides/19/slides19.html#example-call",
    "title": "APIs",
    "section": "Example call",
    "text": "Example call\n\nacs_mn_2020 &lt;- tidycensus::get_acs(\n    year = 2020,\n    state = \"MN\",\n    geography = \"tract\",\n    variables = c(\"B01003_001\", \"B19013_001\"),\n    output = \"wide\",\n    geometry = TRUE\n)"
  },
  {
    "objectID": "slides/19/slides19.html#storing-your-api-key",
    "href": "slides/19/slides19.html#storing-your-api-key",
    "title": "APIs",
    "section": "Storing your API key",
    "text": "Storing your API key\n\n\nCreate a new text file in the same folder as your .rmd\nCopy and paste your census key into the empty file\nSave the file as census_api_key.txt\n\n\n\nRead in the key with the following code:\n\nmy_key &lt;- readLines(\"census_api_key.txt\")\n\nand tell tidycensus what your API key is with:\n\ncensus_api_key(my_key)\n\nDo not commit and push census_api_key.txt to github"
  },
  {
    "objectID": "slides/19/slides19.html#example-call-1",
    "href": "slides/19/slides19.html#example-call-1",
    "title": "APIs",
    "section": "Example call",
    "text": "Example call\n\n\n\nacs_mn_2020 &lt;- tidycensus::get_acs(\n    year = 2020,\n    state = \"MN\",\n    geography = \"tract\",\n    variables = c(\"B01003_001\", \"B19013_001\"),\n    output = \"wide\",\n    geometry = TRUE\n)\n\n\n\n\ngeography = \"tract\": What level of detail to get summary statistics. Other options include “state”, “county”, “combined statistical area”, etc.\n\nvariables = c(\"B01003_001\", \"B19013_001\"): Which survey questions should we get responses to?"
  },
  {
    "objectID": "slides/19/slides19.html#searching-for-variables",
    "href": "slides/19/slides19.html#searching-for-variables",
    "title": "APIs",
    "section": "Searching for variables",
    "text": "Searching for variables\nGetting variables from the Census or ACS requires knowing the variable ID - and there are thousands of these IDs across the different Census files.\n\n\nacs_vars &lt;- load_variables(2020, \"acs5\", cache = TRUE) \nacs_vars \n\n# A tibble: 27,850 × 4\n   name        label                                    concept        geography\n   &lt;chr&gt;       &lt;chr&gt;                                    &lt;chr&gt;          &lt;chr&gt;    \n 1 B01001A_001 Estimate!!Total:                         SEX BY AGE (W… tract    \n 2 B01001A_002 Estimate!!Total:!!Male:                  SEX BY AGE (W… tract    \n 3 B01001A_003 Estimate!!Total:!!Male:!!Under 5 years   SEX BY AGE (W… tract    \n 4 B01001A_004 Estimate!!Total:!!Male:!!5 to 9 years    SEX BY AGE (W… tract    \n 5 B01001A_005 Estimate!!Total:!!Male:!!10 to 14 years  SEX BY AGE (W… tract    \n 6 B01001A_006 Estimate!!Total:!!Male:!!15 to 17 years  SEX BY AGE (W… tract    \n 7 B01001A_007 Estimate!!Total:!!Male:!!18 and 19 years SEX BY AGE (W… tract    \n 8 B01001A_008 Estimate!!Total:!!Male:!!20 to 24 years  SEX BY AGE (W… tract    \n 9 B01001A_009 Estimate!!Total:!!Male:!!25 to 29 years  SEX BY AGE (W… tract    \n10 B01001A_010 Estimate!!Total:!!Male:!!30 to 34 years  SEX BY AGE (W… tract    \n# ℹ 27,840 more rows"
  },
  {
    "objectID": "slides/19/slides19.html#the-two-we-used-were",
    "href": "slides/19/slides19.html#the-two-we-used-were",
    "title": "APIs",
    "section": "The two we used were:",
    "text": "The two we used were:\n\nacs_vars %&gt;%\n  filter(name %in% c(\"B01003_001\", \"B19013_001\"))\n\n# A tibble: 2 × 4\n  name       label                                             concept geography\n  &lt;chr&gt;      &lt;chr&gt;                                             &lt;chr&gt;   &lt;chr&gt;    \n1 B01003_001 Estimate!!Total                                   TOTAL … block gr…\n2 B19013_001 Estimate!!Median household income in the past 12… MEDIAN… block gr…"
  },
  {
    "objectID": "slides/19/slides19.html#but-we-could-search-for-other-variables-using-label",
    "href": "slides/19/slides19.html#but-we-could-search-for-other-variables-using-label",
    "title": "APIs",
    "section": "But we could search for other variables using label\n",
    "text": "But we could search for other variables using label\n\n\nacs_vars %&gt;%\n  filter(str_detect(label, \"degree\"))\n\n# A tibble: 345 × 4\n   name         label                                          concept geography\n   &lt;chr&gt;        &lt;chr&gt;                                          &lt;chr&gt;   &lt;chr&gt;    \n 1 B06009PR_004 Estimate!!Total:!!Some college or associate's… PLACE … &lt;NA&gt;     \n 2 B06009PR_005 Estimate!!Total:!!Bachelor's degree            PLACE … &lt;NA&gt;     \n 3 B06009PR_006 Estimate!!Total:!!Graduate or professional de… PLACE … &lt;NA&gt;     \n 4 B06009PR_010 Estimate!!Total:!!Born in Puerto Rico:!!Some … PLACE … &lt;NA&gt;     \n 5 B06009PR_011 Estimate!!Total:!!Born in Puerto Rico:!!Bache… PLACE … &lt;NA&gt;     \n 6 B06009PR_012 Estimate!!Total:!!Born in Puerto Rico:!!Gradu… PLACE … &lt;NA&gt;     \n 7 B06009PR_016 Estimate!!Total:!!Born in the United States:!… PLACE … &lt;NA&gt;     \n 8 B06009PR_017 Estimate!!Total:!!Born in the United States:!… PLACE … &lt;NA&gt;     \n 9 B06009PR_018 Estimate!!Total:!!Born in the United States:!… PLACE … &lt;NA&gt;     \n10 B06009PR_022 Estimate!!Total:!!Native; born elsewhere:!!So… PLACE … &lt;NA&gt;     \n# ℹ 335 more rows"
  },
  {
    "objectID": "slides/19/slides19.html#your-turn",
    "href": "slides/19/slides19.html#your-turn",
    "title": "APIs",
    "section": "Your turn",
    "text": "Your turn\n\nacs_vars &lt;- load_variables(2020, \"acs5\", cache = TRUE) \n\n\n\nSearch for two new variables using load_variables (Can you explain what they are?)\nRun another call to tidycensus::get_acs using your two variables\n\n\n\ncountdown(5)\n\n\n\n−&plus;\n\n05:00"
  },
  {
    "objectID": "slides/19/slides19.html#whats-going-on-behind-the-scenes-with-get_acs",
    "href": "slides/19/slides19.html#whats-going-on-behind-the-scenes-with-get_acs",
    "title": "APIs",
    "section": "What’s going on behind the scenes with get_acs?",
    "text": "What’s going on behind the scenes with get_acs?\nLet’s take a peek at the census API user guide. There’s a menu option for “Example API Queries”. We’ll talk through the ACS Example.\n\n“E” means Estimate, “M” means “Margin of Error”\n“PE” means Percentage Estimate, “PM” means “Percentage Margin of Error”"
  },
  {
    "objectID": "slides/19/slides19.html#example-the-total-number-of-hmong-people-living-in-each-u.s.-state",
    "href": "slides/19/slides19.html#example-the-total-number-of-hmong-people-living-in-each-u.s.-state",
    "title": "APIs",
    "section": "Example: the total number of Hmong people living in each U.S. state",
    "text": "Example: the total number of Hmong people living in each U.S. state\nAPI Query: https://api.census.gov/data/2019/acs/acs1?get=NAME,B02015_009E,B02015_009M‌&for=state:*\nThis URL-looking-thing communicates to the Census API exactly the search terms we want in the data it returns to us"
  },
  {
    "objectID": "slides/19/slides19.html#lets-break-it-down",
    "href": "slides/19/slides19.html#lets-break-it-down",
    "title": "APIs",
    "section": "Let’s break it down:",
    "text": "Let’s break it down:\n\nHost name: https://api.census.gov/data\nYear: https://api.census.gov/data/2019\n\nDataset name: https://api.census.gov/data/2019/acs/acs1\n\n“get” https://api.census.gov/data/2019/acs/acs1?get=\n\nVariables to get: https://api.census.gov/data/2019/acs/acs1?get=NAME,B02015_009E,B02015_009M\n\nGet variables that are NAMEd B02015_009E (total number of Hmong people) and B02015_009E (corresponding margin of error)\n\n\nGeographies to use: https://api.census.gov/data/2019/acs/acs1?get=NAME,B02015_009E,B02015_009M&for=state: *\n\n& separates variables from geographies\nstate:* means “all states”"
  },
  {
    "objectID": "slides/19/slides19.html#section-1",
    "href": "slides/19/slides19.html#section-1",
    "title": "APIs",
    "section": "",
    "text": "“hitter2”\nallows us to send “queries” to any API via R\n\n\ninstall.packages(\"httr2\")\nlibrary(httr2)"
  },
  {
    "objectID": "slides/19/slides19.html#sending-our-census-query",
    "href": "slides/19/slides19.html#sending-our-census-query",
    "title": "APIs",
    "section": "Sending our census query",
    "text": "Sending our census query\n\nhmong_state_request &lt;- request(\"https://api.census.gov/data\") %&gt;% \n    req_url_path_append(\"2019\") %&gt;% \n    req_url_path_append(\"acs\") %&gt;% \n    req_url_path_append(\"acs1\") %&gt;% \n    req_url_query(get = c(\"NAME\", \"B02015_009E\", \"B02015_009M\"), `for` = I(\"state:*\"), key = census_api_key, .multi = \"comma\")\n\nrequest sets the host name"
  },
  {
    "objectID": "slides/19/slides19.html#sending-our-census-query-1",
    "href": "slides/19/slides19.html#sending-our-census-query-1",
    "title": "APIs",
    "section": "Sending our census query",
    "text": "Sending our census query\n\nhmong_state_request &lt;- request(\"https://api.census.gov/data\") %&gt;% \n    req_url_path_append(\"2019\") %&gt;% \n    req_url_path_append(\"acs\") %&gt;% \n    req_url_path_append(\"acs1\") %&gt;% \n    req_url_query(get = c(\"NAME\", \"B02015_009E\", \"B02015_009M\"), `for` = I(\"state:*\"), key = census_api_key, .multi = \"comma\")\n\nreq_url_path_append adds the year and dataset that we are trying to access"
  },
  {
    "objectID": "slides/19/slides19.html#sending-our-census-query-2",
    "href": "slides/19/slides19.html#sending-our-census-query-2",
    "title": "APIs",
    "section": "Sending our census query",
    "text": "Sending our census query\n\nhmong_state_request &lt;- request(\"https://api.census.gov/data\") %&gt;% \n    req_url_path_append(\"2019\") %&gt;% \n    req_url_path_append(\"acs\") %&gt;% \n    req_url_path_append(\"acs1\") %&gt;% \n    req_url_query(get = c(\"NAME\", \"B02015_009E\", \"B02015_009M\"), \n                  `for` = I(\"state:*\"), \n                  key = census_api_key, \n                  .multi = \"comma\")\n\nreq_url_query is where we specify what to return:\n\nThe .multi argument controls how multiple values for a given key are combined.\nThe I() function around \"state:*\" inhibits parsing of special characters like : and *. (It’s known as the “as-is” function.)\nThe backticks around for are needed because for is a reserved word in R (for for-loops). You’ll need backticks whenever the key name has special characters (like spaces, dashes).\nWe also tell the census what our API key is"
  },
  {
    "objectID": "slides/19/slides19.html#results-in-a-httr2_request",
    "href": "slides/19/slides19.html#results-in-a-httr2_request",
    "title": "APIs",
    "section": "Results in a <httr2_request>\n",
    "text": "Results in a &lt;httr2_request&gt;\n\n\nhmong_state_request\n\n&lt;httr2_request&gt;\nGET\nhttps://api.census.gov/data/2019/acs/acs1?get=NAME,B02015_009E,B02015_009M&for=state:*&key=4a2344XXXXXXXXXXXXXXXXXXXXXXXXXXXXX\nBody: empty"
  },
  {
    "objectID": "slides/19/slides19.html#why-on-earth-would-we-do-this-instead-of-using-the-url",
    "href": "slides/19/slides19.html#why-on-earth-would-we-do-this-instead-of-using-the-url",
    "title": "APIs",
    "section": "Why on earth would we do this instead of using the URL",
    "text": "Why on earth would we do this instead of using the URL\n\nTo generalize the code with functions (this is what wrapper packages do!)\nTo handle special characters (URLs can’t contain spaces)\nTo iterate over multiple years, or multiple geometries, or …."
  },
  {
    "objectID": "slides/19/slides19.html#actually-getting-the-data",
    "href": "slides/19/slides19.html#actually-getting-the-data",
    "title": "APIs",
    "section": "Actually getting the data",
    "text": "Actually getting the data\n\nhmong_state_response &lt;- req_perform(hmong_state_request)\nhmong_state_response\n\n&lt;httr2_response&gt;\nGET\nhttps://api.census.gov/data/2019/acs/acs1?get=NAME,B02015_009E,B02015_009M&for=state:*&key=4a2344XXXXXXXXXXXXXXXXXXXXXXXXXXXXX\nStatus: 200 OK\nContent-Type: application/json\nBody: In memory (1691 bytes)"
  },
  {
    "objectID": "slides/19/slides19.html#actually-getting-the-data-in-the-form-we-can-work-with",
    "href": "slides/19/slides19.html#actually-getting-the-data-in-the-form-we-can-work-with",
    "title": "APIs",
    "section": "Actually getting the data in the form we can work with",
    "text": "Actually getting the data in the form we can work with\n\nhmong_state_tbl &lt;- hmong_state_response %&gt;%\n  resp_body_json(simplifyVector = TRUE) %&gt;%\n  janitor::row_to_names(1) %&gt;%\n  as_tibble()\n\nhmong_state_tbl\n\n# A tibble: 52 × 4\n   NAME      B02015_009E B02015_009M state\n   &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt;\n 1 Illinois  655         511         17   \n 2 Georgia   3162        1336        13   \n 3 Idaho     &lt;NA&gt;        &lt;NA&gt;        16   \n 4 Hawaii    56          92          15   \n 5 Indiana   1344        1198        18   \n 6 Iowa      685         705         19   \n 7 Kansas    2189        1177        20   \n 8 Kentucky  530         503         21   \n 9 Louisiana 0           224         22   \n10 Maine     &lt;NA&gt;        &lt;NA&gt;        23   \n# ℹ 42 more rows"
  },
  {
    "objectID": "slides/19/slides19.html#your-turn-1",
    "href": "slides/19/slides19.html#your-turn-1",
    "title": "APIs",
    "section": "Your turn",
    "text": "Your turn\n\n\nEdit the httr code to access a new variable of your choice\nMake a httr request to access the 1-year ACS data from 2018, 2019, 2021, and 2022. Make sure to save your results from each call!\nCombine all years into a single dataset\nMake a time series plot with your chosen variable on the y-axis, year on the x-axis, colored by state.\n\nYou may want to first filter to only a few states\nYou will need to do some cleaning of the data"
  },
  {
    "objectID": "slides/19/slides19.html#neat-wrapper-packages-or-apis",
    "href": "slides/19/slides19.html#neat-wrapper-packages-or-apis",
    "title": "APIs",
    "section": "Neat Wrapper packages or APIs",
    "text": "Neat Wrapper packages or APIs\n\n\nSportsDataverse has a ton of R packages for accessing a variety of sports data\nPublic APIs\n\nUrban Institute’s Education Data Portal and R package\n\nROpenSci"
  },
  {
    "objectID": "slides/19/slides19.html#creditsfurther-resources",
    "href": "slides/19/slides19.html#creditsfurther-resources",
    "title": "APIs",
    "section": "Credits/Further resources",
    "text": "Credits/Further resources\n\nJenny Bryan’s Stat545\nLeslie Myint’s Stat/Comp 212\nCensus API User Guide\nTidyCensus vignette"
  },
  {
    "objectID": "slides/07/slides07.html#dplyr",
    "href": "slides/07/slides07.html#dplyr",
    "title": "Data Wrangling: Verbs",
    "section": "{dplyr}",
    "text": "{dplyr}\n\n\n\nA package that transforms data\nImplements a grammar of transforming tabular data\nPart of the tidyverse"
  },
  {
    "objectID": "slides/07/slides07.html#warm-up",
    "href": "slides/07/slides07.html#warm-up",
    "title": "Data Wrangling: Verbs",
    "section": "Warm up",
    "text": "Warm up\n\nWith your neighbors, identify the data verb (function) that does the following:\n\nPicks rows by their values\nReorders the rows\nPicks variables by their names\nCreates new variables with functions of existing variables\n\n\n\n\n\n−+\n02:30"
  },
  {
    "objectID": "slides/07/slides07.html#logical-tests",
    "href": "slides/07/slides07.html#logical-tests",
    "title": "Data Wrangling: Verbs",
    "section": "Logical tests",
    "text": "Logical tests\n\n\nFor help:\n?Comparison\n\n\n\n\nSyntax\nDescription\n\n\n\n\nx &lt; y\nless than\n\n\nx &gt; y\ngreater than\n\n\nx &lt;= y\nless than or equal to\n\n\nx &gt;= y\ngreater than or equal to\n\n\nx == y\nequal to\n\n\nx != y\nnot equal to\n\n\nx %in% y\ngroup membership\n\n\nis.na(x)\nis NA (missing)\n\n\n!is.na(x)\nis not NA"
  },
  {
    "objectID": "slides/07/slides07.html#your-turn",
    "href": "slides/07/slides07.html#your-turn",
    "title": "Data Wrangling: Verbs",
    "section": "Your turn:",
    "text": "Your turn:\n\nWith your neighbors, use filter() to wrangle the nycflights23::flights data frame.\n\nFind all flights that had an arrival delay of two or more hours.\nFind all flights to MSP\nFind all flights that arrived more than two hours late, but left less than one hour late\n(if time) Find all flights that were delayed by at least an hour, but made up over 30 minutes in flight.\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/07/slides07.html#slice.data-...",
    "href": "slides/07/slides07.html#slice.data-...",
    "title": "Data Wrangling: Verbs",
    "section": "slice(.data, ...)",
    "text": "slice(.data, ...)\nExtract (omit) rows by row number"
  },
  {
    "objectID": "slides/07/slides07.html#slicing-flights-data",
    "href": "slides/07/slides07.html#slicing-flights-data",
    "title": "Data Wrangling: Verbs",
    "section": "Slicing flights data",
    "text": "Slicing flights data\nExtracting rows 10 to 20\n\nslice(flights, 10:20)\n\n# A tibble: 11 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1      547            545         2      845            852\n 2  2023     1     1      549            559       -10      905            901\n 3  2023     1     1      551            600        -9      846            859\n 4  2023     1     1      552            559        -7      857            911\n 5  2023     1     1      554            600        -6      914            920\n 6  2023     1     1      554            600        -6      725            735\n 7  2023     1     1      558            605        -7      719            750\n 8  2023     1     1      600            600         0      729            752\n 9  2023     1     1      600            600         0      745            755\n10  2023     1     1      600            600         0      810            840\n11  2023     1     1      603            605        -2      800            818\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#slicing-flights-data-1",
    "href": "slides/07/slides07.html#slicing-flights-data-1",
    "title": "Data Wrangling: Verbs",
    "section": "Slicing flights data",
    "text": "Slicing flights data\nOmitting rows 100 to 1000\n\nslice(flights, -c(100:1000))\n\n# A tibble: 434,451 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1        1           2038       203      328              3\n 2  2023     1     1       18           2300        78      228            135\n 3  2023     1     1       31           2344        47      500            426\n 4  2023     1     1       33           2140       173      238           2352\n 5  2023     1     1       36           2048       228      223           2252\n 6  2023     1     1      503            500         3      808            815\n 7  2023     1     1      520            510        10      948            949\n 8  2023     1     1      524            530        -6      645            710\n 9  2023     1     1      537            520        17      926            818\n10  2023     1     1      547            545         2      845            852\n# ℹ 434,441 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#select",
    "href": "slides/07/slides07.html#select",
    "title": "Data Wrangling: Verbs",
    "section": "select()",
    "text": "select()\nExtract columns by name or number\n\nselect(.data, ...)\n\n\n\n\nSource: software carpentry"
  },
  {
    "objectID": "slides/07/slides07.html#storms-data",
    "href": "slides/07/slides07.html#storms-data",
    "title": "Data Wrangling: Verbs",
    "section": "Storms data",
    "text": "Storms data\n\nglimpse(storms)\n\nRows: 19,537\nColumns: 13\n$ name                         &lt;chr&gt; \"Amy\", \"Amy\", \"Amy\", \"Amy\", \"Amy\", \"Amy\",…\n$ year                         &lt;dbl&gt; 1975, 1975, 1975, 1975, 1975, 1975, 1975,…\n$ month                        &lt;dbl&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,…\n$ day                          &lt;int&gt; 27, 27, 27, 27, 28, 28, 28, 28, 29, 29, 2…\n$ hour                         &lt;dbl&gt; 0, 6, 12, 18, 0, 6, 12, 18, 0, 6, 12, 18,…\n$ lat                          &lt;dbl&gt; 27.5, 28.5, 29.5, 30.5, 31.5, 32.4, 33.3,…\n$ long                         &lt;dbl&gt; -79.0, -79.0, -79.0, -79.0, -78.8, -78.7,…\n$ status                       &lt;fct&gt; tropical depression, tropical depression,…\n$ category                     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wind                         &lt;int&gt; 25, 25, 25, 25, 25, 25, 25, 30, 35, 40, 4…\n$ pressure                     &lt;int&gt; 1013, 1013, 1013, 1013, 1012, 1012, 1011,…\n$ tropicalstorm_force_diameter &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ hurricane_force_diameter     &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\n\n\nSubset of the NOAA Atlantic hurricane database best track data, https://www.nhc.noaa.gov/data/#hurda"
  },
  {
    "objectID": "slides/07/slides07.html#select-helpers",
    "href": "slides/07/slides07.html#select-helpers",
    "title": "Data Wrangling: Verbs",
    "section": "select() helpers",
    "text": "select() helpers\n\n:-starts_with()ends_with()contains()\n\n\nselect range of columns\n\nselect(storms, status:pressure)\n\n# A tibble: 19,537 × 4\n   status              category  wind pressure\n   &lt;fct&gt;                  &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 tropical depression       NA    25     1013\n 2 tropical depression       NA    25     1013\n 3 tropical depression       NA    25     1013\n 4 tropical depression       NA    25     1013\n 5 tropical depression       NA    25     1012\n 6 tropical depression       NA    25     1012\n 7 tropical depression       NA    25     1011\n 8 tropical depression       NA    30     1006\n 9 tropical storm            NA    35     1004\n10 tropical storm            NA    40     1002\n# ℹ 19,527 more rows\n\n\n\n\nselect every column but\n\nselect(storms, -c(status, pressure))\n\n# A tibble: 19,537 × 11\n   name   year month   day  hour   lat  long category  wind\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;\n 1 Amy    1975     6    27     0  27.5 -79         NA    25\n 2 Amy    1975     6    27     6  28.5 -79         NA    25\n 3 Amy    1975     6    27    12  29.5 -79         NA    25\n 4 Amy    1975     6    27    18  30.5 -79         NA    25\n 5 Amy    1975     6    28     0  31.5 -78.8       NA    25\n 6 Amy    1975     6    28     6  32.4 -78.7       NA    25\n 7 Amy    1975     6    28    12  33.3 -78         NA    25\n 8 Amy    1975     6    28    18  34   -77         NA    30\n 9 Amy    1975     6    29     0  34.4 -75.8       NA    35\n10 Amy    1975     6    29     6  34   -74.8       NA    40\n# ℹ 19,527 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;\n\n\n\n\nselect columns that start with…\n\nselect(storms, starts_with(\"w\"))\n\n# A tibble: 19,537 × 1\n    wind\n   &lt;int&gt;\n 1    25\n 2    25\n 3    25\n 4    25\n 5    25\n 6    25\n 7    25\n 8    30\n 9    35\n10    40\n# ℹ 19,527 more rows\n\n\n\n\nselect columns that end with…\n\nselect(storms, ends_with(\"e\"))\n\n# A tibble: 19,537 × 2\n   name  pressure\n   &lt;chr&gt;    &lt;int&gt;\n 1 Amy       1013\n 2 Amy       1013\n 3 Amy       1013\n 4 Amy       1013\n 5 Amy       1012\n 6 Amy       1012\n 7 Amy       1011\n 8 Amy       1006\n 9 Amy       1004\n10 Amy       1002\n# ℹ 19,527 more rows\n\n\n\n\nselect columns whose names contain…\n\nselect(storms, contains(\"d\"))\n\n# A tibble: 19,537 × 4\n     day  wind tropicalstorm_force_diameter hurricane_force_diameter\n   &lt;int&gt; &lt;int&gt;                        &lt;int&gt;                    &lt;int&gt;\n 1    27    25                           NA                       NA\n 2    27    25                           NA                       NA\n 3    27    25                           NA                       NA\n 4    27    25                           NA                       NA\n 5    28    25                           NA                       NA\n 6    28    25                           NA                       NA\n 7    28    25                           NA                       NA\n 8    28    30                           NA                       NA\n 9    29    35                           NA                       NA\n10    29    40                           NA                       NA\n# ℹ 19,527 more rows"
  },
  {
    "objectID": "slides/07/slides07.html#try-it",
    "href": "slides/07/slides07.html#try-it",
    "title": "Data Wrangling: Verbs",
    "section": "Try it:",
    "text": "Try it:\n\nBrainstorm as many ways as possible to select() the following columns from flight:\n\ndep_time\ndep_delay\narr_time\narr_delay\n\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/07/slides07.html#arrange",
    "href": "slides/07/slides07.html#arrange",
    "title": "Data Wrangling: Verbs",
    "section": "arrange()",
    "text": "arrange()\nOrder rows from smallest to largest"
  },
  {
    "objectID": "slides/07/slides07.html#arranging-by-wind-speed",
    "href": "slides/07/slides07.html#arranging-by-wind-speed",
    "title": "Data Wrangling: Verbs",
    "section": "Arranging by wind speed",
    "text": "Arranging by wind speed\nBy default, arrange orders in ascending order\n\nOriginal DataAscendingDescending\n\n\n\nstorms\n\n# A tibble: 19,537 × 13\n   name   year month   day  hour   lat  long status      category  wind pressure\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;          &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Amy    1975     6    27     0  27.5 -79   tropical d…       NA    25     1013\n 2 Amy    1975     6    27     6  28.5 -79   tropical d…       NA    25     1013\n 3 Amy    1975     6    27    12  29.5 -79   tropical d…       NA    25     1013\n 4 Amy    1975     6    27    18  30.5 -79   tropical d…       NA    25     1013\n 5 Amy    1975     6    28     0  31.5 -78.8 tropical d…       NA    25     1012\n 6 Amy    1975     6    28     6  32.4 -78.7 tropical d…       NA    25     1012\n 7 Amy    1975     6    28    12  33.3 -78   tropical d…       NA    25     1011\n 8 Amy    1975     6    28    18  34   -77   tropical d…       NA    30     1006\n 9 Amy    1975     6    29     0  34.4 -75.8 tropical s…       NA    35     1004\n10 Amy    1975     6    29     6  34   -74.8 tropical s…       NA    40     1002\n# ℹ 19,527 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;\n\n\n\n\n\narrange(storms, wind)\n\n# A tibble: 19,537 × 13\n   name      year month   day  hour   lat  long status   category  wind pressure\n   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Bonnie    1986     6    28     6  36.5 -91.3 tropica…       NA    10     1013\n 2 Bonnie    1986     6    28    12  37.2 -90   tropica…       NA    10     1012\n 3 Charley   1986     8    13    12  30.1 -84   subtrop…       NA    10     1009\n 4 Charley   1986     8    13    18  30.8 -84   subtrop…       NA    10     1012\n 5 Charley   1986     8    14     0  31.4 -83.6 subtrop…       NA    10     1013\n 6 Charley   1986     8    14     6  32   -83.1 subtrop…       NA    10     1014\n 7 Charley   1986     8    14    12  32.5 -82.5 subtrop…       NA    10     1015\n 8 Charley   1986     8    14    18  32.4 -82   subtrop…       NA    10     1015\n 9 AL031987  1987     8    16    18  30.9 -83.2 tropica…       NA    10     1014\n10 AL031987  1987     8    17     0  31.4 -82.9 tropica…       NA    10     1015\n# ℹ 19,527 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;\n\n\n\n\n\narrange(storms, desc(wind))\n\n# A tibble: 19,537 × 13\n   name     year month   day  hour   lat  long status    category  wind pressure\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;        &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Allen    1980     8     7    18  21.8 -86.4 hurricane        5   165      899\n 2 Gilbert  1988     9    14     0  19.7 -83.8 hurricane        5   160      888\n 3 Wilma    2005    10    19    12  17.3 -82.8 hurricane        5   160      882\n 4 Dorian   2019     9     1    16  26.5 -77   hurricane        5   160      910\n 5 Dorian   2019     9     1    18  26.5 -77.1 hurricane        5   160      910\n 6 Allen    1980     8     5    12  15.9 -70.5 hurricane        5   155      932\n 7 Allen    1980     8     7    12  21   -84.8 hurricane        5   155      910\n 8 Allen    1980     8     8     0  22.2 -87.9 hurricane        5   155      920\n 9 Allen    1980     8     9     6  25   -94.2 hurricane        5   155      909\n10 Gilbert  1988     9    14     6  19.9 -85.3 hurricane        5   155      889\n# ℹ 19,527 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#try-it-1",
    "href": "slides/07/slides07.html#try-it-1",
    "title": "Data Wrangling: Verbs",
    "section": "Try it:",
    "text": "Try it:\n\nUse arrange to answer the following questions:\n\nWhich flights traveled the farthest?\nWhich traveled the shortest?\nWhich flights lasted the longest?\nWhich lasted the shortest?\n\n\n\n\n\n−+\n02:30"
  },
  {
    "objectID": "slides/07/slides07.html#section-3",
    "href": "slides/07/slides07.html#section-3",
    "title": "Data Wrangling: Verbs",
    "section": "",
    "text": "slice_min(.data, order_by, n)\nselect rows with n smallest values of a variable\nslice_max(.data, order_by, n)\nselect rows with n largest values of a variable"
  },
  {
    "objectID": "slides/07/slides07.html#continuing-storms-example",
    "href": "slides/07/slides07.html#continuing-storms-example",
    "title": "Data Wrangling: Verbs",
    "section": "Continuing storms example",
    "text": "Continuing storms example\n\nslice_maxslice_min\n\n\nExtracting storms with 3 highest wind speeds\n\nslice_max(storms, wind, n = 3)\n\n# A tibble: 5 × 13\n  name     year month   day  hour   lat  long status    category  wind pressure\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;        &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n1 Allen    1980     8     7    18  21.8 -86.4 hurricane        5   165      899\n2 Gilbert  1988     9    14     0  19.7 -83.8 hurricane        5   160      888\n3 Wilma    2005    10    19    12  17.3 -82.8 hurricane        5   160      882\n4 Dorian   2019     9     1    16  26.5 -77   hurricane        5   160      910\n5 Dorian   2019     9     1    18  26.5 -77.1 hurricane        5   160      910\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;\n\n\n\n\nExtracting storms with the lowest wind speed\n\nslice_min(storms, wind, n = 1)\n\n# A tibble: 61 × 13\n   name      year month   day  hour   lat  long status   category  wind pressure\n   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Bonnie    1986     6    28     6  36.5 -91.3 tropica…       NA    10     1013\n 2 Bonnie    1986     6    28    12  37.2 -90   tropica…       NA    10     1012\n 3 Charley   1986     8    13    12  30.1 -84   subtrop…       NA    10     1009\n 4 Charley   1986     8    13    18  30.8 -84   subtrop…       NA    10     1012\n 5 Charley   1986     8    14     0  31.4 -83.6 subtrop…       NA    10     1013\n 6 Charley   1986     8    14     6  32   -83.1 subtrop…       NA    10     1014\n 7 Charley   1986     8    14    12  32.5 -82.5 subtrop…       NA    10     1015\n 8 Charley   1986     8    14    18  32.4 -82   subtrop…       NA    10     1015\n 9 AL031987  1987     8    16    18  30.9 -83.2 tropica…       NA    10     1014\n10 AL031987  1987     8    17     0  31.4 -82.9 tropica…       NA    10     1015\n# ℹ 51 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#star-wars-character-bmi",
    "href": "slides/07/slides07.html#star-wars-character-bmi",
    "title": "Data Wrangling: Verbs",
    "section": "Star Wars character BMI",
    "text": "Star Wars character BMI\n{dplyr} includes a starwars data frame with characteristics of 87 Star Wars characters\n\nglimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"A New Hope\", \"The Empire Strikes Back\", \"Return of the J…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…"
  },
  {
    "objectID": "slides/07/slides07.html#star-wars-character-bmi-1",
    "href": "slides/07/slides07.html#star-wars-character-bmi-1",
    "title": "Data Wrangling: Verbs",
    "section": "Star Wars character BMI",
    "text": "Star Wars character BMI\nSuppose we want to calculate the BMI for each character, \\(\\text{BMI} = \\dfrac{\\text{mass (kg)}}{\\text{height (m)}^2}\\)\n\nstarwars &lt;- mutate(starwars, bmi = mass / (height / 100)^2)\n\n\nselect(starwars, name, bmi, everything())\n\n# A tibble: 87 × 15\n   name        bmi height  mass hair_color skin_color eye_color birth_year sex  \n   &lt;chr&gt;     &lt;dbl&gt;  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;\n 1 Luke Sky…  26.0    172    77 blond      fair       blue            19   male \n 2 C-3PO      26.9    167    75 &lt;NA&gt;       gold       yellow         112   none \n 3 R2-D2      34.7     96    32 &lt;NA&gt;       white, bl… red             33   none \n 4 Darth Va…  33.3    202   136 none       white      yellow          41.9 male \n 5 Leia Org…  21.8    150    49 brown      light      brown           19   fema…\n 6 Owen Lars  37.9    178   120 brown, gr… light      blue            52   male \n 7 Beru Whi…  27.5    165    75 brown      light      blue            47   fema…\n 8 R5-D4      34.0     97    32 &lt;NA&gt;       white, red red             NA   none \n 9 Biggs Da…  25.1    183    84 black      light      brown           24   male \n10 Obi-Wan …  23.2    182    77 auburn, w… fair       blue-gray       57   male \n# ℹ 77 more rows\n# ℹ 6 more variables: gender &lt;chr&gt;, homeworld &lt;chr&gt;, species &lt;chr&gt;,\n#   films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#try-it-2",
    "href": "slides/07/slides07.html#try-it-2",
    "title": "Data Wrangling: Verbs",
    "section": "Try it",
    "text": "Try it\n\nCreate a new column in flights giving the average speed of the flight while it was in the air. What are the units of this variable? Make the variable in terms of miles per hour.\n\n\n\n\n−+\n02:30"
  },
  {
    "objectID": "slides/07/slides07.html#example",
    "href": "slides/07/slides07.html#example",
    "title": "Data Wrangling: Verbs",
    "section": "Example",
    "text": "Example\nThe Federal Aviation Administration (FAA) considers a flight to be delayed when it is 15 minutes later than its scheduled time.\n\nflights &lt;- mutate(\n  flights, \n  delayed = case_when(\n    dep_delay &gt;= 15 ~ \"Delayed\", \n    dep_delay &lt; 15 ~ \"On time\",\n    .default = \"other\")\n)"
  },
  {
    "objectID": "slides/07/slides07.html#your-turn-1",
    "href": "slides/07/slides07.html#your-turn-1",
    "title": "Data Wrangling: Verbs",
    "section": "Your turn",
    "text": "Your turn\n\nSuppose that you don’t think the FAA gives enough information in their definition of a delayed flight, so you come up with the following delay categories:\n\ndep_delay &lt;= 0 -&gt; none\ndep_delay between 1 and 15 minutes -&gt; minimal\ndep_delay between 16 and 30 minutes -&gt; delayed\ndep_delay between 31 and 60 minutes -&gt; major\ndep_delay over 60 minutes -&gt; extreme\n\nUse mutate() and case_when() to create a delay_category variable in the flights data frame."
  },
  {
    "objectID": "slides/07/slides07.html#section-7",
    "href": "slides/07/slides07.html#section-7",
    "title": "Data Wrangling: Verbs",
    "section": "",
    "text": "“dataframe first, dataframe once”\nCombine multiple operations with the pipe\nThink “and then” when reading code"
  },
  {
    "objectID": "slides/07/slides07.html#using",
    "href": "slides/07/slides07.html#using",
    "title": "Data Wrangling: Verbs",
    "section": "Using %>%",
    "text": "Using %&gt;%\n\n%&gt;% passes result on left into first argument of function on right\nChaining functions together lets you read Left-to-right, top-to-bottom"
  },
  {
    "objectID": "slides/07/slides07.html#using-1",
    "href": "slides/07/slides07.html#using-1",
    "title": "Data Wrangling: Verbs",
    "section": "Using %>%",
    "text": "Using %&gt;%\n\n\nfilter():\n\nfilter(storms, status == \"hurricane\")\n\nbecomes\n\nstorms %&gt;%\n  filter(status == \"hurricane\")\n\n\narrange():\n\narrange(storms, wind)\n\nbecomes\n\nstorms %&gt;%\n  arrange(wind)"
  },
  {
    "objectID": "slides/07/slides07.html#using-2",
    "href": "slides/07/slides07.html#using-2",
    "title": "Data Wrangling: Verbs",
    "section": "Using %>%",
    "text": "Using %&gt;%\nWe can also build up a series of pipes.\nWe’re interested in the storms with the lowest wind speed that were still classified as hurricanes.\n\nstorms %&gt;%\n  filter(status == \"hurricane\") %&gt;%\n  arrange(wind)\n\n# A tibble: 4,803 × 13\n   name      year month   day  hour   lat  long status   category  wind pressure\n   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Blanche   1975     7    27     6  35.9 -70   hurrica…        1    65      987\n 2 Caroline  1975     8    30     0  23.3 -94.2 hurrica…        1    65      990\n 3 Caroline  1975     8    30     6  23.5 -94.9 hurrica…        1    65      990\n 4 Caroline  1975     8    30    12  23.7 -95.6 hurrica…        1    65      989\n 5 Doris     1975     8    31     0  34.9 -46.3 hurrica…        1    65      990\n 6 Doris     1975     8    31     6  34.8 -45.7 hurrica…        1    65      990\n 7 Eloise    1975     9    16    18  19.5 -68.4 hurrica…        1    65     1002\n 8 Eloise    1975     9    17     0  19.6 -69.2 hurrica…        1    65      997\n 9 Eloise    1975     9    22     6  24.8 -89.4 hurrica…        1    65      993\n10 Faye      1975     9    26     0  26.5 -60   hurrica…        1    65      990\n# ℹ 4,793 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#using-3",
    "href": "slides/07/slides07.html#using-3",
    "title": "Data Wrangling: Verbs",
    "section": "Using %>%",
    "text": "Using %&gt;%\nWe’re interested in the storms with the lowest wind speed that were still classified as hurricanes, that reached category 2.\n\nstorms %&gt;%\n  filter(status == \"hurricane\") %&gt;%\n  filter(category &gt; 1) %&gt;%\n  arrange(wind)\n\n# A tibble: 2,255 × 13\n   name    year month   day  hour   lat  long status    category  wind pressure\n   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;        &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Eloise  1975     9    22    18  26.5 -89.4 hurricane        2    85      980\n 2 Faye    1975     9    26    18  31   -63.1 hurricane        2    85      985\n 3 Faye    1975     9    28     0  38.4 -63.7 hurricane        2    85      985\n 4 Gladys  1975    10     3     6  43.7 -57   hurricane        2    85      960\n 5 Gladys  1975    10     3    12  46.6 -50.6 hurricane        2    85      960\n 6 Emmy    1976     8    26    18  27.7 -54.8 hurricane        2    85      976\n 7 Emmy    1976     8    27    12  30.9 -53.7 hurricane        2    85      975\n 8 Emmy    1976     8    28    12  33.5 -56.6 hurricane        2    85      975\n 9 Emmy    1976     8    31    12  35.1 -44.9 hurricane        2    85      977\n10 Gloria  1976     9    30     6  32.2 -59.8 hurricane        2    85      971\n# ℹ 2,245 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;"
  },
  {
    "objectID": "slides/07/slides07.html#combining-with-ggplot",
    "href": "slides/07/slides07.html#combining-with-ggplot",
    "title": "Data Wrangling: Verbs",
    "section": "Combining with ggplot",
    "text": "Combining with ggplot\nPipes become especially useful when we combine them with ggplot():\n\n\nstorms %&gt;%\n  filter(status == \"hurricane\") %&gt;%\n  filter(category &gt; 1) %&gt;%\n  ggplot(aes(x = wind, y = hurricane_force_diameter)) + \n  geom_jitter()"
  },
  {
    "objectID": "slides/07/slides07.html#your-turn-2",
    "href": "slides/07/slides07.html#your-turn-2",
    "title": "Data Wrangling: Verbs",
    "section": "Your turn",
    "text": "Your turn\n\nChain the last two parts together, so that the resulting dataset contains both avg_speed and delay_category. Pipe this new dataset into ggplot() to answer the question “is there a relationship between average speed and how late a flight is delayed?”\nIf you have time, create a new graph which only contains flights to MSP.\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/08/slides08.html#the-college-scorecard",
    "href": "slides/08/slides08.html#the-college-scorecard",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "The College Scorecard",
    "text": "The College Scorecard\n\nThe College Scorecard is designed to increase transparency, putting the power in the hands of the public — from those choosing colleges to those improving college quality — to see how well different schools are serving their students.\n\n\n\nRows: 187\nColumns: 13\n$ unitid         &lt;dbl&gt; 228343, 177719, 367884, 149781, 135364, 212601, 133979,…\n$ school         &lt;chr&gt; \"Southwestern University\", \"Barnes-Jewish College Goldf…\n$ type           &lt;chr&gt; \"private\", \"private\", \"private\", \"private\", \"private\", …\n$ city           &lt;chr&gt; \"Georgetown\", \"Saint Louis\", \"Fort Myers\", \"Wheaton\", \"…\n$ state          &lt;chr&gt; \"TX\", \"MO\", \"FL\", \"IL\", \"GA\", \"PA\", \"FL\", \"CA\", \"IN\", \"…\n$ region         &lt;chr&gt; \"Southwest\", \"Plains\", \"Southeast\", \"Great Lakes\", \"Sou…\n$ admission_rate &lt;dbl&gt; 0.4903, NA, 0.6121, 0.8481, 0.5000, 0.7552, 0.3999, 0.5…\n$ act            &lt;dbl&gt; 26, NA, NA, 29, NA, 23, NA, 22, 25, 31, NA, NA, 20, 20,…\n$ undergrads     &lt;dbl&gt; 1507, 569, 832, 2358, 235, 2866, 1049, 4516, 2120, 1545…\n$ cost           &lt;dbl&gt; 55886, NA, 27425, 49214, NA, 44896, 27460, 58014, 46440…\n$ grad_rate      &lt;dbl&gt; 0.6945, NA, 0.2621, 0.8878, 0.5000, 0.6770, 0.3644, 0.7…\n$ fy_retention   &lt;dbl&gt; 0.8571, NA, 0.4783, 0.9262, NA, 0.8217, 0.6355, 0.8179,…\n$ fedloan        &lt;dbl&gt; 0.5105, 0.8185, 0.6213, 0.4902, 0.5529, 0.5524, 0.6755,…"
  },
  {
    "objectID": "slides/08/slides08.html#function-application-syntax",
    "href": "slides/08/slides08.html#function-application-syntax",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Function-application syntax",
    "text": "Function-application syntax\n\nmn_colleges &lt;- filter(colleges, state == \"MN\")\nmn_colleges &lt;- select(mn_colleges, school, city, admission_rate:fedloan)\nmn_colleges\n\n# A tibble: 3 × 9\n  school      city  admission_rate   act undergrads  cost grad_rate fy_retention\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 Macalester… Sain…          0.323    31       2079 68627     0.908        0.934\n2 North Cent… Minn…          0.899    21        955 36349     0.512        0.8  \n3 University… Croo…          0.684    NA       1839 23290     0.5          0.717\n# ℹ 1 more variable: fedloan &lt;dbl&gt;"
  },
  {
    "objectID": "slides/08/slides08.html#nested-function-calls",
    "href": "slides/08/slides08.html#nested-function-calls",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Nested function calls",
    "text": "Nested function calls\n\nselect(filter(colleges, state == \"MN\"), school, city, admission_rate:fedloan)\n\n# A tibble: 3 × 9\n  school      city  admission_rate   act undergrads  cost grad_rate fy_retention\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 Macalester… Sain…          0.323    31       2079 68627     0.908        0.934\n2 North Cent… Minn…          0.899    21        955 36349     0.512        0.8  \n3 University… Croo…          0.684    NA       1839 23290     0.5          0.717\n# ℹ 1 more variable: fedloan &lt;dbl&gt;"
  },
  {
    "objectID": "slides/08/slides08.html#section",
    "href": "slides/08/slides08.html#section",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "",
    "text": "“dataframe first, dataframe once”\nCombine multiple operations with the pipe\nThink “and then” when reading code"
  },
  {
    "objectID": "slides/08/slides08.html#using",
    "href": "slides/08/slides08.html#using",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Using %>%",
    "text": "Using %&gt;%\n\n%&gt;% passes result on left into first argument of function on right\nChaining functions together lets you read Left-to-right, top-to-bottom"
  },
  {
    "objectID": "slides/08/slides08.html#using-1",
    "href": "slides/08/slides08.html#using-1",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Using %>%",
    "text": "Using %&gt;%\nYou can build up a series of pipes:\n\nmn_colleges &lt;- colleges |&gt;                     # dataframe first and then... #&lt;&lt;\n  filter(state == \"MN\") |&gt;\n  select(school, city, admission_rate:fedloan)"
  },
  {
    "objectID": "slides/08/slides08.html#using-2",
    "href": "slides/08/slides08.html#using-2",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Using %>%",
    "text": "Using %&gt;%\nYou can build up a series of pipes:\n\nmn_colleges &lt;- colleges |&gt;                     # dataframe first and then... #&lt;&lt;\n  filter(state == \"MN\") |&gt;                     # filter out MN colleges and then...#&lt;&lt;\n  select(school, city, admission_rate:fedloan)"
  },
  {
    "objectID": "slides/08/slides08.html#using-3",
    "href": "slides/08/slides08.html#using-3",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Using %>%",
    "text": "Using %&gt;%\nYou can build up a series of pipes:\n\nmn_colleges &lt;- colleges |&gt;                     # dataframe first and then... #&lt;&lt;\n  filter(state == \"MN\") |&gt;                     # filter out MN colleges and then...#&lt;&lt;\n  select(school, city, admission_rate:fedloan) # select the columns of interest #&lt;&lt;"
  },
  {
    "objectID": "slides/08/slides08.html#warm-up",
    "href": "slides/08/slides08.html#warm-up",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Warm Up",
    "text": "Warm Up\n\nRewrite each code chunk as a single chain of commands using |&gt; or %&gt;%\n\nChunk 1:\n\nlog2(sqrt(16))\n\nChunk 2:\n\nlibrary(nycflights23) # need to load, not in pipeline\nmsp &lt;- filter(flights, dest == \"MSP\", carrier == \"DL\")\nmsp_narrow &lt;- select(msp, year, month, day, starts_with(\"sched\"), \n                     contains(\"delay\"), origin)\nmsp_narrow &lt;- relocate(msp_narrow, origin, everything())\n\n\n\n\n−+\n02:30"
  },
  {
    "objectID": "slides/08/slides08.html#the-base-pipe",
    "href": "slides/08/slides08.html#the-base-pipe",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "The |> (base) pipe",
    "text": "The |&gt; (base) pipe\n\n|&gt; pipe operator was introduced in R v4.1\nFor simple uses, acts the same as %&gt;% but is more rigid\nI’ll use both in class examples, but you can use |&gt; or %&gt;%"
  },
  {
    "objectID": "slides/08/slides08.html#your-turn",
    "href": "slides/08/slides08.html#your-turn",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Your turn",
    "text": "Your turn\n\nChain the last two parts together, so that the resulting dataset contains both avg_speed and delay_category. Pipe this new dataset into ggplot() to answer the question “is there a relationship between average speed and how late a flight is delayed?”\nIf you have time, create a new graph which only contains flights to MSP.\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/08/slides08.html#computing-statistics-summarize",
    "href": "slides/08/slides08.html#computing-statistics-summarize",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Computing statistics: summarize",
    "text": "Computing statistics: summarize\n\ncollapse many values down into a statistic\nsummarize(data, newstat = fun(var)) applies the fun function to var variable(s) and returns one value in newstat column"
  },
  {
    "objectID": "slides/08/slides08.html#computing-statistics-summarize-1",
    "href": "slides/08/slides08.html#computing-statistics-summarize-1",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Computing statistics: summarize",
    "text": "Computing statistics: summarize\n\ndplyrbase R\n\n\nAverage and SD of cost in a data frame format:\n\n\ncolleges %&gt;%\n  summarize(\n    avg_cost = mean(cost, na.rm = TRUE), \n    sd_cost = sd(cost , na.rm = TRUE)\n  )\n\n\n# A tibble: 1 × 2\n  avg_cost sd_cost\n     &lt;dbl&gt;   &lt;dbl&gt;\n1   36620.  16244.\n\n\n\n\n\nmean(colleges$cost, na.rm = TRUE)\n\n[1] 36619.72\n\nsd(colleges$cost, na.rm = TRUE)\n\n[1] 16243.9"
  },
  {
    "objectID": "slides/08/slides08.html#your-turn-1",
    "href": "slides/08/slides08.html#your-turn-1",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Your turn",
    "text": "Your turn\n\nUse summarize() to compute statistics about the data:\n\nThe lowest and highest distance traveled\nThe lowest and highest air_time\nThe median dep_delay\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/08/slides08.html#your-turn-2",
    "href": "slides/08/slides08.html#your-turn-2",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Your turn",
    "text": "Your turn\n\nExtract the rows for Delta flights. (Hint: look at the airlines dataset, which is also distributed in the {nycflights23} R package, to find the carrier shortcut code)\nThen use summarize() and a summary function to find:\n\nThe number of flights in this subset\nThe median dep_delay. How does it compare to the overall median?\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/08/slides08.html#across",
    "href": "slides/08/slides08.html#across",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "across()",
    "text": "across()\nIf you want to calculate the same summary statistics for many variables, across() can help!\n\ncolleges %&gt;%\n  summarize(across(admission_rate:fedloan, ~ mean(.x, na.rm = TRUE)))\n\n# A tibble: 1 × 7\n  admission_rate   act undergrads   cost grad_rate fy_retention fedloan\n           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;\n1          0.688  23.2      3559. 36620.     0.550        0.743   0.533"
  },
  {
    "objectID": "slides/08/slides08.html#across-where",
    "href": "slides/08/slides08.html#across-where",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "across() + where()",
    "text": "across() + where()\nwhere() can help you apply functions to all columns of a certain type (e.g., numeric)\n\ncolleges %&gt;%\n  summarize(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)))\n\n# A tibble: 1 × 8\n   unitid admission_rate   act undergrads   cost grad_rate fy_retention fedloan\n    &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;\n1 203732.          0.688  23.2      3559. 36620.     0.550        0.743   0.533\n\n\nBut make sure they make sense!"
  },
  {
    "objectID": "slides/08/slides08.html#group_by",
    "href": "slides/08/slides08.html#group_by",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "group_by()",
    "text": "group_by()\nGroups cases by common values of one or more columns\n\ncolleges %&gt;% \n  group_by(state)\n\n\n\n# A tibble: 187 × 13\n# Groups:   state [44]\n  unitid school   type  city  state region admission_rate   act undergrads  cost\n   &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 228343 Southwe… priv… Geor… TX    South…          0.490    26       1507 55886\n2 177719 Barnes-… priv… Sain… MO    Plains         NA        NA        569    NA\n3 367884 Hodges … priv… Fort… FL    South…          0.612    NA        832 27425\n# ℹ 184 more rows\n# ℹ 3 more variables: grad_rate &lt;dbl&gt;, fy_retention &lt;dbl&gt;, fedloan &lt;dbl&gt;\n\n\nHow does this help us?"
  },
  {
    "objectID": "slides/08/slides08.html#spit-apply-combine",
    "href": "slides/08/slides08.html#spit-apply-combine",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Spit-apply-combine",
    "text": "Spit-apply-combine"
  },
  {
    "objectID": "slides/08/slides08.html#statistics-by-group-group_by-summarize",
    "href": "slides/08/slides08.html#statistics-by-group-group_by-summarize",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Statistics by group: group_by + summarize",
    "text": "Statistics by group: group_by + summarize\nSummary statistics by state\n\n\ncolleges %&gt;%\n  group_by(state) %&gt;%\n  summarize(\n    n_schools = n(),\n    avg_cost = mean(cost, na.rm = TRUE),\n    min_size = min(undergrads, na.rm = TRUE),\n    max_size = max(undergrads, na.rm = TRUE)\n  )\n\n\n# A tibble: 44 × 5\n   state n_schools avg_cost min_size max_size\n   &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 AL            4   22242.      245     7785\n 2 AR            3   43816.      512     1447\n 3 AZ            2   33388.      803    33715\n 4 CA            9   42807.       43    23337\n 5 CO            2   45574      5755     8448\n 6 CT            3   29895.      174     4425\n 7 FL            5   34747.       39     2401\n 8 GA            6   27961       235     9742\n 9 HI            1   36765      1558     1558\n10 IA            1     NaN       339      339\n# ℹ 34 more rows"
  },
  {
    "objectID": "slides/08/slides08.html#your-turn-3",
    "href": "slides/08/slides08.html#your-turn-3",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Your turn",
    "text": "Your turn\n\nUse group_by(), summarize(), and slice_max() to display the five dest airports with the most flights from NYC airports in 2023. Your display should include the median flight delay for these airports.\n\n\n\n\n−+\n03:30"
  },
  {
    "objectID": "slides/08/slides08.html#calculating-counts",
    "href": "slides/08/slides08.html#calculating-counts",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Calculating counts",
    "text": "Calculating counts\ncount() can be used as a short cut to group_by() + summarize() if you are only calculating counts\n\ngroup_by()count()\n\n\n\n\ncolleges %&gt;% \n  group_by(state) %&gt;%\n  summarize(n = n())\n\n\n# A tibble: 44 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AL        4\n 2 AR        3\n 3 AZ        2\n 4 CA        9\n 5 CO        2\n 6 CT        3\n 7 FL        5\n 8 GA        6\n 9 HI        1\n10 IA        1\n# ℹ 34 more rows\n\n\n\n\n\n\ncolleges %&gt;% count(state)\n\n\n# A tibble: 44 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AL        4\n 2 AR        3\n 3 AZ        2\n 4 CA        9\n 5 CO        2\n 6 CT        3\n 7 FL        5\n 8 GA        6\n 9 HI        1\n10 IA        1\n# ℹ 34 more rows"
  },
  {
    "objectID": "slides/08/slides08.html#calculations-by-group-group_by-mutate",
    "href": "slides/08/slides08.html#calculations-by-group-group_by-mutate",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Calculations by group: group_by + mutate",
    "text": "Calculations by group: group_by + mutate\nCalculate z-scores within regions\n\n\ncolleges %&gt;%\n  group_by(region) %&gt;%\n  mutate(z_cost = (cost - mean(cost, na.rm = TRUE)) / sd(cost, na.rm = TRUE))\n\n\n# A tibble: 187 × 14\n# Groups:   region [10]\n   unitid school  type  city  state region admission_rate   act undergrads  cost\n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 228343 Southw… priv… Geor… TX    South…          0.490    26       1507 55886\n 2 177719 Barnes… priv… Sain… MO    Plains         NA        NA        569    NA\n 3 367884 Hodges… priv… Fort… FL    South…          0.612    NA        832 27425\n 4 149781 Wheato… priv… Whea… IL    Great…          0.848    29       2358 49214\n 5 135364 Luther… priv… Lith… GA    South…          0.5      NA        235    NA\n 6 212601 Gannon… priv… Erie  PA    Mid E…          0.755    23       2866 44896\n 7 133979 Florid… priv… Miam… FL    South…          0.400    NA       1049 27460\n 8 117140 Univer… priv… La V… CA    Far W…          0.548    22       4516 58014\n 9 152567 Trine … priv… Ango… IN    Great…          0.816    25       2120 46440\n10 237057 Whitma… priv… Wall… WA    Far W…          0.559    31       1545 68082\n# ℹ 177 more rows\n# ℹ 4 more variables: grad_rate &lt;dbl&gt;, fy_retention &lt;dbl&gt;, fedloan &lt;dbl&gt;,\n#   z_cost &lt;dbl&gt;"
  },
  {
    "objectID": "slides/08/slides08.html#ungroup",
    "href": "slides/08/slides08.html#ungroup",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "ungroup()",
    "text": "ungroup()\n\nOnce data are grouped, they remain grouped until you manually ungroup them\nSome summary functions ungroup them for you, e.g., count() and summarize()\n\n\n\ncolleges %&gt;%\n  group_by(region) %&gt;%\n  mutate(z_cost = (cost - mean(cost, na.rm = TRUE)) / sd(cost, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  select(school, city, cost, z_cost)\n\n\nWith ungroup()Without ungroup()\n\n\n\n\n# A tibble: 187 × 4\n   school                                           city           cost z_cost\n   &lt;chr&gt;                                            &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1 Southwestern University                          Georgetown    55886  1.51 \n 2 Barnes-Jewish College Goldfarb School of Nursing Saint Louis      NA NA    \n 3 Hodges University                                Fort Myers    27425 -0.467\n 4 Wheaton College                                  Wheaton       49214  1.06 \n 5 Luther Rice College & Seminary                   Lithonia         NA NA    \n 6 Gannon University                                Erie          44896  0.261\n 7 Florida Memorial University                      Miami Gardens 27460 -0.465\n 8 University of La Verne                           La Verne      58014  1.14 \n 9 Trine University                                 Angola        46440  0.849\n10 Whitman College                                  Walla Walla   68082  1.79 \n# ℹ 177 more rows\n\n\n\n\n\n\n# A tibble: 187 × 5\n# Groups:   region [10]\n   region      school                                         city   cost z_cost\n   &lt;chr&gt;       &lt;chr&gt;                                          &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Southwest   Southwestern University                        Geor… 55886  1.51 \n 2 Plains      Barnes-Jewish College Goldfarb School of Nurs… Sain…    NA NA    \n 3 Southeast   Hodges University                              Fort… 27425 -0.467\n 4 Great Lakes Wheaton College                                Whea… 49214  1.06 \n 5 Southeast   Luther Rice College & Seminary                 Lith…    NA NA    \n 6 Mid East    Gannon University                              Erie  44896  0.261\n 7 Southeast   Florida Memorial University                    Miam… 27460 -0.465\n 8 Far West    University of La Verne                         La V… 58014  1.14 \n 9 Great Lakes Trine University                               Ango… 46440  0.849\n10 Far West    Whitman College                                Wall… 68082  1.79 \n# ℹ 177 more rows"
  },
  {
    "objectID": "slides/08/slides08.html#aside-code-commenting",
    "href": "slides/08/slides08.html#aside-code-commenting",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Aside: code commenting",
    "text": "Aside: code commenting\nIn R, you can use # for adding comments to your code. Any text that follows the # will be printed as-is and won’t be run as code. This is useful for leaving comments in your code and for temporarily disabling certain lines of code for debugging.\n\n\ncolleges %&gt;%\n  group_by(state) %&gt;%\n  summarize(\n    n_schools = n(),                               # This is a reminder to me\n    # avg_cost = mean(cost, na.rm = TRUE),         # This line isn't run\n    min_size = min(undergrads, na.rm = TRUE),\n    max_size = max(undergrads, na.rm = TRUE)\n  )\n\n\n# A tibble: 44 × 4\n   state n_schools min_size max_size\n   &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 AL            4      245     7785\n 2 AR            3      512     1447\n 3 AZ            2      803    33715\n 4 CA            9       43    23337\n 5 CO            2     5755     8448\n 6 CT            3      174     4425\n 7 FL            5       39     2401\n 8 GA            6      235     9742\n 9 HI            1     1558     1558\n10 IA            1      339      339\n# ℹ 34 more rows"
  },
  {
    "objectID": "slides/08/slides08.html#aside-code-commenting-1",
    "href": "slides/08/slides08.html#aside-code-commenting-1",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Aside: code commenting",
    "text": "Aside: code commenting\nAnd it works especially well when you’ve used chaining in your code\n\n\ncolleges %&gt;%\n  #group_by(state) %&gt;%\n  summarize(\n    n_schools = n(),                               \n    avg_cost = mean(cost, na.rm = TRUE),         \n    min_size = min(undergrads, na.rm = TRUE),\n    max_size = max(undergrads, na.rm = TRUE)\n  )\n\n\n# A tibble: 1 × 4\n  n_schools avg_cost min_size max_size\n      &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1       187   36620.        0    33715"
  },
  {
    "objectID": "slides/08/slides08.html#which-is-easier-to-read",
    "href": "slides/08/slides08.html#which-is-easier-to-read",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Which is easier to read?",
    "text": "Which is easier to read?\n\nOption AOption B\n\n\n\ngroup_by(colleges, region) %&gt;% mutate(z_cost = (cost - mean(cost, na.rm = TRUE)) / sd(cost, na.rm = TRUE)) %&gt;% ungroup() \n\n# A tibble: 187 × 14\n   unitid school  type  city  state region admission_rate   act undergrads  cost\n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 228343 Southw… priv… Geor… TX    South…          0.490    26       1507 55886\n 2 177719 Barnes… priv… Sain… MO    Plains         NA        NA        569    NA\n 3 367884 Hodges… priv… Fort… FL    South…          0.612    NA        832 27425\n 4 149781 Wheato… priv… Whea… IL    Great…          0.848    29       2358 49214\n 5 135364 Luther… priv… Lith… GA    South…          0.5      NA        235    NA\n 6 212601 Gannon… priv… Erie  PA    Mid E…          0.755    23       2866 44896\n 7 133979 Florid… priv… Miam… FL    South…          0.400    NA       1049 27460\n 8 117140 Univer… priv… La V… CA    Far W…          0.548    22       4516 58014\n 9 152567 Trine … priv… Ango… IN    Great…          0.816    25       2120 46440\n10 237057 Whitma… priv… Wall… WA    Far W…          0.559    31       1545 68082\n# ℹ 177 more rows\n# ℹ 4 more variables: grad_rate &lt;dbl&gt;, fy_retention &lt;dbl&gt;, fedloan &lt;dbl&gt;,\n#   z_cost &lt;dbl&gt;\n\n\n\n\n\ncolleges %&gt;%\n  group_by(region) %&gt;%\n  mutate(z_cost = (cost - mean(cost, na.rm = TRUE)) / sd(cost, na.rm = TRUE)) %&gt;%\n  ungroup() #&lt;&lt;\n\n# A tibble: 187 × 14\n   unitid school  type  city  state region admission_rate   act undergrads  cost\n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 228343 Southw… priv… Geor… TX    South…          0.490    26       1507 55886\n 2 177719 Barnes… priv… Sain… MO    Plains         NA        NA        569    NA\n 3 367884 Hodges… priv… Fort… FL    South…          0.612    NA        832 27425\n 4 149781 Wheato… priv… Whea… IL    Great…          0.848    29       2358 49214\n 5 135364 Luther… priv… Lith… GA    South…          0.5      NA        235    NA\n 6 212601 Gannon… priv… Erie  PA    Mid E…          0.755    23       2866 44896\n 7 133979 Florid… priv… Miam… FL    South…          0.400    NA       1049 27460\n 8 117140 Univer… priv… La V… CA    Far W…          0.548    22       4516 58014\n 9 152567 Trine … priv… Ango… IN    Great…          0.816    25       2120 46440\n10 237057 Whitma… priv… Wall… WA    Far W…          0.559    31       1545 68082\n# ℹ 177 more rows\n# ℹ 4 more variables: grad_rate &lt;dbl&gt;, fy_retention &lt;dbl&gt;, fedloan &lt;dbl&gt;,\n#   z_cost &lt;dbl&gt;"
  },
  {
    "objectID": "slides/08/slides08.html#which-is-easier-to-read-1",
    "href": "slides/08/slides08.html#which-is-easier-to-read-1",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Which is easier to read?",
    "text": "Which is easier to read?\n\nOption AOption B\n\n\n\npalmerpenguins::penguins |&gt;\n  filter(species == \"Adelie\") |&gt;\n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point() + \n  scale_color_viridis_d(option = \"magma\",end = .75) + \n  theme_bw(base_family = \"Times\") + \n  theme(legend.position = \"none\",\n        panel.grid.minor = element_blank(),\n        panel.grid.major.x = element_blank(),\n        axis.title.x = element_text(color = \"darkred\"))\n\n\n\n\npalmerpenguins::penguins |&gt;\n  filter(species == \"Adelie\") |&gt;\n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point() + scale_color_viridis_d(option = \"magma\",end = .75) + \n  theme_bw(base_family = \"Times\") + \n  theme(legend.position = \"none\", panel.grid.minor = element_blank(), panel.grid.major.x = element_blank(),\n        axis.title.x = element_text(color = \"darkred\"))"
  },
  {
    "objectID": "slides/08/slides08.html#style.tidyverse.org",
    "href": "slides/08/slides08.html#style.tidyverse.org",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "<style.tidyverse.org>",
    "text": "&lt;style.tidyverse.org&gt;"
  },
  {
    "objectID": "slides/08/slides08.html#example-pipes-and-whitespace",
    "href": "slides/08/slides08.html#example-pipes-and-whitespace",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Example: Pipes and whitespace",
    "text": "Example: Pipes and whitespace\n|&gt; should always have a space before it, and should usually be followed by a new line. After the first step, each line should be indented by two spaces.\nGood:\n\niris |&gt;\n  summarize(across(where(is.numeric), mean), .by = Species) |&gt;\n  pivot_longer(!Species, names_to = \"measure\", values_to = \"value\") |&gt;\n  arrange(value)\n\nBad:\n\niris |&gt; summarize(across(where(is.numeric), mean), .by = Species) |&gt;\npivot_longer(!Species, names_to = \"measure\", values_to = \"value\") |&gt;\narrange(value)"
  },
  {
    "objectID": "slides/08/slides08.html#example-long-lines",
    "href": "slides/08/slides08.html#example-long-lines",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Example: long lines",
    "text": "Example: long lines\nIf the arguments to a function don’t all fit on one line, put each argument on its own line and indent:\nGood:\n\niris |&gt;\n  summarise(\n    Sepal.Length = mean(Sepal.Length),\n    Sepal.Width = mean(Sepal.Width),\n    .by = Species\n  )\n\nBad:\n\niris |&gt;\n  summarise(Sepal.Length = mean(Sepal.Length), Sepal.Width = mean(Sepal.Width), .by = Species)"
  },
  {
    "objectID": "slides/08/slides08.html#ggplot2-whitespace-and-indenting",
    "href": "slides/08/slides08.html#ggplot2-whitespace-and-indenting",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "ggplot2 whitespace and indenting",
    "text": "ggplot2 whitespace and indenting\n+ should always have a space before it, and should be followed by a new line. After the first step, each line should be indented by two spaces.\nIf you are creating a ggplot off of a dplyr pipeline, there should only be one level of indentation.\nGood:\n\niris |&gt;\n  filter(Species == \"setosa\") |&gt;\n  ggplot(aes(x = Sepal.Width, y = Sepal.Length)) +\n  geom_point()\n\nBad:\n\niris |&gt;\n  filter(Species == \"setosa\") |&gt;\n  ggplot(aes(x = Sepal.Width, y = Sepal.Length)) +\n    geom_point()\n\nBad:\n\niris |&gt;\n  filter(Species == \"setosa\") |&gt;\n  ggplot(aes(x = Sepal.Width, y = Sepal.Length)) + geom_point()"
  },
  {
    "objectID": "slides/08/slides08.html#ggplot2-long-lines",
    "href": "slides/08/slides08.html#ggplot2-long-lines",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "ggplot2 long lines",
    "text": "ggplot2 long lines\nIf the arguments to a ggplot2 layer don’t all fit on one line, put each argument on its own line and indent:\nGood:\n\niris |&gt;\n  ggplot(aes(x = Sepal.Width, y = Sepal.Length, color = Species)) +\n  geom_point() +\n  labs(\n    x = \"Sepal width, in cm\",\n    y = \"Sepal length, in cm\",\n    title = \"Sepal length vs. width of irises\"\n  )\n\nBad:\n\niris |&gt;\n  ggplot(aes(x = Sepal.Width, y = Sepal.Length, color = Species)) +\n  geom_point() +\n  labs(x = \"Sepal width, in cm\", y = \"Sepal length, in cm\", title = \"Sepal length vs. width of irises\")"
  },
  {
    "objectID": "slides/08/slides08.html#code-style-summary",
    "href": "slides/08/slides08.html#code-style-summary",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "Code style summary",
    "text": "Code style summary\n\nAll code style guides are opinionated and subjective\nUsing consistent style makes it easier for collaborators (including future you!) to read and understand your code\nTry to follow the tidyverse style guide in this class"
  },
  {
    "objectID": "slides/08/slides08.html#a-shortcut",
    "href": "slides/08/slides08.html#a-shortcut",
    "title": "Data Wrangling: Pipes & Groups",
    "section": "A shortcut",
    "text": "A shortcut\nIn RStudio,\n\nHighlight the code that you want to reformat\nGo to “code –&gt; reformat code”\nMarvel in wonder\n\n\nTry it\n\nReformat your code from the flights activity so far according to the tidyverse style guide"
  },
  {
    "objectID": "slides/06/slides06.html#today",
    "href": "slides/06/slides06.html#today",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Today",
    "text": "Today\n\n{patchwork}\nColorblind-friendly color palettes\nWriting alt-text"
  },
  {
    "objectID": "slides/06/slides06.html#small-multiples",
    "href": "slides/06/slides06.html#small-multiples",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Small Multiples",
    "text": "Small Multiples\nEach plot shares aesthetics but shows different subsets of data"
  },
  {
    "objectID": "slides/06/slides06.html#compound-plots",
    "href": "slides/06/slides06.html#compound-plots",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Compound Plots",
    "text": "Compound Plots\nThe plots might share data, but don’t share aesthetics"
  },
  {
    "objectID": "slides/06/slides06.html#compound-plot-example",
    "href": "slides/06/slides06.html#compound-plot-example",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Compound Plot Example",
    "text": "Compound Plot Example\n\nlibrary(palmerpenguins)\nggplot(penguins) + \n  geom_histogram(bins = 20, col = \"white\", aes(x = body_mass_g))\n\n\n\n\n\n\n\nggplot(penguins) + \n  geom_histogram(bins = 20, col = \"white\", aes(x = flipper_length_mm))\n\n\n\n\n\n\n\nggplot(penguins) + \n  geom_point(aes(x = body_mass_g, y = flipper_length_mm))"
  },
  {
    "objectID": "slides/06/slides06.html#patchwork",
    "href": "slides/06/slides06.html#patchwork",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Patchwork",
    "text": "Patchwork\n\nlibrary(patchwork)\np1 = ggplot(penguins) + \n  geom_histogram(bins = 20, col = \"white\", aes(x = body_mass_g))\n\np2 = ggplot(penguins) + \n  geom_histogram(bins = 20, col = \"white\", aes(x = flipper_length_mm))\n\np3 = ggplot(penguins) + \n  geom_point(aes(x = body_mass_g, y = flipper_length_mm))\n\n(p1 + p2)/p3"
  },
  {
    "objectID": "slides/06/slides06.html#patchwork-layout-2",
    "href": "slides/06/slides06.html#patchwork-layout-2",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Patchwork (layout 2)",
    "text": "Patchwork (layout 2)\n\np3 + (p1/p2)\n\n\n\n\n\n\n\n\n\n\nFor more complex layouts, see the “Controlling Layouts” vignette"
  },
  {
    "objectID": "slides/06/slides06.html#patchwork-with-a-shared-legend",
    "href": "slides/06/slides06.html#patchwork-with-a-shared-legend",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Patchwork (with a shared legend)",
    "text": "Patchwork (with a shared legend)\n\np1 = ggplot(penguins) + \n  geom_histogram(bins = 20, col = \"white\", aes(x = body_mass_g, fill = species))\n\np2 = ggplot(penguins) + \n  geom_histogram(bins = 20,  col = \"white\", aes(x = flipper_length_mm, fill = species))\n\np3 = ggplot(penguins) + \n  geom_point(pch = 21, alpha = .9, col = \"white\", aes(x = body_mass_g, y = flipper_length_mm, fill = species)) +\n  theme(legend.position = \"none\")\n\np3 + (p1/p2) + \n  plot_layout(guides = 'collect')"
  },
  {
    "objectID": "slides/06/slides06.html#patchwork-with-annotation",
    "href": "slides/06/slides06.html#patchwork-with-annotation",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Patchwork (with annotation)",
    "text": "Patchwork (with annotation)\n\np3 + (p1/p2) + \n  plot_layout(guides = 'collect') + \n  plot_annotation(\n    title = \"Penguin Plot\",\n    tag_levels = \"A\"\n  )"
  },
  {
    "objectID": "slides/06/slides06.html#patchwork-with-a-common-theme",
    "href": "slides/06/slides06.html#patchwork-with-a-common-theme",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Patchwork (with a common theme)",
    "text": "Patchwork (with a common theme)\n\np3 + (p1/p2) + \n  plot_layout(guides = 'collect') & \n  theme_minimal() &\n  scale_fill_viridis_d()"
  },
  {
    "objectID": "slides/06/slides06.html#but-what-does-this-have-to-do-with-accessibility",
    "href": "slides/06/slides06.html#but-what-does-this-have-to-do-with-accessibility",
    "title": "(Closer to) Accessible Data Viz",
    "section": "But what does this have to do with accessibility?",
    "text": "But what does this have to do with accessibility?\n\nOutput (knitted files, slides, websites, etc.) should be designed to make it as easy as possible for the user to understand your content\nThere’s a cognitive load involved with scrolling or turning a physical page and trying to remember a visual from the previous page\nWhen plots belong together, we should put them together"
  },
  {
    "objectID": "slides/06/slides06.html#color-scales",
    "href": "slides/06/slides06.html#color-scales",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Color scales",
    "text": "Color scales\nUse colorblind friendly color scales (e.g., Okabe Ito, viridis)"
  },
  {
    "objectID": "slides/06/slides06.html#section-1",
    "href": "slides/06/slides06.html#section-1",
    "title": "(Closer to) Accessible Data Viz",
    "section": "",
    "text": "colorBlindness::displayAllColors(scales::hue_pal()(10))"
  },
  {
    "objectID": "slides/06/slides06.html#section-2",
    "href": "slides/06/slides06.html#section-2",
    "title": "(Closer to) Accessible Data Viz",
    "section": "",
    "text": "colorBlindness::displayAllColors(rainbow(10))"
  },
  {
    "objectID": "slides/06/slides06.html#section-3",
    "href": "slides/06/slides06.html#section-3",
    "title": "(Closer to) Accessible Data Viz",
    "section": "",
    "text": "colorBlindness::displayAllColors(colorblindr::palette_OkabeIto)"
  },
  {
    "objectID": "slides/06/slides06.html#section-4",
    "href": "slides/06/slides06.html#section-4",
    "title": "(Closer to) Accessible Data Viz",
    "section": "",
    "text": "colorBlindness::displayAllColors(viridisLite::viridis(10))"
  },
  {
    "objectID": "slides/06/slides06.html#double-encoding",
    "href": "slides/06/slides06.html#double-encoding",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Double encoding",
    "text": "Double encoding\nUse shape and color where possible\n\n\n\nDefault ggplot2 scale\n\n\n\n\n\n\n\n\n\n\nDefault ggplot2 scale with deuteranopia\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mine Çetinkaya-Rundel, Sta313. Generated with {colorblindr}."
  },
  {
    "objectID": "slides/06/slides06.html#use-direct-labeling",
    "href": "slides/06/slides06.html#use-direct-labeling",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Use direct labeling",
    "text": "Use direct labeling\n\nPrefer direct labeling where color is used to display information over a legend\nQuicker to read\nEnsures graph can be understood without reliance on color"
  },
  {
    "objectID": "slides/06/slides06.html#without-direct-labeling",
    "href": "slides/06/slides06.html#without-direct-labeling",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Without direct labeling",
    "text": "Without direct labeling\n\n\nDefault ggplot2 scale\n\n\n\n\n\n\n\n\n\n\nDefault ggplot2 scale with deuteranopia\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mine Çetinkaya-Rundel, Sta313. Generated with {colorblindr}."
  },
  {
    "objectID": "slides/06/slides06.html#with-direct-labeling",
    "href": "slides/06/slides06.html#with-direct-labeling",
    "title": "(Closer to) Accessible Data Viz",
    "section": "With direct labeling",
    "text": "With direct labeling\n\n\nDefault ggplot2 scale\n\n\n\n\n\n\n\n\n\n\nDefault ggplot2 scale with deuteranopia\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mine Çetinkaya-Rundel, Sta313. Generated with {colorblindr}."
  },
  {
    "objectID": "slides/06/slides06.html#use-whitespace-or-pattern-to-separate-elements",
    "href": "slides/06/slides06.html#use-whitespace-or-pattern-to-separate-elements",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Use whitespace or pattern to separate elements",
    "text": "Use whitespace or pattern to separate elements\n\nSeparate elements with whitespace or pattern\nAllows for distinguishing between data without entirely relying on contrast between colors"
  },
  {
    "objectID": "slides/06/slides06.html#without-whitespace",
    "href": "slides/06/slides06.html#without-whitespace",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Without whitespace",
    "text": "Without whitespace\n\n\nDefault ggplot2 scale\n\n\n\n\n\n\n\n\n\n\nDefault ggplot2 scale with tritanopia\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mine Çetinkaya-Rundel, Sta313. Generated with {colorblindr}."
  },
  {
    "objectID": "slides/06/slides06.html#with-whitespace",
    "href": "slides/06/slides06.html#with-whitespace",
    "title": "(Closer to) Accessible Data Viz",
    "section": "With whitespace",
    "text": "With whitespace\n\n\nDefault ggplot2 scale\n\n\n\n\n\n\n\n\n\n\nDefault ggplot2 scale with tritanopia\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mine Çetinkaya-Rundel, Sta313. Generated with {colorblindr}."
  },
  {
    "objectID": "slides/06/slides06.html#alternative-text",
    "href": "slides/06/slides06.html#alternative-text",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Alternative text",
    "text": "Alternative text\n\nIt is read by screen readers in place of images allowing the content and function of the image to be accessible to those with visual or certain cognitive disabilities.\nIt is displayed in place of the image in browsers if the image file is not loaded or when the user has chosen not to view images.\nIt provides a semantic meaning and description to images which can be read by search engines or be used to later determine the content of the image from page context alone.\n\n\n\nSource: WebAIM"
  },
  {
    "objectID": "slides/06/slides06.html#alt-and-surrounding-text",
    "href": "slides/06/slides06.html#alt-and-surrounding-text",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Alt and surrounding text",
    "text": "Alt and surrounding text\nCHART TYPE of TYPE OF DATA where REASON FOR INCLUDING CHART\n(plus link to data source somewhere in the text)\n\nCHART TYPE: It’s helpful for people with partial sight to know what chart type it is and gives context for understanding the rest of the visual.\nTYPE OF DATA: What data is included in the chart? The x and y axis labels may help you figure this out.\nREASON FOR INCLUDING CHART: Think about why you’re including this visual. What does it show that’s meaningful. There should be a point to every visual and you should tell people what to look for.\nLink to data source: Don’t include this in your alt text, but it should be included somewhere in the surrounding text.\n\n\n\nSource: Writing Alt Text for Data Visualization"
  },
  {
    "objectID": "slides/06/slides06.html#alt-text-practice",
    "href": "slides/06/slides06.html#alt-text-practice",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Alt Text Practice",
    "text": "Alt Text Practice\nCHART TYPE of TYPE OF DATA where REASON FOR INCLUDING CHART\n\n\n\n\n\n\n\n\n\n\n\n\n\nA scatterplot\nof median hourly wage of RN’s by year in California, Minnesota, and New York. The x-axis starts at the year 1996 and ends at the year 2020.\nThe three states follow the same linear increasing trend until about 2007, when New York and Minnesota begin to flatten.\n\n\n\n\n\n−+\n01:30"
  },
  {
    "objectID": "slides/06/slides06.html#section-5",
    "href": "slides/06/slides06.html#section-5",
    "title": "(Closer to) Accessible Data Viz",
    "section": "",
    "text": "Accessible Visualization via Natural Language Descriptions: A Four-Level Model of Semantic Content\nAlan Lundgard, MIT CSAIL\nArvind Satyanarayan, MIT CSAIL\nIEEE Transactions on Visualization & Computer Graphics (Proceedings of IEEE VIS), 2021\n\nTo demonstrate how our model can be applied to evaluate the effectiveness of visualization descriptions, we conduct a mixed-methods evaluation with 30 blind and 90 sighted readers, and find that these reader groups differ significantly on which semantic content they rank as most useful. Together, our model and findings suggest that access to meaningful information is strongly reader-specific, and that research in automatic visualization captioning should orient toward descriptions that more richly communicate overall trends and statistics, sensitive to reader preferences."
  },
  {
    "objectID": "slides/06/slides06.html#lets-try-it",
    "href": "slides/06/slides06.html#lets-try-it",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Let’s try it!",
    "text": "Let’s try it!\nCHART TYPE of TYPE OF DATA where REASON FOR INCLUDING CHART\n\n\nTake one graph and two blank cards\nWrite an alt text description of your graph on one of your blank cards.\n\nPlease label with your plot number!\n\nIn two’s or three’s, trade alt text descriptions only\nOn your second blank card, try to draw the graph based on the alt text provided.\nNow, look at the original graph. How’d you do?\nTape the original graphs, alt text, and hand drawn graphs up on the board and have a look around\n\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/06/slides06.html#recap",
    "href": "slides/06/slides06.html#recap",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Recap",
    "text": "Recap\n\nWhat was hard about writing alt text?\nLooking at the graphs, do you notice things that make it harder/easier to write alt text?\nWhat was hard about recreating from the alt text?"
  },
  {
    "objectID": "slides/06/slides06.html#adding-alt-text-to-plots",
    "href": "slides/06/slides06.html#adding-alt-text-to-plots",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Adding alt text to plots",
    "text": "Adding alt text to plots\nShort:\n\n```{r}\n#| fig-alt: Alt text goes here.\n\n# code for plot goes here\n```\n\n\nLonger:\n\n```{r}\n#| fig-alt: |\n#|   Longer alt text goes here. Make sure to add line breaks ~roughly\n#|   80 characters.\n\n# code for plot goes here\n```"
  },
  {
    "objectID": "slides/06/slides06.html#using-okabe-ito-palette",
    "href": "slides/06/slides06.html#using-okabe-ito-palette",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Using Okabe Ito palette",
    "text": "Using Okabe Ito palette\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = hourly_wage_median, color = state)) +\n  geom_point(size = 2) +\n  ggthemes::scale_color_colorblind() +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(\n    x = \"Year\", y = \"Median hourly wage\", color = \"State\",\n    title = \"Median hourly wage of Registered Nurses\"\n  ) +\n  theme(\n    legend.position = c(0.15, 0.75),\n    legend.background = element_rect(fill = \"white\", color = \"white\")\n  )"
  },
  {
    "objectID": "slides/06/slides06.html#double-encoding-1",
    "href": "slides/06/slides06.html#double-encoding-1",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Double Encoding",
    "text": "Double Encoding\nUse both color and shape aesthetics\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = hourly_wage_median, color = state, shape = state)) +\n  geom_point(size = 2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(\n    x = \"Year\", y = \"Median hourly wage\", color = \"State\", shape = \"State\",\n    title = \"Median hourly wage of Registered Nurses\"\n  ) +\n  theme(\n    legend.position = c(0.15, 0.75),\n    legend.background = element_rect(fill = \"white\", color = \"white\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#direct-labeling",
    "href": "slides/06/slides06.html#direct-labeling",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Direct Labeling",
    "text": "Direct Labeling\nCould do “by hand” with annotate(). Alternatively, use geom_text()\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = annual_salary_median, color = state)) +\n  geom_line(show.legend = FALSE, linewidth = 2) +\n  geom_text(\n    data = nurses_subset |&gt; filter(year == max(year)),\n    aes(label = state), hjust = 0, nudge_x = 1,\n    show.legend = FALSE, size = 6\n  ) +\n  scale_y_continuous(labels = scales::label_dollar(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"Year\", y = \"Annual median salary\", color = \"State\",\n    title = \"Annual median salary of Registered Nurses\"\n  ) +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    plot.margin = margin(0.1, 0.9, 0.1, 0.1, \"in\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#direct-labeling-1",
    "href": "slides/06/slides06.html#direct-labeling-1",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Direct Labeling",
    "text": "Direct Labeling\nFirst, filter the data to include the endpoints only. Use the label aesthetic to map to the label in your data (in this case, state). geom_label by default will use the x and y aesthetics defined in ggplot()\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = annual_salary_median, color = state)) +\n  geom_line(show.legend = FALSE, linewidth = 2) +\n  geom_text(\n    data = nurses_subset |&gt; filter(year == max(year)),\n    aes(label = state)\n  ) +\n  scale_y_continuous(labels = scales::label_dollar(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"Year\", y = \"Annual median salary\", color = \"State\",\n    title = \"Annual median salary of Registered Nurses\"\n  ) +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    plot.margin = margin(0.1, 0.9, 0.1, 0.1, \"in\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#direct-labeling-2",
    "href": "slides/06/slides06.html#direct-labeling-2",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Direct Labeling",
    "text": "Direct Labeling\n(Here’s what it looks like if we don’t filter to the endpoints)\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = annual_salary_median, color = state)) +\n  geom_line(show.legend = FALSE, linewidth = 2) +\n  geom_text(\n    aes(label = state)\n  ) +\n  scale_y_continuous(labels = scales::label_dollar(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"Year\", y = \"Annual median salary\", color = \"State\",\n    title = \"Annual median salary of Registered Nurses\"\n  ) +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    plot.margin = margin(0.1, 0.9, 0.1, 0.1, \"in\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#direct-labeling-3",
    "href": "slides/06/slides06.html#direct-labeling-3",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Direct Labeling",
    "text": "Direct Labeling\nhjust=0 means “left justified”, or make the label start at the x-y coordinate you gave it. size = 6 makes the label bigger\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = annual_salary_median, color = state)) +\n  geom_line(show.legend = FALSE, linewidth = 2) +\n  geom_text(\n    data = nurses_subset |&gt; filter(year == max(year)),\n    aes(label = state), \n    hjust = 0, \n    size = 6\n  ) +\n  scale_y_continuous(labels = scales::label_dollar(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"Year\", y = \"Annual median salary\", color = \"State\",\n    title = \"Annual median salary of Registered Nurses\"\n  ) +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    plot.margin = margin(0.1, 0.9, 0.1, 0.1, \"in\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#direct-labeling-4",
    "href": "slides/06/slides06.html#direct-labeling-4",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Direct Labeling",
    "text": "Direct Labeling\nnudge_x = 1 “nudges” each label one unit in the x-direction (so each label is a small distance away from what it’s labeling). show.legend=FALSE tells ggplot not to include the aesthetics for geom_text in the legend\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = annual_salary_median, color = state)) +\n  geom_line(show.legend = FALSE, linewidth = 2) +\n  geom_text(\n    data = nurses_subset |&gt; filter(year == max(year)),\n    aes(label = state), \n    hjust = 0, \n    size = 6,\n    nudge_x = 1,\n    show.legend = FALSE,\n  ) +\n  scale_y_continuous(labels = scales::label_dollar(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"Year\", y = \"Annual median salary\", color = \"State\",\n    title = \"Annual median salary of Registered Nurses\"\n  ) +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    plot.margin = margin(0.1, 0.9, 0.1, 0.1, \"in\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#direct-labeling-5",
    "href": "slides/06/slides06.html#direct-labeling-5",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Direct Labeling",
    "text": "Direct Labeling\nFinally, we have to tell ggplot not to trim the plot, and leave room in the right margin for the labels themselves\n\n\nnurses_subset |&gt;\n  ggplot(aes(x = year, y = annual_salary_median, color = state)) +\n  geom_line(show.legend = FALSE, linewidth = 2) +\n  geom_text(\n    data = nurses_subset |&gt; filter(year == max(year)),\n    aes(label = state), \n    hjust = 0, \n    size = 6,\n    nudge_x = 1,\n    show.legend = FALSE,\n  ) +\n  scale_y_continuous(labels = scales::label_dollar(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"Year\", y = \"Annual median salary\", color = \"State\",\n    title = \"Annual median salary of Registered Nurses\"\n  ) +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    plot.margin = margin(0.1, 0.9, 0.1, 0.1, \"in\")\n    )"
  },
  {
    "objectID": "slides/06/slides06.html#add-whitespace",
    "href": "slides/06/slides06.html#add-whitespace",
    "title": "(Closer to) Accessible Data Viz",
    "section": "Add whitespace",
    "text": "Add whitespace\nSet the color aesthetic to white\n\n\nnurses_subset |&gt;\n  filter(year %in% c(2000, 2010, 2020)) |&gt;\n  ggplot(aes(x = factor(year), y = total_employed_rn, fill = state)) +\n  geom_col(position = \"fill\", color = \"white\", linewidth = 1) +\n  labs(\n    x = \"Year\", y = \"Proportion of Registered Nurses\", fill = \"State\",\n    title = \"Total employed Registered Nurses\"\n  )"
  },
  {
    "objectID": "slides/12/slides12.html#today",
    "href": "slides/12/slides12.html#today",
    "title": "Working with Factors",
    "section": "Today",
    "text": "Today\n\nsetup chunk and alt-text\nHW5 and Portfolio 2 grace period\nNew stuff!"
  },
  {
    "objectID": "slides/12/slides12.html#survivor-castaways-data",
    "href": "slides/12/slides12.html#survivor-castaways-data",
    "title": "Working with Factors",
    "section": "Survivor castaways data",
    "text": "Survivor castaways data\n\n\n# A tibble: 1,351 × 29\n   version version_season season_name      season full_name castaway_id castaway\n   &lt;fct&gt;   &lt;chr&gt;          &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;   \n 1 US      US01           Survivor: Borneo      1 Sonja Ch… US0001      Sonja   \n 2 US      US01           Survivor: Borneo      1 B.B. And… US0002      B.B.    \n 3 US      US01           Survivor: Borneo      1 Stacey S… US0003      Stacey  \n 4 US      US01           Survivor: Borneo      1 Ramona G… US0004      Ramona  \n 5 US      US01           Survivor: Borneo      1 Dirk Been US0005      Dirk    \n 6 US      US01           Survivor: Borneo      1 Joel Klug US0006      Joel    \n 7 US      US01           Survivor: Borneo      1 Gretchen… US0007      Gretchen\n 8 US      US01           Survivor: Borneo      1 Greg Buis US0008      Greg    \n 9 US      US01           Survivor: Borneo      1 Jenna Le… US0009      Jenna   \n10 US      US01           Survivor: Borneo      1 Gervase … US0010      Gervase \n# ℹ 1,341 more rows\n# ℹ 22 more variables: age &lt;dbl&gt;, city &lt;chr&gt;, state &lt;chr&gt;, episode &lt;dbl&gt;,\n#   day &lt;dbl&gt;, order &lt;dbl&gt;, result &lt;chr&gt;, place &lt;dbl&gt;, jury_status &lt;chr&gt;,\n#   original_tribe &lt;chr&gt;, jury &lt;lgl&gt;, finalist &lt;lgl&gt;, winner &lt;lgl&gt;,\n#   acknowledge &lt;lgl&gt;, ack_look &lt;lgl&gt;, ack_speak &lt;lgl&gt;, ack_gesture &lt;lgl&gt;,\n#   ack_smile &lt;lgl&gt;, ack_quote &lt;chr&gt;, ack_score &lt;dbl&gt;, jury1 &lt;dbl&gt;, jury2 &lt;fct&gt;"
  },
  {
    "objectID": "slides/12/slides12.html#both-of-these-are-categorical-variables",
    "href": "slides/12/slides12.html#both-of-these-are-categorical-variables",
    "title": "Working with Factors",
    "section": "Both of these are categorical variables",
    "text": "Both of these are categorical variables\n\nunique(castaways$version)\n\n[1] US AU SA UK NZ\nLevels: AU NZ SA UK US\n\n\n\nunique(castaways$season_name) %&gt;% head()\n\n[1] \"Survivor: Borneo\"                 \"Survivor: The Australian Outback\"\n[3] \"Survivor: Africa\"                 \"Survivor: Marquesas\"             \n[5] \"Survivor: Thailand\"               \"Survivor: The Amazon\"            \n\n\n\nBut are stored as different types\n\nclass(castaways$version)\n\n[1] \"factor\"\n\n\n\nclass(castaways$season_name) \n\n[1] \"character\""
  },
  {
    "objectID": "slides/12/slides12.html#same-graph-colored-by-the-same-categorical-variable",
    "href": "slides/12/slides12.html#same-graph-colored-by-the-same-categorical-variable",
    "title": "Working with Factors",
    "section": "Same graph, colored by the same categorical variable",
    "text": "Same graph, colored by the same categorical variable"
  },
  {
    "objectID": "slides/12/slides12.html#factors",
    "href": "slides/12/slides12.html#factors",
    "title": "Working with Factors",
    "section": "Factors",
    "text": "Factors\nR’s representation of categorical data. Consists of:\n\nA set of values\nAn ordered set of valid levels\n\n\n\neyes &lt;- factor(x = c(\"blue\", \"green\", \"green\"), \n               levels = c(\"blue\", \"brown\", \"green\"))\neyes\n\n[1] blue  green green\nLevels: blue brown green"
  },
  {
    "objectID": "slides/12/slides12.html#factors-1",
    "href": "slides/12/slides12.html#factors-1",
    "title": "Working with Factors",
    "section": "Factors",
    "text": "Factors\nStored as an integer vector with a levels attribute\n\nunclass(eyes)\n\n[1] 1 3 3\nattr(,\"levels\")\n[1] \"blue\"  \"brown\" \"green\""
  },
  {
    "objectID": "slides/12/slides12.html#section",
    "href": "slides/12/slides12.html#section",
    "title": "Working with Factors",
    "section": "",
    "text": "Simple functions for working with factors.\nPart of the tidyverse\n\n\n# loaded with tidyverse\nlibrary(forcats)"
  },
  {
    "objectID": "slides/12/slides12.html#gss_cat",
    "href": "slides/12/slides12.html#gss_cat",
    "title": "Working with Factors",
    "section": "gss_cat",
    "text": "gss_cat\nA sample of data from the General Social Survey, a long-running US survey conducted by NORC at the University of Chicago.\n\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Not str r… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Strong de… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Ind,near … Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n10  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n# ℹ 21,473 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#warm-up",
    "href": "slides/12/slides12.html#warm-up",
    "title": "Working with Factors",
    "section": "Warm up",
    "text": "Warm up\n\nUse gss_cat to answer the following questions.\n\nWhich religions watch the least TV?\nDo married people watch more or less TV than single people?\n\n\n\n\n\n\n−&plus;\n\n04:00"
  },
  {
    "objectID": "slides/12/slides12.html#which-religions-watch-the-least-tv",
    "href": "slides/12/slides12.html#which-religions-watch-the-least-tv",
    "title": "Working with Factors",
    "section": "Which religions watch the least TV?",
    "text": "Which religions watch the least TV?\n\n\n\ngss_cat\n\n\n\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Not str r… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Strong de… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Ind,near … Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n10  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n# ℹ 21,473 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#which-religions-watch-the-least-tv-1",
    "href": "slides/12/slides12.html#which-religions-watch-the-least-tv-1",
    "title": "Working with Factors",
    "section": "Which religions watch the least TV?",
    "text": "Which religions watch the least TV?\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours)\n\n\n\n\n# A tibble: 11,337 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 3  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 4  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 5  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 6  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n 7  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n 8  2000 Married          53 White $25000 or more Not str d… Prot… Other       2\n 9  2000 Married          52 White $25000 or more Strong de… Prot… Sout…       1\n10  2000 Divorced         52 White $25000 or more Ind,near … None  Not …       1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#which-religions-watch-the-least-tv-2",
    "href": "slides/12/slides12.html#which-religions-watch-the-least-tv-2",
    "title": "Working with Factors",
    "section": "Which religions watch the least TV?",
    "text": "Which religions watch the least TV?\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  group_by(relig)\n\n\n\n\n# A tibble: 11,337 × 9\n# Groups:   relig [15]\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 3  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 4  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 5  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 6  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n 7  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n 8  2000 Married          53 White $25000 or more Not str d… Prot… Other       2\n 9  2000 Married          52 White $25000 or more Strong de… Prot… Sout…       1\n10  2000 Divorced         52 White $25000 or more Ind,near … None  Not …       1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#which-religions-watch-the-least-tv-3",
    "href": "slides/12/slides12.html#which-religions-watch-the-least-tv-3",
    "title": "Working with Factors",
    "section": "Which religions watch the least TV?",
    "text": "Which religions watch the least TV?\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  group_by(relig) %&gt;%\n  summarize(tvhours = mean(tvhours))\n\n\n\n\n# A tibble: 15 × 2\n   relig                   tvhours\n   &lt;fct&gt;                     &lt;dbl&gt;\n 1 No answer                  2.72\n 2 Don't know                 4.62\n 3 Inter-nondenominational    2.87\n 4 Native american            3.46\n 5 Christian                  2.79\n 6 Orthodox-christian         2.42\n 7 Moslem/islam               2.44\n 8 Other eastern              1.67\n 9 Hinduism                   1.89\n10 Buddhism                   2.38\n11 Other                      2.73\n12 None                       2.71\n13 Jewish                     2.52\n14 Catholic                   2.96\n15 Protestant                 3.15"
  },
  {
    "objectID": "slides/12/slides12.html#which-religions-watch-the-least-tv-4",
    "href": "slides/12/slides12.html#which-religions-watch-the-least-tv-4",
    "title": "Working with Factors",
    "section": "Which religions watch the least TV?",
    "text": "Which religions watch the least TV?\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  group_by(relig) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, relig))"
  },
  {
    "objectID": "slides/12/slides12.html#which-religions-watch-the-least-tv-5",
    "href": "slides/12/slides12.html#which-religions-watch-the-least-tv-5",
    "title": "Working with Factors",
    "section": "Which religions watch the least TV?",
    "text": "Which religions watch the least TV?\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  group_by(relig) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, relig)) +\n    geom_point()"
  },
  {
    "objectID": "slides/12/slides12.html#which-do-you-prefer",
    "href": "slides/12/slides12.html#which-do-you-prefer",
    "title": "Working with Factors",
    "section": "Which do you prefer?",
    "text": "Which do you prefer?"
  },
  {
    "objectID": "slides/12/slides12.html#why-is-the-y-axis-in-this-order",
    "href": "slides/12/slides12.html#why-is-the-y-axis-in-this-order",
    "title": "Working with Factors",
    "section": "Why is the y-axis in this order?",
    "text": "Why is the y-axis in this order?"
  },
  {
    "objectID": "slides/12/slides12.html#levels",
    "href": "slides/12/slides12.html#levels",
    "title": "Working with Factors",
    "section": "levels()",
    "text": "levels()\nUse levels() to access a factor’s levels\n\ngss_cat %&gt;% pull(relig) %&gt;% levels()\n\n [1] \"No answer\"               \"Don't know\"             \n [3] \"Inter-nondenominational\" \"Native american\"        \n [5] \"Christian\"               \"Orthodox-christian\"     \n [7] \"Moslem/islam\"            \"Other eastern\"          \n [9] \"Hinduism\"                \"Buddhism\"               \n[11] \"Other\"                   \"None\"                   \n[13] \"Jewish\"                  \"Catholic\"               \n[15] \"Protestant\"              \"Not applicable\""
  },
  {
    "objectID": "slides/12/slides12.html#most-useful-factor-skills",
    "href": "slides/12/slides12.html#most-useful-factor-skills",
    "title": "Working with Factors",
    "section": "Most useful factor skills:",
    "text": "Most useful factor skills:\n1. Reorder the levels\n2. Recode the levels\n3. Collapse levels"
  },
  {
    "objectID": "slides/12/slides12.html#fct_reorder",
    "href": "slides/12/slides12.html#fct_reorder",
    "title": "Working with Factors",
    "section": "fct_reorder",
    "text": "fct_reorder\n\n\n\n\n.f factor vector\n\n.x variable to reorder by (in conjunction with .fun)\n\n.fun function to reorder by\n\n.desc put levels in descending order?\n\n\n\nfct_reorder(\n  .f, \n  .x, \n  .fun = median, \n  ...,\n  .desc = FALSE \n  )"
  },
  {
    "objectID": "slides/12/slides12.html#reorder-relig-by-tvhours",
    "href": "slides/12/slides12.html#reorder-relig-by-tvhours",
    "title": "Working with Factors",
    "section": "Reorder relig by tvhours",
    "text": "Reorder relig by tvhours\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  group_by(relig) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(\n    x = tvhours,\n    y = relig\n  )) +\n    geom_point()"
  },
  {
    "objectID": "slides/12/slides12.html#reorder-relig-by-tvhours-1",
    "href": "slides/12/slides12.html#reorder-relig-by-tvhours-1",
    "title": "Working with Factors",
    "section": "Reorder relig by tvhours",
    "text": "Reorder relig by tvhours\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  group_by(relig) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(\n    x = tvhours,\n    y = fct_reorder(relig, tvhours)                 #ROTATE\n  )) +\n    geom_point()"
  },
  {
    "objectID": "slides/12/slides12.html#try-it",
    "href": "slides/12/slides12.html#try-it",
    "title": "Working with Factors",
    "section": "Try it",
    "text": "Try it\n\nUse rincome_summary to construct a dotplot of rincome against age.\nReorder rincome by age\n\n\nrincome_summary &lt;- gss_cat %&gt;%\n  group_by(rincome) %&gt;%\n  summarize(\n    age = mean(age, na.rm = TRUE),\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\n\n\n\n\n−&plus;\n\n02:30"
  },
  {
    "objectID": "slides/12/slides12.html#which-do-you-prefer-1",
    "href": "slides/12/slides12.html#which-do-you-prefer-1",
    "title": "Working with Factors",
    "section": "Which do you prefer?",
    "text": "Which do you prefer?"
  },
  {
    "objectID": "slides/12/slides12.html#fct_reorder2",
    "href": "slides/12/slides12.html#fct_reorder2",
    "title": "Working with Factors",
    "section": "fct_reorder2",
    "text": "fct_reorder2\nReorders the levels of a factor by the Y values associated with the largest X values.\n\n\n\n\n.f factor vector\n\n.x X variable\n\n.y Y variable\n\n.fun function to reorder by\n\n.desc put levels in descending order?\n\n\n\nfct_reorder2(\n  .f, \n  .x, \n  .y, \n  .fun = median, \n  ...,\n  .desc = FALSE\n  )"
  },
  {
    "objectID": "slides/12/slides12.html#reorder-marital",
    "href": "slides/12/slides12.html#reorder-marital",
    "title": "Working with Factors",
    "section": "Reorder marital",
    "text": "Reorder marital\n\n\n\ngss_cat %&gt;%\n  drop_na(age) %&gt;%\n  count(age, marital) %&gt;%\n  group_by(age) %&gt;%\n  mutate(prop = n / sum(n)) %&gt;%\n  ggplot(\n    aes(age,\n        prop,\n        color = marital )) +\n\n  geom_line() +\n  scale_color_colorblind(\"\")"
  },
  {
    "objectID": "slides/12/slides12.html#reorder-marital-1",
    "href": "slides/12/slides12.html#reorder-marital-1",
    "title": "Working with Factors",
    "section": "Reorder marital",
    "text": "Reorder marital\n\n\n\ngss_cat %&gt;%\n  drop_na(age) %&gt;%\n  count(age, marital) %&gt;%\n  group_by(age) %&gt;%\n  mutate(prop = n / sum(n)) %&gt;%\n  ggplot(\n    aes(age,\n        prop,\n        color = fct_reorder2(marital, .x = age, .y = prop))) + #ROTATE\n\n  geom_line() +\n  scale_color_colorblind(\"\")"
  },
  {
    "objectID": "slides/12/slides12.html#other-reordering-functions",
    "href": "slides/12/slides12.html#other-reordering-functions",
    "title": "Working with Factors",
    "section": "Other reordering functions",
    "text": "Other reordering functions\n\n\n\ngss_cat %&gt;%\n  ggplot() +\n  geom_bar(aes(x = marital))"
  },
  {
    "objectID": "slides/12/slides12.html#other-reordering-functions-1",
    "href": "slides/12/slides12.html#other-reordering-functions-1",
    "title": "Working with Factors",
    "section": "Other reordering functions",
    "text": "Other reordering functions\n\n\n\ngss_cat %&gt;%\n  ggplot() +\n  geom_bar(aes(x = fct_infreq(marital)))"
  },
  {
    "objectID": "slides/12/slides12.html#other-reordering-functions-2",
    "href": "slides/12/slides12.html#other-reordering-functions-2",
    "title": "Working with Factors",
    "section": "Other reordering functions",
    "text": "Other reordering functions\n\n\n\ngss_cat %&gt;%\n  ggplot() +\n  geom_bar(aes(x = fct_rev(fct_infreq(marital))))"
  },
  {
    "objectID": "slides/12/slides12.html#which-political-leaning-watches-more-tv",
    "href": "slides/12/slides12.html#which-political-leaning-watches-more-tv",
    "title": "Working with Factors",
    "section": "Which political leaning watches more TV?",
    "text": "Which political leaning watches more TV?\n\n\n\n\n\n\n\n\nHow could we improve the partyid labels?"
  },
  {
    "objectID": "slides/12/slides12.html#fct_recode",
    "href": "slides/12/slides12.html#fct_recode",
    "title": "Working with Factors",
    "section": "fct_recode",
    "text": "fct_recode\nChanges values of levels\n\n\n\n\n.f factor vector\n\n... new level = old level pairs (as a named character vector)\n\n\n\nfct_recode(.f, ...)"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid",
    "href": "slides/12/slides12.html#recoding-partyid",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat\n\n\n\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Not str r… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Strong de… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Ind,near … Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n10  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n# ℹ 21,473 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-1",
    "href": "slides/12/slides12.html#recoding-partyid-1",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours)\n\n\n\n\n# A tibble: 11,337 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 3  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 4  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 5  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 6  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n 7  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n 8  2000 Married          53 White $25000 or more Not str d… Prot… Other       2\n 9  2000 Married          52 White $25000 or more Strong de… Prot… Sout…       1\n10  2000 Divorced         52 White $25000 or more Ind,near … None  Not …       1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-2",
    "href": "slides/12/slides12.html#recoding-partyid-2",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours)\n\n\n\n\n# A tibble: 11,337 × 2\n   partyid            tvhours\n   &lt;fct&gt;                &lt;int&gt;\n 1 Ind,near rep            12\n 2 Independent              2\n 3 Ind,near rep             4\n 4 Not str democrat         1\n 5 Not str republican       3\n 6 Not str democrat         0\n 7 Strong republican        3\n 8 Not str democrat         2\n 9 Strong democrat          1\n10 Ind,near dem             1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-3",
    "href": "slides/12/slides12.html#recoding-partyid-3",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n    mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\"))\n\n\n\n\n# A tibble: 11,337 × 2\n   partyid               tvhours\n   &lt;fct&gt;                   &lt;int&gt;\n 1 Independent, near rep      12\n 2 Independent                 2\n 3 Independent, near rep       4\n 4 Democrat, weak              1\n 5 Republican, weak            3\n 6 Democrat, weak              0\n 7 Republican, strong          3\n 8 Democrat, weak              2\n 9 Democrat, strong            1\n10 Independent, near dem       1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-4",
    "href": "slides/12/slides12.html#recoding-partyid-4",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n    mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\")) %&gt;%\n  group_by(partyid)\n\n\n\n\n# A tibble: 11,337 × 2\n# Groups:   partyid [10]\n   partyid               tvhours\n   &lt;fct&gt;                   &lt;int&gt;\n 1 Independent, near rep      12\n 2 Independent                 2\n 3 Independent, near rep       4\n 4 Democrat, weak              1\n 5 Republican, weak            3\n 6 Democrat, weak              0\n 7 Republican, strong          3\n 8 Democrat, weak              2\n 9 Democrat, strong            1\n10 Independent, near dem       1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-5",
    "href": "slides/12/slides12.html#recoding-partyid-5",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n    mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\")) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours))\n\n\n\n\n# A tibble: 10 × 2\n   partyid               tvhours\n   &lt;fct&gt;                   &lt;dbl&gt;\n 1 No answer                3.22\n 2 Don't know               2   \n 3 Other party              2.79\n 4 Republican, strong       2.72\n 5 Republican, weak         2.63\n 6 Independent, near rep    2.77\n 7 Independent              3.08\n 8 Independent, near dem    2.80\n 9 Democrat, weak           3.04\n10 Democrat, strong         3.52"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-6",
    "href": "slides/12/slides12.html#recoding-partyid-6",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n    mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\")) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, fct_reorder(partyid, tvhours)))"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-7",
    "href": "slides/12/slides12.html#recoding-partyid-7",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n    mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\")) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, fct_reorder(partyid, tvhours))) +\n  geom_point()"
  },
  {
    "objectID": "slides/12/slides12.html#recoding-partyid-8",
    "href": "slides/12/slides12.html#recoding-partyid-8",
    "title": "Working with Factors",
    "section": "Recoding partyid",
    "text": "Recoding partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n    mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\")) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, fct_reorder(partyid, tvhours))) +\n  geom_point() +\n  labs(y = \"partyid\")"
  },
  {
    "objectID": "slides/12/slides12.html#how-can-we-combine-these-factor-levels",
    "href": "slides/12/slides12.html#how-can-we-combine-these-factor-levels",
    "title": "Working with Factors",
    "section": "How can we combine these factor levels?",
    "text": "How can we combine these factor levels?"
  },
  {
    "objectID": "slides/12/slides12.html#fct_collapse",
    "href": "slides/12/slides12.html#fct_collapse",
    "title": "Working with Factors",
    "section": "fct_collapse()",
    "text": "fct_collapse()\nChanges multiple levels into single levels\n\n\n\n\n.f factor vector\n\n... named arguments set to a character vector (levels in the vector will be collapsed to the name of the argument)\n\n\n\nfct_collapse(.f, ...)"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid",
    "href": "slides/12/slides12.html#collapsing-partyid",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat\n\n\n\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Not str r… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Strong de… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Ind,near … Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n10  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n# ℹ 21,473 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-1",
    "href": "slides/12/slides12.html#collapsing-partyid-1",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours)\n\n\n\n\n# A tibble: 11,337 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 3  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 4  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 5  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 6  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n 7  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n 8  2000 Married          53 White $25000 or more Not str d… Prot… Other       2\n 9  2000 Married          52 White $25000 or more Strong de… Prot… Sout…       1\n10  2000 Divorced         52 White $25000 or more Ind,near … None  Not …       1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-2",
    "href": "slides/12/slides12.html#collapsing-partyid-2",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours)\n\n\n\n\n# A tibble: 11,337 × 2\n   partyid            tvhours\n   &lt;fct&gt;                &lt;int&gt;\n 1 Ind,near rep            12\n 2 Independent              2\n 3 Ind,near rep             4\n 4 Not str democrat         1\n 5 Not str republican       3\n 6 Not str democrat         0\n 7 Strong republican        3\n 8 Not str democrat         2\n 9 Strong democrat          1\n10 Ind,near dem             1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-3",
    "href": "slides/12/slides12.html#collapsing-partyid-3",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n  mutate(\n    partyid =\n      fct_collapse(\n        partyid,\n        conservative = c(\"Strong republican\",\n                         \"Not str republican\",\n                         \"Ind,near rep\"),\n        liberal = c(\"Strong democrat\",\n                    \"Not str democrat\",\n                    \"Ind,near dem\"))\n  )\n\n\n\n\n# A tibble: 11,337 × 2\n   partyid      tvhours\n   &lt;fct&gt;          &lt;int&gt;\n 1 conservative      12\n 2 Independent        2\n 3 conservative       4\n 4 liberal            1\n 5 conservative       3\n 6 liberal            0\n 7 conservative       3\n 8 liberal            2\n 9 liberal            1\n10 liberal            1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-4",
    "href": "slides/12/slides12.html#collapsing-partyid-4",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n  mutate(\n    partyid =\n      fct_collapse(\n        partyid,\n        conservative = c(\"Strong republican\",\n                         \"Not str republican\",\n                         \"Ind,near rep\"),\n        liberal = c(\"Strong democrat\",\n                    \"Not str democrat\",\n                    \"Ind,near dem\"))\n  ) %&gt;%\n  group_by(partyid)\n\n\n\n\n# A tibble: 11,337 × 2\n# Groups:   partyid [6]\n   partyid      tvhours\n   &lt;fct&gt;          &lt;int&gt;\n 1 conservative      12\n 2 Independent        2\n 3 conservative       4\n 4 liberal            1\n 5 conservative       3\n 6 liberal            0\n 7 conservative       3\n 8 liberal            2\n 9 liberal            1\n10 liberal            1\n# ℹ 11,327 more rows"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-5",
    "href": "slides/12/slides12.html#collapsing-partyid-5",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n  mutate(\n    partyid =\n      fct_collapse(\n        partyid,\n        conservative = c(\"Strong republican\",\n                         \"Not str republican\",\n                         \"Ind,near rep\"),\n        liberal = c(\"Strong democrat\",\n                    \"Not str democrat\",\n                    \"Ind,near dem\"))\n  ) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours))\n\n\n\n\n# A tibble: 6 × 2\n  partyid      tvhours\n  &lt;fct&gt;          &lt;dbl&gt;\n1 No answer       3.22\n2 Don't know      2   \n3 Other party     2.79\n4 conservative    2.69\n5 Independent     3.08\n6 liberal         3.15"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-6",
    "href": "slides/12/slides12.html#collapsing-partyid-6",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n  mutate(\n    partyid =\n      fct_collapse(\n        partyid,\n        conservative = c(\"Strong republican\",\n                         \"Not str republican\",\n                         \"Ind,near rep\"),\n        liberal = c(\"Strong democrat\",\n                    \"Not str democrat\",\n                    \"Ind,near dem\"))\n  ) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, fct_reorder(partyid, tvhours)))"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-7",
    "href": "slides/12/slides12.html#collapsing-partyid-7",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n  mutate(\n    partyid =\n      fct_collapse(\n        partyid,\n        conservative = c(\"Strong republican\",\n                         \"Not str republican\",\n                         \"Ind,near rep\"),\n        liberal = c(\"Strong democrat\",\n                    \"Not str democrat\",\n                    \"Ind,near dem\"))\n  ) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, fct_reorder(partyid, tvhours))) +\n  geom_point()"
  },
  {
    "objectID": "slides/12/slides12.html#collapsing-partyid-8",
    "href": "slides/12/slides12.html#collapsing-partyid-8",
    "title": "Working with Factors",
    "section": "Collapsing partyid",
    "text": "Collapsing partyid\n\n\n\ngss_cat %&gt;%\n  drop_na(tvhours) %&gt;%\n  select(partyid, tvhours) %&gt;%\n  mutate(\n    partyid =\n      fct_collapse(\n        partyid,\n        conservative = c(\"Strong republican\",\n                         \"Not str republican\",\n                         \"Ind,near rep\"),\n        liberal = c(\"Strong democrat\",\n                    \"Not str democrat\",\n                    \"Ind,near dem\"))\n  ) %&gt;%\n  group_by(partyid) %&gt;%\n  summarize(tvhours = mean(tvhours)) %&gt;%\n  ggplot(aes(tvhours, fct_reorder(partyid, tvhours))) +\n  geom_point() +\n  labs(y = \"partyid\")"
  },
  {
    "objectID": "slides/12/slides12.html#your-turn",
    "href": "slides/12/slides12.html#your-turn",
    "title": "Working with Factors",
    "section": "Your turn",
    "text": "Your turn\n\nCollapse the marital variable to have levels Married, not_married, and No answer\nInclude \"Never married\", \"Divorced\", and “Widowed\" in not_married\n\n\n\n\n\n−&plus;\n\n02:00"
  },
  {
    "objectID": "slides/12/slides12.html#there-are-relatively-few-points-in-each-of-these-groups",
    "href": "slides/12/slides12.html#there-are-relatively-few-points-in-each-of-these-groups",
    "title": "Working with Factors",
    "section": "There are relatively few points in each of these groups",
    "text": "There are relatively few points in each of these groups"
  },
  {
    "objectID": "slides/12/slides12.html#fct_lump",
    "href": "slides/12/slides12.html#fct_lump",
    "title": "Working with Factors",
    "section": "fct_lump()",
    "text": "fct_lump()\nCollapses levels with fewest values into a single level.\nBy default collapses as many levels as possible such that the new level is still the smallest.\n\n\n\n\nf factor vector\n\nn preserve the most common n levels\nother_level = \"Other\"\n\n\n\nfct_lump(\n  f, \n  n, \n  other_level = \"Other\", \n  ...\n)"
  },
  {
    "objectID": "slides/12/slides12.html#lumping-parytid",
    "href": "slides/12/slides12.html#lumping-parytid",
    "title": "Working with Factors",
    "section": "Lumping parytid",
    "text": "Lumping parytid\n\n\n\ngss_cat %&gt;%\n  mutate(partyid = partyid) %&gt;%\n  ggplot(aes(partyid)) +\n  geom_bar() +\n  labs(x = \"partyid\")"
  },
  {
    "objectID": "slides/12/slides12.html#lumping-parytid-1",
    "href": "slides/12/slides12.html#lumping-parytid-1",
    "title": "Working with Factors",
    "section": "Lumping parytid",
    "text": "Lumping parytid\n\n\n\ngss_cat %&gt;%\n  mutate(partyid = fct_lump(partyid, n = 2)) %&gt;%\n  ggplot(aes(partyid)) +\n  geom_bar() +\n  labs(x = \"partyid\")"
  },
  {
    "objectID": "slides/12/slides12.html#lumping-parytid-2",
    "href": "slides/12/slides12.html#lumping-parytid-2",
    "title": "Working with Factors",
    "section": "Lumping parytid",
    "text": "Lumping parytid\n\n\n\ngss_cat %&gt;%\n  mutate(partyid = fct_lump(partyid, n = 3)) %&gt;%\n  ggplot(aes(partyid)) +\n  geom_bar() +\n  labs(x = \"partyid\")"
  },
  {
    "objectID": "slides/14/slides14.html#today",
    "href": "slides/14/slides14.html#today",
    "title": "Text Analysis",
    "section": "Today",
    "text": "Today\n\nMidterm check-in\nQuestions about lab quiz, project, etc.\nRegex\nIntro to Text Analysis"
  },
  {
    "objectID": "slides/14/slides14.html#midterm-check-in",
    "href": "slides/14/slides14.html#midterm-check-in",
    "title": "Text Analysis",
    "section": "Midterm check-in",
    "text": "Midterm check-in\nThings that are going well:\n\nLike getting immediate practice in class\nLearning a lot on homeworks\nBecoming more efficient/neater/cleaner/cleverer in R\nBuilding a presence on GitHub\nWorking with peers\nBuilding confidence\n\nggplot skills\nEnjoying coming to class (demos, lectures, group work, activities)"
  },
  {
    "objectID": "slides/14/slides14.html#overview-of-responses",
    "href": "slides/14/slides14.html#overview-of-responses",
    "title": "Text Analysis",
    "section": "Overview of responses",
    "text": "Overview of responses\n[graphs from google]"
  },
  {
    "objectID": "slides/14/slides14.html#suggested-changes",
    "href": "slides/14/slides14.html#suggested-changes",
    "title": "Text Analysis",
    "section": "Suggested changes:",
    "text": "Suggested changes:\n\nCheat sheets on quizzes ✅\nPost solutions to in-class exercises ✅\nMore time for in-class lab quizzes ﹖\n\nMy takeaways\n\nMore direction on portfolio projects with clear rubrics\nLimit “tricky” homework problems each assignment\nDo more live coding/demos in class"
  },
  {
    "objectID": "slides/14/slides14.html#suggested-changes-1",
    "href": "slides/14/slides14.html#suggested-changes-1",
    "title": "Text Analysis",
    "section": "Suggested changes:",
    "text": "Suggested changes:\n\nLectures aren’t helpful and we should dedicate more time to in-class coding practice\nPlease spend more time explaining commands and doing demos before we do in-class coding practice\nWe should have more time doing “your turn” activities so we have time to talk through them in groups\nWe should condense the time spent on “your turn” activities so we can get through everything on the slides and have more demos\nThe homeworks stress me out because they’re too long; fewer problems would help\nThe homeworks stress me out because they sometimes contain less than 10 problems. Maybe they should be longer?"
  },
  {
    "objectID": "slides/14/slides14.html#concerns-about-grading-scheme",
    "href": "slides/14/slides14.html#concerns-about-grading-scheme",
    "title": "Text Analysis",
    "section": "Concerns about grading scheme:",
    "text": "Concerns about grading scheme:\n\nLots of frustration about lack of partial credit on homework\nStill getting comfy with revisions on projects\n\n“I worked really hard and made a couple small mistakes and had to do a revision”\n\n\n“Bar” for homework/portfolio projects feels high\nTime pressures on lab quizzes"
  },
  {
    "objectID": "slides/14/slides14.html#goals-of-the-grading-scheme",
    "href": "slides/14/slides14.html#goals-of-the-grading-scheme",
    "title": "Text Analysis",
    "section": "Goals of the grading scheme:",
    "text": "Goals of the grading scheme:\n\n\nHomework\n\nCan you apply techniques from class/readings in new settings?\nCan you read R documentation to figure out new things?\nCan you work through some tricky ideas without a time limit?\n\n\nPortfolio Projects\n\nCan you answer less-structured questions with data?\nAre you learning how to “scope” a data analysis?\nCan you put together a polished final product?\n\n\nLab Quizzes\n\nCan you repeat things we have done in class and on homework with limited access to resources?\nAre you learning how to answer questions with data quickly?\nAre you developing proficiency with R?\n\n\n\nRevision is a key part of this course design!"
  },
  {
    "objectID": "slides/14/slides14.html#example",
    "href": "slides/14/slides14.html#example",
    "title": "Text Analysis",
    "section": "Example",
    "text": "Example\nSuppose we wish to anonymize phone numbers in survey results\n\na1 &lt;- \"Home: 507-645-5489\"\na2 &lt;- \"Cell: 219.917.9871\"\na3 &lt;- \"My work phone is 507-202-2332\"\na4 &lt;- \"I don't have a phone\"\ninfo &lt;- c(a1, a2, a3, a4)\n\n\n\n[1] \"Home: 507-645-5489\"            \"Cell: 219.917.9871\"           \n[3] \"My work phone is 507-202-2332\" \"I don't have a phone\""
  },
  {
    "objectID": "slides/14/slides14.html#visualizing-matches",
    "href": "slides/14/slides14.html#visualizing-matches",
    "title": "Text Analysis",
    "section": "Visualizing matches",
    "text": "Visualizing matches\nThe helper function str_view() finds regex matches\n\nstr_view(a1, \"5\")\n\n[1] │ Home: &lt;5&gt;07-64&lt;5&gt;-&lt;5&gt;489"
  },
  {
    "objectID": "slides/14/slides14.html#match-any-character",
    "href": "slides/14/slides14.html#match-any-character",
    "title": "Text Analysis",
    "section": "\n. match any character",
    "text": ". match any character\nFind a “-” and any (.) character that follows\n\nstr_view(a1, \"-.\")\n\n[1] │ Home: 507&lt;-6&gt;45&lt;-5&gt;489"
  },
  {
    "objectID": "slides/14/slides14.html#match-any-occurence",
    "href": "slides/14/slides14.html#match-any-occurence",
    "title": "Text Analysis",
    "section": "\n[] match any occurence",
    "text": "[] match any occurence\nFind any numbers between 0 and 9\n\nstr_view(a1, \"[0123456789]\")\n\n[1] │ Home: &lt;5&gt;&lt;0&gt;&lt;7&gt;-&lt;6&gt;&lt;4&gt;&lt;5&gt;-&lt;5&gt;&lt;4&gt;&lt;8&gt;&lt;9&gt;"
  },
  {
    "objectID": "slides/14/slides14.html#match-any-occurence-1",
    "href": "slides/14/slides14.html#match-any-occurence-1",
    "title": "Text Analysis",
    "section": "\n[] match any occurence",
    "text": "[] match any occurence\nFind any numbers between 2 and 7\n\nstr_view(a1, \"[2-7]\")\n\n[1] │ Home: &lt;5&gt;0&lt;7&gt;-&lt;6&gt;&lt;4&gt;&lt;5&gt;-&lt;5&gt;&lt;4&gt;89"
  },
  {
    "objectID": "slides/14/slides14.html#your-turn",
    "href": "slides/14/slides14.html#your-turn",
    "title": "Text Analysis",
    "section": "Your turn:",
    "text": "Your turn:\n\nDetect either “.” or “-” in the info vector.\n\n\na1 &lt;- \"Home: 507-645-5489\"\na2 &lt;- \"Cell: 219.917.9871\"\na3 &lt;- \"My work phone is 507-202-2332\"\na4 &lt;- \"I don't have a phone\"\ninfo &lt;- c(a1, a2, a3, a4)\n\n\n\n\n\n−&plus;\n\n02:00"
  },
  {
    "objectID": "slides/14/slides14.html#special-patterns",
    "href": "slides/14/slides14.html#special-patterns",
    "title": "Text Analysis",
    "section": "Special patterns",
    "text": "Special patterns\nThere are a number of special patterns that match more than one character\n\n\n\n\\\\d - digit\n\n\\\\s - white space\n\n\\\\w - word\n\n\\\\t - tab\n\n\\\\n - newline\n\n\n\n\nstr_view(a1, \"\\\\d\")\n\n[1] │ Home: &lt;5&gt;&lt;0&gt;&lt;7&gt;-&lt;6&gt;&lt;4&gt;&lt;5&gt;-&lt;5&gt;&lt;4&gt;&lt;8&gt;&lt;9&gt;\n\n\n\n\n\nOutside of R, these would be single back slashes."
  },
  {
    "objectID": "slides/14/slides14.html#caution",
    "href": "slides/14/slides14.html#caution",
    "title": "Text Analysis",
    "section": "Caution!",
    "text": "Caution!\n\nstr_view(a1, \"\\\\w\")\n\n[1] │ &lt;H&gt;&lt;o&gt;&lt;m&gt;&lt;e&gt;: &lt;5&gt;&lt;0&gt;&lt;7&gt;-&lt;6&gt;&lt;4&gt;&lt;5&gt;-&lt;5&gt;&lt;4&gt;&lt;8&gt;&lt;9&gt;"
  },
  {
    "objectID": "slides/14/slides14.html#match-any-occurence-except",
    "href": "slides/14/slides14.html#match-any-occurence-except",
    "title": "Text Analysis",
    "section": "\n[^] match any occurence except",
    "text": "[^] match any occurence except\nANYTHING BUT numbers between 2 and 7\n\nstr_view(a1, \"[^2-7]\")\n\n[1] │ &lt;H&gt;&lt;o&gt;&lt;m&gt;&lt;e&gt;&lt;:&gt;&lt; &gt;5&lt;0&gt;7&lt;-&gt;645&lt;-&gt;54&lt;8&gt;&lt;9&gt;\n\n\n\n\nCommon pitfall: forgetting the brackets"
  },
  {
    "objectID": "slides/14/slides14.html#anchors",
    "href": "slides/14/slides14.html#anchors",
    "title": "Text Analysis",
    "section": "Anchors",
    "text": "Anchors\nAnchors look for matches at the start ^ or end $\n\n\n[1] │ Home: 507-645-5489\n[2] │ Cell: 219.917.9871\n[3] │ My work phone is 507-202-2332\n[4] │ I don't have a phone\n\n\n\n\nEntries that start with a digit\nEntries that end with a digit\n\n\n\n\nstr_view(info, \"^\\\\d\")\n\n\n\n\nstr_view(info, \"\\\\d$\")\n\n[1] │ Home: 507-645-548&lt;9&gt;\n[2] │ Cell: 219.917.987&lt;1&gt;\n[3] │ My work phone is 507-202-233&lt;2&gt;"
  },
  {
    "objectID": "slides/14/slides14.html#use-regex-in-str_detect-str_sub-etc",
    "href": "slides/14/slides14.html#use-regex-in-str_detect-str_sub-etc",
    "title": "Text Analysis",
    "section": "Use regex in str_detect, str_sub, etc:",
    "text": "Use regex in str_detect, str_sub, etc:\n\nstr_view(info)\n\n[1] │ Home: 507-645-5489\n[2] │ Cell: 219.917.9871\n[3] │ My work phone is 507-202-2332\n[4] │ I don't have a phone\n\n\n\nstr_detect(info, \"\\\\d\")\n\n[1]  TRUE  TRUE  TRUE FALSE\n\n\n\nstr_replace_all(info, \"\\\\d\", \"X\")\n\n[1] \"Home: XXX-XXX-XXXX\"            \"Cell: XXX.XXX.XXXX\"           \n[3] \"My work phone is XXX-XXX-XXXX\" \"I don't have a phone\""
  },
  {
    "objectID": "slides/14/slides14.html#your-turn-1",
    "href": "slides/14/slides14.html#your-turn-1",
    "title": "Text Analysis",
    "section": "Your turn",
    "text": "Your turn\n\nFill in the code to determine how many baby names in 2015 ended with a vowel.\nUse a regular expression to specify the pattern.\n\n\nbabynames %&gt;% \n  ___(___ == ___) %&gt;%                       # extract year 2015\n  ___(ends_with_vowel = ___(___, ___)) %&gt;%  # create logical column\n  count(ends_with_vowel)                    # create a frequency table\n\n\n\n\n\n−&plus;\n\n03:00"
  },
  {
    "objectID": "slides/14/slides14.html#alternative-patterns",
    "href": "slides/14/slides14.html#alternative-patterns",
    "title": "Text Analysis",
    "section": "Alternative patterns",
    "text": "Alternative patterns\n| allows you to match one or more alternative patterns\n\nstr_view(info, \"^H|C\")\n\n[1] │ &lt;H&gt;ome: 507-645-5489\n[2] │ &lt;C&gt;ell: 219.917.9871"
  },
  {
    "objectID": "slides/14/slides14.html#fixing-the-order-of-operations",
    "href": "slides/14/slides14.html#fixing-the-order-of-operations",
    "title": "Text Analysis",
    "section": "“Fixing” the order of operations",
    "text": "“Fixing” the order of operations\nWhy are these different?\n\n\n\nstr_view(info, \"^H|C.\")\n\n[1] │ &lt;H&gt;ome: 507-645-5489\n[2] │ &lt;Ce&gt;ll: 219.917.9871\n\n\n\n\nstr_view(info, \"^(H|C).\")\n\n[1] │ &lt;Ho&gt;me: 507-645-5489\n[2] │ &lt;Ce&gt;ll: 219.917.9871"
  },
  {
    "objectID": "slides/14/slides14.html#repetition",
    "href": "slides/14/slides14.html#repetition",
    "title": "Text Analysis",
    "section": "Repetition",
    "text": "Repetition\nYou can search for a pattern followed by the number of matches\n\n\n\n\n?: 0 or 1\n\n+: 1 or more\n\n*: 0 or more\n\n{n}: exactly n times\n\n{n,}: n or more times\n\n{,m}: at most m times\n\n{n,m}: between n and m times\n\n\nExample: detect three digits in a row\n\nstr_view(a1, \"\\\\d{3}\")\n\n[1] │ Home: &lt;507&gt;-&lt;645&gt;-&lt;548&gt;9"
  },
  {
    "objectID": "slides/14/slides14.html#your-turn-2",
    "href": "slides/14/slides14.html#your-turn-2",
    "title": "Text Analysis",
    "section": "Your turn:",
    "text": "Your turn:\nFill in the code to determine how many baby names in 2015 started or ended with a vowel.\nUse a regular expression to specify the pattern.\n\nbabynames %&gt;% \n  ___(___ == ___) %&gt;%           \n  ___(bookend.vowel = ___(___, ___)) %&gt;%  \n  count(bookend.vowel)             \n\n\n\n\n\n−&plus;\n\n02:00"
  },
  {
    "objectID": "slides/14/slides14.html#duplicating-groups",
    "href": "slides/14/slides14.html#duplicating-groups",
    "title": "Text Analysis",
    "section": "Duplicating groups",
    "text": "Duplicating groups\nUse escaped numbers (\\\\1, \\\\2, etc) to repeat a group based on position\nWhich numbers have the same 1st and 3rd digits?\n\nphone_numbers &lt;- c(\"515 111 2244\", \"310 549 6892\", \"474 234 7548\")\nstr_view(phone_numbers, \"(\\\\d)\\\\d\\\\1\")\n\n[1] │ &lt;515&gt; &lt;111&gt; 2244\n[3] │ &lt;474&gt; 234 7548"
  },
  {
    "objectID": "slides/14/slides14.html#your-turn-if-time",
    "href": "slides/14/slides14.html#your-turn-if-time",
    "title": "Text Analysis",
    "section": "Your turn (if time)",
    "text": "Your turn (if time)\n\nTry the regular expressions from 13-strings-regex.rmd\n\n\ncountdown::countdown(6)\n\n\n\n−&plus;\n\n06:00"
  },
  {
    "objectID": "slides/14/slides14.html#text-analysis",
    "href": "slides/14/slides14.html#text-analysis",
    "title": "Text Analysis",
    "section": "Text Analysis",
    "text": "Text Analysis\nUp to this point, we’ve been thinking of string data as a column in our dataset:\n\nNames\nPhone numbers\nAddresses\nCourse titles\netc.\n\n\nwhich are all relatively short and structured. We can extract meaning from them using relatively simple functions."
  },
  {
    "objectID": "slides/14/slides14.html#sometimes-text-data-is-more-unstructured",
    "href": "slides/14/slides14.html#sometimes-text-data-is-more-unstructured",
    "title": "Text Analysis",
    "section": "Sometimes, text data is more unstructured",
    "text": "Sometimes, text data is more unstructured\n\nlibrary(mdsr)\nDataSciencePapers &lt;- DataSciencePapers |&gt;\n  mutate(\n    submitted = lubridate::ymd_hms(submitted), \n    updated = lubridate::ymd_hms(updated)\n  )\nglimpse(DataSciencePapers)\n\nRows: 1,089\nColumns: 15\n$ id               &lt;chr&gt; \"astro-ph/0701361v1\", \"0901.2805v1\", \"0901.3118v2\", \"…\n$ submitted        &lt;dttm&gt; 2007-01-12 03:28:11, 2009-01-19 10:38:33, 2009-01-20…\n$ updated          &lt;dttm&gt; 2007-01-12 03:28:11, 2009-01-19 10:38:33, 2009-01-24…\n$ title            &lt;chr&gt; \"How to Make the Dream Come True: The Astronomers' Da…\n$ abstract         &lt;chr&gt; \"  Astronomy is one of the most data-intensive of the…\n$ authors          &lt;chr&gt; \"Ray P Norris\", \"Heinz Andernach\", \"O. V. Verkhodanov…\n$ affiliations     &lt;chr&gt; \"\", \"\", \"Special Astrophysical Observatory, Nizhnij A…\n$ link_abstract    &lt;chr&gt; \"http://arxiv.org/abs/astro-ph/0701361v1\", \"http://ar…\n$ link_pdf         &lt;chr&gt; \"http://arxiv.org/pdf/astro-ph/0701361v1\", \"http://ar…\n$ link_doi         &lt;chr&gt; \"\", \"http://dx.doi.org/10.2481/dsj.8.41\", \"http://dx.…\n$ comment          &lt;chr&gt; \"Submitted to Data Science Journal Presented at CODAT…\n$ journal_ref      &lt;chr&gt; \"\", \"\", \"\", \"\", \"EPJ Data Science, 1:9, 2012\", \"\", \"E…\n$ doi              &lt;chr&gt; \"\", \"10.2481/dsj.8.41\", \"10.2481/dsj.8.34\", \"\", \"10.1…\n$ primary_category &lt;chr&gt; \"astro-ph\", \"astro-ph.IM\", \"astro-ph.IM\", \"astro-ph.I…\n$ categories       &lt;chr&gt; \"astro-ph\", \"astro-ph.IM|astro-ph.CO\", \"astro-ph.IM|a…\n\n\nNote: may need to install mdsr, tidytext and stopwords packages"
  },
  {
    "objectID": "slides/14/slides14.html#section",
    "href": "slides/14/slides14.html#section",
    "title": "Text Analysis",
    "section": "",
    "text": "DataSciencePapers %&gt;%\n  filter(str_detect(abstract, \"grammar of graphics\")) %&gt;%\n  pull(abstract)\n\n[1] \"  The R programming language is built on an ecosystem of packages, some that\\nallow analysts to accomplish the same tasks. For example, there are at least\\ntwo clear workflows for creating data visualizations in R: using the base\\ngraphics package (referred to as \\\"base R\\\") and the ggplot2 add-on package based\\non the grammar of graphics. Here we perform an empirical study of the quality\\nof scientific graphics produced by beginning R users. In our experiment,\\nlearners taking a data science course on the Coursera platform were randomized\\nto complete identical plotting exercises in either the base R or the ggplot2\\nsystem. Learners were then asked to evaluate their peers in terms of visual\\ncharacteristics key to scientific cognition. We observed that graphics created\\nwith the two systems rated similarly on many characteristics. However, ggplot2\\ngraphics were generally judged to be more visually pleasing and, in the case of\\nfaceted scientific plots, easier to understand. Our results suggest that while\\nboth graphic systems are useful in the hands of beginning users, ggplot2's\\nnatural faceting system may be easier to use by beginning users for displaying\\nmore complex relationships.\\n\""
  },
  {
    "objectID": "slides/14/slides14.html#section-1",
    "href": "slides/14/slides14.html#section-1",
    "title": "Text Analysis",
    "section": "",
    "text": "Functions for text analysis that follow tidy data principles\nNot part of the tidyverse, but plays well with other packages\n\n\nlibrary(tidytext)"
  },
  {
    "objectID": "slides/14/slides14.html#some-notation",
    "href": "slides/14/slides14.html#some-notation",
    "title": "Text Analysis",
    "section": "Some notation",
    "text": "Some notation\ndocument: an observation of text data (in this case, an abstract)\n\ncorpus: collection of many documents\n\n\ntoken: a unit of analysis within the document (typically a word, but could be a sentence or a line or a pair of words, etc.)"
  },
  {
    "objectID": "slides/14/slides14.html#text-as-tidy-data",
    "href": "slides/14/slides14.html#text-as-tidy-data",
    "title": "Text Analysis",
    "section": "Text as tidy data",
    "text": "Text as tidy data\n\n\ntokenize each document\n\nEach row in the dataset is a token\n\n\nRemove stopwords\n\nWords like “the” and “is” typically aren’t interesting\nMakes the dataset smaller and easier to work with\n\n\nCount the tokens\n(optional) fancy count the tokens\n\nStandardize based on total number of tokens\nHow common is a token relative to other documents\n\nHow common are “good words” or “bad words”\nHow common are pairs of words"
  },
  {
    "objectID": "slides/14/slides14.html#unnest_tokens",
    "href": "slides/14/slides14.html#unnest_tokens",
    "title": "Text Analysis",
    "section": "unnest_tokens()",
    "text": "unnest_tokens()\n\n\n\n\ntbl: our data\n\noutput: what should the output column be called?\n\ninput: what column do we tokenize?\n\ntoken: default is “word” but can also be “ngrams”, “sentences”, “lines”, “pargraphs”, etc.\n\nto_lower: should tokens be converted to lowercase\n\n\n\nunnest_tokens(\n  tbl,\n  output,\n  input,\n  token = \"words\",\n  to_lower = TRUE,\n  drop = TRUE,\n  ...\n)"
  },
  {
    "objectID": "slides/14/slides14.html#tokenize",
    "href": "slides/14/slides14.html#tokenize",
    "title": "Text Analysis",
    "section": "Tokenize",
    "text": "Tokenize\n\nlibrary(tidytext)\nDataSciencePapers |&gt;\n  unnest_tokens(output = word, input = abstract) |&gt;\n  select(id, word)\n\n# A tibble: 194,983 × 2\n   id                 word     \n   &lt;chr&gt;              &lt;chr&gt;    \n 1 astro-ph/0701361v1 astronomy\n 2 astro-ph/0701361v1 is       \n 3 astro-ph/0701361v1 one      \n 4 astro-ph/0701361v1 of       \n 5 astro-ph/0701361v1 the      \n 6 astro-ph/0701361v1 most     \n 7 astro-ph/0701361v1 data     \n 8 astro-ph/0701361v1 intensive\n 9 astro-ph/0701361v1 of       \n10 astro-ph/0701361v1 the      \n# ℹ 194,973 more rows"
  },
  {
    "objectID": "slides/14/slides14.html#remove-stopwords",
    "href": "slides/14/slides14.html#remove-stopwords",
    "title": "Text Analysis",
    "section": "Remove stopwords",
    "text": "Remove stopwords\n\nDataSciencePapers |&gt;\n  unnest_tokens(word, abstract) |&gt;\n  anti_join(get_stopwords(source = \"stopwords-iso\"), by = \"word\") |&gt;\n  select(id, word)\n\n# A tibble: 98,780 × 2\n   id                 word         \n   &lt;chr&gt;              &lt;chr&gt;        \n 1 astro-ph/0701361v1 astronomy    \n 2 astro-ph/0701361v1 data         \n 3 astro-ph/0701361v1 intensive    \n 4 astro-ph/0701361v1 sciences     \n 5 astro-ph/0701361v1 data         \n 6 astro-ph/0701361v1 technology   \n 7 astro-ph/0701361v1 accelerating \n 8 astro-ph/0701361v1 quality      \n 9 astro-ph/0701361v1 effectiveness\n10 astro-ph/0701361v1 rate         \n# ℹ 98,770 more rows"
  },
  {
    "objectID": "slides/14/slides14.html#aside-clean-the-categories",
    "href": "slides/14/slides14.html#aside-clean-the-categories",
    "title": "Text Analysis",
    "section": "Aside: clean the categories",
    "text": "Aside: clean the categories\n\n\nDataSciencePapers |&gt;\n  select(primary_category) \n\n\n# A tibble: 1,089 × 1\n   primary_category\n   &lt;chr&gt;           \n 1 astro-ph        \n 2 astro-ph.IM     \n 3 astro-ph.IM     \n 4 astro-ph.IM     \n 5 cs.SI           \n 6 astro-ph.IM     \n 7 cs.CL           \n 8 physics.soc-ph  \n 9 physics.geo-ph  \n10 physics.soc-ph  \n# ℹ 1,079 more rows"
  },
  {
    "objectID": "slides/14/slides14.html#aside-clean-the-categories-1",
    "href": "slides/14/slides14.html#aside-clean-the-categories-1",
    "title": "Text Analysis",
    "section": "Aside: clean the categories",
    "text": "Aside: clean the categories\n\n\nDataSciencePapers |&gt;\n  separate(primary_category, into = c(\"broad\", \"specific\"), sep = \"\\\\.\") |&gt;\n  select(broad, specific) |&gt;\n  unique()\n\n\n# A tibble: 99 × 2\n   broad    specific\n   &lt;chr&gt;    &lt;chr&gt;   \n 1 astro-ph &lt;NA&gt;    \n 2 astro-ph IM      \n 3 cs       SI      \n 4 cs       CL      \n 5 physics  soc-ph  \n 6 physics  geo-ph  \n 7 q-bio    PE      \n 8 stat     AP      \n 9 cs       SE      \n10 physics  ed-ph   \n# ℹ 89 more rows"
  },
  {
    "objectID": "slides/14/slides14.html#count-the-tokens",
    "href": "slides/14/slides14.html#count-the-tokens",
    "title": "Text Analysis",
    "section": "Count the tokens",
    "text": "Count the tokens\n\nDataSciencePapers |&gt;\n  unnest_tokens(word, abstract) |&gt;\n  anti_join(get_stopwords(source = \"stopwords-iso\"), by = \"word\") %&gt;%\n  group_by(broad) %&gt;%\n  count(word) %&gt;%\n  slice_max(n, n = 15) %&gt;%\n  filter(broad %in% c(\"physics\", \"cs\", \"stat\", \"math\")) %&gt;%\n  ggplot(aes(x = n, y = fct_reorder(word, n))) + \n  geom_col() + \n  facet_wrap(~broad, scales = \"free_y\") + \n  labs(\n    y = \"Word\"\n  )"
  },
  {
    "objectID": "slides/14/slides14.html#count-the-tokens-output",
    "href": "slides/14/slides14.html#count-the-tokens-output",
    "title": "Text Analysis",
    "section": "Count the tokens",
    "text": "Count the tokens"
  },
  {
    "objectID": "slides/14/slides14.html#make-it-fancy-n-grams",
    "href": "slides/14/slides14.html#make-it-fancy-n-grams",
    "title": "Text Analysis",
    "section": "Make it ~ fancy ~: n-grams",
    "text": "Make it ~ fancy ~: n-grams\n\n\n\n\ntoken is set to “ngrams”\nalso specify n=2 (2 words)\n\n\n\nunnest_tokens(\n  tbl,\n  output,\n  input,\n  token = \"words\",\n  to_lower = TRUE,\n  drop = TRUE,\n  ...\n)"
  },
  {
    "objectID": "slides/14/slides14.html#make-it-fancy-n-grams-1",
    "href": "slides/14/slides14.html#make-it-fancy-n-grams-1",
    "title": "Text Analysis",
    "section": "Make it ~ fancy ~: n-grams",
    "text": "Make it ~ fancy ~: n-grams\n\narxiv_papers |&gt;\n  unnest_tokens(bigram, abstract_clean, token = \"ngrams\", n = 2) |&gt;\n  group_by(broad) %&gt;%\n  count(bigram) %&gt;%\n  slice_max(n, n = 10) %&gt;%\n  filter(broad %in% c(\"physics\", \"cs\", \"stat\", \"math\")) %&gt;%\n  ggplot(aes(x = n, y = fct_reorder(bigram, n))) + \n  geom_col() + \n  facet_wrap(~broad, scales = \"free_y\") + \n  labs(\n    y = \"2-gram\"\n  )"
  },
  {
    "objectID": "slides/14/slides14.html#make-it-fancy-n-grams-1-output",
    "href": "slides/14/slides14.html#make-it-fancy-n-grams-1-output",
    "title": "Text Analysis",
    "section": "Make it ~ fancy ~: n-grams",
    "text": "Make it ~ fancy ~: n-grams"
  },
  {
    "objectID": "slides/14/slides14.html#what-if-we-remove-bigrams-that-include-data",
    "href": "slides/14/slides14.html#what-if-we-remove-bigrams-that-include-data",
    "title": "Text Analysis",
    "section": "What if we remove bigrams that include “data”?",
    "text": "What if we remove bigrams that include “data”?\n\narxiv_papers |&gt;\n  unnest_tokens(bigram, abstract_clean, token = \"ngrams\", n = 2) |&gt;\n  group_by(broad) %&gt;%\n  count(bigram) %&gt;%\n  filter(str_detect(bigram, \"data\", negate = TRUE)) %&gt;%\n  slice_max(n, n = 10) %&gt;%\n  filter( n &gt; 1) %&gt;%\n  filter(broad %in% c(\"physics\", \"cs\", \"stat\", \"math\")) %&gt;%\n  ggplot(aes(x = n, y = fct_reorder(bigram, n))) + \n  geom_col() + \n  facet_wrap(~broad, scales = \"free_y\") + \n  labs(\n    y = \"2-gram\"\n  )"
  },
  {
    "objectID": "slides/14/slides14.html#what-if-we-remove-bigrams-that-include-data-output",
    "href": "slides/14/slides14.html#what-if-we-remove-bigrams-that-include-data-output",
    "title": "Text Analysis",
    "section": "What if we remove bigrams that include “data”?",
    "text": "What if we remove bigrams that include “data”?"
  },
  {
    "objectID": "slides/14/slides14.html#make-it-fancy-tf-idf",
    "href": "slides/14/slides14.html#make-it-fancy-tf-idf",
    "title": "Text Analysis",
    "section": "Make it ~ fancy ~: tf-idf",
    "text": "Make it ~ fancy ~: tf-idf\nIdea: how common are certain tokens relative to the rest of the documents in the corpus?\n\ntf(t,d) = “term frequency”: what proportion of document d is term t?\n\n\nidf = “inverse document frequency”: log-scaled inverse fraction of documents that contain the term\n\\[\\text{idf} = \\log \\frac{\\text{number of documents}}{\\text{number of documents containing term t}}\\]\n\n\n\\[\\text{tf-df(t, d)} = \\frac{\\text{tf(t, d)}}{\\text{idf(t)}}\\]"
  },
  {
    "objectID": "slides/14/slides14.html#highest-tf-idfs-are-used-a-lot-within-an-abstract-and-rarely-in-other-abstracts",
    "href": "slides/14/slides14.html#highest-tf-idfs-are-used-a-lot-within-an-abstract-and-rarely-in-other-abstracts",
    "title": "Text Analysis",
    "section": "highest tf-idf’s are used a lot within an abstract, and rarely in other abstracts",
    "text": "highest tf-idf’s are used a lot within an abstract, and rarely in other abstracts\n\narxiv_papers %&gt;%\n  unnest_tokens(word, abstract_clean) |&gt;\n  count(id, word) |&gt;\n  bind_tf_idf(word, id, n) |&gt;\n  group_by(word) |&gt;\n  mutate(total_n = sum(n)) |&gt;\n  ungroup() |&gt;\n  arrange(desc(tf_idf)) \n\n# A tibble: 74,165 × 7\n   id           word            n    tf   idf tf_idf total_n\n   &lt;chr&gt;        &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;int&gt;\n 1 2007.12681v1 fintech         8 0.154  6.99  1.08        8\n 2 1707.07029v1 reflections     1 0.167  6.30  1.05        2\n 3 1507.00333v3 mf             14 0.14   6.99  0.979      14\n 4 1906.04572v1 utv             8 0.116  6.99  0.811       8\n 5 2006.00371v1 ridge           3 0.125  6.30  0.787       4\n 6 1907.09387v1 4.0             5 0.102  6.99  0.714       5\n 7 1906.04572v1 cor             7 0.101  6.99  0.709       7\n 8 2001.06937v1 gans           10 0.122  5.61  0.684      13\n 9 1606.06769v1 traffic        17 0.17   4.00  0.680      63\n10 1810.10989v3 speech          7 0.130  5.20  0.674      15\n# ℹ 74,155 more rows"
  },
  {
    "objectID": "slides/14/slides14.html#section-2",
    "href": "slides/14/slides14.html#section-2",
    "title": "Text Analysis",
    "section": "",
    "text": "arxiv_papers %&gt;%\n  unnest_tokens(word, abstract_clean) |&gt;\n  count(id, word) |&gt;\n  bind_tf_idf(word, id, n) |&gt;\n  left_join(arxiv_papers |&gt;\n              select(id, broad)) |&gt;\n  group_by(broad) %&gt;%\n  slice_max(tf_idf, n = 15) %&gt;%\n  filter(broad %in% c(\"physics\", \"cs\", \"stat\", \"math\")) %&gt;%\n  ggplot(aes(x = n, y = fct_reorder(word, n))) + \n  geom_col() + \n  facet_wrap(~broad, scales = \"free_y\") + \n  labs(\n    y = \"word\"\n  )"
  },
  {
    "objectID": "slides/14/slides14.html#your-turn-3",
    "href": "slides/14/slides14.html#your-turn-3",
    "title": "Text Analysis",
    "section": "Your turn:",
    "text": "Your turn:\n\nTry to learn something new from the arXiv data, using stringr or tidytext tools\n\nTry a trigram analysis\nIn the bigram analysis, we treated “data” as a stopword. Try customizing your own stopwords.\nTry a text analysis of the arXiv titles rather than the abstracts."
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "The best place to come for help is Amanda’s office hours! I can help with anything related to the course. You can also check my calendar for one-on-one appointment slots.\n\n\n\nStudents needing help with their Statistics coursework and R/Rstudio questions can get help from Stats Lab Assistants in the Stats Lab in CMC 304. Stats Lab Assistants are primiarily for Stat 120 (Intro Stats), but they may also be able to assist with general R/Rstudio questions.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#where-can-i-get-help",
    "href": "course-faq.html#where-can-i-get-help",
    "title": "FAQ",
    "section": "",
    "text": "The best place to come for help is Amanda’s office hours! I can help with anything related to the course. You can also check my calendar for one-on-one appointment slots.\n\n\n\nStudents needing help with their Statistics coursework and R/Rstudio questions can get help from Stats Lab Assistants in the Stats Lab in CMC 304. Stats Lab Assistants are primiarily for Stat 120 (Intro Stats), but they may also be able to assist with general R/Rstudio questions.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "notes/01-r-basics.html",
    "href": "notes/01-r-basics.html",
    "title": "R Basics",
    "section": "",
    "text": "In your previous statistics course at Carleton, you likely loaded at least one add-on R package. In this course, we’ll use a lot of tools found in the tidyverse of R packages. To load many of these packages at once, you can use the library(&lt;package_name&gt;) command. So to load the tidyverse we run:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\nNote\n\n\n\nAbove we see a lot of extra info printed when we load the tidyverse. These messages are just telling you what packages are now available to you and warning you that a few functions (e.g., filter) has been replaced by the tidyverse version. We’ll see how to suppress these messages later."
  },
  {
    "objectID": "notes/01-r-basics.html#loading-r-packages",
    "href": "notes/01-r-basics.html#loading-r-packages",
    "title": "R Basics",
    "section": "",
    "text": "In your previous statistics course at Carleton, you likely loaded at least one add-on R package. In this course, we’ll use a lot of tools found in the tidyverse of R packages. To load many of these packages at once, you can use the library(&lt;package_name&gt;) command. So to load the tidyverse we run:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\nNote\n\n\n\nAbove we see a lot of extra info printed when we load the tidyverse. These messages are just telling you what packages are now available to you and warning you that a few functions (e.g., filter) has been replaced by the tidyverse version. We’ll see how to suppress these messages later."
  },
  {
    "objectID": "notes/01-r-basics.html#creating-and-naming-objects",
    "href": "notes/01-r-basics.html#creating-and-naming-objects",
    "title": "R Basics",
    "section": "Creating and naming objects",
    "text": "Creating and naming objects\nAll R statements where you create objects have the form:\n\nobject_name &lt;- value\n\nAt first, we’ll be creating a lot of data objects. For example, we an load a data set containing the ratings for each episode of The Office using the code\n\noffice_ratings &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-17/office_ratings.csv\")\n\nIn this class you will be creating a lot of objects, so you’ll need to come up with names for those objects. Trying to think of informative/meaningful names for objects is hard, but necessary work! Below are the fundamental rules for naming objects in R:\n\nnames can’t start with a number\nnames are case-sensitive\nsome common letters are used internally by R and should be avoided as variable names (c, q, t, C, D, F, T, I)\nThere are reserved words that R won’t let you use for variable names (for, in, while, if, else, repeat, break, next)\nR will let you use the name of a predefined function—but don’t do it!\n\nYou can always check to see if you the name you want to use is already taken via exists():\nFor example lm exists\n\nexists(\"lm\")\n\n[1] TRUE\n\n\nbut carleton_college doesn’t.\n\nexists(\"carleton_college\")\n\n[1] FALSE\n\n\nThere are also a lot of naming styles out there, and if you have coded in another language, you may have already developed a preference. Below is an illustration by Allison Horst\n\n\n\n\n\n\n\n\nI generally following the tidyverse style guide, so you’ll see that I use only lowercase letters, numbers, and _ (snake case)."
  },
  {
    "objectID": "notes/01-r-basics.html#overviews-of-data-frames",
    "href": "notes/01-r-basics.html#overviews-of-data-frames",
    "title": "R Basics",
    "section": "Overviews of data frames",
    "text": "Overviews of data frames\nAbove, you loaded in a data set called office_ratings. Data sets are stored as a special data structure called a data frame. Data frames are the most-commonly used data structure for data analysis in R. For now, think of them like spreadsheets.\nOnce you have your data frame, you can get a quick overview of it using a few commands (below I use data_set as a generic placeholder for the data frame’s name):\n\n\n\n\n\n\nCommand\nDescription\n\n\n\nhead(data_set)\nprint the first 6 rows\n\n\ntail(data_set)\nprint the last 6 rows\n\n\nglimpse(data_set)\na quick overview where columns run down the screen and the data values run across. This allows you to see every column in the data frame.\n\n\nstr(data_set)\na quick overview like glimpse(), but without some of the formatting\n\n\nsummary(data_set)\nquick summary statistics for each column\n\n\ndim(data_set)\nthe number of rows and columns\n\n\nnrow(data_set)\nthe number of rows\n\n\nncol(data_set)\nthe number of columns"
  },
  {
    "objectID": "notes/01-r-basics.html#tibbles",
    "href": "notes/01-r-basics.html#tibbles",
    "title": "R Basics",
    "section": "Tibbles",
    "text": "Tibbles\nA tibble, or a tbl_df is another version of a data frame which is used by default in a lot of the tidyverse packages that we’ll use.\n\nTibbles are data.frames that are lazy and surly: they do less (i.e. they don’t change variable names or types, and don’t do partial matching) and complain more (e.g. when a variable does not exist). This forces you to confront problems earlier, typically leading to cleaner, more expressive code. Tibbles also have an enhanced print() method which makes them easier to use with large datasets containing complex objects.\n\n\n\n\n\n\n\n Check point\n\n\n\nRun the above commands on the office_ratings data set. Compare and contrast the information returned by each command.\n\n\n\n\n\n\n\n\nGetting a spreadsheet\n\n\n\nIn RStudio, you can run the command View(data_set) to pull up a spreadsheet representation of a data frame. You can also click on the name of the data frame in the Environment pane. This can be a great way help you think about the data, and even has some interactive functions (e.g., filtering and searching); however, never include View(data_set) in an .Rmd file!!\n\n\n\n\n\n\n\n\nReview from intro stats\n\n\n\nIn intro stats we used the terms cases (or observations) and variables to describe the rows and columns of a data frame, respectively."
  },
  {
    "objectID": "notes/01-r-basics.html#extracting-pieces-of-data-frames",
    "href": "notes/01-r-basics.html#extracting-pieces-of-data-frames",
    "title": "R Basics",
    "section": "Extracting pieces of data frames",
    "text": "Extracting pieces of data frames\nSince data frames are the fundamental data structure for most analyses in R, it’s important to know how to work with them. You already know how to get an overview of a data frame, but that isn’t always very informative. Often, you want to extract pieces of a data frame, such as a specific column or row.\nExtracting rows\nData frames can be indexed by their row/column numbers. To extract elements of a data frame, the basic syntax is data_set[row.index, column.index]. So, to extract the 10th row of office_ratings we run\n\noffice_ratings[10, ]\n\n# A tibble: 1 × 6\n  season episode title    imdb_rating total_votes air_date  \n   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n1      2       4 The Fire         8.4        2713 2005-10-11\n\n\nNotice that to extract an entire row, we leave the column index position blank.\nWe can also extract multiple rows by creating a vector of row indices. For example, we can extract the first 5 rows via\n\noffice_ratings[1:5, ]\n\n# A tibble: 5 × 6\n  season episode title         imdb_rating total_votes air_date  \n   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n1      1       1 Pilot                 7.6        3706 2005-03-24\n2      1       2 Diversity Day         8.3        3566 2005-03-29\n3      1       3 Health Care           7.9        2983 2005-04-05\n4      1       4 The Alliance          8.1        2886 2005-04-12\n5      1       5 Basketball            8.4        3179 2005-04-19\n\n\nHere, 1:5 create a sequence of integers from 1 to 5.\nWe could also specify arbitrary row index values by combing the values into a vector. For example, we could extract the 1st, 13th, 64th, and 128th rows via\n\noffice_ratings[c(1, 13, 64, 128), ]\n\n# A tibble: 4 × 6\n  season episode title            imdb_rating total_votes air_date  \n   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n1      1       1 Pilot                    7.6        3706 2005-03-24\n2      2       7 The Client               8.6        2631 2005-11-08\n3      4      13 Job Fair                 7.9        1977 2008-05-08\n4      7      11 Classy Christmas         8.9        2138 2010-12-09\n\n\nExtracting columns\nSimilar to extracting rows, we can use a numeric index to extract the columns of a data frame. For example, to extract the 3rd column, we can run\n\noffice_ratings[,3]\n\n# A tibble: 188 × 1\n   title            \n   &lt;chr&gt;            \n 1 Pilot            \n 2 Diversity Day    \n 3 Health Care      \n 4 The Alliance     \n 5 Basketball       \n 6 Hot Girl         \n 7 The Dundies      \n 8 Sexual Harassment\n 9 Office Olympics  \n10 The Fire         \n# ℹ 178 more rows\n\n\nAlternatively, we can pass in the column name in quotes instead of the column number\n\noffice_ratings[,\"title\"]\n\n# A tibble: 188 × 1\n   title            \n   &lt;chr&gt;            \n 1 Pilot            \n 2 Diversity Day    \n 3 Health Care      \n 4 The Alliance     \n 5 Basketball       \n 6 Hot Girl         \n 7 The Dundies      \n 8 Sexual Harassment\n 9 Office Olympics  \n10 The Fire         \n# ℹ 178 more rows\n\n\nNotice that the extracted column is still formatted as a data frame (or tibble). If you want to extract the contents of the column and just have a vector of titles, you have a few options.\n\nYou could use double brackets with the column number:\n\n\noffice_ratings[[3]]\n\n\nYou could use double brackets with the column name in quotes:\n\n\noffice_ratings[[\"title\"]]\n\n\nYou could use the $ extractor with the column name (not in quotes):\n\n\noffice_ratings$title\n\n\n\n\n\n\n\n Check point\n\n\n\n\nExtract the 35th row of office_ratings.\nExtract rows 35, 36, 37, and 38 of office_ratings.\nExtract the imdb_rating column from office ratings using the column index number.\nExtract the imdb_rating column from office ratings using the column name."
  },
  {
    "objectID": "notes/01-r-basics.html#lists",
    "href": "notes/01-r-basics.html#lists",
    "title": "R Basics",
    "section": "Lists",
    "text": "Lists\nIt turns out that data frames are special cases of lists, a more general data structure. In a data frame, each column is an element of the data list and each column must be of the same length. In general, lists can be comprised of elements of vastly different lengths and data types.\nAs an example, let’s construct a list of the faculty in the MAST department and what is being taught this winter.\n\nstat_faculty &lt;- c(\"Kelling\", \"Loy\", \"Luby\", \"Poppick\", \"St. Clair\", \"Wadsworth\")\nstat_courses &lt;- c(120, 220, 230, 250, 285, 330)\nmath_faculty &lt;- c(\"Brooke\", \"Davis\", \"Egge\", \"Gomez-Gonzales\", \"Haunsperger\", \"Johnson\", \n                  \"Meyer\", \"Montee\", \"Shrestha\",\"Terry\", \"Thompson\", \"Turnage-Butterbaugh\")\nmath_courses &lt;- c(101, 106, 111, 120, 210, 211, 232, 236, 240, 241, 251, 321, 333, 395)\n\nmast &lt;- list(stat_faculty = stat_faculty, stat_courses = stat_courses, \n             math_faculty = math_faculty, math_courses = math_courses)\n\nOverview of a list\nYou can get an overview of a list a few ways:\n\n\nglimpse(list_name) and str(list_name) list the elements of the list and the first few entries of each element.\n\n\nglimpse(mast)\n\nList of 4\n $ stat_faculty: chr [1:6] \"Kelling\" \"Loy\" \"Luby\" \"Poppick\" ...\n $ stat_courses: num [1:6] 120 220 230 250 285 330\n $ math_faculty: chr [1:12] \"Brooke\" \"Davis\" \"Egge\" \"Gomez-Gonzales\" ...\n $ math_courses: num [1:14] 101 106 111 120 210 211 232 236 240 241 ...\n\n\n\n\nlength(list_name) will tell you how many elements are in the list\n\n\nlength(mast)\n\n[1] 4\n\n\nExtracting elements of a list\nSince data frames are lists, you’ve already seen how to extract elements of a list. For example, to extract the stat_faculty you could run\n\nmast[[1]]\n\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n\nor\n\nmast[[\"stat_faculty\"]]\n\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you had only used a single bracket above, the returned object would still be a list, which is typically not what we would want.\n\nmast[1]\n\n$stat_faculty\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n\n\n\n\n\n\n\n\n\n Check point\n\n\n\nExtract the statistics courses offered this term."
  },
  {
    "objectID": "notes/01-r-basics.html#vectors",
    "href": "notes/01-r-basics.html#vectors",
    "title": "R Basics",
    "section": "Vectors",
    "text": "Vectors\nThe columns of the office_ratings data frame and the elements of the mast list were comprised of (atomic) vectors. Unlike lists, all elements within a vector share the same type. For example, all names in the stat_faculty vector were character strings and all ratings in the imdb_rating column were numeric. We’ll deal with a variety of types of vectors in this course, including:\n\nnumeric\ncharacter (text)\nlogical (TRUE/FALSE)\n\nExtracting elements of a vector\nJust like with lists (and therefore data frames), we use brackets to extract elements from a vector. As an example, let’s work with the title column from office_ratings.\n\ntitle &lt;- office_ratings$title # vector of titles\n\nTo extract the 111th title, we run\n\ntitle[111]\n\n[1] \"New Leads\"\n\n\nor two extract the 100th through 111th titles, we run\n\ntitle[100:111]\n\n [1] \"Double Date\"          \"Murder\"               \"Shareholder Meeting\" \n [4] \"Scott's Tots\"         \"Secret Santa\"         \"The Banker\"          \n [7] \"Sabre\"                \"Manager and Salesman\" \"The Delivery: Part 1\"\n[10] \"The Delivery: Part 2\" \"St. Patrick's Day\"    \"New Leads\"           \n\n\nNegative indices\nSometimes, we want to “kick out” elements of our vector. To do this, we can use a negative index value. For example,\n\ntitle[-1]\n\nreturns all but the first title—that is, it kicks out the first title. To kick out multiple elements, we need to negate a vector of indices. For example, below we kick out the first 10 titles\n\ntitle[-c(1:10)]\n\nAnd now we kick out the 5th, 50th, and 150th titles\n\ntitle[-c(5, 50, 150)]\n\nThis idea can be adapted to lists and data frames. For example, to kick out the first row of office_ratings, we run\n\noffice_ratings[-1,]\n\n# A tibble: 187 × 6\n   season episode title             imdb_rating total_votes air_date  \n    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n 1      1       2 Diversity Day             8.3        3566 2005-03-29\n 2      1       3 Health Care               7.9        2983 2005-04-05\n 3      1       4 The Alliance              8.1        2886 2005-04-12\n 4      1       5 Basketball                8.4        3179 2005-04-19\n 5      1       6 Hot Girl                  7.8        2852 2005-04-26\n 6      2       1 The Dundies               8.7        3213 2005-09-20\n 7      2       2 Sexual Harassment         8.2        2736 2005-09-27\n 8      2       3 Office Olympics           8.4        2742 2005-10-04\n 9      2       4 The Fire                  8.4        2713 2005-10-11\n10      2       5 Halloween                 8.2        2561 2005-10-18\n# ℹ 177 more rows\n\n\nor to kick out the math courses from the mast list we run\n\nmast[-4]\n\n$stat_faculty\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n$stat_courses\n[1] 120 220 230 250 285 330\n\n$math_faculty\n [1] \"Brooke\"              \"Davis\"               \"Egge\"               \n [4] \"Gomez-Gonzales\"      \"Haunsperger\"         \"Johnson\"            \n [7] \"Meyer\"               \"Montee\"              \"Shrestha\"           \n[10] \"Terry\"               \"Thompson\"            \"Turnage-Butterbaugh\"\n\n\nLogical indices\nIt’s great to be able to extract (or omit) elements using indices, but sometimes we don’t know what index value we should use. For example, if you wanted to extract all of the 300-level statistics courses from the stat_courses vector, you would need to manually determine that positions 2:5 meet that requirement. That’s a lot of work! A better alternative is to allow R to find the elements meeting that requirement using logical operators. Below is a table summarizing common logical operators in R.\n\n\nComparison\nMeaning\n\n\n\n&lt;\nless than\n\n\n&gt;\ngreater than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;=\ngreater than or equal to\n\n\n==\nis equal to\n\n\n!=\nnot equal to\n\n\n\nIn order to extract the 300-level statistics courses, we’ll take two steps:\n\nWe’ll determine whether each course is numbered at least 300,\nthen we’ll use that sequence of TRUEs/FALSEs to extract the course.\n\nSo, first we use the logical operator &gt;= to compare stat_courses and 300. This returns TRUE if the element meets the specification and FALSE otherwise.\n\nstat_courses &gt;= 300\n\n[1] FALSE FALSE FALSE FALSE FALSE  TRUE\n\n\nNow, we can use this vector as our index. Only the TRUE elements will be extracted:\n\nstat_courses[stat_courses &gt;= 300]\n\n[1] 330\n\n\nThe same idea can be used with data frames and lists, just remember how to format the brackets and indices!\n\n\n\n\n\n\n Check point\n\n\n\n\nExtract all statistics courses below 250 from stat_courses.\nExtract all math courses except for 240 (probability) from math_courses.\nExtract all rows from season 3 of The Office."
  },
  {
    "objectID": "portfolio/portfolio-2.html",
    "href": "portfolio/portfolio-2.html",
    "title": "Portfolio Project 2",
    "section": "",
    "text": "For your second portfolio project, you’ll apply what you’ve learned about wrangling data using the tidyverse. Your goal is to learn which areas of the U.S. struggle with weather prediction and explore possible reasons why. Speciﬁcally, you will focus on the error in high and low temperature forecasting, and may wish to also consider precipitation and outlook.\nYou should write a short report describing your ﬁndings. I envision an introductory paragraph that provides some context to your data, and a couple paragraphs outlining your ﬁndings. That’s it. I’m looking for something that is insightful and well-crafted, rather than long and exhaustive.\nYou should write your blog post in R Markdown, create any graphics using ggplot2, and use tools from this class for data wrangling. To submit your work, push both your R Markdown (.Rmd) ﬁle and knitted output document to GitHub. Do not forget to give your post an informative title!",
    "crumbs": [
      "Portfolio Projects",
      "Portfolio Project 2"
    ]
  },
  {
    "objectID": "portfolio/portfolio-2.html#weather-forecasts.csv",
    "href": "portfolio/portfolio-2.html#weather-forecasts.csv",
    "title": "Portfolio Project 2",
    "section": "weather-forecasts.csv",
    "text": "weather-forecasts.csv\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\ndate\ndate\ndate described by the forecast\n\n\ncity\nfactor\nobservation city\n\n\nstate\nfactor\nstate or territory\n\n\nhigh_or_low\nfactor\nwhether the forecast is for the high temperature of the low temperature\n\n\nforecast_hours_before\ninteger\nthe number of hours before the observation (one of 12, 24, 36, or 48)\n\n\nobserved_temp\ninteger\nthe actual observed temperature on that date (high or low)\n\n\nforecast_temp\ninteger\nthe predicted temperature on that date (high or low)\n\n\nobserved_precip\ndouble\nthe observed precipitation on that date, in inches; note that some observations lack an indication of precipitation, while others explicitly report 0\n\n\nforecast_outlook\nfactor\nan abbreviation for the general outlook, such as precipitation type\n\n\npossible_error\nfactor\neither (1) “none” if the row contains no potential errors or (2) thename of the variable that is the cause of the potential error",
    "crumbs": [
      "Portfolio Projects",
      "Portfolio Project 2"
    ]
  },
  {
    "objectID": "portfolio/portfolio-2.html#forecast_cities.csv",
    "href": "portfolio/portfolio-2.html#forecast_cities.csv",
    "title": "Portfolio Project 2",
    "section": "forecast_cities.csv",
    "text": "forecast_cities.csv\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\ncity\ncharacter\ncity\n\n\nstate\ncharacter\nstate or territory\n\n\nlon lat\ndouble\nlongitude\n\n\nlat\ndouble\nlatitude\n\n\nkoppen\ncharacter\nKöppen climate classiﬁcation\n\n\nelevation\ndouble\nelevation in meters\n\n\ndistance_to_coast\ndouble\ndistance_to_coast in miles\n\n\nwind\ndouble\nmean wind speed\n\n\nelevation_change_four\ndouble\ngreatest elevation change in meters out of the four closest points to this city in a collection of elevations used by the team at Saint Louis University\n\n\nelevation_change_eight\ndouble\ngreatest elevation change in meters out of the eight closest points to this city in a collection of elevations used by the team at Saint Louis University\n\n\navg_annual_precip\ndouble\naverage annual precipitation in inches",
    "crumbs": [
      "Portfolio Projects",
      "Portfolio Project 2"
    ]
  },
  {
    "objectID": "portfolio/portfolio-2.html#outlook_meanings.csv",
    "href": "portfolio/portfolio-2.html#outlook_meanings.csv",
    "title": "Portfolio Project 2",
    "section": "outlook_meanings.csv",
    "text": "outlook_meanings.csv\n\n\n\nvariable\nclass\n\n\n\n\nforecast_outlook\ncharacter\n\n\nmeaning\ncharacter",
    "crumbs": [
      "Portfolio Projects",
      "Portfolio Project 2"
    ]
  },
  {
    "objectID": "portfolio/portfolio-1.html",
    "href": "portfolio/portfolio-1.html",
    "title": "Portfolio Project 1",
    "section": "",
    "text": "Overview\nIn your first mini-project, you’ll apply what you’ve learned about ggplot2 and design principles to replicate and redesign a published graph. This project consists of three parts:\n\nReplicating an existing graph using ggplot2. Depending on the graph you choose, this may require some creativity in recreating data.\nUsing design principles from class, re-design the original graph to be better. This should include, at minimum, changes to two of the “layers” of the grammar of graphics (data, aesthetics, geometries, facets, statistics, coordinates, and theme).\nA written summary (no more than 1 printed page) including (1) an evaluation of the original graph and (2) reasoning for your design choices in improving the graph. This should include references to readings and discussions from class.\n\n\n\nOptions and Examples\nThe list below includes some good places to get started finding a graph. You do not have to choose a graph from one of these sources. It can be hard to find associated data with some published graphs, so don’t spend too much time trying to find data for a specific graph before moving on.\n\nOur World In Data\nFiveThirtyEight + Associated R Package (See available data here).\nHelpMeViz\nDataIsPlural\nTidyTuesday – If you choose this option, please be especially kind in your critique. This is a weekly R community activity, and many submissions are by beginners.\nr/dataisbeautiful\nr/dataisugly\n\n\n\nSubmission\nYour submission should include two visualizations (replication and improvement), a written overview of your work, and all associated code. You should work in a rmarkdown or quarto file. Your knitted/rendered file can be either pdf or html. I will distribute GitHub skeleton repos that you should fill in as you work. You should commit your final code and output file to your repo and link your repo to gradescope to submit.\n\n\nRubric\nA successful project will:\n\nInclude all necessary components pushed to GitHub and linked to gradescope\nContain code, plots, and written summary in a single .rmd document\nThe .rmd with all necessary code for recreation\nThe .rmd does not include unnecessary code\nProvide a thoughtful summary and critique\nThe replication matches the original graph on all layers of the grammar of graphics (data, aesthetics, geometries, facets, statistics, coordinates, and theme)\nThe improved graph has made changes to at least two of the layers\n\nAesthetics faithfully represent the representation of the underlying data\n\nMeet minimum submission quality standards\n\nVery few grammatical mistakes, spelling mistakes, or typos\nAppropriate labels and font sizes\nA readable theme\nThe rendered document does not contain any unnecessary content (package loading messages, warnings, etc.)\n\n\nAn excellent project will meet all of the requirements for a successful project, plus\n\nBe published (publicly!) to the web. (It is a portfolio project, after all). I recommend using RPubs as it’s very easy to publish a standalone website through RStudio, but if you have a public-facing website, that’s great too! Please include a URL in your YAML header so I can find it when grading.\n\nThere are lots of reasons you might not want the world to know that you are enrolled in this class, and this is one of your rights under FERPA. If you’re not comfortable including your name, you don’t have to! Your public document can be authored by “Student” (which has a history of being used in statistics).\nIf you are not comfortable attaching your name to something public-facing and this solution doesn’t work for you, please contact me on slack at least 72 hours before the due date so we can make an alternative plan.\n\nThe improved graph has made changes to at least four of the layers of the grammar of graphics (data, aesthetics, geometries, facets, statistics, coordinates, and theme)\n\nAll changes to aesthetics, geometries, etc. should be faithful representations of the underlying data (e.g. changes for the sake of making a change don’t count!)\n\n\nFor this portfolio project, you may work individually or in pairs. If you choose to work in a pair, let me know as soon as you decide so I can make a group repo for you. Both partners should have a record of committing and pushing to the repo.\n\n\nFAQ\nIf you have any questions, please post them to the #portfolio-projects channel on slack.",
    "crumbs": [
      "Portfolio Projects",
      "Portfolio Project 1"
    ]
  },
  {
    "objectID": "activities/16-functions.html",
    "href": "activities/16-functions.html",
    "title": "16-functions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(palmerpenguins) # load penguins data"
  },
  {
    "objectID": "activities/16-functions.html#your-turn-3-functions",
    "href": "activities/16-functions.html#your-turn-3-functions",
    "title": "16-functions",
    "section": "Your turn: 3 functions",
    "text": "Your turn: 3 functions\nTurn the following code snippets into functions. Think about what each function does before you begin, and be sure to give each function an informative name.\n\nmean(is.na(x))\nx / sum(x, na.rm = TRUE)\nsd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)"
  },
  {
    "objectID": "activities/16-functions.html#your-turn-column_mean",
    "href": "activities/16-functions.html#your-turn-column_mean",
    "title": "16-functions",
    "section": "Your turn: column_mean\n",
    "text": "Your turn: column_mean\n\n\nWrite a function called column_mean that takes a data set and column name (as a string) as inputs and returns the column mean as output. (Hint: access the column using [[)\nYou should also include a na.rm argument and set the default to TRUE so that NAs are removed from the calculation by default.\nTest your function on the mtcars data set.\n\n&gt; column_mean(mtcars, \"cyl\")\n[1] 6.1875"
  },
  {
    "objectID": "activities/16-functions.html#your-turn-scatterplot",
    "href": "activities/16-functions.html#your-turn-scatterplot",
    "title": "16-functions",
    "section": "Your turn: scatterplot\n",
    "text": "Your turn: scatterplot\n\nWrite a plotting function that makes a scatterplot of any two quantitative variables, coloring the points by a 3rd categorical variable.\nTest your function with the following examples:\nscatterplot(unscaled_cancer, Radius, Texture, Class)\nscatterplot(penguins, bill_length_mm, bill_depth_mm, species)"
  },
  {
    "objectID": "activities/16-functions.html#your-turn-scatterplot-2",
    "href": "activities/16-functions.html#your-turn-scatterplot-2",
    "title": "16-functions",
    "section": "Your turn: scatterplot 2",
    "text": "Your turn: scatterplot 2\nEdit your scatterplot function to include an argument called draw_line. If draw_line is TRUE, your function should add a line of best fit to your scatterplot. Test your function with the following examples\nscatterplot(unscaled_cancer, Radius, Texture, Class, draw_line = FALSE)\nscatterplot(penguins, bill_length_mm, bill_depth_mm, species, draw_line = TRUE)"
  },
  {
    "objectID": "activities/16-functions.html#section",
    "href": "activities/16-functions.html#section",
    "title": "16-functions",
    "section": "1",
    "text": "1\nConsider the following function and subsequent call of that function. What causes this error? How can you fix it?\n\nsummarize_species &lt;- function(pattern = \"Human\") {\n  starwars |&gt;\n    filter(species == pattern) |&gt;\n    summarize(\n      num_people = n(),\n      avg_height = mean(height, na.rm = TRUE)\n    )\n}\n\nsummarize_species(Wookiee)"
  },
  {
    "objectID": "activities/16-functions.html#section-1",
    "href": "activities/16-functions.html#section-1",
    "title": "16-functions",
    "section": "2",
    "text": "2\nYou can tell R to print messages using print(\"your message here\"). Edit the function above to first check if pattern is one of the species in the dataset. If it’s not, your function should print an informative message and then return()."
  },
  {
    "objectID": "activities/16-functions.html#section-2",
    "href": "activities/16-functions.html#section-2",
    "title": "16-functions",
    "section": "3",
    "text": "3\nGiven a vector of birthdates, write a function to compute the age in years. See if your function works on the easy vector first, then try the hard vector.\n\nhard &lt;- c(\"15 Feb 1992\", \"10 March 1985\", \"03/28/2024\", \"09/30/2005\")\neasy &lt;- mdy(c(\"2/15/1992\", \"3/10/1985\", \"3/28/2024\", \"9/30/2005\"))"
  },
  {
    "objectID": "activities/10-combining.html",
    "href": "activities/10-combining.html",
    "title": "\nbind_ and _join: Combining Data",
    "section": "",
    "text": "Click the “code” button above to copy and paste the source code, or pull a fresh version of the “activities” repo from GitHub."
  },
  {
    "objectID": "activities/10-combining.html#example-1-star-wars-characters",
    "href": "activities/10-combining.html#example-1-star-wars-characters",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Example 1: Star Wars Characters",
    "text": "Example 1: Star Wars Characters\nDataset 1:\n\nEach row in the dataset corresponds to a star wars character\nThe columns include their name, height, mass, homeworld, species, and the first_film they appeared in\n\n\nstarwars_characters\n\n# A tibble: 87 × 6\n   name               height  mass homeworld species first_film\n   &lt;chr&gt;               &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;     \n 1 Luke Skywalker        172    77 Tatooine  Human   A New Hope\n 2 C-3PO                 167    75 Tatooine  Droid   A New Hope\n 3 R2-D2                  96    32 Naboo     Droid   A New Hope\n 4 Darth Vader           202   136 Tatooine  Human   A New Hope\n 5 Leia Organa           150    49 Alderaan  Human   A New Hope\n 6 Owen Lars             178   120 Tatooine  Human   A New Hope\n 7 Beru Whitesun Lars    165    75 Tatooine  Human   A New Hope\n 8 R5-D4                  97    32 Tatooine  Droid   A New Hope\n 9 Biggs Darklighter     183    84 Tatooine  Human   A New Hope\n10 Obi-Wan Kenobi        182    77 Stewjon   Human   A New Hope\n# ℹ 77 more rows\n\n\nDataset 2:\nThe dataset is formatted the same, but includes two characters that were first introduced in *The Last Jedi, a Star Wars movie that came out after the first datset was released.\n\nstarwars_lastjedi\n\n# A tibble: 2 × 6\n  name         height mass  homeworld species first_film   \n  &lt;chr&gt;        &lt;lgl&gt;  &lt;lgl&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;        \n1 Rose Tico    NA     NA    Otomok    Human   The Last Jedi\n2 Amilyn Holdo NA     NA    &lt;NA&gt;      Human   The Last Jedi\n\n\nHow should these datasets be combined?"
  },
  {
    "objectID": "activities/10-combining.html#example-2-stats-sections",
    "href": "activities/10-combining.html#example-2-stats-sections",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Example 2: Stats Sections",
    "text": "Example 2: Stats Sections\nDataset 1:\nThis dataset includes the number of sections of stats courses offered in Fall 2024 and Winter 2025 terms.\n\nstats_sections_fw\n\n# A tibble: 8 × 3\n  class    fall winter\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 stat120     3      3\n2 stat220     1      1\n3 stat230     1      1\n4 stat250     0      1\n5 stat270     1      0\n6 stat285     1      1\n7 stat320     0      0\n8 stat330     0      1\n\n\nDataset 2:\nThis dataset includes the number of sections of stats courses offered in the Spring 2025 term.\n\nstats_sections_s\n\n# A tibble: 8 × 1\n  spring\n   &lt;dbl&gt;\n1      4\n2      1\n3      1\n4      1\n5      0\n6      1\n7      1\n8      0\n\n\nHow should these datasets be combined?"
  },
  {
    "objectID": "activities/10-combining.html#example-3-survivor-castaways",
    "href": "activities/10-combining.html#example-3-survivor-castaways",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Example 3: Survivor castaways",
    "text": "Example 3: Survivor castaways\nDataset 1:\n\nThis dataset includes information about each castaway’s performance in a given season of Survivor (US seasons)\nIt includes a castaway ID, first name, season name and number, and the results for that castaway in that season (their overall place, whether they made the jury, and whether they were a finalist)\n\n\nus_castaway_results\n\n# A tibble: 870 × 7\n   castaway_id castaway season_name      season place jury  finalist\n   &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;   \n 1 US0001      Sonja    Survivor: Borneo      1    16 FALSE FALSE   \n 2 US0002      B.B.     Survivor: Borneo      1    15 FALSE FALSE   \n 3 US0003      Stacey   Survivor: Borneo      1    14 FALSE FALSE   \n 4 US0004      Ramona   Survivor: Borneo      1    13 FALSE FALSE   \n 5 US0005      Dirk     Survivor: Borneo      1    12 FALSE FALSE   \n 6 US0006      Joel     Survivor: Borneo      1    11 FALSE FALSE   \n 7 US0007      Gretchen Survivor: Borneo      1    10 FALSE FALSE   \n 8 US0008      Greg     Survivor: Borneo      1     9 TRUE  FALSE   \n 9 US0009      Jenna    Survivor: Borneo      1     8 TRUE  FALSE   \n10 US0010      Gervase  Survivor: Borneo      1     7 TRUE  FALSE   \n# ℹ 860 more rows\n\n\nDataset 2:\n\nThis dataset includes information about each castaway who has appeared on Survivor (including non-US seasons)\nIt includes a castaway ID, their full name, date of birth, gender and occupation as presented in the show, and their Myers-Briggs personality type.\n\n\ncast_details\n\n# A tibble: 1,118 × 6\n   castaway_id full_name        date_of_birth gender occupation personality_type\n   &lt;chr&gt;       &lt;chr&gt;            &lt;date&gt;        &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;           \n 1 US0014      Rudy Boesch      1928-01-20    Male   Retired N… ISTJ            \n 2 US0002      B.B. Andersen    1936-01-18    Male   Real Esta… ESTJ            \n 3 US0001      Sonja Christoph… 1937-01-28    Female Musician   ENFP            \n 4 US0075      Jake Billingsley 1941-08-21    Male   Land Brok… ISFJ            \n 5 US0151      Jim Lynch        1942-01-07    Male   Retired F… ISTJ            \n 6 US0474      Joseph Del Campo 1943-07-04    Male   Former FB… ISTJ            \n 7 US0304      Jimmy Johnson    1943-07-16    Male   Former NF… ESFJ            \n 8 US0047      Kim Johnson      1944-09-18    Female Retired T… ISFJ            \n 9 US0128      Scout Cloud Lee  1944-11-08    Female Rancher    INFJ            \n10 US0061      Paschal English  1945-03-05    Male   Judge      ISFJ            \n# ℹ 1,108 more rows\n\n\nWe are interested in exploring the relationship between overall place on a Survivor season and personality type. How should these datasets be combined?\nStop here"
  },
  {
    "objectID": "activities/10-combining.html#task-line-plot",
    "href": "activities/10-combining.html#task-line-plot",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Task: line plot",
    "text": "Task: line plot\nFinish the code to make a line plot of viewers against episode, colored and grouped by series. (remember to remove #| eval: false)\n\ntidy_ratings2 %&gt;%\n  ggplot(aes(x = _____, y = _____, col = _____, group = _____)) +\n  geom_line() + \n  scale_color_viridis_c(option = \"plasma\", end = .8)"
  },
  {
    "objectID": "activities/10-combining.html#task-add-series-9-14-to-the-dataset",
    "href": "activities/10-combining.html#task-add-series-9-14-to-the-dataset",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Task: Add series 9-14 to the dataset",
    "text": "Task: Add series 9-14 to the dataset\nThe code chunk below loads the new dataset\n\nmessy_ratings2b &lt;- read_csv(\"https://stat220-w25.github.io/data/messy_ratings2_9_14.csv\")\nmessy_ratings2b\n\n# A tibble: 6 × 21\n  series e1_7day e1_28day e2_7day e2_28day e3_7day e3_28day e4_7day e4_28day\n   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1      9    9.55     9.92    9.31     9.76    8.91     9.35    8.88     9.41\n2     10    9.62    10.0     9.38     9.8     8.94     9.42    8.96     9.49\n3     11   11.2     11.8    10.8     11.4    10.7     11.2    10.6     11.2 \n4     12    9.57    10.2     8.98     9.64    8.69     9.39    8.75     9.13\n5     13    8.3      1       7.6      1       7.35     1       7.76     1   \n6     14    7.84     1       7.54     1       7.28     1       7.12     1   \n# ℹ 12 more variables: e5_7day &lt;dbl&gt;, e5_28day &lt;dbl&gt;, e6_7day &lt;dbl&gt;,\n#   e6_28day &lt;dbl&gt;, e7_7day &lt;dbl&gt;, e7_28day &lt;dbl&gt;, e8_7day &lt;dbl&gt;,\n#   e8_28day &lt;dbl&gt;, e9_7day &lt;dbl&gt;, e9_28day &lt;dbl&gt;, e10_7day &lt;dbl&gt;,\n#   e10_28day &lt;dbl&gt;\n\n\nCombine with bind_rows()\n\nCombine the two messy datasets by using bind_rows(). Be sure to look at your resulting dataset and make sure it has the right format\n\n# your code here\n\nCombine with join()\n\nWe’ll practice joining with the tidy versions of the data. First, create tidy_ratings2b using the new dataset. Follow the same steps as what was used to create tidy_ratings2\n\n# your code here\n\nOnce you’re satisfied, that the two tidy datasets look similar enough to combine, remove #| eval: false from the following code chunk and run it. Did it work? Why or why not?\n\ntidy_ratings = tidy_ratings2 %&gt;%\n  left_join(tidy_ratings2b)\n\nUse the correction _join function here. Save your dataset to the tidy_ratings object.\n\n# your code here\n\nCombine with bind_cols\n\nTo join the two datasets using bind_cols, you’ll first have to un-tidy your tidy datasets, so that each episode number is in a row and each series number is in a column. After using bind_cols() the first few rows of your final dataset should look like this:\n# A tibble: 10 × 16\n   episode period    s1    s2    s3    s4    s5    s6    s7    s8    s9   s10   s11   s12   s13   s14\n     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1       1      7  2.24  3.1   3.85  6.6   8.51  11.6  13.6  9.46  9.55  9.62  11.2  9.57  8.3   7.84\n 2       2      7  3     3.53  4.6   6.65  8.79  11.6  13.4  9.23  9.31  9.38  10.8  8.98  7.6   7.54\n 3       3      7  3     3.82  4.53  7.17  9.28  12.0  13.0  8.68  8.91  8.94  10.7  8.69  7.35  7.28\nStop here and let Amanda know you’ve finished"
  },
  {
    "objectID": "activities/10-combining.html#footnotes",
    "href": "activities/10-combining.html#footnotes",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Footnotes",
    "text": "Footnotes\n\nTalk it over: does everybody remember what makes a dataset “tidy”?↩︎"
  },
  {
    "objectID": "activities/05-maps.html",
    "href": "activities/05-maps.html",
    "title": "Maps",
    "section": "",
    "text": "states &lt;- map_data(\"state\")\nggplot(states, aes(x=long, y=lat, group=group)) + \n    geom_polygon(color=\"gold2\", fill=\"navyblue\")\n\n\n\n\n\n\n\n\nEdit the code so that each state is a different color\n\nstates &lt;- map_data(\"state\")\nggplot(states, aes(x=long, y=lat, group=group)) + \n    geom_polygon(color=\"gold2\", fill=\"navyblue\")"
  },
  {
    "objectID": "activities/05-maps.html#your-turn",
    "href": "activities/05-maps.html#your-turn",
    "title": "Maps",
    "section": "",
    "text": "Edit the code so that each state is a different color\n\nstates &lt;- map_data(\"state\")\nggplot(states, aes(x=long, y=lat, group=group)) + \n    geom_polygon(color=\"gold2\", fill=\"navyblue\")"
  },
  {
    "objectID": "activities/21-scraping.html",
    "href": "activities/21-scraping.html",
    "title": "21-scraping",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rvest)\n\nCarleton Class Schedule\nhttps://www.carleton.edu/catalog/current/search/?subject=STAT&term=25WI\nView the page source to try to find the html elements where this data is located (e.g. ‘h1’, ‘p’, ‘table’)\n\nCourse number\nCourse title\nCourse description\nCourse meetings\nFaculty\nCourse meetings\nSelectorGadget\n\nUse the SelectorGadget to explore http://www.imdb.com/chart/top\nWhat should the columns of our target dataset be? Do they correspond to any specific css selectors?\nScraping IMDb Movie Page\n\nimdb &lt;- read_html(\"http://www.imdb.com/chart/top\")\n\n\n_______ &lt;- imdb %&gt;%\n  html_elements(\".with-margin .ipc-title__text\") %&gt;%\n  html_text()\n\n_______ &lt;- imdb %&gt;%\n  html_elements(\".cli-title-metadata-item:nth-child(1)\") %&gt;%\n  html_text()\n\n_______ &lt;- imdb %&gt;%\n  html_elements(\".cli-title-metadata-item:nth-child(2)\") %&gt;%\n  html_text()\n\n_______ &lt;- imdb %&gt;%\n  html_elements(\".cli-title-metadata-item:nth-child(3)\") %&gt;%\n  html_text()\n\nimdb_top_250 &lt;- tibble(\n  \n  )\n\nimdb_top_250\n\nYour Turn: IMDb TV Shows Page\nIn an R script:\n\nScrape the names, scores, and years of most popular TV shows on IMDB: www.imdb.com/chart/tvmeter\nCreate a data frame called tvshows with the variables: rank, title, stars, year, episodes, n_ratings\nWrangle your resulting data so that all variable types are imported correctly\nUse write_csv to save your file. If time, read it into the 21-scraping.rmd and make a graph"
  },
  {
    "objectID": "activities/10-combining-solutions.html",
    "href": "activities/10-combining-solutions.html",
    "title": "\nbind_ and _join: Combining Data",
    "section": "",
    "text": "Click the “code” button above to copy and paste the source code, or pull a fresh version of the “activities” repo from GitHub."
  },
  {
    "objectID": "activities/10-combining-solutions.html#task",
    "href": "activities/10-combining-solutions.html#task",
    "title": "\nbind_ and _join: Combining Data",
    "section": "Task",
    "text": "Task\n\nmessy_ratings2b &lt;- read_csv(here(here(), \"data/messy_ratings2_9_14.csv\"))\n\nCombine with bind_rows()\n\n\nmessy_ratings2 %&gt;%\n  bind_rows(messy_ratings2b)\n\n# A tibble: 14 × 21\n   series e1_7day e1_28day e2_7day e2_28day e3_7day e3_28day e4_7day e4_28day\n    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1      1    2.24    NA       3       NA       3       NA       2.6     NA   \n 2      2    3.1     NA       3.53    NA       3.82    NA       3.6     NA   \n 3      3    3.85    NA       4.6     NA       4.53    NA       4.71    NA   \n 4      4    6.6     NA       6.65    NA       7.17    NA       6.82    NA   \n 5      5    8.51    NA       8.79    NA       9.28    NA      10.2     NA   \n 6      6   11.6     11.7    11.6     11.8    12.0     NA      12.4     12.7 \n 7      7   13.6     13.9    13.4     13.7    13.0     13.4    13.3     13.9 \n 8      8    9.46     9.72    9.23     9.53    8.68     9.06    8.55     8.87\n 9      9    9.55     9.92    9.31     9.76    8.91     9.35    8.88     9.41\n10     10    9.62    10.0     9.38     9.8     8.94     9.42    8.96     9.49\n11     11   11.2     11.8    10.8     11.4    10.7     11.2    10.6     11.2 \n12     12    9.57    10.2     8.98     9.64    8.69     9.39    8.75     9.13\n13     13    8.3      1       7.6      1       7.35     1       7.76     1   \n14     14    7.84     1       7.54     1       7.28     1       7.12     1   \n# ℹ 12 more variables: e5_7day &lt;dbl&gt;, e5_28day &lt;dbl&gt;, e6_7day &lt;dbl&gt;,\n#   e6_28day &lt;dbl&gt;, e7_7day &lt;dbl&gt;, e7_28day &lt;dbl&gt;, e8_7day &lt;dbl&gt;,\n#   e8_28day &lt;dbl&gt;, e9_7day &lt;dbl&gt;, e9_28day &lt;dbl&gt;, e10_7day &lt;dbl&gt;,\n#   e10_28day &lt;dbl&gt;\n\n\nCombine with join()\n\nFirst, create tidy_ratings2b\n\ntidy_ratings2b &lt;- messy_ratings2b %&gt;%\n  select(series, contains(\"7day\")) %&gt;%\n  pivot_longer(-series, names_to = \"episode\", values_to = \"viewers\") %&gt;%\n  separate(episode, into = c(\"episode\", \"period\")) %&gt;%\n  mutate(\n    episode = parse_number(episode),\n    period = parse_number(period)\n  )\n\nWhy doesn’t left_join() work?\n\ntidy_ratings2 %&gt;%\n  left_join(tidy_ratings2b)\n\n# A tibble: 80 × 4\n   series episode period viewers\n    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1      1       1      7    2.24\n 2      1       2      7    3   \n 3      1       3      7    3   \n 4      1       4      7    2.6 \n 5      1       5      7    3.03\n 6      1       6      7    2.75\n 7      1       7      7   NA   \n 8      1       8      7   NA   \n 9      1       9      7   NA   \n10      1      10      7   NA   \n# ℹ 70 more rows\n\n\nWhich _join do we use?\n\ntidy_ratings2 %&gt;%\n  full_join(tidy_ratings2b)\n\n# A tibble: 140 × 4\n   series episode period viewers\n    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1      1       1      7    2.24\n 2      1       2      7    3   \n 3      1       3      7    3   \n 4      1       4      7    2.6 \n 5      1       5      7    3.03\n 6      1       6      7    2.75\n 7      1       7      7   NA   \n 8      1       8      7   NA   \n 9      1       9      7   NA   \n10      1      10      7   NA   \n# ℹ 130 more rows\n\n\nCombine with bind_cols\n\nWhy doesn’t this work?\n\nseasoncols_ratings2 = tidy_ratings2 %&gt;%\n  pivot_wider(names_from = series, \n              values_from = viewers, \n              names_prefix = \"s\")\n\nseasoncols_ratings2b = tidy_ratings2b %&gt;%\n  pivot_wider(names_from = series, values_from = viewers)\n\nseasoncols_ratings2 %&gt;%\n  bind_cols(seasoncols_ratings2b)\n\n# A tibble: 10 × 18\n   episode...1 period...2    s1    s2    s3    s4    s5    s6    s7    s8\n         &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1           1          7  2.24  3.1   3.85  6.6   8.51  11.6  13.6  9.46\n 2           2          7  3     3.53  4.6   6.65  8.79  11.6  13.4  9.23\n 3           3          7  3     3.82  4.53  7.17  9.28  12.0  13.0  8.68\n 4           4          7  2.6   3.6   4.71  6.82 10.2   12.4  13.3  8.55\n 5           5          7  3.03  3.83  4.61  6.95  9.95  12.4  13.1  8.61\n 6           6          7  2.75  4.25  4.82  7.32 10.1   12    13.1  8.61\n 7           7          7 NA     4.42  5.1   7.76 10.3   12.4  13.4  9.01\n 8           8          7 NA     5.06  5.35  7.41  9.02  11.1  13.3  8.95\n 9           9          7 NA    NA     5.7   7.41 10.7   12.6  13.4  9.03\n10          10          7 NA    NA     6.74  9.45 13.5   15.0  15.9 10.0 \n# ℹ 8 more variables: episode...11 &lt;dbl&gt;, period...12 &lt;dbl&gt;, `9` &lt;dbl&gt;,\n#   `10` &lt;dbl&gt;, `11` &lt;dbl&gt;, `12` &lt;dbl&gt;, `13` &lt;dbl&gt;, `14` &lt;dbl&gt;\n\n\nSolve it by removing the episode/period\n\nseasoncols_ratings2b = tidy_ratings2b %&gt;%\n  pivot_wider(names_from = series, \n              values_from = viewers, \n              names_prefix = \"s\") %&gt;%\n  select(-c(episode, period))\n\nseasoncols_ratings2 %&gt;%\n  bind_cols(seasoncols_ratings2b)\n\n# A tibble: 10 × 16\n   episode period    s1    s2    s3    s4    s5    s6    s7    s8    s9   s10\n     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1       1      7  2.24  3.1   3.85  6.6   8.51  11.6  13.6  9.46  9.55  9.62\n 2       2      7  3     3.53  4.6   6.65  8.79  11.6  13.4  9.23  9.31  9.38\n 3       3      7  3     3.82  4.53  7.17  9.28  12.0  13.0  8.68  8.91  8.94\n 4       4      7  2.6   3.6   4.71  6.82 10.2   12.4  13.3  8.55  8.88  8.96\n 5       5      7  3.03  3.83  4.61  6.95  9.95  12.4  13.1  8.61  8.67  9.26\n 6       6      7  2.75  4.25  4.82  7.32 10.1   12    13.1  8.61  8.91  8.7 \n 7       7      7 NA     4.42  5.1   7.76 10.3   12.4  13.4  9.01  9.22  8.98\n 8       8      7 NA     5.06  5.35  7.41  9.02  11.1  13.3  8.95  9.69  9.19\n 9       9      7 NA    NA     5.7   7.41 10.7   12.6  13.4  9.03  9.5   9.34\n10      10      7 NA    NA     6.74  9.45 13.5   15.0  15.9 10.0  10.3  10.0 \n# ℹ 4 more variables: s11 &lt;dbl&gt;, s12 &lt;dbl&gt;, s13 &lt;dbl&gt;, s14 &lt;dbl&gt;\n\n\nStop here and let Amanda know you’ve finished"
  },
  {
    "objectID": "activities/04-customizing-plots.html",
    "href": "activities/04-customizing-plots.html",
    "title": "Customizing plots",
    "section": "",
    "text": "Note: This code reads the same dataset in that we used last time and then creates two new columns based on an old one. Make sure to run this chunk before trying to make your graph!\n\nseason_summary = readr::read_csv(\"https://math.carleton.edu/aluby/stat220/survivor_season_summary.csv\") |&gt;\n  separate(timeslot, into = c(\"day_of_week\", \"time\"))\n\nRows: 47 Columns: 30\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (13): version, version_season, season_name, location, country, tribe_se...\ndbl  (13): season, n_cast, n_tribes, n_finalists, n_jury, viewers_reunion, v...\ndate  (4): premiered, ended, filming_started, filming_ended\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: Expected 2 pieces. Additional pieces discarded in 42 rows [1, 2, 3, 4, 5, 6, 7,\n8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]."
  },
  {
    "objectID": "activities/04-customizing-plots.html#load-data",
    "href": "activities/04-customizing-plots.html#load-data",
    "title": "Customizing plots",
    "section": "",
    "text": "Note: This code reads the same dataset in that we used last time and then creates two new columns based on an old one. Make sure to run this chunk before trying to make your graph!\n\nseason_summary = readr::read_csv(\"https://math.carleton.edu/aluby/stat220/survivor_season_summary.csv\") |&gt;\n  separate(timeslot, into = c(\"day_of_week\", \"time\"))\n\nRows: 47 Columns: 30\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (13): version, version_season, season_name, location, country, tribe_se...\ndbl  (13): season, n_cast, n_tribes, n_finalists, n_jury, viewers_reunion, v...\ndate  (4): premiered, ended, filming_started, filming_ended\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: Expected 2 pieces. Additional pieces discarded in 42 rows [1, 2, 3, 4, 5, 6, 7,\n8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]."
  },
  {
    "objectID": "activities/04-customizing-plots.html#make-histogram",
    "href": "activities/04-customizing-plots.html#make-histogram",
    "title": "Customizing plots",
    "section": "Make histogram",
    "text": "Make histogram\n\n# Include your code here"
  },
  {
    "objectID": "activities/18-iteration-2.html",
    "href": "activities/18-iteration-2.html",
    "title": "18: Iteration II",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "activities/18-iteration-2.html#try-it-map",
    "href": "activities/18-iteration-2.html#try-it-map",
    "title": "18: Iteration II",
    "section": "Try it: map\n",
    "text": "Try it: map\n\n\nEdit the code chunk below so it returns a numeric vector (remove eval: false)\nEdit the code chunk so it only maps to the numeric columns (3-12) of unscaled cancer\n\n\nmap(unscaled_cancer, mean)\n\n\n\nmap the summary function to all columns in the {palmerpenguins} penguins data\n\n\n# your code here"
  },
  {
    "objectID": "activities/18-iteration-2.html#your-turn-penguins-and-map",
    "href": "activities/18-iteration-2.html#your-turn-penguins-and-map",
    "title": "18: Iteration II",
    "section": "Your turn: penguins and map\n",
    "text": "Your turn: penguins and map\n\nUsing the penguins data, use map to calculate the range of a numeric variable and the table of a factor variable. (It may be helpful to first write a custom function for this output)\nYour result should be a list (it will have length 8).\n\n# your code here"
  },
  {
    "objectID": "activities/18-iteration-2.html#more-practice-survivor-data",
    "href": "activities/18-iteration-2.html#more-practice-survivor-data",
    "title": "18: Iteration II",
    "section": "More practice: survivor data",
    "text": "More practice: survivor data\n\nus_castaway_results \n\n# A tibble: 870 × 7\n   castaway_id castaway season_name      season place jury  finalist\n   &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;   \n 1 US0001      Sonja    Survivor: Borneo      1    16 FALSE FALSE   \n 2 US0002      B.B.     Survivor: Borneo      1    15 FALSE FALSE   \n 3 US0003      Stacey   Survivor: Borneo      1    14 FALSE FALSE   \n 4 US0004      Ramona   Survivor: Borneo      1    13 FALSE FALSE   \n 5 US0005      Dirk     Survivor: Borneo      1    12 FALSE FALSE   \n 6 US0006      Joel     Survivor: Borneo      1    11 FALSE FALSE   \n 7 US0007      Gretchen Survivor: Borneo      1    10 FALSE FALSE   \n 8 US0008      Greg     Survivor: Borneo      1     9 TRUE  FALSE   \n 9 US0009      Jenna    Survivor: Borneo      1     8 TRUE  FALSE   \n10 US0010      Gervase  Survivor: Borneo      1     7 TRUE  FALSE   \n# ℹ 860 more rows\n\n\n\nWrite a function called finalists that takes the input of a survivor season (as a numeric) and outputs a string of the finalists’ names for that season. The finalists’ names should be separated with a comma.\nUse map_chr to return a character vector of finalists for seasons 31-40."
  },
  {
    "objectID": "activities/18-iteration-2.html#your-turn-sample_finalists",
    "href": "activities/18-iteration-2.html#your-turn-sample_finalists",
    "title": "18: Iteration II",
    "section": "Your turn: sample_finalists\n",
    "text": "Your turn: sample_finalists\n\nSome survivor seasons only had 16 players, while others had 22. This could result in some seasons being slightly under/overrepresented in our sample. Let’s account for this.\nEdit this experiment to instead randomly sample one player from each season (this results in 47 players) and then sample 20 players from the 47 random ones.\n(Hint: look at the by argument in slice_sample)\n\n# edit this function\nsample_finalists = function(n){\n    us_castaway_results %&gt;%\n    slice_sample(n = n) %&gt;%\n    filter(finalist) %&gt;%\n    count() %&gt;%\n    pull(n)\n}\n\n\n# your iteration code here"
  },
  {
    "objectID": "activities/17-iteration.html",
    "href": "activities/17-iteration.html",
    "title": "17: Iteration",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "activities/17-iteration.html#your-turn-for-loop",
    "href": "activities/17-iteration.html#your-turn-for-loop",
    "title": "17: Iteration",
    "section": "Your turn: For loop",
    "text": "Your turn: For loop\nLoad the palmerpenguins package.\nWrite a for loop that calculates the mean of the numeric variables in the penguins data set and stores the means in a named vector."
  },
  {
    "objectID": "activities/17-iteration.html#your-turn-summarytable-for-loop",
    "href": "activities/17-iteration.html#your-turn-summarytable-for-loop",
    "title": "17: Iteration",
    "section": "Your turn: summary/table for loop",
    "text": "Your turn: summary/table for loop\nRevisit the {palmerpenguins} penguins data.\nWrite a for loop that calculates the summary() of a numeric variable and the table() of a factor variable.\nStore the results in a list (it will have length 8)."
  },
  {
    "objectID": "activities/17-iteration.html#your-turn-across",
    "href": "activities/17-iteration.html#your-turn-across",
    "title": "17: Iteration",
    "section": "Your turn: across",
    "text": "Your turn: across\nUse summarize and across to find the range of any quantitative variables, and the number of levels of any factor variables in the penguins dataset."
  },
  {
    "objectID": "activities/17-iteration.html#your-turn-map",
    "href": "activities/17-iteration.html#your-turn-map",
    "title": "17: Iteration",
    "section": "Your turn: map",
    "text": "Your turn: map\nUsing the penguins data, use map to calculate the summary() of a numeric variable and the table() of a factor variable. (It may be helpful to first write a custom function)\nYour result should be a list (it will have length 8)."
  },
  {
    "objectID": "activities/17-iteration.html#survivor-data",
    "href": "activities/17-iteration.html#survivor-data",
    "title": "17: Iteration",
    "section": "Survivor data",
    "text": "Survivor data\n\nWrite a function called finalists that takes the input of a survivor season (as a numeric) and outputs a vector of the finalists’ names for that season.\nUse map to return a list of finalists for seasons 31-40.\nNow, return a character vector instead of a list (you may need to edit your function). For each season, the finalists’ names should be separated with a comma.\n\n\nload(url(\"https://stat220-w25.github.io/data/combining-data-examples.Rda\"))\nus_castaway_results\n\n# A tibble: 870 × 7\n   castaway_id castaway season_name      season place jury  finalist\n   &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;   \n 1 US0001      Sonja    Survivor: Borneo      1    16 FALSE FALSE   \n 2 US0002      B.B.     Survivor: Borneo      1    15 FALSE FALSE   \n 3 US0003      Stacey   Survivor: Borneo      1    14 FALSE FALSE   \n 4 US0004      Ramona   Survivor: Borneo      1    13 FALSE FALSE   \n 5 US0005      Dirk     Survivor: Borneo      1    12 FALSE FALSE   \n 6 US0006      Joel     Survivor: Borneo      1    11 FALSE FALSE   \n 7 US0007      Gretchen Survivor: Borneo      1    10 FALSE FALSE   \n 8 US0008      Greg     Survivor: Borneo      1     9 TRUE  FALSE   \n 9 US0009      Jenna    Survivor: Borneo      1     8 TRUE  FALSE   \n10 US0010      Gervase  Survivor: Borneo      1     7 TRUE  FALSE   \n# ℹ 860 more rows"
  },
  {
    "objectID": "activities/17-iteration.html#explain-a-function",
    "href": "activities/17-iteration.html#explain-a-function",
    "title": "17: Iteration",
    "section": "Explain a function",
    "text": "Explain a function\nExplain what each step of the pipeline in this function does.\n\nshow_missing &lt;- function(df, group_vars, summary_vars = everything()) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) sum(is.na(x))),\n      .groups = \"drop\"\n    ) |&gt;\n    select(where(\\(x) any(x &gt; 0)))\n}\n\nnycflights23::flights |&gt; show_missing(c(year, month, day))\n\n# A tibble: 365 × 9\n    year month   day dep_time dep_delay arr_time arr_delay tailnum air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;     &lt;int&gt;    &lt;int&gt;     &lt;int&gt;   &lt;int&gt;    &lt;int&gt;\n 1  2023     1     1        5         5        6         9       2        9\n 2  2023     1     2       28        28       30        37       8       37\n 3  2023     1     3       16        16       16        19       1       19\n 4  2023     1     4       16        16       18        21       2       21\n 5  2023     1     5       10        10       10        13       0       13\n 6  2023     1     6        1         1        1         3       0        3\n 7  2023     1     7        1         1        1         3       0        3\n 8  2023     1     8        0         0        0         1       0        1\n 9  2023     1     9       15        15       15        16       1       16\n10  2023     1    10        4         4        4         4       1        4\n# ℹ 355 more rows"
  },
  {
    "objectID": "activities/11-import-solutions.html",
    "href": "activities/11-import-solutions.html",
    "title": "Data import and dates/times – Solutions",
    "section": "",
    "text": "Click the “code” button above to copy and paste the source code, or pull a fresh version of the “activities” repo from GitHub.\nWarm Up\nUse read_csv() to import the desserts data set from\nhttps://stat220-w25.github.io/data/desserts.csv\n\ndesserts &lt;- read_csv(here::here(here::here(), \"data/desserts.csv\"))\n\nYour turn\nUse the appropriate read_&lt;type&gt;() function to import the following data sets:\n\nhttps://stat220-w25.github.io/data/data-4.csv\nhttps:/stat220-w25.github.io/data/tricky-1.csv\nhttps://stat220-w25.github.io/data/tricky-2.csv\n\nIf you hit any errors/problems, be sure to explore them and identify the issue, even if you can’t “fix” it.\ndata-4.csv\nOpening the URL for data-4.csv you see that the delimiter is |, so you should use read_delim():\n\ndata4 &lt;- read_delim(here::here(here::here(),\"data/data-4.csv\"), delim = \"|\")\n\ntricky-1.csv\nAt first glance it isn’t obvious what is tricky about tricky-1.csv; however, if you try to use read_csv() you’ll hit the following problem:\n\ntricky1 &lt;- read_csv(\"https:/stat220-w25.github.io/data/tricky-1.csv\")\nproblems(tricky1)\n\nThe output of problems() here is that in rows 4 and 7 read_csv only finds 4 columns, but 5 are expected. Looking at the imported data set we see that the city is missing in rows three and 6 (the 4th and 7th rows of the original data file).\n\ntricky1\n\nWe can fix this with post processing:\n\ntricky1[3, ] &lt;- c(tricky1[3, 1:2], NA, tricky1[3, 3:4])\ntricky1[6, ] &lt;- c(tricky1[4, 1], NA, tricky1[4, 3:5])\n\ntricky-2.csv\nTo begin, we can attempt to read in the tricky-2.csv file:\n\ntricky2 &lt;- read_csv(here::here(here::here(),\"data/tricky-2.csv\"))\nproblems(tricky2)\n\nThis looks like a missing value problem again! Let’s look at the rows with missing values:\n\ntricky2 %&gt;% slice(8:21)\n\nWhy are there state abbreviations in the latitude column?!? (Because not all the rows put quotes around the “City, State” so it added an extra column!)\nOne solution is to parse the file in pieces. First, we can import the first 7 rows of the file:\n\ntricky2_part1 &lt;- read_csv(\n  \"https://aloy.rbind.io/data/tricky-2.csv\",\n  n_max = 7\n)\n\nNext, we parse the other rows, and manually specify the column names, since we are skipping the first row:\n\ntricky2_part2 &lt;- read_csv(\n  \"https://aloy.rbind.io/data/tricky-2.csv\",\n  skip = 8, \n  col_names = c(\"iata\", \"airport\", \"city\", \"state\",  \"latitude\", \"longitude\")\n)\n\nNow, we have to use some data wrangling skills to combine everything. First, we must create a state column in tricky2_part1\n\ntricky2_part1 &lt;- tricky2_part1 %&gt;%\n  separate(city, into = c(\"city\", \"state\"), sep = \",\")\n\nThen, we need to bind the two sets of rows together using bind_rows():\n\ntricky2 &lt;- bind_rows(tricky2_part1, tricky2_part2)\n\nTime – plot\nDays – make a list of class days\nStart by printing the dates only\nNext, print them in the format “Week 4 Wednesday: Jan 29 2025”"
  },
  {
    "objectID": "activities/22-interactivity.html",
    "href": "activities/22-interactivity.html",
    "title": "22-interactivity",
    "section": "",
    "text": "library(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DT)\nlibrary(plotly)\nlibrary(flexdashboard)\nlibrary(leaflet)\n\nPlotly 1\nLoad the palmerpenguins data set and create a scatterplot of body_mass_g vs. flipper_length_mm from the penguins data set. Use color and shape to specify the species.\nOnce you have a static graphic you’re happy with, load plotly and convert it to an interactive graphic.\n\nWhat tools tips are included by default?\nChange the default tooltip to include “Species”\n(If time) use stringr so that the tooltip shows: “Species: Adelie” instead of just “Adelie”\nPlotly 2\nCreate a bar chart of species from the penguins data set, then convert it to an interactive bar chart.\n\nWhat tools tips are included by default?\nWhat would you change?\nLeaflet\n\nFind the names of the 3 islands in penguins\n\nFind appropriate lat/long locations for each of the islands in penguins using the internet\nCreate a leaflet map with markers for each island (Tip: Start with the world map with no zoom)\nInclude a popup with the island name\nDT Table\n\nCreate a {DT} table of the penguins dataset\nAdd the option to filter, and make the font size 14pt\nPutting it all together\n\nMake all graphs plotly’s with appropriate tooltips\nReplace the data output with your {DT} datatable\nInclude your leaflet map on a new page\n\nAdd value boxes on the same page as your map that show the number of penguins that live on each island\nChange the theme of the dashboard"
  },
  {
    "objectID": "computing/git-stat220.html",
    "href": "computing/git-stat220.html",
    "title": "GitHub Classroom Guide for Stat 220",
    "section": "",
    "text": "Jump to… Individual assignments | Group work | Additional resources\nThis is a guide for students to setup Git and GitHub for use in Stat 220.\nIf you are using the maize RStudio server, then you can connect to GitHub without any extra software downloads. If you are using RStudio on your computer, then you will need to download Git software (as directed in Computing Access) to use GitHub connected projects.\nI will host all of our course materials on GitHub, and you will use GitHub to submit homework and collaborate on projects.",
    "crumbs": [
      "Computing",
      "Git/Github in Stat 220"
    ]
  },
  {
    "objectID": "computing/git-stat220.html#getting-setup-with-git-and-github",
    "href": "computing/git-stat220.html#getting-setup-with-git-and-github",
    "title": "GitHub Classroom Guide for Stat 220",
    "section": "Getting setup with Git and GitHub",
    "text": "Getting setup with Git and GitHub\nIf you are not working on the maize RStudio server, then make sure that you have installed all of the software mentioned in Computing Access. In addition, you should install the usethis and gitcreds R packages.\nEveryone needs to connect Git and GitHub by doing the following:\n\nRegister for account on GitHub (https://github.com/). I recommend using a username that incorporates your name (e.g. aluby). Please use your Carleton email with this account (you can connect multiple emails to a single GitHub account)\n\nSetup options in Git by running the following code chunk in your console:\nlibrary(usethis)\nuse_git_config(user.name = \"Jane Doe\", user.email = \"jane@example.org\")\nchanging the first two lines to your own name and email (this should be the email associated with your GitHub account).\n\n\nIn order to commit and push to GitHub via R, you need to create a PAT (Personal Access Token). This is like a Password 2.0. When RStudio prompts you for your GitHub username and password, use your PAT instead.\n\nComplete the steps in Happy Git with R Ch 9.3 to get a personal access token. I recommend using the “classic” token, but either should work. You will need workflow, user, and repo scopes (permissions) for this class, and I recommend setting it for 90 days so you won’t need a new one through the end of the term. Make sure to save this somewhere safe!\n\n\nIt will be annoying to type your PAT in anytime you want to push to github. Instead, tell R to store your git credentials. First, save your name and email:\n\nuse_git_config(user.name = \"Jane Doe\", user.email = \"jane@example.org\")\nThen, run the following command:\ngitcreds::gitcreds_set()\nWhen prompted for your password, use your PAT from Step 3.\n&gt; gitcreds::gitcreds_set()\n\n? Enter password or token: ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n-&gt; Adding new credentials...\n-&gt; Removing credentials from cache...\n-&gt; Done.\nTo see if things are set up correctly, run\nusethis::git_sitrep()\nand one of the results should be something like the following:\n── GitHub user \n• Default GitHub host: \"https://github.com\"\n• Personal access token for \"https://github.com\": &lt;discovered&gt;\n• GitHub user: \"aluby\"\n• Token scopes: \"admin:org\", \"repo\", \"user\", and \"workflow\"\n• Email(s): \"aluby@carleton.edu\"\nif instead of &lt;discovered&gt; you see &lt;unset&gt;, you may need to enter your PAT again. (I have no idea why it sometimes needs it twice)",
    "crumbs": [
      "Computing",
      "Git/Github in Stat 220"
    ]
  },
  {
    "objectID": "computing/git-stat220.html#individual-assignments",
    "href": "computing/git-stat220.html#individual-assignments",
    "title": "GitHub Classroom Guide for Stat 220",
    "section": "Individual assignments",
    "text": "Individual assignments\nIf you followed the suggestions in the Using Rstudio in Stat 220 page, then you should already have an assignments folder on your computer or maize account.\nEach new assignment/project will be posted as a repository on GitHub and added directly to your account (within the Stat220 organization). This repository will contain assignment details (README, .Rmd).\nCreating an individual assignment repo and project\n\nGo to our course GitHub organization page and find your homework repo, such as hw-1-username (where your username is attached).\nEnter the online assignment repository on GitHub. Click the green “Code” button. Most of you should just use the default setting which is to “clone” (copy) using HTTPS. Click the clipboard to the right of the URL to copy the repo location. (If you are using SSH, make sure it says “Clone with SSH” in bold in the top left of the pop-up box. If not, click the “SSH” button and copy the link in the box to your clipboard.)\nNow open up RStudio and create a project as follows:\n\n\nClick the Project button in the upper right corner of your RStudio window and select New Project….\n\n \n\n\n\n\n\n\n\n\n\nSelect Version Control and then New Project\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaste the link you just copied into the Repository URL box. Leave the Project directory name blank (or keep the auto-filled name). Use the Browse button to find your assignments folder, then click Create Project\n\n\n\n\n\n\n\n\n\n\n   \nWarning: If you received an error in the above steps, you may have to clone with HTTPS instead of SSH (or vice versa). You can do this by again clicking on the “Clone or Download” button in the repository page, then clicking “Use HTTPS” in the top right of the pop-up box. Now copy the link and repeat this step.\nWorking on your assignment\nAn RStudio project should now open, which will allow you to start working on your homework assignment. You should see the project assignment name in the top right side of Rstudio. You will probably see a blank console screen when you open a new project. Look in the Files tab for your homework .Rmd file. Click on whatever file you want to edit (probably the .Rmd file) and edit away. Make sure that your current assignment’s project is the one open and showing in the upper rightproject name. To open a project, click on the .Rproj file or use the Open Project… option available in the upper right project link.\nCommits\nAfter you make changes to the homework assignment, commit them. What are commits you ask? Commits are essentially taking a snapshot of your projects. Commits save this snapshot to your local version of Git (located on your hard drive or the maize server). For example, if I make changes to a code so that it prints “Hello world”, and then commit them with an informative message, I can look at the history of my commits and view the code that I wrote at that time. If I made some more changes to the function that resulted in an error, I could go back to the commit where the code was originally working. This prevents you from creating several versions of your homework (homework-v1, homework-v2, …) or from trying to remember what your code originally looked like.\nYou can make commits in the Git tab in RStudio.\n\n\n\n\n\n\n\n\nClick the Commit button in the Git tab. Check the boxes of the files that you want to commit, enter your commit message (briefly state what changes have been made), then hit Commit. You can read how to do this in RStudio in more detail here: http://r-pkgs.had.co.nz/git.html#git-commit.\nTwo things about committing.\n\nYou should commit somewhat frequently. At minimum, if you’re doing a homework assignment, you should make a commit each time that you’ve finished a question.\nLeave informative commit messages. “Added stuff” will not help you if you’re looking at your commit history in a year. A message like “Added initial version of hello-world function” will be more useful.\nPushing changes to Github\nAt some point you’ll want to get the updated version of the assignment back onto GitHub, either so that we can help you with your code or so that it can be graded. You will also want to push work frequently when you have a shared GitHub repo for project collaborations (i.e. more than one person is working on a project and code). If you are ready to push, you can again click on the “Up” Push arrow in the Git tab or in the Commit pop-up window or in the Git tab (shown above).\nTo “turn in” an assignment, all you need to do is push all your relevant files to Github by the deadline.",
    "crumbs": [
      "Computing",
      "Git/Github in Stat 220"
    ]
  },
  {
    "objectID": "computing/git-stat220.html#group-work",
    "href": "computing/git-stat220.html#group-work",
    "title": "GitHub Classroom Guide for Stat 220",
    "section": "Group work",
    "text": "Group work\nCollaborative Github assignments are pretty similar to individual assignments.\nCreating a group/partner assignment repo and project\nGo to our course GitHub organization page and find the repo for your group, for example if your group name is “team01” the you might find the mp1-team01 repo. Clone this repo to your computer/maize account using the same steps done for an individual assignment (see steps 2-3).\nWorking with collaborative repos\nFor group homework, I suggest that only the recorder edit the group-homework-x.Rmd file to avoid merge conflicts! Other group members can create a new Markdown doc to run and save commands. Only the recorder needs to push changes (answers) to the Github repo and all others can then pull these changes (i.e. the final answers) after the HW is submitted.\nWhen you are working together on a Github project, you should commit and push your modifications frequently. You will also need to frequently pull updates from Github down to your local version of RStudio. These updates are changes that your teammates have made since your last pull. To pull in changes, click the “Down” Pull arrow in the Git tab (shown above).\nIf you get an error about conflict after pulling or pushing, don’t freak out! This can happen if you edit a file (usually an .Rmd or .R file) in a location that was also changed by a teammate. When this happens you should attempt to fix the merge conflict. Take a look at this resource site and try to fix the merge conflict in Rstudio. If that doesn’t work contact me!",
    "crumbs": [
      "Computing",
      "Git/Github in Stat 220"
    ]
  },
  {
    "objectID": "computing/git-stat220.html#additional-resources",
    "href": "computing/git-stat220.html#additional-resources",
    "title": "GitHub Classroom Guide for Stat 220",
    "section": "Additional resources",
    "text": "Additional resources\n\nHappy Git and GitHub for the useR\nRstudio, Git and GitHub\nInteractive learning guide for Git\nGitHub Guides\nGit setup for Windows (video)\nGit setup for Mac (video)\nHow to clone, edit, and push homework assignments with GitHub Classroom (video)\n\n\nAcknowledgements\nMost of this content in this guide was taken from https://github.com/jfiksel/github-classroom-for-students and edited by Adam Loy for our classroom use. and is licensed under the CC BY-NC 3.0 Creative Commons License.",
    "crumbs": [
      "Computing",
      "Git/Github in Stat 220"
    ]
  },
  {
    "objectID": "computing/computing-access.html",
    "href": "computing/computing-access.html",
    "title": "Computing Access",
    "section": "",
    "text": "I expect you to use RStudio to run R in this course. You have two options for using RStudio:\n\nWe have a Carleton server hosting Rstudio at https://maize.mathcs.carleton.edu/. Your files on this account will be accessible as long as you are a student at Carleton. Use your Carleton credentials to access your account and you need to be running the Carleton VPN (below) to access this server. Use this option if\n\nyour personal computer is old and/or slow\nyou prefer to use school computers (lab or library computers)\n\nYou can also run R/RStudio from your personal computer. If you use a local version of R/RStudio this term, make sure that you have recently updated both R and RStudio.\nTo check your version of R, run the command getRversion() and compare your version to the newest version posted on https://cran.r-project.org/. If you need an update, then install the newer version using the installation directions above.\nIn RStudio, check for updates with the menu option Help &gt; Check for updates. Follow directions if an update is needed.\nFor a fresh download:\n\nDownload the latest version of R for your operating system from https://cran.r-project.org/\nDownload the free RStudio desktop version from https://posit.co/download/rstudio-desktop/\n\nUse the default download and install options for each. For R, download the “precompiled binary” distribution rather than the source code.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing/computing-access.html#rrstudio",
    "href": "computing/computing-access.html#rrstudio",
    "title": "Computing Access",
    "section": "",
    "text": "I expect you to use RStudio to run R in this course. You have two options for using RStudio:\n\nWe have a Carleton server hosting Rstudio at https://maize.mathcs.carleton.edu/. Your files on this account will be accessible as long as you are a student at Carleton. Use your Carleton credentials to access your account and you need to be running the Carleton VPN (below) to access this server. Use this option if\n\nyour personal computer is old and/or slow\nyou prefer to use school computers (lab or library computers)\n\nYou can also run R/RStudio from your personal computer. If you use a local version of R/RStudio this term, make sure that you have recently updated both R and RStudio.\nTo check your version of R, run the command getRversion() and compare your version to the newest version posted on https://cran.r-project.org/. If you need an update, then install the newer version using the installation directions above.\nIn RStudio, check for updates with the menu option Help &gt; Check for updates. Follow directions if an update is needed.\nFor a fresh download:\n\nDownload the latest version of R for your operating system from https://cran.r-project.org/\nDownload the free RStudio desktop version from https://posit.co/download/rstudio-desktop/\n\nUse the default download and install options for each. For R, download the “precompiled binary” distribution rather than the source code.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing/computing-access.html#vpn",
    "href": "computing/computing-access.html#vpn",
    "title": "Computing Access",
    "section": "VPN",
    "text": "VPN\nIf you plan to use the maize server and you plan to do any work off campus this term (e.g., while on a field trip, travel for athletics, or just sitting in Little Joy) you need to install Carleton’s VPN to have access.\nTo install the GlobalProtect VPN follow directions provided by ITS.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing/computing-access.html#git-and-github",
    "href": "computing/computing-access.html#git-and-github",
    "title": "Computing Access",
    "section": "Git and GitHub",
    "text": "Git and GitHub\nGit is version control software that you install locally on your computer. Git is already installed on the maize RStudio server.\nGithub is a cloud-based service for hosting git projects. It allows multiple users to share and contribute to projects and it is how you will be submitting homework assignments and projects for this class. More information about Github for this class is found on Moodle.\nIf you are using a local install of R/RStudio, then you will need to install Git.\nInstalling Git\nDirections for both Windows & Mac here at http://happygitwithr.com/install-git.html.\n\nIf you are using maize, then there is nothing you need to install.\nWindows users should follow Option 1 in 6.2.\nMac users can follow Option 1 in 6.3 if comfortable, otherwise follow Option 2\nLinux users can follow 6.4.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing/computing-access.html#latex",
    "href": "computing/computing-access.html#latex",
    "title": "Computing Access",
    "section": "LaTeX",
    "text": "LaTeX\nYou need a LaTeX compiler to create a pdf document from a R Markdown file. If you use the maize server, you don’t need to install anything (the server already has a LaTeX compiler). If you are using a local RStudio, you should install a Latex compiler.\nInstalling LaTeX (not needed if you are using the maize server)\nIf you don’t already have a tex package installed on your computer, the easiest option to create pdf’s is to use the tinytex R package. This can be installed with the following R commands:\n\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()  # install TinyTeX\n\nIf you’d like a stand alone LaTeX package, you could install the basic installations of either:\n\nMacTeX for Mac (3.2GB!)\nMiKTeX for Windows (190MB)\n\n\nAcknowledgements\nThis installation guide was written by Adam Loy and is based on the guide from stat545.com and is licensed under the CC BY-NC 3.0 Creative Commons License.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing/r-basics-refresher.html",
    "href": "computing/r-basics-refresher.html",
    "title": "R Basics",
    "section": "",
    "text": "In your previous statistics course at Carleton, you likely loaded at least one add-on R package. In this course, we’ll use a lot of tools found in the tidyverse of R packages. To load many of these packages at once, you can use the library(&lt;package_name&gt;) command. So to load the tidyverse we run:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\nNote\n\n\n\nAbove we see a lot of extra info printed when we load the tidyverse. These messages are just telling you what packages are now available to you and warning you that a few functions (e.g., filter) has been replaced by the tidyverse version. We’ll see how to suppress these messages later."
  },
  {
    "objectID": "computing/r-basics-refresher.html#loading-r-packages",
    "href": "computing/r-basics-refresher.html#loading-r-packages",
    "title": "R Basics",
    "section": "",
    "text": "In your previous statistics course at Carleton, you likely loaded at least one add-on R package. In this course, we’ll use a lot of tools found in the tidyverse of R packages. To load many of these packages at once, you can use the library(&lt;package_name&gt;) command. So to load the tidyverse we run:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\nNote\n\n\n\nAbove we see a lot of extra info printed when we load the tidyverse. These messages are just telling you what packages are now available to you and warning you that a few functions (e.g., filter) has been replaced by the tidyverse version. We’ll see how to suppress these messages later."
  },
  {
    "objectID": "computing/r-basics-refresher.html#creating-and-naming-objects",
    "href": "computing/r-basics-refresher.html#creating-and-naming-objects",
    "title": "R Basics",
    "section": "Creating and naming objects",
    "text": "Creating and naming objects\nAll R statements where you create objects have the form:\n\nobject_name &lt;- value\n\nAt first, we’ll be creating a lot of data objects. For example, we an load a data set containing the ratings for each episode of The Office using the code\n\noffice_ratings &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-17/office_ratings.csv\")\n\nIn this class you will be creating a lot of objects, so you’ll need to come up with names for those objects. Trying to think of informative/meaningful names for objects is hard, but necessary work! Below are the fundamental rules for naming objects in R:\n\nnames can’t start with a number\nnames are case-sensitive\nsome common letters are used internally by R and should be avoided as variable names (c, q, t, C, D, F, T, I)\nThere are reserved words that R won’t let you use for variable names (for, in, while, if, else, repeat, break, next)\nR will let you use the name of a predefined function—but don’t do it!\n\nYou can always check to see if you the name you want to use is already taken via exists():\nFor example lm exists\n\nexists(\"lm\")\n\n[1] TRUE\n\n\nbut carleton_college doesn’t.\n\nexists(\"carleton_college\")\n\n[1] FALSE\n\n\nThere are also a lot of naming styles out there, and if you have coded in another language, you may have already developed a preference. Below is an illustration by Allison Horst\n\n\n\n\n\n\n\n\nI generally following the tidyverse style guide, so you’ll see that I use only lowercase letters, numbers, and _ (snake case)."
  },
  {
    "objectID": "computing/r-basics-refresher.html#overviews-of-data-frames",
    "href": "computing/r-basics-refresher.html#overviews-of-data-frames",
    "title": "R Basics",
    "section": "Overviews of data frames",
    "text": "Overviews of data frames\nAbove, you loaded in a data set called office_ratings. Data sets are stored as a special data structure called a data frame. Data frames are the most-commonly used data structure for data analysis in R. For now, think of them like spreadsheets.\nOnce you have your data frame, you can get a quick overview of it using a few commands (below I use data_set as a generic placeholder for the data frame’s name):\n\n\n\n\n\n\nCommand\nDescription\n\n\n\nhead(data_set)\nprint the first 6 rows\n\n\ntail(data_set)\nprint the last 6 rows\n\n\nglimpse(data_set)\na quick overview where columns run down the screen and the data values run across. This allows you to see every column in the data frame.\n\n\nstr(data_set)\na quick overview like glimpse(), but without some of the formatting\n\n\nsummary(data_set)\nquick summary statistics for each column\n\n\ndim(data_set)\nthe number of rows and columns\n\n\nnrow(data_set)\nthe number of rows\n\n\nncol(data_set)\nthe number of columns"
  },
  {
    "objectID": "computing/r-basics-refresher.html#tibbles",
    "href": "computing/r-basics-refresher.html#tibbles",
    "title": "R Basics",
    "section": "Tibbles",
    "text": "Tibbles\nA tibble, or a tbl_df is another version of a data frame which is used by default in a lot of the tidyverse packages that we’ll use.\n\nTibbles are data.frames that are lazy and surly: they do less (i.e. they don’t change variable names or types, and don’t do partial matching) and complain more (e.g. when a variable does not exist). This forces you to confront problems earlier, typically leading to cleaner, more expressive code. Tibbles also have an enhanced print() method which makes them easier to use with large datasets containing complex objects.\n\n\n\n\n\n\n\n Check point\n\n\n\nRun the above commands on the office_ratings data set. Compare and contrast the information returned by each command.\n\n\n\n\n\n\n\n\nGetting a spreadsheet\n\n\n\nIn RStudio, you can run the command View(data_set) to pull up a spreadsheet representation of a data frame. You can also click on the name of the data frame in the Environment pane. This can be a great way help you think about the data, and even has some interactive functions (e.g., filtering and searching); however, never include View(data_set) in an .Rmd file!!\n\n\n\n\n\n\n\n\nReview from intro stats\n\n\n\nIn intro stats we used the terms cases (or observations) and variables to describe the rows and columns of a data frame, respectively."
  },
  {
    "objectID": "computing/r-basics-refresher.html#extracting-pieces-of-data-frames",
    "href": "computing/r-basics-refresher.html#extracting-pieces-of-data-frames",
    "title": "R Basics",
    "section": "Extracting pieces of data frames",
    "text": "Extracting pieces of data frames\nSince data frames are the fundamental data structure for most analyses in R, it’s important to know how to work with them. You already know how to get an overview of a data frame, but that isn’t always very informative. Often, you want to extract pieces of a data frame, such as a specific column or row.\nExtracting rows\nData frames can be indexed by their row/column numbers. To extract elements of a data frame, the basic syntax is data_set[row.index, column.index]. So, to extract the 10th row of office_ratings we run\n\noffice_ratings[10, ]\n\n# A tibble: 1 × 6\n  season episode title    imdb_rating total_votes air_date  \n   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n1      2       4 The Fire         8.4        2713 2005-10-11\n\n\nNotice that to extract an entire row, we leave the column index position blank.\nWe can also extract multiple rows by creating a vector of row indices. For example, we can extract the first 5 rows via\n\noffice_ratings[1:5, ]\n\n# A tibble: 5 × 6\n  season episode title         imdb_rating total_votes air_date  \n   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n1      1       1 Pilot                 7.6        3706 2005-03-24\n2      1       2 Diversity Day         8.3        3566 2005-03-29\n3      1       3 Health Care           7.9        2983 2005-04-05\n4      1       4 The Alliance          8.1        2886 2005-04-12\n5      1       5 Basketball            8.4        3179 2005-04-19\n\n\nHere, 1:5 create a sequence of integers from 1 to 5.\nWe could also specify arbitrary row index values by combing the values into a vector. For example, we could extract the 1st, 13th, 64th, and 128th rows via\n\noffice_ratings[c(1, 13, 64, 128), ]\n\n# A tibble: 4 × 6\n  season episode title            imdb_rating total_votes air_date  \n   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n1      1       1 Pilot                    7.6        3706 2005-03-24\n2      2       7 The Client               8.6        2631 2005-11-08\n3      4      13 Job Fair                 7.9        1977 2008-05-08\n4      7      11 Classy Christmas         8.9        2138 2010-12-09\n\n\nExtracting columns\nSimilar to extracting rows, we can use a numeric index to extract the columns of a data frame. For example, to extract the 3rd column, we can run\n\noffice_ratings[,3]\n\n# A tibble: 188 × 1\n   title            \n   &lt;chr&gt;            \n 1 Pilot            \n 2 Diversity Day    \n 3 Health Care      \n 4 The Alliance     \n 5 Basketball       \n 6 Hot Girl         \n 7 The Dundies      \n 8 Sexual Harassment\n 9 Office Olympics  \n10 The Fire         \n# ℹ 178 more rows\n\n\nAlternatively, we can pass in the column name in quotes instead of the column number\n\noffice_ratings[,\"title\"]\n\n# A tibble: 188 × 1\n   title            \n   &lt;chr&gt;            \n 1 Pilot            \n 2 Diversity Day    \n 3 Health Care      \n 4 The Alliance     \n 5 Basketball       \n 6 Hot Girl         \n 7 The Dundies      \n 8 Sexual Harassment\n 9 Office Olympics  \n10 The Fire         \n# ℹ 178 more rows\n\n\nNotice that the extracted column is still formatted as a data frame (or tibble). If you want to extract the contents of the column and just have a vector of titles, you have a few options.\n\nYou could use double brackets with the column number:\n\n\noffice_ratings[[3]]\n\n\nYou could use double brackets with the column name in quotes:\n\n\noffice_ratings[[\"title\"]]\n\n\nYou could use the $ extractor with the column name (not in quotes):\n\n\noffice_ratings$title\n\n\n\n\n\n\n\n Check point\n\n\n\n\nExtract the 35th row of office_ratings.\nExtract rows 35, 36, 37, and 38 of office_ratings.\nExtract the imdb_rating column from office ratings using the column index number.\nExtract the imdb_rating column from office ratings using the column name."
  },
  {
    "objectID": "computing/r-basics-refresher.html#lists",
    "href": "computing/r-basics-refresher.html#lists",
    "title": "R Basics",
    "section": "Lists",
    "text": "Lists\nIt turns out that data frames are special cases of lists, a more general data structure. In a data frame, each column is an element of the data list and each column must be of the same length. In general, lists can be comprised of elements of vastly different lengths and data types.\nAs an example, let’s construct a list of the faculty in the MAST department and what is being taught this winter.\n\nstat_faculty &lt;- c(\"Kelling\", \"Loy\", \"Luby\", \"Poppick\", \"St. Clair\", \"Wadsworth\")\nstat_courses &lt;- c(120, 220, 230, 250, 285, 330)\nmath_faculty &lt;- c(\"Brooke\", \"Davis\", \"Egge\", \"Gomez-Gonzales\", \"Haunsperger\", \"Johnson\", \n                  \"Meyer\", \"Montee\", \"Shrestha\",\"Terry\", \"Thompson\", \"Turnage-Butterbaugh\")\nmath_courses &lt;- c(101, 106, 111, 120, 210, 211, 232, 236, 240, 241, 251, 321, 333, 395)\n\nmast &lt;- list(stat_faculty = stat_faculty, stat_courses = stat_courses, \n             math_faculty = math_faculty, math_courses = math_courses)\n\nOverview of a list\nYou can get an overview of a list a few ways:\n\n\nglimpse(list_name) and str(list_name) list the elements of the list and the first few entries of each element.\n\n\nglimpse(mast)\n\nList of 4\n $ stat_faculty: chr [1:6] \"Kelling\" \"Loy\" \"Luby\" \"Poppick\" ...\n $ stat_courses: num [1:6] 120 220 230 250 285 330\n $ math_faculty: chr [1:12] \"Brooke\" \"Davis\" \"Egge\" \"Gomez-Gonzales\" ...\n $ math_courses: num [1:14] 101 106 111 120 210 211 232 236 240 241 ...\n\n\n\n\nlength(list_name) will tell you how many elements are in the list\n\n\nlength(mast)\n\n[1] 4\n\n\nExtracting elements of a list\nSince data frames are lists, you’ve already seen how to extract elements of a list. For example, to extract the stat_faculty you could run\n\nmast[[1]]\n\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n\nor\n\nmast[[\"stat_faculty\"]]\n\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you had only used a single bracket above, the returned object would still be a list, which is typically not what we would want.\n\nmast[1]\n\n$stat_faculty\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n\n\n\n\n\n\n\n\n\n Check point\n\n\n\nExtract the statistics courses offered this term."
  },
  {
    "objectID": "computing/r-basics-refresher.html#vectors",
    "href": "computing/r-basics-refresher.html#vectors",
    "title": "R Basics",
    "section": "Vectors",
    "text": "Vectors\nThe columns of the office_ratings data frame and the elements of the mast list were comprised of (atomic) vectors. Unlike lists, all elements within a vector share the same type. For example, all names in the stat_faculty vector were character strings and all ratings in the imdb_rating column were numeric. We’ll deal with a variety of types of vectors in this course, including:\n\nnumeric\ncharacter (text)\nlogical (TRUE/FALSE)\n\nExtracting elements of a vector\nJust like with lists (and therefore data frames), we use brackets to extract elements from a vector. As an example, let’s work with the title column from office_ratings.\n\ntitle &lt;- office_ratings$title # vector of titles\n\nTo extract the 111th title, we run\n\ntitle[111]\n\n[1] \"New Leads\"\n\n\nor two extract the 100th through 111th titles, we run\n\ntitle[100:111]\n\n [1] \"Double Date\"          \"Murder\"               \"Shareholder Meeting\" \n [4] \"Scott's Tots\"         \"Secret Santa\"         \"The Banker\"          \n [7] \"Sabre\"                \"Manager and Salesman\" \"The Delivery: Part 1\"\n[10] \"The Delivery: Part 2\" \"St. Patrick's Day\"    \"New Leads\"           \n\n\nNegative indices\nSometimes, we want to “kick out” elements of our vector. To do this, we can use a negative index value. For example,\n\ntitle[-1]\n\nreturns all but the first title—that is, it kicks out the first title. To kick out multiple elements, we need to negate a vector of indices. For example, below we kick out the first 10 titles\n\ntitle[-c(1:10)]\n\nAnd now we kick out the 5th, 50th, and 150th titles\n\ntitle[-c(5, 50, 150)]\n\nThis idea can be adapted to lists and data frames. For example, to kick out the first row of office_ratings, we run\n\noffice_ratings[-1,]\n\n# A tibble: 187 × 6\n   season episode title             imdb_rating total_votes air_date  \n    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;    \n 1      1       2 Diversity Day             8.3        3566 2005-03-29\n 2      1       3 Health Care               7.9        2983 2005-04-05\n 3      1       4 The Alliance              8.1        2886 2005-04-12\n 4      1       5 Basketball                8.4        3179 2005-04-19\n 5      1       6 Hot Girl                  7.8        2852 2005-04-26\n 6      2       1 The Dundies               8.7        3213 2005-09-20\n 7      2       2 Sexual Harassment         8.2        2736 2005-09-27\n 8      2       3 Office Olympics           8.4        2742 2005-10-04\n 9      2       4 The Fire                  8.4        2713 2005-10-11\n10      2       5 Halloween                 8.2        2561 2005-10-18\n# ℹ 177 more rows\n\n\nor to kick out the math courses from the mast list we run\n\nmast[-4]\n\n$stat_faculty\n[1] \"Kelling\"   \"Loy\"       \"Luby\"      \"Poppick\"   \"St. Clair\" \"Wadsworth\"\n\n$stat_courses\n[1] 120 220 230 250 285 330\n\n$math_faculty\n [1] \"Brooke\"              \"Davis\"               \"Egge\"               \n [4] \"Gomez-Gonzales\"      \"Haunsperger\"         \"Johnson\"            \n [7] \"Meyer\"               \"Montee\"              \"Shrestha\"           \n[10] \"Terry\"               \"Thompson\"            \"Turnage-Butterbaugh\"\n\n\nLogical indices\nIt’s great to be able to extract (or omit) elements using indices, but sometimes we don’t know what index value we should use. For example, if you wanted to extract all of the 300-level statistics courses from the stat_courses vector, you would need to manually determine that positions 2:5 meet that requirement. That’s a lot of work! A better alternative is to allow R to find the elements meeting that requirement using logical operators. Below is a table summarizing common logical operators in R.\n\n\nComparison\nMeaning\n\n\n\n&lt;\nless than\n\n\n&gt;\ngreater than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;=\ngreater than or equal to\n\n\n==\nis equal to\n\n\n!=\nnot equal to\n\n\n\nIn order to extract the 300-level statistics courses, we’ll take two steps:\n\nWe’ll determine whether each course is numbered at least 300,\nthen we’ll use that sequence of TRUEs/FALSEs to extract the course.\n\nSo, first we use the logical operator &gt;= to compare stat_courses and 300. This returns TRUE if the element meets the specification and FALSE otherwise.\n\nstat_courses &gt;= 300\n\n[1] FALSE FALSE FALSE FALSE FALSE  TRUE\n\n\nNow, we can use this vector as our index. Only the TRUE elements will be extracted:\n\nstat_courses[stat_courses &gt;= 300]\n\n[1] 330\n\n\nThe same idea can be used with data frames and lists, just remember how to format the brackets and indices!\n\n\n\n\n\n\n Check point\n\n\n\n\nExtract all statistics courses below 250 from stat_courses.\nExtract all math courses except for 240 (probability) from math_courses.\nExtract all rows from season 3 of The Office.\n\n\n\ns"
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Public Syllabus",
    "section": "",
    "text": "Note: This is a partial syllabus designed to be public-facing. Carleton students should see the version on Moodle for all course details.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#meetings",
    "href": "course-syllabus.html#meetings",
    "title": "Public Syllabus",
    "section": "Meetings",
    "text": "Meetings\nThere will be three course meetings per week (Mondays, Wednesdays, and Fridays). Daily attendance and active participation is expected. Course meetings will combine demonstrations/lecture and in-class group exercises. On most days, I’ll ask you to complete a reading or watch a short video before class.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#assignments",
    "href": "course-syllabus.html#assignments",
    "title": "Public Syllabus",
    "section": "Assignments",
    "text": "Assignments\nHomework will be assigned once-ish per week, distributed via GitHub. You will submit homework assignments via gradescope. You will use quarto for all assignments and submit all necessary work for each assignment on GitHub.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#portfolio-projects",
    "href": "course-syllabus.html#portfolio-projects",
    "title": "Public Syllabus",
    "section": "Portfolio Projects",
    "text": "Portfolio Projects\nPortfolio project require you to integrate several smaller computational tasks and require clear communication of the proposed solution or findings to a broader audience. You will typically work in pairs or triples.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#lab-quizzes",
    "href": "course-syllabus.html#lab-quizzes",
    "title": "Public Syllabus",
    "section": "Lab Quizzes",
    "text": "Lab Quizzes\nPart of being proficient in data science is being able to do basic data analysis “on the fly”, without access to class resources. There will be 3 short (~30 minute) in-class lab quizzes to assess your ability to do basic tasks in R. I recognize that “in the real world”, you will almost always have access to your resources, so you will also have 48 hours to re-submit.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#final-project",
    "href": "course-syllabus.html#final-project",
    "title": "Public Syllabus",
    "section": "Final Project",
    "text": "Final Project\nThe final project is a capstone experience synthesizing everything you’ve learned over the course of the term. This is an opportunity for you to exercise your creativity and create something meaningful. The final project is wildly open-ended and more details will follow.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#communication",
    "href": "course-syllabus.html#communication",
    "title": "Public Syllabus",
    "section": "Communication",
    "text": "Communication\nAssignments and slides will be shared publicly on our course website. Grades will be posted on Moodle. Please use our github discussion page for any homework or course content questions; email me privately with any personal matters (grade discussions, illness, emergency, etc.). Any time-sensitive announcements will be sent via email. It is your responsibility to make sure that your notification settings allow time-sensitive announcements to reach you.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#textbook",
    "href": "course-syllabus.html#textbook",
    "title": "Public Syllabus",
    "section": "Textbook",
    "text": "Textbook\nThere is no “perfect” data science textbook. We will use excerpts from the following texts:\n\nR for Data Science 2e\nModern Data Science with R 3e\nFundamentals of Data Visualization\n\nThese books are all freely available online. If you prefer a hard copy, they are also available for purchase through the publisher.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#software",
    "href": "course-syllabus.html#software",
    "title": "Public Syllabus",
    "section": "Software",
    "text": "Software\nThe use of the R programming language, with the RStudio interface is an essential component of this course.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "lab-quiz/lab-quiz-02.html",
    "href": "lab-quiz/lab-quiz-02.html",
    "title": "Lab Quiz 02 Info",
    "section": "",
    "text": "Our second lab quiz is scheduled for Friday of Week 5. The first half of class will cover new content, and the second half of class you will complete the in-person portion of the lab quiz."
  },
  {
    "objectID": "lab-quiz/lab-quiz-02.html#data-wrangling",
    "href": "lab-quiz/lab-quiz-02.html#data-wrangling",
    "title": "Lab Quiz 02 Info",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nKnow how the following verbs act on a data set: filter, distinct, slice, slice_min, slice_max, mutate, select, arrange, relocate, *_join (all flavors discussed in class), bind_rows, bind_cols, pivot_wider, and pivot_longer, separate, unite, group_by, ungroup, summarize, count, rowwise\n\nSyntax for using\nDescribe what the output would look like\n\n\nGiven a data set and goal, identify and utilize the appropriate verb to create the data set of interest\nGiven a dataset, describe if it is tidy. If it is not, describe what a tidy format would look like"
  },
  {
    "objectID": "lab-quiz/lab-quiz-02.html#datestimes",
    "href": "lab-quiz/lab-quiz-02.html#datestimes",
    "title": "Lab Quiz 02 Info",
    "section": "Dates/Times",
    "text": "Dates/Times\n\nUse {lubridate} functions to parse dates into ISO8601 format\n\n\nmdy ymd dmy etc.\n\n\nUse {lubridate} functions to to extract elements of a date/time\n\n\nyear month day week wday etc."
  },
  {
    "objectID": "lab-quiz/lab-quiz-02.html#factors",
    "href": "lab-quiz/lab-quiz-02.html#factors",
    "title": "Lab Quiz 02 Info",
    "section": "Factors",
    "text": "Factors\n\nCreate a factor to represent a categorical variable\nGiven a factor, modify the levels as needed for the analysis by recoding, reordering, or combining levels.\n\n\nfct_reorder, fct_reorder2, fct_infreq, fct_rev, fct_recode"
  },
  {
    "objectID": "lab-quiz/lab-quiz-02.html#resubmission",
    "href": "lab-quiz/lab-quiz-02.html#resubmission",
    "title": "Lab Quiz 02 Info",
    "section": "Resubmission",
    "text": "Resubmission\nYou may resubmit the lab quiz by 11am on Sunday (48 hours). Resubmissions will be submitted through Gradescope."
  },
  {
    "objectID": "lab-quiz/lab-quiz-02.html#rules",
    "href": "lab-quiz/lab-quiz-02.html#rules",
    "title": "Lab Quiz 02 Info",
    "section": "Rules",
    "text": "Rules\n\nYour solutions must be written up in the R Markdown (Rmd) file called lab-quiz-02.Rmd. This file must include your code and write up for each task. Your “submission” will be whatever is in your exam repository at the deadline. Commit and push the Rmd and outputs of that file.\nThis exam is limited notes, closed internet, closed other people.\n\nYou have until 10:45am to complete this exam and turn it in via your personal Github repo - late work will not be accepted. Technical difficulties are not an excuse for late work - do not wait until the last minute to knit / commit / push.\n\nIf you do have technical issues, you will be able to solve them for the resubmission, but if you do not turn in the in-class portion you will not receive any points\n\nExample: I run into a knitting issue and don’t leave myself time to commit to github, so I’m not able to turn anything in for the in-class portion. I work hard over the weekend to make sure everything is correct for the resubmission. I earn 0/10 on the in-class and 10/10 on the resubmission, so my score for the lab quiz is 10/20.\nExample: I run into a knitting issue 2 minutes before the deadline, but make sure to commit my .rmd and submit to gradescope before trying to solve the issue. I fix the knitting issue over over the weekend, and also find an error in one of my problems I submitted. I earn 8/10 on the in-class (1 unsuccessful problem + no output file) and 10/10 on the resubmission, so my score for the lab quiz is 18/20.\n\n\n\n\nEven if the answer seems obvious from the R output, make sure to state it in your narrative as well. For example, if the question is asking what is 2 + 2, and you have the code in your document, you should additionally have a sentence that states “2 + 2 is 4.”\nYou may only use the packages provided in the initial .rmd file for this assignment. Your solutions may not use any other R packages."
  },
  {
    "objectID": "lab-quiz/lab-quiz-02.html#data",
    "href": "lab-quiz/lab-quiz-02.html#data",
    "title": "Lab Quiz 02 Info",
    "section": "Data",
    "text": "Data\nThe nycflights23 package contains information about all flights that departed from NYC (e.g. EWR, JFK and LGA) in 2023. The main data is in the flights data frame, but there are additional data sets which may help understand what causes delays, specifically:\n\n\nweather: hourly meteorological data for each airport\n\nplanes: construction information about each plane\n\nairports: airport names and locations\n\nairlines: translation between two letter carrier codes and names\n\n\nlibrary(tidyverse)\nlibrary(nycflights23)\nq &lt;- 0"
  },
  {
    "objectID": "lab-quiz/lab-quiz-02.html#questions",
    "href": "lab-quiz/lab-quiz-02.html#questions",
    "title": "Lab Quiz 02 Info",
    "section": "Questions",
    "text": "Questions\nQuestion 1\na\nFilter the flights dataset to only include flights from JFK to MSP. Call this new dataset jfk_msp_flights\n\n# your code here\n\nb\nI’d like to create a table with the median flight delay for each month among flights from JFK to MSP. I try the following code but it’s giving me an error. Fix the code, then tell me which month has the longest and shortest median delay.\n\njfk_msp_flights %&gt;%\n  select(month) %&gt;%\n  summarize(\n    med_flight_delay = median(dep_delay, na.rm = TRUE)\n  )\n\nc\nExplain why na.rm = TRUE is included in the code chunk from part (b) (no R code needed)\nQuestion 2\nUse mutate to create a new column in the flights dataset that contains the day of the week of the flight (“Monday”, “Tuesday”, etc.).\nQuestion 3\nFor the next two questions, use the plot below to answer the questions.\n\n\n\n\n\n\n\n\na\nTo create this plot, I had to do a few things. First, I combined the flights dataset (which contains information about arrival delay) with the airports dataset (which contains the full name of the airports, along with their time zones). Did I use a left_join, full_join, bind_rows, or bind_cols to combine them? Explain how you can tell.\nb\nNext, I grouped by airport name and found the median arrival delay with summarize. I then created a new variable called colorby using mutate that I used to color the points. How do you think I computed this variable? Be as specific as possible.\nQuestion 4\nHere is the code that I used to create the ggplot. Edit this code so that the airports are listed in order of shortest arrival delay at the top to longest arrival delay at the bottom\n\nplot_data = read_csv(\"https://stat220-w25.github.io/data/lq2_plot_data.csv\")\n\nplot_data %&gt;%\n  ggplot(\n    aes(x = med_arr_delay, y = name, col = colorby)\n  ) +\n  geom_point() + \n  theme(legend.position = \"bottom\") + \n  labs(\n    title = \"Median Arrival Delay for flights from NYC airports in 2023\",\n    subtitle = \"Among West Coast time zone airports\"\n  )"
  }
]